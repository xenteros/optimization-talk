{"traceEvents":[{"ph":"M","pid":21732,"tid":21732,"name":"process_name","args":{"name":"MainProcess"}},{"ph":"M","pid":21732,"tid":30224,"name":"thread_name","args":{"name":"MainThread"}},{"pid":21732,"tid":30224,"ts":2302198044360.7,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044368.2,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044374.1,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044379.6,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044385.0,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044391.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044396.5,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044401.7,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044416.0,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044423.2,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044429.4,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044434.7,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044441.7,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044447.0,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044452.9,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044458.8,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044464.0,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044469.5,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044475.7,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044481.2,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044487.1,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044492.5,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044497.7,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044502.9,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044507.9,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044299.7,"dur":208.7,"name":"main (C:\\Users\\adam\\AppData\\Local\\Temp\\ipykernel_21732\\4866851.py:1)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044532.7,"dur":0.4,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044531.6,"dur":1.9,"name":"parent (<frozen importlib._bootstrap>:405)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044540.8,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044541.5,"dur":0.4,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044540.3,"dur":1.8,"name":"_handle_fromlist (<frozen importlib._bootstrap>:1207)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044548.2,"dur":0.1,"name":"nt.fspath","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044548.9,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044548.7,"dur":0.5,"name":"_get_bothseps (<frozen ntpath>:35)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044549.6,"dur":0.1,"name":"nt.fspath","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044549.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044550.2,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044550.6,"dur":0.3,"name":"str.replace","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044549.5,"dur":2.9,"name":"splitdrive (<frozen ntpath>:154)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044552.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044554.5,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044548.0,"dur":7.1,"name":"split (<frozen ntpath>:208)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044547.7,"dur":7.8,"name":"dirname (<frozen ntpath>:249)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044560.3,"dur":0.02,"name":"nt.fspath","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044560.5,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044561.2,"dur":0.02,"name":"nt.fspath","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044564.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044564.6,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044564.9,"dur":0.1,"name":"str.replace","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044561.1,"dur":4.9,"name":"splitdrive (<frozen ntpath>:154)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044567.5,"dur":0.02,"name":"nt.fspath","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044567.7,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044568.0,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044568.3,"dur":0.4,"name":"str.replace","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044567.4,"dur":1.9,"name":"splitdrive (<frozen ntpath>:154)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044560.1,"dur":10.8,"name":"join (<frozen ntpath>:107)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044574.1,"dur":49.5,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044573.5,"dur":50.8,"name":"exists (<frozen genericpath>:16)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044633.3,"dur":6.2,"name":"_hashlib.new","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044632.0,"dur":7.7,"name":"__hash_new (C:\\Users\\adam\\miniconda3\\Lib\\hashlib.py:152)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044640.2,"dur":55.5,"name":"io.open","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044698.3,"dur":34.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044733.7,"dur":135.3,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044869.4,"dur":19.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044889.8,"dur":127.9,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045018.0,"dur":17.0,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045035.7,"dur":128.4,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045164.3,"dur":15.0,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045180.0,"dur":131.7,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045312.0,"dur":16.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045329.1,"dur":129.4,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045458.8,"dur":13.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045472.9,"dur":130.7,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045603.9,"dur":14.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045618.8,"dur":128.2,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045747.3,"dur":14.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045762.1,"dur":131.9,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045894.4,"dur":18.8,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198045913.9,"dur":128.6,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046043.2,"dur":15.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046059.2,"dur":130.6,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046190.1,"dur":18.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046209.4,"dur":133.1,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046343.2,"dur":17.9,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046361.7,"dur":131.0,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046493.5,"dur":21.0,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046515.2,"dur":10.9,"name":"_hashlib.HASH.update","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046526.3,"dur":6.7,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046533.5,"dur":18.0,"name":"_io.BufferedReader.__exit__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046552.3,"dur":5.4,"name":"_hashlib.HASH.hexdigest","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044627.6,"dur":1930.3,"name":"file_hash (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py:27)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044572.2,"dur":1991.6,"name":"_has_hash (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py:65)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044546.2,"dur":2018.3,"name":"_fetch (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py:166)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046576.1,"dur":0.6,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046577.5,"dur":0.6,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046578.2,"dur":0.5,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046579.2,"dur":1.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046589.7,"dur":0.8,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046585.5,"dur":5.5,"name":"__init__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:104)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046582.6,"dur":8.7,"name":"helper (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:287)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046604.4,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046606.0,"dur":2.4,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046604.0,"dur":4.7,"name":"is_url (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\util.py:14)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046602.0,"dur":7.0,"name":"file_or_url_context (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\util.py:20)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046597.5,"dur":11.6,"name":"builtins.next","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046596.5,"dur":12.7,"name":"__enter__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:132)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046616.1,"dur":0.4,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046617.2,"dur":0.3,"name":"dict.pop","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046639.7,"dur":0.3,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046670.4,"dur":0.6,"name":"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1091)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046669.9,"dur":1.2,"name":"__call__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:686)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046669.3,"dur":2.0,"name":"_missing_ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:118)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046671.6,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046662.4,"dur":9.4,"name":"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1091)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046655.5,"dur":16.5,"name":"__call__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:686)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046686.7,"dur":0.3,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:444)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046692.1,"dur":0.9,"name":"value (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1249)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046691.1,"dur":2.0,"name":"__get__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:193)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046694.5,"dur":1.1,"name":"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1091)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046694.0,"dur":1.7,"name":"__call__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:686)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046688.0,"dur":7.9,"name":"io_mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:138)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046696.7,"dur":0.2,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:444)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046697.8,"dur":0.1,"name":"value (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1249)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046697.5,"dur":0.5,"name":"__get__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:193)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046698.7,"dur":0.3,"name":"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1091)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046698.4,"dur":0.7,"name":"__call__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:686)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046697.3,"dur":1.9,"name":"io_mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:138)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046699.8,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046700.5,"dur":0.4,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046701.4,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046701.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046702.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046702.3,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046702.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046703.1,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046703.6,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046704.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046705.7,"dur":0.5,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046706.5,"dur":0.8,"name":"str.find","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046707.8,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046710.0,"dur":0.3,"name":"str.find","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046714.8,"dur":62.9,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046713.8,"dur":64.8,"name":"exists (<frozen genericpath>:16)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046783.5,"dur":0.8,"name":"nt.fspath","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046784.7,"dur":0.4,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046785.5,"dur":1.4,"name":"nt._path_normpath","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046783.1,"dur":4.0,"name":"normpath (<frozen ntpath>:538)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046787.2,"dur":2.5,"name":"nt._getfullpathname","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046782.2,"dur":7.7,"name":"abspath (<frozen ntpath>:570)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046791.2,"dur":35.5,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046791.0,"dur":36.3,"name":"exists (<frozen genericpath>:16)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046685.5,"dur":142.3,"name":"_parse_uri (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:280)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046835.8,"dur":0.9,"name":"type.__new__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046840.8,"dur":0.3,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046841.3,"dur":0.2,"name":"nt.fspath","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046841.8,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046842.9,"dur":0.3,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046854.0,"dur":0.5,"name":"str.replace","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046861.8,"dur":0.4,"name":"str.lstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046858.5,"dur":4.3,"name":"splitroot (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:147)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046863.8,"dur":1.1,"name":"str.split","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046866.2,"dur":1.9,"name":"sys.intern","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046868.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046868.8,"dur":0.4,"name":"sys.intern","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046869.3,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046869.7,"dur":0.5,"name":"sys.intern","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046870.22,"dur":0.08,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046870.5,"dur":0.4,"name":"sys.intern","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046871.0,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046871.3,"dur":0.3,"name":"sys.intern","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046871.7,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046872.1,"dur":0.3,"name":"sys.intern","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046872.5,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046872.7,"dur":0.3,"name":"sys.intern","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046873.1,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046873.4,"dur":0.6,"name":"sys.intern","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046874.1,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046874.4,"dur":0.2,"name":"sys.intern","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046874.62,"dur":0.18,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046875.5,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046876.0,"dur":0.2,"name":"list.reverse","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046851.0,"dur":25.4,"name":"parse_parts (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:56)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046840.1,"dur":36.5,"name":"_parse_args (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:484)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046835.0,"dur":43.3,"name":"_from_parts (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:504)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046832.0,"dur":46.7,"name":"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:868)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046882.2,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046881.8,"dur":3.5,"name":"name (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:622)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046885.8,"dur":0.7,"name":"str.rfind","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046886.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046880.7,"dur":6.7,"name":"suffix (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:630)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046888.3,"dur":0.2,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046890.3,"dur":0.4,"name":"format_hint (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:438)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046647.0,"dur":243.8,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:216)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046891.7,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046893.1,"dur":0.1,"name":"format_hint (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:434)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046894.1,"dur":0.2,"name":"extension (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:426)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046895.7,"dur":0.02,"name":"extension (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:426)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046903.7,"dur":0.3,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046908.5,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046907.8,"dur":1.1,"name":"_sanity_check (<frozen importlib._bootstrap>:1101)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046912.9,"dur":0.5,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046914.2,"dur":0.5,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046914.9,"dur":0.3,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046911.8,"dur":3.6,"name":"_find_and_load (<frozen importlib._bootstrap>:1165)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046905.8,"dur":9.7,"name":"_gcd_import (<frozen importlib._bootstrap>:1192)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046903.4,"dur":12.2,"name":"import_module (C:\\Users\\adam\\miniconda3\\Lib\\importlib\\__init__.py:108)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046916.4,"dur":0.5,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046900.3,"dur":17.0,"name":"plugin_class (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\config\\plugins.py:89)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046926.2,"dur":0.8,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046929.6,"dur":0.1,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046930.8,"dur":1.1,"name":"__init__ (<frozen importlib._bootstrap>:165)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046935.8,"dur":0.5,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046941.1,"dur":2.9,"name":"_thread.allocate_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046944.4,"dur":1.2,"name":"_thread.allocate_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046940.5,"dur":6.9,"name":"__init__ (<frozen importlib._bootstrap>:71)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046949.4,"dur":0.2,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046935.2,"dur":14.6,"name":"_get_module_lock (<frozen importlib._bootstrap>:179)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046953.9,"dur":0.2,"name":"_thread.get_ident","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046956.0,"dur":0.2,"name":"_thread.lock.__exit__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046953.4,"dur":3.2,"name":"acquire (<frozen importlib._bootstrap>:100)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046932.8,"dur":23.9,"name":"__enter__ (<frozen importlib._bootstrap>:169)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046957.2,"dur":0.1,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046963.0,"dur":0.6,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046970.8,"dur":0.1,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046970.5,"dur":0.6,"name":"__enter__ (<frozen importlib._bootstrap>:1026)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046974.0,"dur":1.3,"name":"builtins.locals","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046975.6,"dur":2.4,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046978.9,"dur":0.4,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046979.9,"dur":0.1,"name":"<lambda> (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046973.1,"dur":7.0,"name":"find_spec (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:89)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046981.2,"dur":0.1,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046980.9,"dur":0.5,"name":"__exit__ (<frozen importlib._bootstrap>:1030)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046982.4,"dur":0.1,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046982.3,"dur":2.1,"name":"__enter__ (<frozen importlib._bootstrap>:1026)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046986.9,"dur":2.7,"name":"_imp.is_builtin","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046986.1,"dur":3.8,"name":"find_spec (<frozen importlib._bootstrap>:748)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046990.4,"dur":0.02,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046990.2,"dur":0.3,"name":"__exit__ (<frozen importlib._bootstrap>:1030)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046991.3,"dur":0.1,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046991.2,"dur":0.3,"name":"__enter__ (<frozen importlib._bootstrap>:1026)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047002.5,"dur":0.8,"name":"_imp.find_frozen","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047002.3,"dur":1.1,"name":"_call_with_frames_removed (<frozen importlib._bootstrap>:233)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046994.2,"dur":9.5,"name":"find_spec (<frozen importlib._bootstrap>:920)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047004.2,"dur":0.1,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047004.1,"dur":0.3,"name":"__exit__ (<frozen importlib._bootstrap>:1030)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047005.2,"dur":0.1,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047005.1,"dur":0.22,"name":"__enter__ (<frozen importlib._bootstrap>:1026)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047011.1,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047013.3,"dur":1.2,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047014.9,"dur":0.02,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047015.2,"dur":0.5,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047016.0,"dur":0.4,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047022.2,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047024.2,"dur":43.4,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047023.7,"dur":44.2,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047071.0,"dur":2.2,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047079.0,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047084.4,"dur":0.7,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047085.4,"dur":0.3,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047086.2,"dur":0.4,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047088.5,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047088.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047089.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047089.7,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047091.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047092.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047091.2,"dur":1.0,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047092.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047093.3,"dur":0.6,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047078.6,"dur":15.7,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047096.4,"dur":0.8,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047098.6,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047100.0,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047100.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047100.7,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047101.8,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047102.1,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047102.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047102.7,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047105.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047106.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047105.5,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047106.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047106.8,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047098.4,"dur":8.9,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047107.8,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047109.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047110.3,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047110.6,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047111.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047111.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047112.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047112.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047112.9,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047113.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047113.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047113.4,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047114.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047114.5,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047109.0,"dur":5.9,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047115.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047116.4,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047117.4,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047117.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047118.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047118.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047119.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047119.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047119.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047120.5,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047120.8,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047120.3,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047121.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047121.3,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047116.2,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047122.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047123.1,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047124.0,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047124.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047124.6,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047125.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047125.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047126.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047126.4,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047127.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047127.3,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047126.8,"dur":1.9,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047129.0,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047129.2,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047122.9,"dur":6.7,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047130.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047021.8,"dur":108.9,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047131.6,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047132.4,"dur":0.8,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047133.6,"dur":0.3,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047134.4,"dur":0.3,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047135.3,"dur":36.4,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047135.2,"dur":36.8,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047173.8,"dur":0.9,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047176.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047178.5,"dur":0.4,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047179.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047179.6,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047180.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047181.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047181.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047181.8,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047182.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047183.1,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047182.5,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047183.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047183.9,"dur":0.3,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047176.2,"dur":8.2,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047184.9,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047186.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047187.2,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047187.5,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047187.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047188.6,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047188.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047189.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047189.5,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047190.2,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047190.5,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047190.0,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047190.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047191.1,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047186.0,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047191.8,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047192.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047193.8,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047194.1,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047196.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047197.2,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047197.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047197.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047198.2,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047198.9,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047199.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047198.7,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047199.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047199.8,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047192.7,"dur":7.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047200.5,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047201.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047202.5,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047202.8,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047203.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047204.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047204.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047204.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047204.9,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047205.5,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047205.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047205.3,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047206.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047206.3,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047201.4,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047207.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047208.0,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047209.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047209.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047209.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047210.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047210.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047211.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047211.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047211.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047212.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047211.7,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047212.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047212.8,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047207.8,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047213.4,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047134.2,"dur":79.9,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047214.6,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047215.1,"dur":0.6,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047215.9,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047216.5,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047218.7,"dur":33.9,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047218.6,"dur":34.3,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047254.3,"dur":0.8,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047256.6,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047258.7,"dur":0.4,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047259.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047259.7,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047260.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047261.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047261.5,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047261.9,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047262.7,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047263.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047262.4,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047263.5,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047263.8,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047256.5,"dur":7.7,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047264.7,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047265.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047266.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047267.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047267.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047268.4,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047268.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047269.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047269.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047269.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047270.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047269.8,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047270.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047270.9,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047265.8,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047271.5,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047272.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047273.4,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047273.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047274.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047274.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047275.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047275.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047275.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047276.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047276.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047276.2,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047277.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047277.3,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047272.4,"dur":7.0,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047279.8,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047280.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047281.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047282.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047282.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047283.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047283.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047284.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047284.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047285.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047285.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047284.8,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047285.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047285.9,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047280.8,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047286.5,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047287.6,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047288.5,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047288.8,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047289.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047290.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047290.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047290.5,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047290.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047291.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047291.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047291.2,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047292.1,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047292.3,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047287.4,"dur":5.2,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047293.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047216.3,"dur":77.4,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047294.1,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047294.7,"dur":0.4,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047295.3,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047295.9,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047296.7,"dur":35.7,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047296.5,"dur":36.1,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047334.0,"dur":0.7,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047336.3,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047338.4,"dur":0.4,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047339.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047339.4,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047340.6,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047340.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047341.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047343.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047344.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047344.5,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047343.9,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047345.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047345.3,"dur":0.3,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047336.1,"dur":9.7,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047346.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047347.5,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047348.6,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047348.9,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047349.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047350.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047350.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047350.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047351.0,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047351.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047351.9,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047351.4,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047352.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047352.5,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047347.3,"dur":5.6,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047353.2,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047354.2,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047355.2,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047355.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047355.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047356.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047357.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047357.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047357.5,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047358.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047358.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047357.9,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047358.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047359.0,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047354.0,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047359.7,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047360.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047361.6,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047361.9,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047362.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047363.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047363.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047363.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047364.0,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047366.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047366.3,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047365.8,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047366.7,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047366.9,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047360.5,"dur":6.8,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047367.7,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047368.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047369.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047370.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047370.3,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047371.2,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047371.5,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047371.8,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047372.2,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047372.8,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047373.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047372.6,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047373.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047373.6,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047368.5,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047374.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047295.7,"dur":79.2,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047375.4,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047376.4,"dur":1.3,"name":"nt.getcwd","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047376.0,"dur":2.3,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047378.6,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047379.2,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047380.0,"dur":34.1,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047379.8,"dur":34.6,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047420.0,"dur":69.9,"name":"nt.listdir","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047491.2,"dur":0.7,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047493.3,"dur":0.5,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047494.5,"dur":0.2,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047494.9,"dur":1.1,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047496.8,"dur":0.2,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047497.3,"dur":0.2,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047497.9,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047498.1,"dur":0.4,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047498.7,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047499.0,"dur":0.1,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047499.4,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047499.6,"dur":0.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047500.1,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047500.3,"dur":0.2,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047500.8,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047501.0,"dur":0.2,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047503.3,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047503.6,"dur":0.1,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047504.0,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047504.2,"dur":0.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047504.7,"dur":0.3,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047505.2,"dur":0.2,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047505.7,"dur":0.02,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047505.9,"dur":0.2,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047506.3,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047506.6,"dur":0.1,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047507.0,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047507.2,"dur":0.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047507.6,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047507.9,"dur":0.2,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047508.3,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047508.5,"dur":0.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047509.0,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047509.2,"dur":0.2,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047509.7,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047509.82,"dur":0.38,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047510.3,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047510.6,"dur":0.1,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047511.0,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047511.2,"dur":0.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047511.6,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047511.9,"dur":0.1,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047512.3,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047512.5,"dur":0.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047512.9,"dur":0.2,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047513.2,"dur":0.1,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047513.6,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047513.8,"dur":0.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047514.2,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047514.5,"dur":0.1,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047514.9,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047515.1,"dur":0.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047515.5,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047515.8,"dur":0.1,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047516.2,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047516.5,"dur":0.1,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047516.9,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047517.1,"dur":0.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047517.5,"dur":0.2,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047517.8,"dur":0.2,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047518.3,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047518.5,"dur":0.2,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047518.9,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047520.6,"dur":0.1,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047520.9,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047521.2,"dur":0.2,"name":"str.partition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047521.6,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047521.8,"dur":0.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047522.3,"dur":0.1,"name":"set.add","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047524.8,"dur":0.3,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047526.8,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047527.2,"dur":0.02,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047527.4,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047527.7,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047528.0,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047528.4,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047528.7,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047529.0,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047529.3,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047529.6,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047529.8,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047530.1,"dur":0.02,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047530.4,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047530.7,"dur":0.2,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047531.0,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047531.3,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047531.6,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047531.9,"dur":0.1,"name":"str.lower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047526.4,"dur":5.8,"name":"<setcomp> (<frozen importlib._bootstrap_external>:1684)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047419.5,"dur":114.2,"name":"_fill_cache (<frozen importlib._bootstrap_external>:1655)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047534.5,"dur":0.9,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047536.7,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047538.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047539.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047539.7,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047541.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047541.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047541.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047542.1,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047542.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047543.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047542.7,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047543.7,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047544.1,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047536.5,"dur":8.0,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047545.1,"dur":4.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047550.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047551.6,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047552.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047553.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047554.7,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047555.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047555.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047555.6,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047556.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047556.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047556.2,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047557.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047557.3,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047550.3,"dur":7.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047558.1,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047559.4,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047560.4,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047560.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047561.0,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047561.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047562.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047562.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047562.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047563.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047563.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047563.2,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047564.1,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047564.3,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047559.2,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047565.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047566.1,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047567.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047567.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047567.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047568.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047568.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047569.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047569.4,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047570.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047570.3,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047569.8,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047570.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047570.9,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047565.9,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047571.5,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047572.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047573.5,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047573.8,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047574.1,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047575.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047576.6,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047576.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047577.2,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047577.9,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047578.2,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047577.7,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047578.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047578.8,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047572.4,"dur":6.7,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047579.5,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047379.0,"dur":201.1,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047580.6,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047581.2,"dur":0.6,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047582.1,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047582.8,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047583.7,"dur":39.3,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047583.5,"dur":39.8,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047624.7,"dur":0.8,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047627.1,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047629.3,"dur":0.5,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047630.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047630.4,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047631.7,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047632.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047632.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047632.7,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047633.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047633.9,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047633.3,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047634.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047634.6,"dur":0.3,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047626.9,"dur":8.2,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047635.6,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047636.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047638.1,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047638.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047638.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047639.6,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047639.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047640.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047640.5,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047641.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047641.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047640.9,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047641.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047642.1,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047636.8,"dur":7.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047644.7,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047645.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047646.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047647.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047647.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047648.3,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047648.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047648.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047649.2,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047649.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047650.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047649.6,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047650.5,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047650.7,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047645.6,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047651.4,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047652.5,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047653.5,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047653.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047654.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047655.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047655.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047655.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047655.9,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047656.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047656.8,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047656.3,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047657.2,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047657.5,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047652.4,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047658.1,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047659.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047660.2,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047660.5,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047660.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047661.6,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047661.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047662.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047662.5,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047663.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047663.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047662.9,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047663.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047664.0,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047659.0,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047664.6,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047582.6,"dur":84.1,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047667.2,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047667.8,"dur":0.5,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047668.6,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047669.2,"dur":0.3,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047670.1,"dur":35.6,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047670.0,"dur":35.9,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047707.3,"dur":0.7,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047709.5,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047711.6,"dur":0.5,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047712.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047712.7,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047714.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047714.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047714.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047714.9,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047715.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047716.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047715.5,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047716.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047716.8,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047709.3,"dur":8.0,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047717.8,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047718.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047720.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047720.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047720.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047721.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047721.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047722.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047722.4,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047723.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047723.3,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047722.8,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047723.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047723.9,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047718.8,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047724.6,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047725.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047726.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047727.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047727.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047728.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047728.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047728.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047729.0,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047731.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047731.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047731.3,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047732.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047732.5,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047725.5,"dur":7.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047733.2,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047734.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047735.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047735.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047736.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047736.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047737.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047737.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047737.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047738.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047738.7,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047738.2,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047739.1,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047739.3,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047734.2,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047740.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047741.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047742.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047742.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047742.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047743.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047743.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047744.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047744.4,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047745.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047745.3,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047744.8,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047745.7,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047745.9,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047740.9,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047746.6,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047669.1,"dur":78.1,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047747.6,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047748.1,"dur":0.5,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047748.9,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047749.6,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047750.6,"dur":35.6,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047750.4,"dur":36.0,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047788.1,"dur":0.7,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047790.4,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047792.5,"dur":0.5,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047795.1,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047795.5,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047796.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047797.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047797.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047797.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047822.9,"dur":0.4,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047824.2,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047821.6,"dur":2.9,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047825.7,"dur":0.4,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047826.8,"dur":0.9,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047790.2,"dur":38.1,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047829.7,"dur":0.9,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047832.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047837.2,"dur":0.8,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047838.3,"dur":0.3,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047838.9,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047840.7,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047841.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047841.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047842.0,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047843.2,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047843.6,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047842.9,"dur":0.9,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047844.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047844.6,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047832.6,"dur":12.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047845.7,"dur":0.4,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047847.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047848.7,"dur":0.3,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047849.1,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047849.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047850.6,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047850.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047851.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047851.6,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047852.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047852.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047852.2,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047853.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047853.6,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047847.1,"dur":6.9,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047854.4,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047855.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047857.3,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047857.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047861.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047862.7,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047863.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047863.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047863.7,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047864.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047864.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047864.3,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047865.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047865.7,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047855.7,"dur":10.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047866.6,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047868.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047869.5,"dur":0.3,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047869.9,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047870.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047871.1,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047871.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047871.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047872.1,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047872.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047873.1,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047872.6,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047873.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047873.8,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047867.9,"dur":6.2,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047874.4,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047749.4,"dur":125.9,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047876.3,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047877.1,"dur":0.7,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047878.2,"dur":0.3,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047879.1,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047880.3,"dur":50.6,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047880.1,"dur":51.1,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047933.1,"dur":1.3,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047936.5,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047939.0,"dur":0.4,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047939.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047940.1,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047941.6,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047941.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047942.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047942.5,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047943.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047943.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047943.2,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047944.4,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047946.8,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047936.3,"dur":11.0,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047948.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047949.3,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047950.5,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047950.8,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047951.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047952.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047952.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047952.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047953.0,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047953.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047953.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047953.5,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047954.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047954.6,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047949.1,"dur":5.8,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047955.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047956.3,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047957.4,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047957.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047958.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047959.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047959.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047959.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047959.9,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047960.5,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047960.8,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047960.3,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047961.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047961.4,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047956.1,"dur":5.6,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047962.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047963.1,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047964.1,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047964.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047964.7,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047965.6,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047965.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047966.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047966.5,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047967.1,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047967.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047966.9,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047967.7,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047968.0,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047962.9,"dur":7.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047970.5,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047971.6,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047972.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047973.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047973.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047974.1,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047974.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047974.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047975.0,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047975.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047975.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047975.4,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047976.4,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047976.6,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047971.4,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047977.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047878.9,"dur":99.0,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047978.6,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047979.3,"dur":1.0,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047980.6,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047981.4,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047982.3,"dur":41.5,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047982.0,"dur":42.0,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048025.5,"dur":0.9,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048028.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048030.6,"dur":0.5,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048031.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048031.7,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048033.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048033.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048033.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048034.0,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048034.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048035.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048034.6,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048035.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048035.9,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048028.0,"dur":8.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048036.9,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048038.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048039.3,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048039.6,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048040.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048040.8,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048041.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048041.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048043.7,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048044.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048044.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048044.2,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048045.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048045.3,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048038.0,"dur":7.7,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048046.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048047.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048048.4,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048048.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048049.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048049.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048050.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048050.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048050.7,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048051.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048051.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048051.2,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048052.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048052.2,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048047.1,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048052.9,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048054.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048055.2,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048055.5,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048055.8,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048056.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048056.9,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048057.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048057.5,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048058.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048058.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048057.9,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048058.7,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048059.0,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048053.9,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048059.6,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048060.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048061.6,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048061.9,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048062.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048063.1,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048063.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048063.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048064.0,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048064.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048066.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048064.4,"dur":2.0,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048066.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048066.9,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048060.4,"dur":6.8,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048067.6,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047981.1,"dur":87.1,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048072.3,"dur":2.9,"name":"__init__ (<frozen importlib._bootstrap>:357)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047010.3,"dur":1065.4,"name":"_get_spec (<frozen importlib._bootstrap_external>:1464)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198047007.1,"dur":1070.0,"name":"find_spec (<frozen importlib._bootstrap_external>:1496)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048078.7,"dur":0.9,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048078.1,"dur":1.7,"name":"__exit__ (<frozen importlib._bootstrap>:1030)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048081.7,"dur":0.3,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048081.4,"dur":0.7,"name":"__enter__ (<frozen importlib._bootstrap>:1026)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048084.1,"dur":1.5,"name":"find_spec (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\six.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048086.1,"dur":0.02,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048085.9,"dur":0.3,"name":"__exit__ (<frozen importlib._bootstrap>:1030)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046967.8,"dur":1118.8,"name":"_find_spec (<frozen importlib._bootstrap>:1054)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048087.9,"dur":1.5,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046962.2,"dur":1131.1,"name":"_find_and_load_unlocked (<frozen importlib._bootstrap>:1120)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048102.1,"dur":0.3,"name":"_thread.get_ident","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048104.7,"dur":0.2,"name":"_thread.lock.__exit__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048101.4,"dur":3.6,"name":"release (<frozen importlib._bootstrap>:125)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048095.2,"dur":10.1,"name":"__exit__ (<frozen importlib._bootstrap>:173)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048108.0,"dur":0.1,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048108.6,"dur":0.4,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048109.5,"dur":0.1,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048107.8,"dur":1.9,"name":"cb (<frozen importlib._bootstrap>:198)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046929.3,"dur":1184.4,"name":"_find_and_load (<frozen importlib._bootstrap>:1165)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048119.7,"dur":0.1,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048120.6,"dur":0.4,"name":"__init__ (<frozen importlib._bootstrap>:165)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048122.3,"dur":0.1,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048125.0,"dur":2.9,"name":"_thread.allocate_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048128.1,"dur":1.1,"name":"_thread.allocate_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048124.7,"dur":5.3,"name":"__init__ (<frozen importlib._bootstrap>:71)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048131.8,"dur":0.1,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048122.1,"dur":10.3,"name":"_get_module_lock (<frozen importlib._bootstrap>:179)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048133.5,"dur":0.1,"name":"_thread.get_ident","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048153.0,"dur":0.3,"name":"_thread.lock.__exit__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048133.3,"dur":20.4,"name":"acquire (<frozen importlib._bootstrap>:100)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048121.5,"dur":32.5,"name":"__enter__ (<frozen importlib._bootstrap>:169)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048154.7,"dur":0.1,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048155.5,"dur":0.3,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048158.3,"dur":0.2,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048158.1,"dur":0.5,"name":"__enter__ (<frozen importlib._bootstrap>:1026)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048160.7,"dur":1.5,"name":"builtins.locals","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048166.1,"dur":1.3,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048168.3,"dur":0.7,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048169.5,"dur":0.1,"name":"<lambda> (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048159.8,"dur":9.9,"name":"find_spec (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:89)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048170.4,"dur":0.1,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048170.2,"dur":0.4,"name":"__exit__ (<frozen importlib._bootstrap>:1030)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048171.6,"dur":0.02,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048171.4,"dur":0.3,"name":"__enter__ (<frozen importlib._bootstrap>:1026)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048172.9,"dur":2.7,"name":"_imp.is_builtin","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048172.6,"dur":3.2,"name":"find_spec (<frozen importlib._bootstrap>:748)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048176.2,"dur":0.1,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048176.1,"dur":0.22,"name":"__exit__ (<frozen importlib._bootstrap>:1030)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048176.9,"dur":0.1,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048176.8,"dur":0.22,"name":"__enter__ (<frozen importlib._bootstrap>:1026)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048178.8,"dur":1.0,"name":"_imp.find_frozen","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048178.6,"dur":1.3,"name":"_call_with_frames_removed (<frozen importlib._bootstrap>:233)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048177.9,"dur":2.3,"name":"find_spec (<frozen importlib._bootstrap>:920)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048180.6,"dur":0.02,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048180.4,"dur":0.3,"name":"__exit__ (<frozen importlib._bootstrap>:1030)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048181.2,"dur":0.1,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048181.1,"dur":0.3,"name":"__enter__ (<frozen importlib._bootstrap>:1026)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048183.4,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048183.9,"dur":1.0,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048185.2,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048185.5,"dur":0.4,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048186.1,"dur":0.3,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048187.3,"dur":0.1,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048188.2,"dur":45.2,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048188.0,"dur":45.7,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048235.6,"dur":1.1,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048238.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048241.1,"dur":0.6,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048241.9,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048242.4,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048244.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048244.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048244.6,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048245.2,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048246.2,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048246.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048245.9,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048247.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048247.4,"dur":0.6,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048238.1,"dur":10.1,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048248.8,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048250.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048251.3,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048254.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048254.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048255.4,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048255.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048256.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048256.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048257.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048257.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048256.8,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048257.7,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048258.0,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048250.1,"dur":8.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048258.9,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048260.0,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048261.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048261.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048261.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048262.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048262.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048263.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048263.4,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048264.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048264.3,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048263.8,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048264.7,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048264.9,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048259.8,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048265.7,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048266.7,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048267.7,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048268.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048268.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048269.2,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048269.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048269.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048270.1,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048270.7,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048271.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048270.5,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048271.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048271.6,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048266.6,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048272.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048273.3,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048274.3,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048274.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048276.2,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048277.2,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048277.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048277.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048278.1,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048278.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048279.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048278.5,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048279.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048279.7,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048273.1,"dur":6.9,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048280.4,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048187.1,"dur":94.2,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048281.7,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048282.3,"dur":0.5,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048283.0,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048283.6,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048284.5,"dur":37.9,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048284.4,"dur":38.3,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048324.2,"dur":0.8,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048326.5,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048328.7,"dur":0.5,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048329.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048329.8,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048331.2,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048331.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048331.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048332.1,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048332.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048333.3,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048332.7,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048333.7,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048334.0,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048326.3,"dur":8.2,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048335.0,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048336.3,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048337.3,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048337.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048338.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048338.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048339.1,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048339.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048339.7,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048340.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048340.7,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048340.2,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048341.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048344.1,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048336.1,"dur":8.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048344.9,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048346.0,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048347.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048347.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048347.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048348.6,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048348.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048349.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048349.5,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048350.2,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048350.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048350.0,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048350.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048351.0,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048345.8,"dur":5.6,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048351.7,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048352.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048353.8,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048354.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048354.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048355.2,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048355.5,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048355.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048356.1,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048356.8,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048357.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048356.6,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048357.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048357.6,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048352.6,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048358.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048359.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048360.3,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048360.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048361.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048361.8,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048362.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048362.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048362.7,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048363.3,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048363.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048363.1,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048363.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048364.2,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048359.2,"dur":12.0,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048371.6,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048283.5,"dur":88.8,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048372.7,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048373.3,"dur":0.6,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048374.1,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048374.7,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048375.6,"dur":35.6,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048375.4,"dur":36.0,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048412.9,"dur":0.9,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048415.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048417.4,"dur":0.4,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048418.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048418.5,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048419.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048420.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048420.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048420.6,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048421.6,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048421.9,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048421.4,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048422.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048422.7,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048415.2,"dur":7.9,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048423.6,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048424.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048425.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048428.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048428.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048429.7,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048430.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048430.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048430.6,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048431.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048431.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048431.2,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048432.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048432.2,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048424.7,"dur":7.9,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048433.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048434.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048435.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048435.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048435.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048436.4,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048436.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048437.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048437.4,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048438.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048438.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048437.8,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048438.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048438.9,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048433.9,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048439.5,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048440.6,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048441.5,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048441.9,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048442.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048443.0,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048443.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048443.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048443.9,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048444.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048444.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048444.4,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048445.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048445.5,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048440.4,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048446.1,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048447.2,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048448.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048448.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048448.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048449.5,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048449.8,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048450.1,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048450.4,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048451.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048451.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048450.9,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048451.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048452.0,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048447.0,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048452.7,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048374.5,"dur":79.0,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048454.0,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048454.5,"dur":0.5,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048455.2,"dur":0.1,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048455.7,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048456.5,"dur":37.7,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048456.4,"dur":38.1,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048496.0,"dur":0.8,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048498.2,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048500.4,"dur":0.4,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048501.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048501.4,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048502.8,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048503.1,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048503.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048503.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048504.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048504.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048504.4,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048505.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048505.7,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048498.0,"dur":8.1,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048506.6,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048508.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048509.0,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048509.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048509.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048510.5,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048510.8,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048511.1,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048511.4,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048512.1,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048512.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048511.9,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048512.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048513.0,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048507.9,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048513.7,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048514.7,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048515.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048516.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048516.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048517.2,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048517.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048517.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048518.0,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048518.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048518.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048518.4,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048519.3,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048519.5,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048514.5,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048520.2,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048521.3,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048522.3,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048522.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048523.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048523.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048524.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048524.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048524.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048525.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048525.7,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048525.2,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048526.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048526.3,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048521.2,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048526.9,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048527.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048528.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048529.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048529.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048530.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048530.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048531.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048531.4,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048532.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048532.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048531.8,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048532.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048532.8,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048527.8,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048533.5,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048455.6,"dur":78.5,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048534.5,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048535.4,"dur":1.6,"name":"nt.getcwd","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048535.0,"dur":2.8,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048538.1,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048538.7,"dur":0.1,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048539.4,"dur":35.2,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048539.3,"dur":35.6,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048576.2,"dur":0.8,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048578.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048580.6,"dur":0.4,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048581.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048581.6,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048582.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048583.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048583.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048583.8,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048584.7,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048585.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048584.4,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048585.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048585.8,"dur":0.3,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048578.3,"dur":8.0,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048586.8,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048587.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048589.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048589.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048589.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048590.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048590.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048591.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048591.4,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048592.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048592.3,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048591.8,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048592.7,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048593.0,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048587.8,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048593.6,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048594.7,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048595.6,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048596.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048596.2,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048597.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048597.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048597.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048598.0,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048598.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048598.9,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048598.4,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048599.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048599.5,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048594.6,"dur":5.2,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048600.1,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048601.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048602.1,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048602.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048602.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048603.6,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048603.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048604.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048604.5,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048605.2,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048605.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048604.9,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048605.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048606.1,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048601.1,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048606.7,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048607.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048608.7,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048609.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048609.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048610.3,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048610.6,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048610.9,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048611.2,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048611.9,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048612.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048611.6,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048612.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048612.7,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048607.6,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048613.3,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048538.5,"dur":75.4,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048614.3,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048614.9,"dur":0.5,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048615.6,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048616.2,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048617.0,"dur":36.2,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048616.8,"dur":36.7,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048654.8,"dur":0.7,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048657.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048659.4,"dur":0.5,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048660.1,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048660.5,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048661.8,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048662.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048662.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048662.7,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048663.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048664.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048663.4,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048664.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048664.8,"dur":0.3,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048657.0,"dur":8.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048665.9,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048667.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048668.3,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048668.6,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048669.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048669.8,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048670.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048670.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048670.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048671.5,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048671.8,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048671.3,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048672.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048672.4,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048667.1,"dur":5.7,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048673.1,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048674.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048675.2,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048675.5,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048675.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048676.7,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048677.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048677.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048677.6,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048678.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048678.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048678.0,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048678.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048679.1,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048674.0,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048679.8,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048680.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048681.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048682.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048682.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048683.4,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048683.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048684.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048684.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048684.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048685.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048684.7,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048685.6,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048685.8,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048680.7,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048686.5,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048687.5,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048688.5,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048688.8,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048689.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048690.0,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048690.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048690.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048690.9,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048691.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048691.8,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048691.3,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048692.2,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048692.4,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048687.3,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048693.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048616.0,"dur":77.9,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048694.3,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048694.8,"dur":0.7,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048695.6,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048696.2,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048697.0,"dur":35.3,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048696.8,"dur":35.7,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048734.0,"dur":0.6,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048736.2,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048738.4,"dur":0.4,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048739.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048739.4,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048740.7,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048741.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048741.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048741.7,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048742.6,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048742.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048742.4,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048743.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048743.7,"dur":0.3,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048736.0,"dur":8.2,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048744.7,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048746.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048747.2,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048747.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048747.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048748.8,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048749.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048749.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048749.7,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048750.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048750.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048750.2,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048751.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048751.3,"dur":0.3,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048745.9,"dur":5.9,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048752.1,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048753.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048754.6,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048754.9,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048755.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048756.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048756.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048756.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048757.0,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048757.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048757.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048757.4,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048758.3,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048758.5,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048753.4,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048759.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048760.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048761.4,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048761.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048762.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048762.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048763.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048763.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048763.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048764.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048764.7,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048764.2,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048765.1,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048765.3,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048760.2,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048766.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048767.0,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048768.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048768.4,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048768.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048769.6,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048769.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048770.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048770.5,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048771.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048771.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048770.9,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048771.7,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048771.9,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048766.8,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048772.6,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048696.0,"dur":77.2,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048773.7,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048774.3,"dur":0.5,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048774.9,"dur":0.3,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048775.5,"dur":0.2,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048776.3,"dur":34.3,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048776.1,"dur":34.8,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048812.2,"dur":0.7,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048814.4,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048816.5,"dur":0.5,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048817.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048817.6,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048818.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048819.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048819.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048819.9,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048820.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048821.1,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048820.5,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048821.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048821.9,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048814.2,"dur":8.1,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048822.8,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048824.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048825.2,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048825.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048825.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048826.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048827.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048827.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048827.6,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048828.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048828.5,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048828.0,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048828.9,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048829.1,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048823.9,"dur":5.6,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048829.8,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048830.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048831.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048832.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048832.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048833.4,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048833.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048834.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048834.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048835.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048835.2,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048834.8,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048835.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048835.9,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048830.7,"dur":5.6,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048836.6,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048837.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048838.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048839.0,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048839.3,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048840.2,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048840.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048840.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048841.0,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048841.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048841.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048841.5,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048842.3,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048842.5,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048837.5,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048843.2,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048844.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048845.2,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048845.5,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048845.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048846.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048847.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048847.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048847.6,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048848.2,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048848.5,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048848.0,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048848.9,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048849.1,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048844.0,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048849.7,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048775.4,"dur":75.0,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048850.8,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048851.4,"dur":0.4,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048852.0,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048852.6,"dur":0.1,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048853.3,"dur":32.4,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048853.2,"dur":32.8,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048887.3,"dur":0.7,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048889.7,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048891.8,"dur":0.5,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048892.5,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048892.9,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048894.1,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048894.4,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048894.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048895.1,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048896.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048896.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048895.8,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048896.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048897.1,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048889.5,"dur":8.0,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048898.0,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048899.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048900.4,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048900.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048901.0,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048901.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048902.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048902.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048902.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048903.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048903.7,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048903.2,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048904.1,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048904.3,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048899.1,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048904.9,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048905.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048907.0,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048907.3,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048907.6,"dur":0.2,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048908.5,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048908.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048909.1,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048909.4,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048910.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048910.3,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048909.8,"dur":0.7,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048910.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048910.9,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048905.8,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048911.5,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048912.8,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048913.8,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048914.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048914.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048915.3,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048915.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048915.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048916.2,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048916.8,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048917.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048916.6,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048917.4,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048917.7,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048912.6,"dur":5.4,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048918.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048919.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048920.2,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048920.6,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048920.9,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048921.7,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048922.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048922.3,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048922.6,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048923.2,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048923.4,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048923.0,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048923.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048924.0,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048919.1,"dur":5.2,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048924.6,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048852.4,"dur":72.9,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048926.1,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048926.6,"dur":1.1,"name":"_path_importer_cache (<frozen importlib._bootstrap_external>:1421)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048927.9,"dur":0.3,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048928.6,"dur":0.1,"name":"str.rpartition","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048929.4,"dur":35.2,"name":"nt.stat","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048929.2,"dur":35.6,"name":"_path_stat (<frozen importlib._bootstrap_external>:140)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048966.3,"dur":0.7,"name":"_relax_case (<frozen importlib._bootstrap_external>:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048968.8,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048971.0,"dur":0.5,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048971.7,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048972.1,"dur":0.3,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048973.4,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048973.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048974.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048974.3,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048975.2,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048975.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048974.9,"dur":0.8,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048976.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048976.3,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048968.7,"dur":8.1,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048977.3,"dur":0.3,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048978.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048979.8,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048980.1,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048980.5,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048981.4,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048981.6,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048981.9,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048982.2,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048982.8,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048983.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048982.7,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048983.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048983.8,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048978.4,"dur":5.7,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048984.4,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048985.5,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048986.6,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048987.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048987.3,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048988.2,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048988.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048988.8,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048989.1,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048989.7,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048990.0,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048989.5,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048990.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048990.6,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048985.3,"dur":5.7,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048991.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048992.3,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048993.4,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048993.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048994.0,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048994.9,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048995.2,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048995.5,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048995.8,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048996.4,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048996.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048996.2,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048997.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048997.3,"dur":0.1,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048992.1,"dur":5.5,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048997.9,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048998.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048999.9,"dur":0.2,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049000.2,"dur":0.2,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049000.6,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049001.4,"dur":0.1,"name":"str.startswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049001.7,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049002.0,"dur":0.1,"name":"str.endswith","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049002.3,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049002.9,"dur":0.02,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049003.1,"dur":0.1,"name":"str.rstrip","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049002.7,"dur":0.6,"name":"<listcomp> (<frozen importlib._bootstrap_external>:119)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049003.5,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049003.7,"dur":0.2,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048998.7,"dur":5.3,"name":"_path_join (<frozen importlib._bootstrap_external>:96)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049004.3,"dur":0.2,"name":"_verbose_message (<frozen importlib._bootstrap>:244)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048928.4,"dur":76.6,"name":"find_spec (<frozen importlib._bootstrap_external>:1604)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049007.1,"dur":1.4,"name":"__init__ (<frozen importlib._bootstrap>:357)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048182.9,"dur":826.1,"name":"_get_spec (<frozen importlib._bootstrap_external>:1464)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048182.1,"dur":827.8,"name":"find_spec (<frozen importlib._bootstrap_external>:1496)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049011.5,"dur":0.5,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049010.9,"dur":1.2,"name":"__exit__ (<frozen importlib._bootstrap>:1030)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049014.0,"dur":0.3,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049013.6,"dur":0.8,"name":"__enter__ (<frozen importlib._bootstrap>:1026)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049015.6,"dur":0.5,"name":"find_spec (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\six.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049016.5,"dur":0.1,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049016.4,"dur":0.3,"name":"__exit__ (<frozen importlib._bootstrap>:1030)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048156.5,"dur":860.5,"name":"_find_spec (<frozen importlib._bootstrap>:1054)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049018.2,"dur":2.6,"name":"str.format","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048155.3,"dur":868.5,"name":"_find_and_load_unlocked (<frozen importlib._bootstrap>:1120)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049026.5,"dur":0.4,"name":"_thread.get_ident","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049029.2,"dur":0.8,"name":"_thread.lock.__exit__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049025.7,"dur":4.6,"name":"release (<frozen importlib._bootstrap>:125)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049024.9,"dur":5.6,"name":"__exit__ (<frozen importlib._bootstrap>:173)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049032.1,"dur":0.1,"name":"_imp.acquire_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049032.7,"dur":0.2,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049033.4,"dur":0.1,"name":"_imp.release_lock","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049031.8,"dur":1.8,"name":"cb (<frozen importlib._bootstrap>:198)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198048118.9,"dur":918.9,"name":"_find_and_load (<frozen importlib._bootstrap>:1165)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049044.2,"dur":0.5,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:444)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049049.0,"dur":0.5,"name":"value (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1249)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049047.9,"dur":1.8,"name":"__get__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:193)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049055.5,"dur":1.4,"name":"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1091)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049052.6,"dur":4.5,"name":"__call__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:686)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049046.0,"dur":11.3,"name":"io_mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:138)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049066.0,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:444)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049067.0,"dur":0.1,"name":"value (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1249)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049066.7,"dur":0.5,"name":"__get__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:193)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049068.0,"dur":0.4,"name":"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1091)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049067.6,"dur":0.9,"name":"__call__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:686)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049066.4,"dur":2.3,"name":"io_mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:138)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049071.3,"dur":0.3,"name":"filename (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:414)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049071.8,"dur":66.0,"name":"io.open","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049065.4,"dur":73.2,"name":"get_file (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:461)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049147.9,"dur":0.7,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049149.7,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049152.4,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049151.5,"dur":1.3,"name":"is_path (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:10)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049153.8,"dur":2.7,"name":"_io.BufferedReader.seek","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049156.8,"dur":18.7,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049178.7,"dur":0.6,"name":"preinit (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:302)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049185.1,"dur":0.4,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049187.7,"dur":1.3,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\GifImagePlugin.py:63)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049190.4,"dur":0.2,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049191.8,"dur":0.4,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\BmpImagePlugin.py:51)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049192.7,"dur":0.1,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049195.9,"dur":2.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049195.0,"dur":3.4,"name":"i32le (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:60)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049193.7,"dur":5.3,"name":"_dib_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\BmpImagePlugin.py:55)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049199.5,"dur":0.1,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049201.1,"dur":0.2,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\JpegImagePlugin.py:347)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049201.9,"dur":0.1,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049203.1,"dur":0.4,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PpmImagePlugin.py:45)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049204.1,"dur":0.02,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049205.2,"dur":0.8,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:692)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049206.5,"dur":0.3,"name":"_io.BufferedReader.seek","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049215.3,"dur":4.0,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:486)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049221.8,"dur":0.4,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049221.5,"dur":0.8,"name":"is_path (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:10)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049229.8,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049230.3,"dur":0.4,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:692)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049235.4,"dur":0.8,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:152)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049234.2,"dur":5.3,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:347)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049243.6,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049244.7,"dur":2.5,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049248.5,"dur":0.7,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049248.2,"dur":1.2,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049249.7,"dur":3.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049243.1,"dur":10.8,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049260.9,"dur":1.0,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049258.0,"dur":4.0,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049263.3,"dur":1.0,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049264.8,"dur":0.6,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049272.3,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049282.6,"dur":0.5,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049271.6,"dur":11.6,"name":"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049284.1,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049283.9,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049284.9,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049284.8,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049267.7,"dur":19.4,"name":"chunk_IHDR (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:412)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049256.4,"dur":30.9,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049292.4,"dur":1.5,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049291.3,"dur":3.1,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049294.9,"dur":0.4,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049294.8,"dur":0.6,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049295.8,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049296.4,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049296.3,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049290.2,"dur":6.8,"name":"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049298.0,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049298.5,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049301.0,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049300.9,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049301.5,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049297.6,"dur":4.9,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049304.0,"dur":0.3,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049303.7,"dur":0.8,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049304.8,"dur":0.3,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049305.4,"dur":0.4,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049309.3,"dur":1.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049310.6,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049309.0,"dur":2.1,"name":"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049311.8,"dur":0.9,"name":"bytes.find","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049313.5,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049313.3,"dur":0.6,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049314.6,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049314.4,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049318.9,"dur":3.9,"name":"zlib.decompressobj","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049323.7,"dur":6.4,"name":"zlib.Decompress.decompress","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049318.6,"dur":11.9,"name":"_safe_zlib_decompress (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:134)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049308.5,"dur":25.1,"name":"chunk_iCCP (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:385)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049303.2,"dur":30.6,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049335.3,"dur":0.2,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049335.0,"dur":0.8,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049336.2,"dur":1.8,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049336.1,"dur":2.0,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049338.4,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049339.0,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049338.9,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049334.5,"dur":5.2,"name":"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049340.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049341.0,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049343.5,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049343.4,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049344.0,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049340.3,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049346.1,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049345.9,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049346.8,"dur":0.3,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049347.4,"dur":0.5,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049350.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049351.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049350.5,"dur":0.8,"name":"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049351.9,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049351.8,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049352.7,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049352.6,"dur":0.32,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049350.0,"dur":4.6,"name":"chunk_pHYs (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:507)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049345.6,"dur":9.2,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049356.1,"dur":0.2,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049356.0,"dur":0.5,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049356.9,"dur":0.1,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049356.8,"dur":0.3,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049357.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049358.1,"dur":0.1,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049358.0,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049355.5,"dur":3.1,"name":"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049359.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049359.7,"dur":1.7,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049361.9,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049361.8,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049362.3,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049359.0,"dur":4.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049364.1,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049363.9,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049364.7,"dur":0.2,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049365.1,"dur":2.8,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049363.6,"dur":4.6,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049369.9,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049369.7,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049370.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049371.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049370.7,"dur":0.7,"name":"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049372.5,"dur":0.5,"name":"bytes.islower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049374.3,"dur":0.2,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049374.2,"dur":0.4,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049375.1,"dur":0.1,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049375.0,"dur":0.3,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049375.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049376.1,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049376.0,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049373.8,"dur":2.8,"name":"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049377.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049377.7,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049379.9,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049379.8,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049380.3,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049377.0,"dur":4.1,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049382.1,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049381.9,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049382.6,"dur":0.2,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049383.1,"dur":0.3,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049386.3,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049386.6,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049386.0,"dur":0.8,"name":"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049387.8,"dur":0.8,"name":"bytes.split","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049389.1,"dur":0.8,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049390.2,"dur":0.3,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049391.4,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049392.7,"dur":0.7,"name":"check_text_memory (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:364)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049385.6,"dur":7.9,"name":"chunk_tEXt (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:524)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049381.6,"dur":12.1,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049394.8,"dur":0.2,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049394.6,"dur":0.5,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049395.6,"dur":0.2,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049395.4,"dur":0.5,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049396.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049396.7,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049396.6,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049394.2,"dur":3.0,"name":"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049397.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049398.4,"dur":1.7,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049400.6,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049400.5,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049401.0,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049397.7,"dur":4.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049402.9,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049402.7,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049403.6,"dur":0.2,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049404.0,"dur":0.6,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049406.0,"dur":2.5,"name":"chunk_IDAT (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:432)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049402.4,"dur":6.3,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049411.6,"dur":0.2,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049229.1,"dur":184.1,"name":"_open (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:704)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049414.5,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049415.4,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049416.0,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049211.5,"dur":205.2,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:108)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049417.6,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049420.6,"dur":0.7,"name":"builtins.max","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049421.5,"dur":0.2,"name":"builtins.max","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049419.9,"dur":2.3,"name":"_decompression_bomb_check (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3172)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049183.5,"dur":239.2,"name":"_open_core (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3262)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049146.5,"dur":276.7,"name":"open (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3193)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049424.9,"dur":0.1,"name":"__enter__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:530)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049426.5,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049426.9,"dur":0.1,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049426.3,"dur":1.0,"name":"__exit__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:541)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049430.9,"dur":0.3,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:444)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049434.4,"dur":0.3,"name":"value (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1249)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049433.4,"dur":1.5,"name":"__get__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:193)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049437.4,"dur":1.0,"name":"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1091)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049436.2,"dur":2.4,"name":"__call__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:686)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049432.3,"dur":6.4,"name":"io_mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:138)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049430.4,"dur":9.0,"name":"get_file (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:461)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049440.7,"dur":0.3,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049441.4,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049442.2,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049441.9,"dur":0.6,"name":"is_path (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:10)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049442.9,"dur":0.3,"name":"_io.BufferedReader.seek","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049443.4,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049444.1,"dur":0.3,"name":"preinit (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:302)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049445.7,"dur":0.2,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049449.1,"dur":0.9,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\GifImagePlugin.py:63)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049450.8,"dur":0.2,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049451.8,"dur":0.3,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\BmpImagePlugin.py:51)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049452.6,"dur":0.1,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049453.9,"dur":0.5,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049453.7,"dur":0.9,"name":"i32le (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:60)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049453.2,"dur":1.8,"name":"_dib_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\BmpImagePlugin.py:55)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049455.5,"dur":0.1,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049456.4,"dur":0.2,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\JpegImagePlugin.py:347)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049457.0,"dur":0.1,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049458.1,"dur":0.4,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PpmImagePlugin.py:45)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049459.0,"dur":0.02,"name":"str.upper","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049459.6,"dur":0.4,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:692)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049460.4,"dur":0.2,"name":"_io.BufferedReader.seek","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049462.5,"dur":1.0,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:486)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049464.9,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049464.6,"dur":0.6,"name":"is_path (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:10)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049466.5,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049467.0,"dur":0.3,"name":"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:692)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049469.2,"dur":0.2,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:152)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049468.5,"dur":1.6,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:347)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049470.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049471.4,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049474.0,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049473.9,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049474.6,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049470.6,"dur":5.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049476.9,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049476.6,"dur":0.7,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049477.7,"dur":0.3,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049478.3,"dur":0.4,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049479.9,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049480.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049479.6,"dur":0.9,"name":"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049481.1,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049481.0,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049481.9,"dur":0.1,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049481.8,"dur":0.3,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049479.1,"dur":4.2,"name":"chunk_IHDR (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:412)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049476.2,"dur":7.3,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049484.6,"dur":0.2,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049484.4,"dur":0.6,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049485.4,"dur":0.1,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049485.3,"dur":0.4,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049486.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049486.5,"dur":0.1,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049486.4,"dur":0.3,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049484.0,"dur":2.9,"name":"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049487.7,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049488.0,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049490.3,"dur":0.1,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049490.1,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049490.6,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049487.4,"dur":3.9,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049492.3,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049492.1,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049493.0,"dur":0.2,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049493.4,"dur":0.3,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049494.9,"dur":0.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049495.5,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049494.6,"dur":1.2,"name":"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049496.1,"dur":0.5,"name":"bytes.find","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049497.3,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049497.1,"dur":0.6,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049498.3,"dur":0.1,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049498.1,"dur":0.4,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049500.0,"dur":2.1,"name":"zlib.decompressobj","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049502.8,"dur":2.9,"name":"zlib.Decompress.decompress","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049499.8,"dur":6.3,"name":"_safe_zlib_decompress (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:134)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049494.2,"dur":13.9,"name":"chunk_iCCP (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:385)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049491.9,"dur":16.4,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049509.5,"dur":0.2,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049509.3,"dur":0.6,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049510.3,"dur":1.3,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049510.2,"dur":1.5,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049512.0,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049512.6,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049512.5,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049508.9,"dur":4.3,"name":"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049513.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049514.3,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049516.7,"dur":0.1,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049516.6,"dur":0.3,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049517.1,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049513.6,"dur":4.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049518.9,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049518.7,"dur":0.6,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049519.6,"dur":0.2,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049520.1,"dur":0.4,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049521.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049521.9,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049521.3,"dur":0.8,"name":"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049522.6,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049522.5,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049523.3,"dur":0.1,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049523.2,"dur":0.3,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049520.8,"dur":3.6,"name":"chunk_pHYs (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:507)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049518.4,"dur":6.2,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049525.7,"dur":0.1,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049525.5,"dur":0.5,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049526.4,"dur":0.1,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049526.3,"dur":0.3,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049526.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049527.4,"dur":0.1,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049527.3,"dur":0.3,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049525.1,"dur":2.7,"name":"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049528.5,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049528.9,"dur":1.7,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049531.1,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049531.0,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049531.5,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049528.2,"dur":4.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049533.2,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049533.0,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049533.8,"dur":0.1,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049534.2,"dur":2.1,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049532.8,"dur":3.8,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049537.6,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049537.4,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049538.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049538.8,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049538.4,"dur":0.7,"name":"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049539.5,"dur":0.1,"name":"bytes.islower","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049540.8,"dur":0.2,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049540.7,"dur":0.5,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049541.6,"dur":0.1,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049541.5,"dur":0.3,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049542.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049542.6,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049542.5,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049540.3,"dur":2.7,"name":"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049543.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049544.1,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049546.3,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049546.2,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049546.7,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049543.4,"dur":3.9,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049548.3,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049548.1,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049548.9,"dur":0.2,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049549.3,"dur":0.5,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049550.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049551.2,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049550.6,"dur":0.8,"name":"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049551.7,"dur":0.2,"name":"bytes.split","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049552.4,"dur":0.4,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049552.9,"dur":0.3,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049553.8,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049554.3,"dur":0.5,"name":"check_text_memory (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:364)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049550.2,"dur":4.8,"name":"chunk_tEXt (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:524)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049547.9,"dur":7.2,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049556.1,"dur":0.2,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049556.0,"dur":0.4,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049556.9,"dur":0.2,"name":"zlib.crc32","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049556.7,"dur":0.5,"name":"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049557.4,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049558.0,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049557.9,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049555.5,"dur":2.9,"name":"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049559.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049559.5,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049561.8,"dur":0.1,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049561.6,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049562.1,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049558.8,"dur":4.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049563.8,"dur":0.2,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049563.6,"dur":0.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049564.4,"dur":0.2,"name":"bytes.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049564.9,"dur":0.3,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049565.6,"dur":1.5,"name":"chunk_IDAT (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:432)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049563.4,"dur":3.9,"name":"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049569.0,"dur":0.1,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049466.2,"dur":103.6,"name":"_open (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:704)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049570.4,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049571.0,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049571.6,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049461.4,"dur":110.5,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:108)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049572.5,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049573.2,"dur":0.3,"name":"builtins.max","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049573.7,"dur":0.2,"name":"builtins.max","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049572.9,"dur":1.4,"name":"_decompression_bomb_check (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3172)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049445.3,"dur":129.3,"name":"_open_core (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3262)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049440.0,"dur":135.3,"name":"open (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3193)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046924.2,"dur":2651.8,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:71)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046639.1,"dur":2937.8,"name":"imopen (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\imopen.py:15)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049579.5,"dur":0.1,"name":"__enter__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py:363)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049588.8,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049593.7,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049594.9,"dur":0.2,"name":"tell (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:912)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049593.1,"dur":2.1,"name":"_seek_check (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:334)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049591.5,"dur":3.9,"name":"seek (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:803)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049601.5,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049602.3,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049614.2,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049618.3,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049619.1,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049637.1,"dur":0.5,"name":"load (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:820)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049643.1,"dur":0.1,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049647.5,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049647.9,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049648.1,"dur":22.7,"name":"PIL._imaging.new","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049671.4,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049646.2,"dur":25.6,"name":"load_prepare (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:314)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049642.6,"dur":29.4,"name":"load_prepare (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:915)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049674.5,"dur":0.2,"name":"_tilesort (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:88)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049673.1,"dur":1.9,"name":"list.sort","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049680.7,"dur":0.3,"name":"<lambda> (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:254)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049679.6,"dur":3.6,"name":"<listcomp> (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:251)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049684.0,"dur":0.5,"name":"_io.BufferedReader.seek","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049685.2,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049688.1,"dur":0.3,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049690.5,"dur":0.6,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049691.8,"dur":2.3,"name":"PIL._imaging.zip_decoder","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049687.6,"dur":6.6,"name":"_getdecoder (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:377)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049695.2,"dur":1.1,"name":"ImagingDecoder.setimage","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049700.7,"dur":0.5,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049701.6,"dur":11.8,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049700.1,"dur":13.5,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049714.8,"dur":43.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049759.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049760.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049761.3,"dur":2.4,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049764.5,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049764.2,"dur":0.9,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049765.3,"dur":0.9,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049760.5,"dur":6.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049767.6,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049768.3,"dur":6.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049759.3,"dur":15.5,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049775.6,"dur":29.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049806.2,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049807.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049807.5,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049809.9,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049809.7,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049810.5,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049806.8,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049812.1,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049812.8,"dur":5.7,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049805.9,"dur":12.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049819.2,"dur":57.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049878.9,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049880.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049880.4,"dur":2.4,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049883.7,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049883.4,"dur":0.8,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049884.4,"dur":1.1,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049879.7,"dur":6.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049886.9,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049887.6,"dur":6.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049878.3,"dur":16.0,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049894.8,"dur":62.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049958.1,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049959.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049959.4,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049961.8,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049961.7,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049962.5,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049958.7,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049964.0,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049964.6,"dur":5.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049957.9,"dur":12.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049970.5,"dur":53.6,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050025.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050026.1,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050026.5,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050028.9,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050028.8,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050029.4,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050025.8,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050031.0,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050031.5,"dur":5.8,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050025.0,"dur":12.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050037.9,"dur":28.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050067.9,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050068.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050069.1,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050071.4,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050071.3,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050071.9,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050068.5,"dur":4.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050073.5,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050074.1,"dur":5.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050067.7,"dur":11.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050079.9,"dur":64.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050145.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050146.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050146.5,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050148.9,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050148.8,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050149.4,"dur":0.9,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050145.9,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050151.2,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050151.7,"dur":5.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050145.0,"dur":12.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050157.6,"dur":47.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050206.4,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050207.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050207.6,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050209.9,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050209.8,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050210.5,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050207.0,"dur":4.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050211.9,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050212.5,"dur":5.9,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050206.2,"dur":12.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050219.1,"dur":18.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050239.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050239.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050240.1,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050242.5,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050242.4,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050243.2,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050239.5,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050244.7,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050245.3,"dur":5.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050238.7,"dur":12.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050251.3,"dur":41.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050293.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050294.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050294.9,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050297.3,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050297.2,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050297.8,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050294.3,"dur":4.3,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050299.3,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050299.8,"dur":5.7,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050293.5,"dur":12.2,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050306.2,"dur":40.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050347.6,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050348.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050348.8,"dur":2.1,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050351.4,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050351.3,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050351.9,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050348.2,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050353.3,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050353.8,"dur":6.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050347.4,"dur":12.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050360.8,"dur":33.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050395.3,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050396.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050396.6,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050399.1,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050399.0,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050399.8,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050395.9,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050401.4,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050401.9,"dur":5.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050395.0,"dur":12.5,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050408.0,"dur":37.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050446.1,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050447.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050447.4,"dur":2.2,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050450.2,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050450.0,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050450.8,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050446.8,"dur":5.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050452.5,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050453.1,"dur":5.6,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050445.8,"dur":13.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050459.5,"dur":26.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050486.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050487.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050487.9,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050490.3,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050490.2,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050490.9,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050487.2,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050492.3,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050492.8,"dur":5.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050486.4,"dur":11.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050498.6,"dur":76.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050579.4,"dur":0.6,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050581.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050582.1,"dur":3.2,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050587.0,"dur":0.8,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050586.2,"dur":1.8,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050588.4,"dur":2.0,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050580.7,"dur":10.1,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050592.3,"dur":0.6,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050593.4,"dur":9.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050578.6,"dur":24.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050603.8,"dur":43.6,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050648.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050649.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050650.1,"dur":2.1,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050652.8,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050652.7,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050653.6,"dur":0.8,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050649.4,"dur":5.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050655.5,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050656.3,"dur":6.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050648.5,"dur":14.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050663.3,"dur":49.5,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050714.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050715.1,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050715.6,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050718.1,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050718.0,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050718.8,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050714.8,"dur":5.1,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050720.8,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050721.5,"dur":5.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050713.9,"dur":13.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050727.6,"dur":47.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050776.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050777.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050777.9,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050780.4,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050780.2,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050781.1,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050777.2,"dur":4.8,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050782.8,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050783.4,"dur":5.8,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050776.3,"dur":13.0,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050789.8,"dur":63.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050854.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050855.5,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050856.0,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050858.7,"dur":0.6,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050858.6,"dur":0.8,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050859.7,"dur":0.8,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050855.2,"dur":5.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050861.6,"dur":0.4,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050862.5,"dur":6.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050854.2,"dur":14.6,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050869.5,"dur":40.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050911.0,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050911.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050912.3,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050914.8,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050914.6,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050915.4,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050911.6,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050917.0,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050917.6,"dur":6.0,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050910.7,"dur":13.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050924.4,"dur":47.7,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050973.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050974.1,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050974.5,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050977.1,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050977.0,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050977.8,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050973.8,"dur":4.8,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050979.3,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050979.9,"dur":5.8,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050973.0,"dur":12.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198050986.3,"dur":56.7,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051044.2,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051045.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051045.6,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051048.0,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051047.9,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051048.7,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051044.8,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051050.2,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051050.8,"dur":5.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051043.9,"dur":12.5,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051056.9,"dur":33.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051091.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051092.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051092.5,"dur":2.4,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051095.5,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051095.3,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051096.1,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051091.9,"dur":5.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051097.6,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051098.2,"dur":5.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051091.0,"dur":12.6,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051104.2,"dur":49.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051154.4,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051155.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051155.7,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051158.3,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051158.2,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051158.9,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051155.1,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051160.5,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051161.1,"dur":5.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051154.2,"dur":12.5,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051167.2,"dur":63.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051231.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051232.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051232.9,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051235.4,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051235.2,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051236.0,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051232.2,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051237.4,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051238.0,"dur":6.0,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051231.3,"dur":12.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051244.6,"dur":49.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051295.0,"dur":0.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051296.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051296.5,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051299.1,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051298.9,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051299.7,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051295.7,"dur":4.8,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051301.3,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051301.9,"dur":5.9,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051294.8,"dur":13.2,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051308.4,"dur":48.9,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051358.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051359.4,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051359.8,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051362.3,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051362.1,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051363.0,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051359.1,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051364.5,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051365.2,"dur":5.7,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051358.2,"dur":12.9,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051371.7,"dur":59.6,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051432.5,"dur":0.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051433.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051433.9,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051436.4,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051436.2,"dur":0.8,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051437.1,"dur":0.8,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051433.2,"dur":4.9,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051438.9,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051439.5,"dur":6.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051432.2,"dur":13.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051446.5,"dur":47.5,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051495.3,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051496.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051496.6,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051499.1,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051498.9,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051499.6,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051495.9,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051501.6,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051502.3,"dur":6.6,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051495.0,"dur":14.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051509.5,"dur":48.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051559.5,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051560.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051561.3,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051563.9,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051563.6,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051564.5,"dur":0.8,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051560.1,"dur":5.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051566.3,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051567.0,"dur":5.9,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051559.2,"dur":13.9,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051573.7,"dur":59.7,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051635.0,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051636.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051636.4,"dur":2.5,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051639.7,"dur":0.5,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051639.4,"dur":0.9,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051640.5,"dur":1.0,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051635.7,"dur":5.9,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051642.4,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051643.0,"dur":6.6,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051634.6,"dur":15.2,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051650.2,"dur":47.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051699.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051699.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051700.3,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051702.7,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051702.6,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051703.3,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051699.7,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051704.8,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051705.3,"dur":6.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051698.9,"dur":13.0,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051712.4,"dur":47.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051761.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051761.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051762.3,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051764.8,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051764.7,"dur":8.8,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051774.2,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051761.7,"dur":13.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051775.8,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051776.4,"dur":6.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051760.9,"dur":22.2,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051783.9,"dur":48.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051833.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051834.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051835.1,"dur":2.2,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051837.9,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051837.8,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051838.6,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051834.5,"dur":5.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051840.4,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051840.9,"dur":5.8,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051833.6,"dur":13.2,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051847.4,"dur":40.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051888.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051889.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051890.0,"dur":2.4,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051893.0,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051892.8,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051893.7,"dur":0.8,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051889.2,"dur":5.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051895.4,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051896.1,"dur":7.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051888.4,"dur":15.2,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051904.1,"dur":52.9,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051958.6,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051959.9,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051960.3,"dur":2.3,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051963.1,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051962.9,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051963.8,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051959.5,"dur":5.1,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051965.6,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051966.2,"dur":6.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051958.2,"dur":14.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198051973.4,"dur":42.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052017.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052018.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052019.0,"dur":2.1,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052021.7,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052021.6,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052022.2,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052018.3,"dur":4.8,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052023.8,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052024.4,"dur":5.8,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052017.3,"dur":13.3,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052031.1,"dur":7.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052039.6,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052040.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052040.8,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052043.2,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052043.1,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052043.7,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052040.2,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052045.3,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052045.8,"dur":5.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052039.4,"dur":12.0,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052052.1,"dur":10.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052063.5,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052064.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052064.8,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052067.2,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052067.0,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052067.6,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052064.1,"dur":4.3,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052069.0,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052069.5,"dur":5.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052063.3,"dur":11.6,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052075.7,"dur":12.9,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052089.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052090.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052091.1,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052093.4,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052093.3,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052093.9,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052090.2,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052095.2,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052095.7,"dur":5.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052089.4,"dur":11.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052101.6,"dur":11.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052113.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052114.6,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052114.9,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052117.4,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052117.3,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052117.9,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052114.3,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052119.4,"dur":0.1,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052119.9,"dur":5.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052113.5,"dur":11.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052125.8,"dur":11.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052138.0,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052138.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052139.2,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052141.6,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052141.5,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052142.2,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052138.6,"dur":4.3,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052143.6,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052144.2,"dur":5.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052137.8,"dur":11.9,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052150.2,"dur":57.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052209.3,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052210.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052210.5,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052213.0,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052212.9,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052213.5,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052209.9,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052215.0,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052215.6,"dur":5.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052209.0,"dur":11.9,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052221.4,"dur":11.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052233.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052234.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052234.7,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052237.1,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052236.9,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052237.6,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052234.1,"dur":4.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052239.0,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052239.5,"dur":5.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052233.3,"dur":11.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052245.2,"dur":18.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052264.7,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052265.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052265.9,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052268.3,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052268.2,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052268.9,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052265.3,"dur":4.3,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052270.3,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052270.9,"dur":5.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052264.5,"dur":11.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052276.6,"dur":12.9,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052290.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052291.3,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052291.6,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052294.1,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052293.9,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052294.6,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052291.0,"dur":4.3,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052295.9,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052296.4,"dur":4.9,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052290.3,"dur":11.2,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052302.1,"dur":34.5,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052338.1,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052339.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052339.4,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052341.9,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052341.7,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052342.5,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052338.7,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052344.0,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052344.5,"dur":5.8,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052337.8,"dur":12.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052351.0,"dur":11.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052363.3,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052364.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052364.4,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052366.7,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052366.6,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052367.2,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052363.9,"dur":4.1,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052368.7,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052369.2,"dur":5.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052363.0,"dur":11.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052375.1,"dur":18.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052394.3,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052395.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052395.5,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052398.0,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052397.9,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052398.5,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052394.9,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052400.0,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052400.6,"dur":5.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052394.1,"dur":11.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052406.4,"dur":26.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052434.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052435.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052435.5,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052437.9,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052437.8,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052438.4,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052434.9,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052440.0,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052440.5,"dur":5.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052434.1,"dur":12.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052446.6,"dur":31.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052478.8,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052479.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052480.1,"dur":2.3,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052482.9,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052482.8,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052483.5,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052479.5,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052484.8,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052485.4,"dur":5.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052478.6,"dur":12.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052491.5,"dur":52.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052544.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052545.7,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052546.0,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052548.4,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052548.3,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052549.1,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052545.4,"dur":4.3,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052550.4,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052550.9,"dur":5.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052544.7,"dur":11.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052557.1,"dur":58.7,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052622.1,"dur":0.7,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052624.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052625.3,"dur":4.3,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052631.3,"dur":1.8,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052630.8,"dur":2.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052634.0,"dur":3.1,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052623.9,"dur":13.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052639.2,"dur":0.8,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052640.6,"dur":12.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052620.9,"dur":32.3,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052654.2,"dur":37.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052693.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052694.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052694.5,"dur":2.1,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052697.3,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052697.1,"dur":0.8,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052698.1,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052693.8,"dur":5.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052700.0,"dur":0.4,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052700.8,"dur":6.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052692.7,"dur":14.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052707.8,"dur":57.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052766.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052767.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052767.7,"dur":2.1,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052770.4,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052770.3,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052771.2,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052767.1,"dur":5.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052772.9,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052773.6,"dur":5.9,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052766.2,"dur":13.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052780.2,"dur":35.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052816.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052817.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052817.6,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052820.1,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052819.9,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052820.8,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052817.0,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052822.2,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052822.9,"dur":5.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052816.2,"dur":12.0,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052828.8,"dur":40.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052870.5,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052871.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052871.8,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052874.4,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052874.2,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052875.0,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052871.1,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052876.7,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052877.3,"dur":5.6,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052870.3,"dur":12.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052883.6,"dur":41.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052926.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052927.0,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052927.3,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052929.7,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052929.6,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052930.3,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052926.7,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052931.9,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052932.6,"dur":5.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052926.0,"dur":12.0,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052938.6,"dur":40.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052980.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052980.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052981.3,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052983.7,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052983.6,"dur":0.4,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052984.2,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052980.7,"dur":4.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052985.6,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052986.2,"dur":5.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052979.9,"dur":11.5,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198052991.9,"dur":40.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053033.1,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053034.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053034.4,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053036.8,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053036.7,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053037.4,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053033.7,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053038.7,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053039.3,"dur":5.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053032.9,"dur":11.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053045.2,"dur":41.7,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053088.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053088.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053089.3,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053091.7,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053091.6,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053092.3,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053088.7,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053093.9,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053094.5,"dur":5.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053087.8,"dur":12.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053100.5,"dur":40.5,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053142.1,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053142.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053143.3,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053145.6,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053145.5,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053146.2,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053142.7,"dur":4.3,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053147.6,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053148.2,"dur":4.9,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053141.9,"dur":11.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053153.8,"dur":48.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053203.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053203.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053204.3,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053206.7,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053206.6,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053207.3,"dur":0.8,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053203.7,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053209.0,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053209.6,"dur":6.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053202.8,"dur":13.3,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053216.7,"dur":43.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053260.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053261.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053262.1,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053264.5,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053264.4,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053265.1,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053261.4,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053266.5,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053267.1,"dur":5.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053260.6,"dur":11.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053272.9,"dur":41.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053315.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053315.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053316.1,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053318.6,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053318.4,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053319.1,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053315.6,"dur":4.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053320.5,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053321.0,"dur":5.0,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053314.7,"dur":11.5,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053326.7,"dur":42.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053369.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053370.7,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053371.1,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053373.5,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053373.4,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053374.1,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053370.4,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053375.5,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053376.1,"dur":5.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053369.7,"dur":12.0,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053382.2,"dur":44.7,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053428.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053428.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053429.4,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053431.9,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053431.7,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053432.5,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053428.7,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053434.0,"dur":0.4,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053434.7,"dur":5.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053427.8,"dur":12.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053440.8,"dur":40.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053482.8,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053483.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053484.0,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053486.5,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053486.3,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053487.1,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053483.4,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053488.7,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053489.3,"dur":5.7,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053482.5,"dur":12.6,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053496.0,"dur":45.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053542.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053543.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053543.5,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053546.1,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053545.9,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053546.6,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053542.9,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053548.1,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053548.6,"dur":6.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053542.1,"dur":12.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053555.4,"dur":50.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053607.5,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053608.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053608.7,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053611.1,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053611.0,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053611.7,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053608.1,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053613.2,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053613.7,"dur":5.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053607.2,"dur":11.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053619.5,"dur":42.5,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053663.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053664.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053664.4,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053666.7,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053666.6,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053667.2,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053663.8,"dur":4.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053668.7,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053669.2,"dur":5.0,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053662.9,"dur":11.5,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053674.9,"dur":35.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053711.4,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053712.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053712.6,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053715.0,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053714.9,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053715.5,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053712.0,"dur":4.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053716.9,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053717.5,"dur":5.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053711.2,"dur":11.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053723.4,"dur":32.0,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053756.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053757.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053757.8,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053760.4,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053760.2,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053760.9,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053757.1,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053762.7,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053763.3,"dur":5.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053756.3,"dur":12.6,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053769.8,"dur":32.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053803.4,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053804.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053804.6,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053807.1,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053807.0,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053808.2,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053804.0,"dur":5.0,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053809.7,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053810.4,"dur":5.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053803.0,"dur":12.9,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053816.5,"dur":30.9,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053848.7,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053849.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053849.8,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053852.2,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053852.1,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053852.8,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053849.2,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053854.3,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053854.9,"dur":5.6,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053848.4,"dur":12.3,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053861.2,"dur":46.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053909.5,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053910.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053910.7,"dur":2.6,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053913.8,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053913.7,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053914.4,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053910.1,"dur":5.1,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053915.9,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053916.6,"dur":6.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053909.2,"dur":13.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053923.5,"dur":42.6,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053967.3,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053968.3,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053968.7,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053971.2,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053971.0,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053971.8,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053968.0,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053973.5,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053974.0,"dur":6.3,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053967.0,"dur":13.5,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198053981.1,"dur":36.7,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054019.7,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054020.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054020.9,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054023.4,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054023.2,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054024.0,"dur":0.8,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054020.3,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054025.9,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054026.5,"dur":5.7,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054019.4,"dur":12.9,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054032.8,"dur":41.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054076.0,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054076.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054077.2,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054079.8,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054079.6,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054080.3,"dur":0.8,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054076.6,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054082.0,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054082.5,"dur":5.8,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054075.5,"dur":13.1,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054089.2,"dur":47.3,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054137.9,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054138.7,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054139.1,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054141.5,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054141.4,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054142.1,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054138.4,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054143.5,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054144.1,"dur":6.0,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054137.6,"dur":12.7,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054150.8,"dur":41.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054193.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054194.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054194.7,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054197.3,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054197.2,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054197.9,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054194.1,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054199.6,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054200.1,"dur":6.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054193.0,"dur":13.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054207.0,"dur":41.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054249.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054250.4,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054250.8,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054253.3,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054253.2,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054253.9,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054250.1,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054255.5,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054256.0,"dur":5.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054249.2,"dur":12.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054262.1,"dur":51.5,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054315.2,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054316.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054316.4,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054319.0,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054318.7,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054319.6,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054315.8,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054321.3,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054322.0,"dur":6.0,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054314.9,"dur":13.3,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054328.7,"dur":39.6,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054369.6,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054370.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054370.9,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054373.4,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054373.1,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054373.9,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054370.3,"dur":4.3,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054375.3,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054375.8,"dur":5.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054369.3,"dur":11.9,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054381.6,"dur":46.8,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054429.7,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054430.6,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054431.0,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054433.5,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054433.3,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054434.1,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054430.4,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054435.6,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054436.3,"dur":5.6,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054429.4,"dur":12.6,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054442.5,"dur":48.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054492.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054492.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054493.2,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054495.7,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054495.5,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054496.2,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054492.6,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054497.7,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054498.2,"dur":5.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054491.8,"dur":12.0,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054504.4,"dur":41.4,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054547.0,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054547.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054548.3,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054550.9,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054550.7,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054551.5,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054547.6,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054553.0,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054553.6,"dur":5.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054546.7,"dur":12.6,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054559.9,"dur":39.9,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054601.2,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054601.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054602.3,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054604.6,"dur":0.4,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054604.5,"dur":0.7,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054605.4,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054601.7,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054606.7,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054607.3,"dur":4.9,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054600.8,"dur":11.6,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054612.9,"dur":43.7,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054658.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054658.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054659.2,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054661.8,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054661.6,"dur":0.6,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054662.3,"dur":0.7,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054658.5,"dur":4.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054663.9,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054664.4,"dur":5.5,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054657.7,"dur":12.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054670.6,"dur":40.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054712.1,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054712.9,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054713.3,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054715.7,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054715.6,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054716.3,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054712.7,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054717.8,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054718.3,"dur":5.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054711.8,"dur":11.9,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054724.2,"dur":44.5,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054770.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054770.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054771.2,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054773.8,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054773.7,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054774.4,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054770.5,"dur":4.6,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054775.8,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054776.4,"dur":5.4,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054769.6,"dur":12.3,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054782.5,"dur":44.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054827.7,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054828.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054828.8,"dur":2.0,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054831.3,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054831.2,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054831.9,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054828.2,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054833.4,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054833.9,"dur":5.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054827.5,"dur":11.6,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054839.6,"dur":36.7,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054877.5,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054878.3,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054878.7,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054881.1,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054881.0,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054881.7,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054878.1,"dur":4.3,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054883.1,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054883.7,"dur":5.0,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054877.3,"dur":11.6,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054889.4,"dur":35.2,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054925.8,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054926.7,"dur":0.02,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054927.1,"dur":1.8,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054929.4,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054929.3,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054929.9,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054926.4,"dur":4.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054931.3,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054931.9,"dur":4.9,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054925.6,"dur":11.3,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054937.4,"dur":45.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054983.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054984.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054984.9,"dur":2.1,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054987.5,"dur":0.2,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054987.4,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054988.1,"dur":0.6,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054984.3,"dur":4.5,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054989.5,"dur":0.3,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054990.2,"dur":5.9,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054983.5,"dur":12.8,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198054996.8,"dur":37.1,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055035.1,"dur":0.2,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055036.0,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055036.4,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055038.8,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055038.7,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055039.4,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055035.7,"dur":4.4,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055040.8,"dur":0.2,"name":"builtins.min","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055041.3,"dur":0.8,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055034.9,"dur":7.4,"name":"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055042.7,"dur":10.7,"name":"ImagingDecoder.decode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055054.8,"dur":0.2,"name":"ImagingDecoder.cleanup","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055065.8,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055066.5,"dur":0.1,"name":"_io.BufferedReader.read","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055066.9,"dur":1.9,"name":"_io.BufferedReader.tell","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055069.3,"dur":0.3,"name":"_struct.unpack_from","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055069.2,"dur":0.5,"name":"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055069.8,"dur":0.5,"name":"re.Pattern.match","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055066.3,"dur":4.2,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055073.6,"dur":0.4,"name":"close (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:182)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055065.1,"dur":10.4,"name":"load_end (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:957)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055081.8,"dur":0.9,"name":"ImagingCore.pixel_access","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055079.4,"dur":3.4,"name":"load (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:820)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049631.6,"dur":5451.4,"name":"load (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:175)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055087.9,"dur":0.2,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055087.2,"dur":1.2,"name":"width (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:498)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055089.6,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055089.3,"dur":0.6,"name":"height (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:502)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055090.5,"dur":0.5,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055094.8,"dur":0.9,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055100.9,"dur":1.9,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055103.8,"dur":1.9,"name":"PIL._imaging.raw_encoder","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055093.9,"dur":11.9,"name":"_getencoder (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:400)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055107.0,"dur":1.5,"name":"ImagingEncoder.setimage","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055109.3,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055110.0,"dur":0.3,"name":"builtins.max","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055110.8,"dur":13.8,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055125.6,"dur":0.3,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055126.3,"dur":10.9,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055137.6,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055138.0,"dur":11.9,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055150.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055150.6,"dur":10.8,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055161.8,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055162.0,"dur":11.5,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055173.9,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055174.4,"dur":10.8,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055185.6,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055185.8,"dur":11.2,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055197.3,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055197.6,"dur":10.8,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055208.8,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055209.0,"dur":12.4,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055221.8,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055222.2,"dur":11.4,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055241.6,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055241.9,"dur":11.6,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055253.8,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055254.0,"dur":11.4,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055265.7,"dur":0.02,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055265.9,"dur":2.4,"name":"ImagingEncoder.encode","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055268.6,"dur":0.1,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055269.3,"dur":74.6,"name":"bytes.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049618.0,"dur":5726.1,"name":"tobytes (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:711)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055351.9,"dur":0.4,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055354.5,"dur":0.2,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055353.8,"dur":1.2,"name":"height (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:502)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055355.8,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055355.6,"dur":0.5,"name":"width (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:498)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055357.3,"dur":0.4,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055349.8,"dur":9.0,"name":"_conv_type_shape (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:229)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049613.2,"dur":5746.8,"name":"__array_interface__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:671)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049602.7,"dur":5777.4,"name":"numpy.asarray","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055382.7,"dur":0.2,"name":"tell (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:912)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055388.3,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055388.8,"dur":0.1,"name":"tell (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:912)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055389.6,"dur":0.4,"name":"dict.copy","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055390.8,"dur":0.2,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055391.6,"dur":0.1,"name":"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055392.0,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055399.3,"dur":0.4,"name":"ImagingCore.pixel_access","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055397.9,"dur":1.9,"name":"load (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:820)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055395.7,"dur":4.6,"name":"load (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:175)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055410.5,"dur":3.5,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3665)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055415.5,"dur":0.2,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055416.6,"dur":0.3,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055421.7,"dur":1.0,"name":"__contains__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3926)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055423.1,"dur":0.02,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055406.1,"dur":17.2,"name":"getexif (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:1419)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055394.1,"dur":29.4,"name":"getexif (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:1015)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055426.1,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055424.9,"dur":1.5,"name":"__len__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3914)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055387.5,"dur":39.3,"name":"metadata (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:492)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055431.7,"dur":65.1,"name":"numpy.array","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049601.1,"dur":5897.4,"name":"_apply_transforms (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:301)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198049586.6,"dur":5913.7,"name":"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:151)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055501.5,"dur":0.2,"name":"numpy.asarray","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055507.0,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055506.5,"dur":0.9,"name":"_flush_writer (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:475)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055511.0,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055513.7,"dur":0.4,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055515.0,"dur":27.6,"name":"_io.BufferedReader.close","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055545.8,"dur":0.3,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:20)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055513.0,"dur":33.6,"name":"_close_fp (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:533)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055547.2,"dur":0.1,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055548.2,"dur":0.1,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:20)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055510.4,"dur":139.9,"name":"close (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:547)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055657.8,"dur":0.4,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:444)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055662.2,"dur":0.4,"name":"value (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1249)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055660.9,"dur":1.9,"name":"__get__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:193)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055666.6,"dur":1.6,"name":"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1091)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055665.1,"dur":3.2,"name":"__call__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:686)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055659.5,"dur":9.0,"name":"io_mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:138)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055670.7,"dur":0.7,"name":"_io.BufferedReader.close","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055656.8,"dur":20.6,"name":"finish (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:540)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055504.3,"dur":173.5,"name":"close (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055503.0,"dur":175.1,"name":"__exit__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py:366)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046624.1,"dur":9054.5,"name":"imread (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\v3.py:6)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055681.4,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055681.0,"dur":0.7,"name":"_flush_writer (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:475)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055682.7,"dur":0.2,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055683.6,"dur":0.1,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055689.5,"dur":0.8,"name":"__getattr__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:23)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055683.4,"dur":7.5,"name":"_close_fp (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:533)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055694.6,"dur":1.0,"name":"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055693.4,"dur":2.5,"name":"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055696.3,"dur":0.1,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055697.3,"dur":0.1,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:20)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055682.5,"dur":15.5,"name":"close (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:547)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055698.8,"dur":0.1,"name":"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:444)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055699.9,"dur":0.1,"name":"value (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1249)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055699.6,"dur":0.6,"name":"__get__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:193)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055701.3,"dur":0.5,"name":"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1091)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055700.7,"dur":1.2,"name":"__call__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:686)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055699.3,"dur":2.8,"name":"io_mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:138)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055698.4,"dur":4.4,"name":"finish (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:540)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055680.5,"dur":22.4,"name":"close (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:143)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055680.1,"dur":22.9,"name":"__del__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py:369)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055704.0,"dur":0.3,"name":"numpy.asarray","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046620.4,"dur":9085.2,"name":"imread (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:9)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046614.7,"dur":9091.5,"name":"call_plugin (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\manage_plugins.py:170)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055712.0,"dur":0.1,"name":"file_or_url_context (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\util.py:20)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055711.2,"dur":1.4,"name":"builtins.next","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055710.6,"dur":3.3,"name":"__exit__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:141)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055715.4,"dur":0.3,"name":"builtins.hasattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198046573.6,"dur":9143.8,"name":"imread (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\_io.py:16)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044529.4,"dur":11188.4,"name":"_load (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py:316)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044527.6,"dur":11190.7,"name":"astronaut (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py:380)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055721.2,"dur":0.2,"name":"_average_dispatcher (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:393)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055734.7,"dur":0.2,"name":"numpy.asanyarray","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055742.7,"dur":0.1,"name":"numpy.asanyarray","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055746.0,"dur":0.5,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055748.3,"dur":1.4,"name":"numpy.core._multiarray_umath.normalize_axis_index","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055745.4,"dur":11.5,"name":"_count_reduce_items (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py:67)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055760.7,"dur":0.3,"name":"builtins.issubclass","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055764.9,"dur":4447.1,"name":"numpy.ufunc.reduce","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060216.2,"dur":0.7,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060225.3,"dur":0.9,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060221.5,"dur":5.2,"name":"__init__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:104)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060218.9,"dur":8.3,"name":"helper (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:287)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060232.8,"dur":2.1,"name":"_contextvars.ContextVar.set","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060231.1,"dur":4.1,"name":"_no_nep50_warning (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_ufunc_config.py:452)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060229.1,"dur":6.2,"name":"builtins.next","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060228.3,"dur":7.1,"name":"__enter__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:132)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060428.0,"dur":1.0,"name":"_contextvars.ContextVar.reset","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060426.8,"dur":2.5,"name":"_no_nep50_warning (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_ufunc_config.py:452)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060426.1,"dur":4.8,"name":"builtins.next","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060424.8,"dur":8.7,"name":"__exit__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:141)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055742.3,"dur":4692.8,"name":"_mean (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py:101)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055736.3,"dur":4700.0,"name":"numpy.ndarray.mean","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198060438.1,"dur":0.4,"name":"numpy.asanyarray","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198055733.6,"dur":4710.4,"name":"average (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:398)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061017.2,"dur":8.7,"name":"Tensor.unfold","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061026.3,"dur":3.0,"name":"Tensor.unfold","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061031.3,"dur":2.4,"name":"Tensor.size","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061034.1,"dur":79.3,"name":"Tensor.contiguous","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061114.3,"dur":9.8,"name":"Tensor.view","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061143.3,"dur":0.3,"name":"_contextvars.ContextVar.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061142.4,"dur":1.4,"name":"parent_header (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:505)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061144.7,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061148.2,"dur":0.8,"name":"nt.getpid","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061147.1,"dur":3.6,"name":"_is_master_process (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:550)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061153.7,"dur":0.3,"name":"dict.items","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061158.6,"dur":0.3,"name":"utcoffset (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\dateutil\\tz\\tz.py:74)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061166.5,"dur":0.5,"name":"_io.StringIO.write","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061167.3,"dur":0.2,"name":"_thread.RLock.__exit__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061177.3,"dur":0.4,"name":"is_set (C:\\Users\\adam\\miniconda3\\Lib\\threading.py:568)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061180.7,"dur":0.7,"name":"_thread.lock.acquire","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061180.0,"dur":1.7,"name":"_wait_for_tstate_lock (C:\\Users\\adam\\miniconda3\\Lib\\threading.py:1118)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061175.6,"dur":6.3,"name":"is_alive (C:\\Users\\adam\\miniconda3\\Lib\\threading.py:1185)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061183.5,"dur":0.2,"name":"collections.deque.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061186.6,"dur":1.6,"name":"_event_pipe (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:138)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061192.3,"dur":196.6,"name":"send (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\zmq\\sugar\\socket.py:621)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061173.0,"dur":216.6,"name":"schedule (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:259)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061169.5,"dur":220.6,"name":"_schedule_flush (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:577)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061392.9,"dur":0.4,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061139.4,"dur":254.0,"name":"write (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:655)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061396.5,"dur":0.2,"name":"_contextvars.ContextVar.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061395.9,"dur":1.0,"name":"parent_header (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:505)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061397.2,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061399.0,"dur":0.4,"name":"nt.getpid","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061398.4,"dur":1.8,"name":"_is_master_process (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:550)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061402.3,"dur":0.3,"name":"dict.items","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061406.1,"dur":0.4,"name":"_io.StringIO.write","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061406.7,"dur":0.2,"name":"_thread.RLock.__exit__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061407.6,"dur":0.2,"name":"_schedule_flush (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:577)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061408.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061395.2,"dur":13.0,"name":"write (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:655)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061127.0,"dur":281.5,"name":"builtins.print","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061409.1,"dur":10.7,"name":"Tensor.view","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061421.4,"dur":10.0,"name":"Tensor.permute","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061431.7,"dur":270.5,"name":"Tensor.contiguous","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061706.5,"dur":6.1,"name":"Tensor.view","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061837.8,"dur":110.5,"name":"Tensor.all","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061955.5,"dur":0.4,"name":"torch._C._has_torch_function_unary","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061966.2,"dur":0.6,"name":"type.__new__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061964.8,"dur":2.1,"name":"__new__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:149)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061970.9,"dur":0.2,"name":"is_scripting (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_jit_internal.py:1120)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061968.6,"dur":4.2,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:74)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061975.0,"dur":0.6,"name":"torch.is_grad_enabled","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061978.2,"dur":0.1,"name":"torch.is_grad_enabled","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061980.1,"dur":1.6,"name":"torch._C._set_grad_enabled","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061978.1,"dur":3.7,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:183)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061974.5,"dur":7.8,"name":"__enter__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:79)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061988.8,"dur":0.6,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061986.9,"dur":3.7,"name":"__init__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:104)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061985.2,"dur":5.6,"name":"helper (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:287)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061994.6,"dur":0.6,"name":"torch._C._len_torch_dispatch_stack","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061997.5,"dur":0.3,"name":"<listcomp> (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:123)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061994.3,"dur":3.9,"name":"_disable_current_modes (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:120)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061992.3,"dur":6.0,"name":"builtins.next","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061991.4,"dur":7.0,"name":"__enter__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:132)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062039.3,"dur":3.8,"name":"torch._C._functorch.is_functorch_wrapped_tensor","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062045.7,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062052.2,"dur":0.6,"name":"type.__new__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062051.7,"dur":1.2,"name":"<lambda> (<string>:1)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062049.6,"dur":3.6,"name":"unpack_dual (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\forward_ad.py:139)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062066.3,"dur":0.9,"name":"torch._C._get_default_device","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062070.8,"dur":0.5,"name":"torch.get_default_dtype","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062073.2,"dur":0.1,"name":"torch.get_default_dtype","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062079.1,"dur":1.2,"name":"torch._is_functional_tensor","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062088.2,"dur":1.3,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062090.1,"dur":1.2,"name":"Tensor.numel","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062098.6,"dur":0.2,"name":"Tensor.numel","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062099.3,"dur":0.8,"name":"Tensor.has_names","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062100.3,"dur":0.1,"name":"Tensor.numel","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062101.2,"dur":1.1,"name":"Tensor._is_zerotensor","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062102.8,"dur":0.8,"name":"Tensor.is_neg","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062118.2,"dur":0.3,"name":"type.__new__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062117.5,"dur":1.02,"name":"__new__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:149)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062120.0,"dur":0.1,"name":"is_scripting (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_jit_internal.py:1120)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062119.4,"dur":1.6,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:74)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062122.0,"dur":0.2,"name":"torch.is_grad_enabled","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062123.0,"dur":0.1,"name":"torch.is_grad_enabled","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062123.5,"dur":0.5,"name":"torch._C._set_grad_enabled","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062122.9,"dur":1.2,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:183)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062121.5,"dur":3.0,"name":"__enter__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:79)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062125.1,"dur":7.6,"name":"Tensor.reshape","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062134.6,"dur":0.1,"name":"torch.is_grad_enabled","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062135.0,"dur":0.3,"name":"torch._C._set_grad_enabled","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062134.5,"dur":0.9,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:183)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062133.7,"dur":1.9,"name":"__exit__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:83)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062139.0,"dur":0.5,"name":"Tensor.dim","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062140.3,"dur":2.8,"name":"torch._C._get_tracing_state","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062144.0,"dur":8.9,"name":"Tensor.unbind","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062153.1,"dur":0.2,"name":"builtins.iter","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062138.2,"dur":15.2,"name":"__iter__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py:1012)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062156.1,"dur":0.1,"name":"torch._C._has_torch_function_unary","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062156.4,"dur":0.2,"name":"Tensor.dim","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062158.1,"dur":4.9,"name":"Tensor.item","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062163.7,"dur":0.7,"name":"bool.__format__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062155.7,"dur":8.8,"name":"__format__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py:961)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062165.1,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062165.32,"dur":0.78,"name":"builtins.max","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062115.4,"dur":53.6,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:122)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062179.9,"dur":0.3,"name":"Tensor.dim","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062182.7,"dur":0.8,"name":"Tensor.item","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062187.0,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062185.8,"dur":2.2,"name":"format (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:192)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062182.2,"dur":5.9,"name":"_scalar_str (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:207)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062179.6,"dur":8.7,"name":"_tensor_str_with_formatter (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:265)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062098.3,"dur":90.3,"name":"_tensor_str (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:302)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062191.8,"dur":0.2,"name":"Tensor.has_names","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062196.0,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062197.0,"dur":0.8,"name":"str.rfind","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062198.9,"dur":0.2,"name":"list.append","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062199.6,"dur":0.3,"name":"str.join","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062195.6,"dur":4.4,"name":"_add_suffixes (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:353)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062204.9,"dur":0.1,"name":"_ParameterMeta.__instancecheck__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062205.3,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062205.8,"dur":0.4,"name":"builtins.getattr","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062203.5,"dur":2.8,"name":"__instancecheck__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\nn\\parameter.py:8)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062201.5,"dur":5.0,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062037.5,"dur":169.1,"name":"_str_intern (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:390)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062208.3,"dur":1.5,"name":"_disable_current_modes (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:120)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062207.9,"dur":2.3,"name":"builtins.next","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062207.5,"dur":4.4,"name":"__exit__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:141)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062214.0,"dur":0.2,"name":"torch.is_grad_enabled","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062214.6,"dur":0.4,"name":"torch._C._set_grad_enabled","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062213.9,"dur":1.2,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:183)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062213.0,"dur":2.4,"name":"__exit__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:83)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061961.2,"dur":254.5,"name":"_str (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:674)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061954.2,"dur":263.1,"name":"__repr__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py:455)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062219.8,"dur":0.2,"name":"_contextvars.ContextVar.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062219.1,"dur":1.0,"name":"parent_header (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:505)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062220.4,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062222.3,"dur":0.5,"name":"nt.getpid","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062221.6,"dur":1.6,"name":"_is_master_process (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:550)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062224.6,"dur":0.2,"name":"dict.items","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062228.7,"dur":0.2,"name":"_io.StringIO.write","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062229.1,"dur":0.2,"name":"_thread.RLock.__exit__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062230.0,"dur":0.2,"name":"_schedule_flush (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:577)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062230.5,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062218.5,"dur":12.2,"name":"write (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:655)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062232.0,"dur":0.1,"name":"_contextvars.ContextVar.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062231.8,"dur":0.4,"name":"parent_header (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:505)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062232.4,"dur":0.02,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062233.1,"dur":0.1,"name":"nt.getpid","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062232.9,"dur":0.5,"name":"_is_master_process (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:550)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062233.9,"dur":0.02,"name":"dict.items","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062235.1,"dur":0.1,"name":"_io.StringIO.write","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062235.3,"dur":0.1,"name":"_thread.RLock.__exit__","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062235.8,"dur":0.2,"name":"_schedule_flush (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:577)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062236.1,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062231.5,"dur":4.72,"name":"write (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:655)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198061949.6,"dur":286.9,"name":"builtins.print","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062248.4,"dur":0.2,"name":"torch._C._has_torch_function_unary","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062249.6,"dur":13.0,"name":"Tensor.numpy","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062263.4,"dur":135.3,"name":"numpy.ndarray.astype","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062248.2,"dur":155.2,"name":"__array__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py:1058)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062423.9,"dur":0.2,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062424.9,"dur":0.2,"name":"dict.get","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062432.9,"dur":0.5,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062433.7,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062432.0,"dur":2.3,"name":"_check_size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:2884)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062434.7,"dur":0.02,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062439.9,"dur":0.2,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062440.2,"dur":0.1,"name":"builtins.len","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062439.2,"dur":1.4,"name":"_check_size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:2884)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062441.0,"dur":0.1,"name":"builtins.isinstance","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062443.2,"dur":3.5,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:486)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062448.2,"dur":4.0,"name":"PIL._imaging.fill","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062454.9,"dur":0.5,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:486)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062457.8,"dur":0.1,"name":"dict.copy","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062454.3,"dur":3.8,"name":"_new (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:514)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062438.7,"dur":19.6,"name":"new (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:2905)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062459.4,"dur":4.3,"name":"PIL._imaging.map_buffer","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062465.1,"dur":0.4,"name":"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:486)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062466.3,"dur":0.02,"name":"dict.copy","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062464.1,"dur":2.4,"name":"_new (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:514)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062429.8,"dur":37.4,"name":"frombuffer (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:2983)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198062412.0,"dur":55.4,"name":"fromarray (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3040)","ph":"X","cat":"FEE"},{"pid":21732,"tid":30224,"ts":2302198044524.6,"dur":17945.2,"name":"folding (C:\\Users\\adam\\AppData\\Local\\Temp\\ipykernel_21732\\2464523178.py:8)","ph":"X","cat":"FEE"}],"viztracer_metadata":{"version":"0.16.2","overflow":false},"file_info":{"files":{"C:\\Users\\adam\\miniconda3\\Lib\\hashlib.py":["#.  Copyright (C) 2005-2010   Gregory P. Smith (greg@krypto.org)\n#  Licensed to PSF under a Contributor Agreement.\n#\n\n__doc__ = \"\"\"hashlib module - A common interface to many hash functions.\n\nnew(name, data=b'', **kwargs) - returns a new hash object implementing the\n                                given hash function; initializing the hash\n                                using the given binary data.\n\nNamed constructor functions are also available, these are faster\nthan using new(name):\n\nmd5(), sha1(), sha224(), sha256(), sha384(), sha512(), blake2b(), blake2s(),\nsha3_224, sha3_256, sha3_384, sha3_512, shake_128, and shake_256.\n\nMore algorithms may be available on your platform but the above are guaranteed\nto exist.  See the algorithms_guaranteed and algorithms_available attributes\nto find out what algorithm names can be passed to new().\n\nNOTE: If you want the adler32 or crc32 hash functions they are available in\nthe zlib module.\n\nChoose your hash function wisely.  Some have known collision weaknesses.\nsha384 and sha512 will be slow on 32 bit platforms.\n\nHash objects have these methods:\n - update(data): Update the hash object with the bytes in data. Repeated calls\n                 are equivalent to a single call with the concatenation of all\n                 the arguments.\n - digest():     Return the digest of the bytes passed to the update() method\n                 so far as a bytes object.\n - hexdigest():  Like digest() except the digest is returned as a string\n                 of double length, containing only hexadecimal digits.\n - copy():       Return a copy (clone) of the hash object. This can be used to\n                 efficiently compute the digests of datas that share a common\n                 initial substring.\n\nFor example, to obtain the digest of the byte string 'Nobody inspects the\nspammish repetition':\n\n    >>> import hashlib\n    >>> m = hashlib.md5()\n    >>> m.update(b\"Nobody inspects\")\n    >>> m.update(b\" the spammish repetition\")\n    >>> m.digest()\n    b'\\\\xbbd\\\\x9c\\\\x83\\\\xdd\\\\x1e\\\\xa5\\\\xc9\\\\xd9\\\\xde\\\\xc9\\\\xa1\\\\x8d\\\\xf0\\\\xff\\\\xe9'\n\nMore condensed:\n\n    >>> hashlib.sha224(b\"Nobody inspects the spammish repetition\").hexdigest()\n    'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'\n\n\"\"\"\n\n# This tuple and __get_builtin_constructor() must be modified if a new\n# always available algorithm is added.\n__always_supported = ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512',\n                      'blake2b', 'blake2s',\n                      'sha3_224', 'sha3_256', 'sha3_384', 'sha3_512',\n                      'shake_128', 'shake_256')\n\n\nalgorithms_guaranteed = set(__always_supported)\nalgorithms_available = set(__always_supported)\n\n__all__ = __always_supported + ('new', 'algorithms_guaranteed',\n                                'algorithms_available', 'pbkdf2_hmac', 'file_digest')\n\n\n__builtin_constructor_cache = {}\n\n# Prefer our blake2 implementation\n# OpenSSL 1.1.0 comes with a limited implementation of blake2b/s. The OpenSSL\n# implementations neither support keyed blake2 (blake2 MAC) nor advanced\n# features like salt, personalization, or tree hashing. OpenSSL hash-only\n# variants are available as 'blake2b512' and 'blake2s256', though.\n__block_openssl_constructor = {\n    'blake2b', 'blake2s',\n}\n\ndef __get_builtin_constructor(name):\n    cache = __builtin_constructor_cache\n    constructor = cache.get(name)\n    if constructor is not None:\n        return constructor\n    try:\n        if name in {'SHA1', 'sha1'}:\n            import _sha1\n            cache['SHA1'] = cache['sha1'] = _sha1.sha1\n        elif name in {'MD5', 'md5'}:\n            import _md5\n            cache['MD5'] = cache['md5'] = _md5.md5\n        elif name in {'SHA256', 'sha256', 'SHA224', 'sha224'}:\n            import _sha256\n            cache['SHA224'] = cache['sha224'] = _sha256.sha224\n            cache['SHA256'] = cache['sha256'] = _sha256.sha256\n        elif name in {'SHA512', 'sha512', 'SHA384', 'sha384'}:\n            import _sha512\n            cache['SHA384'] = cache['sha384'] = _sha512.sha384\n            cache['SHA512'] = cache['sha512'] = _sha512.sha512\n        elif name in {'blake2b', 'blake2s'}:\n            import _blake2\n            cache['blake2b'] = _blake2.blake2b\n            cache['blake2s'] = _blake2.blake2s\n        elif name in {'sha3_224', 'sha3_256', 'sha3_384', 'sha3_512'}:\n            import _sha3\n            cache['sha3_224'] = _sha3.sha3_224\n            cache['sha3_256'] = _sha3.sha3_256\n            cache['sha3_384'] = _sha3.sha3_384\n            cache['sha3_512'] = _sha3.sha3_512\n        elif name in {'shake_128', 'shake_256'}:\n            import _sha3\n            cache['shake_128'] = _sha3.shake_128\n            cache['shake_256'] = _sha3.shake_256\n    except ImportError:\n        pass  # no extension module, this hash is unsupported.\n\n    constructor = cache.get(name)\n    if constructor is not None:\n        return constructor\n\n    raise ValueError('unsupported hash type ' + name)\n\n\ndef __get_openssl_constructor(name):\n    if name in __block_openssl_constructor:\n        # Prefer our builtin blake2 implementation.\n        return __get_builtin_constructor(name)\n    try:\n        # MD5, SHA1, and SHA2 are in all supported OpenSSL versions\n        # SHA3/shake are available in OpenSSL 1.1.1+\n        f = getattr(_hashlib, 'openssl_' + name)\n        # Allow the C module to raise ValueError.  The function will be\n        # defined but the hash not actually available.  Don't fall back to\n        # builtin if the current security policy blocks a digest, bpo#40695.\n        f(usedforsecurity=False)\n        # Use the C function directly (very fast)\n        return f\n    except (AttributeError, ValueError):\n        return __get_builtin_constructor(name)\n\n\ndef __py_new(name, data=b'', **kwargs):\n    \"\"\"new(name, data=b'', **kwargs) - Return a new hashing object using the\n    named algorithm; optionally initialized with data (which must be\n    a bytes-like object).\n    \"\"\"\n    return __get_builtin_constructor(name)(data, **kwargs)\n\n\ndef __hash_new(name, data=b'', **kwargs):\n    \"\"\"new(name, data=b'') - Return a new hashing object using the named algorithm;\n    optionally initialized with data (which must be a bytes-like object).\n    \"\"\"\n    if name in __block_openssl_constructor:\n        # Prefer our builtin blake2 implementation.\n        return __get_builtin_constructor(name)(data, **kwargs)\n    try:\n        return _hashlib.new(name, data, **kwargs)\n    except ValueError:\n        # If the _hashlib module (OpenSSL) doesn't support the named\n        # hash, try using our builtin implementations.\n        # This allows for SHA224/256 and SHA384/512 support even though\n        # the OpenSSL library prior to 0.9.8 doesn't provide them.\n        return __get_builtin_constructor(name)(data)\n\n\ntry:\n    import _hashlib\n    new = __hash_new\n    __get_hash = __get_openssl_constructor\n    algorithms_available = algorithms_available.union(\n            _hashlib.openssl_md_meth_names)\nexcept ImportError:\n    _hashlib = None\n    new = __py_new\n    __get_hash = __get_builtin_constructor\n\ntry:\n    # OpenSSL's PKCS5_PBKDF2_HMAC requires OpenSSL 1.0+ with HMAC and SHA\n    from _hashlib import pbkdf2_hmac\nexcept ImportError:\n    from warnings import warn as _warn\n    _trans_5C = bytes((x ^ 0x5C) for x in range(256))\n    _trans_36 = bytes((x ^ 0x36) for x in range(256))\n\n    def pbkdf2_hmac(hash_name, password, salt, iterations, dklen=None):\n        \"\"\"Password based key derivation function 2 (PKCS #5 v2.0)\n\n        This Python implementations based on the hmac module about as fast\n        as OpenSSL's PKCS5_PBKDF2_HMAC for short passwords and much faster\n        for long passwords.\n        \"\"\"\n        _warn(\n            \"Python implementation of pbkdf2_hmac() is deprecated.\",\n            category=DeprecationWarning,\n            stacklevel=2\n        )\n        if not isinstance(hash_name, str):\n            raise TypeError(hash_name)\n\n        if not isinstance(password, (bytes, bytearray)):\n            password = bytes(memoryview(password))\n        if not isinstance(salt, (bytes, bytearray)):\n            salt = bytes(memoryview(salt))\n\n        # Fast inline HMAC implementation\n        inner = new(hash_name)\n        outer = new(hash_name)\n        blocksize = getattr(inner, 'block_size', 64)\n        if len(password) > blocksize:\n            password = new(hash_name, password).digest()\n        password = password + b'\\x00' * (blocksize - len(password))\n        inner.update(password.translate(_trans_36))\n        outer.update(password.translate(_trans_5C))\n\n        def prf(msg, inner=inner, outer=outer):\n            # PBKDF2_HMAC uses the password as key. We can re-use the same\n            # digest objects and just update copies to skip initialization.\n            icpy = inner.copy()\n            ocpy = outer.copy()\n            icpy.update(msg)\n            ocpy.update(icpy.digest())\n            return ocpy.digest()\n\n        if iterations < 1:\n            raise ValueError(iterations)\n        if dklen is None:\n            dklen = outer.digest_size\n        if dklen < 1:\n            raise ValueError(dklen)\n\n        dkey = b''\n        loop = 1\n        from_bytes = int.from_bytes\n        while len(dkey) < dklen:\n            prev = prf(salt + loop.to_bytes(4))\n            # endianness doesn't matter here as long to / from use the same\n            rkey = from_bytes(prev)\n            for i in range(iterations - 1):\n                prev = prf(prev)\n                # rkey = rkey ^ prev\n                rkey ^= from_bytes(prev)\n            loop += 1\n            dkey += rkey.to_bytes(inner.digest_size)\n\n        return dkey[:dklen]\n\ntry:\n    # OpenSSL's scrypt requires OpenSSL 1.1+\n    from _hashlib import scrypt\nexcept ImportError:\n    pass\n\n\ndef file_digest(fileobj, digest, /, *, _bufsize=2**18):\n    \"\"\"Hash the contents of a file-like object. Returns a digest object.\n\n    *fileobj* must be a file-like object opened for reading in binary mode.\n    It accepts file objects from open(), io.BytesIO(), and SocketIO objects.\n    The function may bypass Python's I/O and use the file descriptor *fileno*\n    directly.\n\n    *digest* must either be a hash algorithm name as a *str*, a hash\n    constructor, or a callable that returns a hash object.\n    \"\"\"\n    # On Linux we could use AF_ALG sockets and sendfile() to archive zero-copy\n    # hashing with hardware acceleration.\n    if isinstance(digest, str):\n        digestobj = new(digest)\n    else:\n        digestobj = digest()\n\n    if hasattr(fileobj, \"getbuffer\"):\n        # io.BytesIO object, use zero-copy buffer\n        digestobj.update(fileobj.getbuffer())\n        return digestobj\n\n    # Only binary files implement readinto().\n    if not (\n        hasattr(fileobj, \"readinto\")\n        and hasattr(fileobj, \"readable\")\n        and fileobj.readable()\n    ):\n        raise ValueError(\n            f\"'{fileobj!r}' is not a file-like object in binary reading mode.\"\n        )\n\n    # binary file, socket.SocketIO object\n    # Note: socket I/O uses different syscalls than file I/O.\n    buf = bytearray(_bufsize)  # Reusable buffer to reduce allocations.\n    view = memoryview(buf)\n    while True:\n        size = fileobj.readinto(buf)\n        if size == 0:\n            break  # EOF\n        digestobj.update(view[:size])\n\n    return digestobj\n\n\nfor __func_name in __always_supported:\n    # try them all, some may not work due to the OpenSSL\n    # version not supporting that algorithm.\n    try:\n        globals()[__func_name] = __get_hash(__func_name)\n    except ValueError:\n        import logging\n        logging.exception('code for hash %s was not found.', __func_name)\n\n\n# Cleanup locals()\ndel __always_supported, __func_name, __get_hash\ndel __py_new, __hash_new, __get_openssl_constructor\n",315],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py":["\"\"\"Standard test images.\n\nFor more images, see\n\n - http://sipi.usc.edu/database/database.php\n\n\"\"\"\nimport numpy as np\nimport shutil\n\nfrom ..util.dtype import img_as_bool\nfrom ._registry import registry, registry_urls\n\nfrom .. import __version__\n\nimport os.path as osp\nimport os\n\n_LEGACY_DATA_DIR = osp.dirname(__file__)\n_DISTRIBUTION_DIR = osp.dirname(_LEGACY_DATA_DIR)\n\ntry:\n    from pooch import file_hash\nexcept ModuleNotFoundError:\n    # Function taken from\n    # https://github.com/fatiando/pooch/blob/master/pooch/utils.py\n    def file_hash(fname, alg=\"sha256\"):\n        \"\"\"\n        Calculate the hash of a given file.\n        Useful for checking if a file has changed or been corrupted.\n        Parameters\n        ----------\n        fname : str\n            The name of the file.\n        alg : str\n            The type of the hashing algorithm\n        Returns\n        -------\n        hash : str\n            The hash of the file.\n        Examples\n        --------\n        >>> fname = \"test-file-for-hash.txt\"\n        >>> with open(fname, \"w\") as f:\n        ...     __ = f.write(\"content of the file\")\n        >>> print(file_hash(fname))\n        0fc74468e6a9a829f103d069aeb2bb4f8646bad58bf146bb0e3379b759ec4a00\n        >>> import os\n        >>> os.remove(fname)\n        \"\"\"\n        import hashlib\n        if alg not in hashlib.algorithms_available:\n            raise ValueError(f'Algorithm \\'{alg}\\' not available in hashlib')\n        # Calculate the hash in chunks to avoid overloading the memory\n        chunksize = 65536\n        hasher = hashlib.new(alg)\n        with open(fname, \"rb\") as fin:\n            buff = fin.read(chunksize)\n            while buff:\n                hasher.update(buff)\n                buff = fin.read(chunksize)\n        return hasher.hexdigest()\n\n\ndef _has_hash(path, expected_hash):\n    \"\"\"Check if the provided path has the expected hash.\"\"\"\n    if not osp.exists(path):\n        return False\n    return file_hash(path) == expected_hash\n\n\ndef _create_image_fetcher():\n    try:\n        import pooch\n        # older versions of Pooch don't have a __version__ attribute\n        if not hasattr(pooch, '__version__'):\n            retry = {}\n        else:\n            retry = {'retry_if_failed': 3}\n    except ImportError:\n        # Without pooch, fallback on the standard data directory\n        # which for now, includes a few limited data samples\n        return None, _LEGACY_DATA_DIR\n\n    # Pooch expects a `+` to exist in development versions.\n    # Since scikit-image doesn't follow that convention, we have to manually\n    # remove `.dev` with a `+` if it exists.\n    # This helps pooch understand that it should look in master\n    # to find the required files\n    if '+git' in __version__:\n        skimage_version_for_pooch = __version__.replace('.dev0+git', '+git')\n    else:\n        skimage_version_for_pooch = __version__.replace('.dev', '+')\n\n    if '+' in skimage_version_for_pooch:\n        url = (\"https://github.com/scikit-image/scikit-image/raw/\"\n               \"{version}/skimage/\")\n    else:\n        url = (\"https://github.com/scikit-image/scikit-image/raw/\"\n               \"v{version}/skimage/\")\n\n    # Create a new friend to manage your sample data storage\n    image_fetcher = pooch.create(\n        # Pooch uses appdirs to select an appropriate directory for the cache\n        # on each platform.\n        # https://github.com/ActiveState/appdirs\n        # On linux this converges to\n        # '$HOME/.cache/scikit-image'\n        # With a version qualifier\n        path=pooch.os_cache(\"scikit-image\"),\n        base_url=url,\n        version=skimage_version_for_pooch,\n        version_dev=\"main\",\n        env=\"SKIMAGE_DATADIR\",\n        registry=registry,\n        urls=registry_urls,\n        # Note: this should read `retry_if_failed=3,`, but we generate that\n        # dynamically at import time above, in case installed pooch is a less\n        # recent version\n        **retry,\n    )\n\n    data_dir = osp.join(str(image_fetcher.abspath), 'data')\n    return image_fetcher, data_dir\n\n\n_image_fetcher, data_dir = _create_image_fetcher()\n\n\ndef _skip_pytest_case_requiring_pooch(data_filename):\n    \"\"\"If a test case is calling pooch, skip it.\n\n    This running the test suite in environments without internet\n    access, skipping only the tests that try to fetch external data.\n    \"\"\"\n\n    # Check if pytest is currently running.\n    # Packagers might use pytest to run the tests suite, but may not\n    # want to run it online with pooch as a dependency.\n    # As such, we will avoid failing the test, and silently skipping it.\n    if 'PYTEST_CURRENT_TEST' in os.environ:\n        # https://docs.pytest.org/en/latest/example/simple.html#pytest-current-test-environment-variable  # noqa\n        import pytest\n        # Pytest skip raises an exception that allows the\n        # tests to be skipped\n        pytest.skip(f'Unable to download {data_filename}',\n                    allow_module_level=True)\n\n\ndef _ensure_cache_dir(*, target_dir):\n    \"\"\"Prepare local cache directory if it doesn't exist already.\n\n    Creates::\n\n        /path/to/target_dir/\n                  data/\n                     README.txt\n    \"\"\"\n    os.makedirs(osp.join(target_dir, \"data\"), exist_ok=True)\n    readme_src = osp.join(_DISTRIBUTION_DIR, \"data/README.txt\")\n    readme_dest = osp.join(target_dir, \"data/README.txt\")\n    if not osp.exists(readme_dest):\n        shutil.copy2(readme_src, readme_dest)\n\n\ndef _fetch(data_filename):\n    \"\"\"Fetch a given data file from either the local cache or the repository.\n\n    This function provides the path location of the data file given\n    its name in the scikit-image repository. If a data file is not included in the\n    distribution and pooch is available, it is downloaded and cached.\n\n    Parameters\n    ----------\n    data_filename : str\n        Name of the file in the scikit-image repository. e.g.\n        'restoration/tess/camera_rl.npy'.\n\n    Returns\n    -------\n    file_path : str\n        Path of the local file.\n\n    Raises\n    ------\n    KeyError:\n        If the filename is not known to the scikit-image distribution.\n\n    ModuleNotFoundError:\n        If the filename is known to the scikit-image distribution but pooch\n        is not installed.\n\n    ConnectionError:\n        If scikit-image is unable to connect to the internet but the\n        dataset has not been downloaded yet.\n    \"\"\"\n    expected_hash = registry[data_filename]\n    if _image_fetcher is None:\n        cache_dir = osp.dirname(data_dir)\n    else:\n        cache_dir = str(_image_fetcher.abspath)\n\n    # Case 1: the file is already cached in `data_cache_dir`\n    cached_file_path = osp.join(cache_dir, data_filename)\n    if _has_hash(cached_file_path, expected_hash):\n        # Nothing to be done, file is where it is expected to be\n        return cached_file_path\n\n    # Case 2: file is present in `legacy_data_dir`\n    legacy_file_path = osp.join(_DISTRIBUTION_DIR, data_filename)\n    if _has_hash(legacy_file_path, expected_hash):\n        return legacy_file_path\n\n    # Case 3: file is not present locally\n    if _image_fetcher is None:\n        _skip_pytest_case_requiring_pooch(data_filename)\n        raise ModuleNotFoundError(\n            \"The requested file is part of the scikit-image distribution, \"\n            \"but requires the installation of an optional dependency, pooch. \"\n            \"To install pooch, use your preferred python package manager. \"\n            \"Follow installation instruction found at \"\n            \"https://scikit-image.org/docs/stable/user_guide/install.html\"\n        )\n    # Download the data with pooch which caches it automatically\n    _ensure_cache_dir(target_dir=cache_dir)\n    try:\n        cached_file_path = _image_fetcher.fetch(data_filename)\n        return cached_file_path\n    except ConnectionError as err:\n        _skip_pytest_case_requiring_pooch(data_filename)\n        # If we decide in the future to suppress the underlying 'requests'\n        # error, change this to `raise ... from None`. See PEP 3134.\n        raise ConnectionError(\n            'Tried to download a scikit-image dataset, but no internet '\n            'connection is available. To avoid this message in the '\n            'future, try `skimage.data.download_all()` when you are '\n            'connected to the internet.'\n        ) from err\n\n\ndef download_all(directory=None):\n    \"\"\"Download all datasets for use with scikit-image offline.\n\n    Scikit-image datasets are no longer shipped with the library by default.\n    This allows us to use higher quality datasets, while keeping the\n    library download size small.\n\n    This function requires the installation of an optional dependency, pooch,\n    to download the full dataset. Follow installation instruction found at\n\n        https://scikit-image.org/docs/stable/user_guide/install.html\n\n    Call this function to download all sample images making them available\n    offline on your machine.\n\n    Parameters\n    ----------\n    directory: path-like, optional\n        The directory where the dataset should be stored.\n\n    Raises\n    ------\n    ModuleNotFoundError:\n        If pooch is not install, this error will be raised.\n\n    Notes\n    -----\n    scikit-image will only search for images stored in the default directory.\n    Only specify the directory if you wish to download the images to your own\n    folder for a particular reason. You can access the location of the default\n    data directory by inspecting the variable `skimage.data.data_dir`.\n    \"\"\"\n\n    if _image_fetcher is None:\n        raise ModuleNotFoundError(\n            \"To download all package data, scikit-image needs an optional \"\n            \"dependency, pooch.\"\n            \"To install pooch, follow our installation instructions found at \"\n            \"https://scikit-image.org/docs/stable/user_guide/install.html\"\n        )\n    # Consider moving this kind of logic to Pooch\n    old_dir = _image_fetcher.path\n    try:\n        if directory is not None:\n            directory = osp.expanduser(directory)\n            _image_fetcher.path = directory\n        _ensure_cache_dir(target_dir=_image_fetcher.path)\n\n        for data_filename in _image_fetcher.registry:\n            file_path = _fetch(data_filename)\n\n            # Copy to `directory` or implicit cache if it is not already there\n            if not file_path.startswith(str(_image_fetcher.path)):\n                dest_path = osp.join(_image_fetcher.path, data_filename)\n                os.makedirs(osp.dirname(dest_path), exist_ok=True)\n                shutil.copy2(file_path, dest_path)\n    finally:\n        _image_fetcher.path = old_dir\n\n\ndef lbp_frontal_face_cascade_filename():\n    \"\"\"Return the path to the XML file containing the weak classifier cascade.\n\n    These classifiers were trained using LBP features. The file is part\n    of the OpenCV repository [1]_.\n\n    References\n    ----------\n    .. [1] OpenCV lbpcascade trained files\n           https://github.com/opencv/opencv/tree/master/data/lbpcascades\n    \"\"\"\n\n    return _fetch('data/lbpcascade_frontalface_opencv.xml')\n\n\ndef _load(f, as_gray=False):\n    \"\"\"Load an image file located in the data directory.\n\n    Parameters\n    ----------\n    f : string\n        File name.\n    as_gray : bool, optional\n        Whether to convert the image to grayscale.\n\n    Returns\n    -------\n    img : ndarray\n        Image loaded from ``skimage.data_dir``.\n    \"\"\"\n    # importing io is quite slow since it scans all the backends\n    # we lazy import it here\n    from ..io import imread\n    return imread(_fetch(f), as_gray=as_gray)\n\n\ndef camera():\n    \"\"\"Gray-level \"camera\" image.\n\n    Can be used for segmentation and denoising examples.\n\n    Returns\n    -------\n    camera : (512, 512) uint8 ndarray\n        Camera image.\n\n    Notes\n    -----\n    No copyright restrictions. CC0 by the photographer (Lav Varshney).\n\n    .. versionchanged:: 0.18\n        This image was replaced due to copyright restrictions. For more\n        information, please see [1]_.\n\n    References\n    ----------\n    .. [1] https://github.com/scikit-image/scikit-image/issues/3927\n    \"\"\"\n    return _load(\"data/camera.png\")\n\n\ndef eagle():\n    \"\"\"A golden eagle.\n\n    Suitable for examples on segmentation, Hough transforms, and corner\n    detection.\n\n    Notes\n    -----\n    No copyright restrictions. CC0 by the photographer (Dayane Machado).\n\n    Returns\n    -------\n    eagle : (2019, 1826) uint8 ndarray\n        Eagle image.\n    \"\"\"\n    return _load(\"data/eagle.png\")\n\n\ndef astronaut():\n    \"\"\"Color image of the astronaut Eileen Collins.\n\n    Photograph of Eileen Collins, an American astronaut. She was selected\n    as an astronaut in 1992 and first piloted the space shuttle STS-63 in\n    1995. She retired in 2006 after spending a total of 38 days, 8 hours\n    and 10 minutes in outer space.\n\n    This image was downloaded from the NASA Great Images database\n    <https://flic.kr/p/r9qvLn>`__.\n\n    No known copyright restrictions, released into the public domain.\n\n    Returns\n    -------\n    astronaut : (512, 512, 3) uint8 ndarray\n        Astronaut image.\n    \"\"\"\n\n    return _load(\"data/astronaut.png\")\n\n\ndef brick():\n    \"\"\"Brick wall.\n\n    Returns\n    -------\n    brick : (512, 512) uint8 image\n        A small section of a brick wall.\n\n    Notes\n    -----\n    The original image was downloaded from\n    `CC0Textures <https://cc0textures.com/view.php?tex=Bricks25>`_ and licensed\n    under the Creative Commons CC0 License.\n\n    A perspective transform was then applied to the image, prior to\n    rotating it by 90 degrees, cropping and scaling it to obtain the final\n    image.\n    \"\"\"\n\n    \"\"\"\n    The following code was used to obtain the final image.\n\n    >>> import sys; print(sys.version)\n    >>> import platform; print(platform.platform())\n    >>> import skimage; print(f'scikit-image version: {skimage.__version__}')\n    >>> import numpy; print(f'numpy version: {numpy.__version__}')\n    >>> import imageio; print(f'imageio version {imageio.__version__}')\n    3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 21:52:21)\n    [GCC 7.3.0]\n    Linux-5.0.0-20-generic-x86_64-with-debian-buster-sid\n    scikit-image version: 0.16.dev0\n    numpy version: 1.16.4\n    imageio version 2.4.1\n\n    >>> import requests\n    >>> import zipfile\n    >>> url = 'https://cdn.struffelproductions.com/file/cc0textures/Bricks25/%5B2K%5DBricks25.zip'\n    >>> r = requests.get(url)\n    >>> with open('[2K]Bricks25.zip', 'bw') as f:\n    ...     f.write(r.content)\n    >>> with zipfile.ZipFile('[2K]Bricks25.zip') as z:\n    ... z.extract('Bricks25_col.jpg')\n\n    >>> from numpy.linalg import inv\n    >>> from skimage.transform import rescale, warp, rotate\n    >>> from skimage.color import rgb2gray\n    >>> from imageio import imread, imwrite\n    >>> from skimage import img_as_ubyte\n    >>> import numpy as np\n\n\n    >>> # Obtained playing around with GIMP 2.10 with their perspective tool\n    >>> H = inv(np.asarray([[ 0.54764, -0.00219, 0],\n    ...                     [-0.12822,  0.54688, 0],\n    ...                     [-0.00022,        0, 1]]))\n\n\n    >>> brick_orig = imread('Bricks25_col.jpg')\n    >>> brick = warp(brick_orig, H)\n    >>> brick = rescale(brick[:1024, :1024], (0.5, 0.5, 1))\n    >>> brick = rotate(brick, -90)\n    >>> imwrite('brick.png', img_as_ubyte(rgb2gray(brick)))\n    \"\"\"\n    return _load(\"data/brick.png\", as_gray=True)\n\n\ndef grass():\n    \"\"\"Grass.\n\n    Returns\n    -------\n    grass : (512, 512) uint8 image\n        Some grass.\n\n    Notes\n    -----\n    The original image was downloaded from\n    `DeviantArt <https://www.deviantart.com/linolafett/art/Grass-01-434853879>`__\n    and licensed under the Creative Commons CC0 License.\n\n    The downloaded image was cropped to include a region of ``(512, 512)``\n    pixels around the top left corner, converted to grayscale, then to uint8\n    prior to saving the result in PNG format.\n\n    \"\"\"\n\n    \"\"\"\n    The following code was used to obtain the final image.\n\n    >>> import sys; print(sys.version)\n    >>> import platform; print(platform.platform())\n    >>> import skimage; print(f'scikit-image version: {skimage.__version__}')\n    >>> import numpy; print(f'numpy version: {numpy.__version__}')\n    >>> import imageio; print(f'imageio version {imageio.__version__}')\n    3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 21:52:21)\n    [GCC 7.3.0]\n    Linux-5.0.0-20-generic-x86_64-with-debian-buster-sid\n    scikit-image version: 0.16.dev0\n    numpy version: 1.16.4\n    imageio version 2.4.1\n\n    >>> import requests\n    >>> import zipfile\n    >>> url = 'https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/a407467e-4ff0-49f1-923f-c9e388e84612/d76wfef-2878b78d-5dce-43f9-be36-26ec9bc0df3b.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7InBhdGgiOiJcL2ZcL2E0MDc0NjdlLTRmZjAtNDlmMS05MjNmLWM5ZTM4OGU4NDYxMlwvZDc2d2ZlZi0yODc4Yjc4ZC01ZGNlLTQzZjktYmUzNi0yNmVjOWJjMGRmM2IuanBnIn1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmZpbGUuZG93bmxvYWQiXX0.98hIcOTCqXWQ67Ec5bM5eovKEn2p91mWB3uedH61ynI'\n    >>> r = requests.get(url)\n    >>> with open('grass_orig.jpg', 'bw') as f:\n    ...     f.write(r.content)\n    >>> grass_orig = imageio.imread('grass_orig.jpg')\n    >>> grass = skimage.img_as_ubyte(skimage.color.rgb2gray(grass_orig[:512, :512]))\n    >>> imageio.imwrite('grass.png', grass)\n    \"\"\"\n    return _load(\"data/grass.png\", as_gray=True)\n\n\ndef gravel():\n    \"\"\"Gravel\n\n    Returns\n    -------\n    gravel : (512, 512) uint8 image\n        Grayscale gravel sample.\n\n    Notes\n    -----\n    The original image was downloaded from\n    `CC0Textures <https://cc0textures.com/view.php?tex=Gravel04>`__ and\n    licensed under the Creative Commons CC0 License.\n\n    The downloaded image was then rescaled to ``(1024, 1024)``, then the\n    top left ``(512, 512)`` pixel region  was cropped prior to converting the\n    image to grayscale and uint8 data type. The result was saved using the\n    PNG format.\n    \"\"\"\n\n    \"\"\"\n    The following code was used to obtain the final image.\n\n    >>> import sys; print(sys.version)\n    >>> import platform; print(platform.platform())\n    >>> import skimage; print(f'scikit-image version: {skimage.__version__}')\n    >>> import numpy; print(f'numpy version: {numpy.__version__}')\n    >>> import imageio; print(f'imageio version {imageio.__version__}')\n    3.7.3 | packaged by conda-forge | (default, Jul  1 2019, 21:52:21)\n    [GCC 7.3.0]\n    Linux-5.0.0-20-generic-x86_64-with-debian-buster-sid\n    scikit-image version: 0.16.dev0\n    numpy version: 1.16.4\n    imageio version 2.4.1\n\n    >>> import requests\n    >>> import zipfile\n\n    >>> url = 'https://cdn.struffelproductions.com/file/cc0textures/Gravel04/%5B2K%5DGravel04.zip'\n    >>> r = requests.get(url)\n    >>> with open('[2K]Gravel04.zip', 'bw') as f:\n    ...     f.write(r.content)\n\n    >>> with zipfile.ZipFile('[2K]Gravel04.zip') as z:\n    ...     z.extract('Gravel04_col.jpg')\n\n    >>> from skimage.transform import resize\n    >>> gravel_orig = imageio.imread('Gravel04_col.jpg')\n    >>> gravel = resize(gravel_orig, (1024, 1024))\n    >>> gravel = skimage.img_as_ubyte(skimage.color.rgb2gray(gravel[:512, :512]))\n    >>> imageio.imwrite('gravel.png', gravel)\n    \"\"\"\n    return _load(\"data/gravel.png\", as_gray=True)\n\n\ndef text():\n    \"\"\"Gray-level \"text\" image used for corner detection.\n\n    Notes\n    -----\n    This image was downloaded from Wikipedia\n    <https://en.wikipedia.org/wiki/File:Corner.png>`__.\n\n    No known copyright restrictions, released into the public domain.\n\n    Returns\n    -------\n    text : (172, 448) uint8 ndarray\n        Text image.\n    \"\"\"\n\n    return _load(\"data/text.png\")\n\n\ndef checkerboard():\n    \"\"\"Checkerboard image.\n\n    Checkerboards are often used in image calibration, since the\n    corner-points are easy to locate.  Because of the many parallel\n    edges, they also visualise distortions particularly well.\n\n    Returns\n    -------\n    checkerboard : (200, 200) uint8 ndarray\n        Checkerboard image.\n    \"\"\"\n    return _load(\"data/chessboard_GRAY.png\")\n\n\ndef cells3d():\n    \"\"\"3D fluorescence microscopy image of cells.\n\n    The returned data is a 3D multichannel array with dimensions provided in\n    ``(z, c, y, x)`` order. Each voxel has a size of ``(0.29 0.26 0.26)``\n    micrometer. Channel 0 contains cell membranes, channel 1 contains nuclei.\n\n    Returns\n    -------\n    cells3d: (60, 2, 256, 256) uint16 ndarray\n        The volumetric images of cells taken with an optical microscope.\n\n    Notes\n    -----\n    The data for this was provided by the Allen Institute for Cell Science.\n\n    It has been downsampled by a factor of 4 in the row and column dimensions\n    to reduce computational time.\n\n    The microscope reports the following voxel spacing in microns:\n\n        * Original voxel size is ``(0.290, 0.065, 0.065)``.\n        * Scaling factor is ``(1, 4, 4)`` in each dimension.\n        * After rescaling the voxel size is ``(0.29 0.26 0.26)``.\n    \"\"\"\n\n    return _load(\"data/cells3d.tif\")\n\n\ndef human_mitosis():\n    \"\"\"Image of human cells undergoing mitosis.\n\n    Returns\n    -------\n    human_mitosis: (512, 512) uint8 ndarray\n        Data of human cells undergoing mitosis taken during the preparation\n        of the manuscript in [1]_.\n\n    Notes\n    -----\n    Copyright David Root. Licensed under CC-0 [2]_.\n\n    References\n    ----------\n    .. [1] Moffat J, Grueneberg DA, Yang X, Kim SY, Kloepfer AM, Hinkle G,\n           Piqani B, Eisenhaure TM, Luo B, Grenier JK, Carpenter AE, Foo SY,\n           Stewart SA, Stockwell BR, Hacohen N, Hahn WC, Lander ES,\n           Sabatini DM, Root DE (2006) A lentiviral RNAi library for human and\n           mouse genes applied to an arrayed viral high-content screen. Cell,\n           124(6):1283-98 / :DOI: `10.1016/j.cell.2006.01.040` PMID 16564017\n\n    .. [2] GitHub licensing discussion\n           https://github.com/CellProfiler/examples/issues/41\n\n    \"\"\"\n    return _load('data/mitosis.tif')\n\n\ndef cell():\n    \"\"\"Cell floating in saline.\n\n    This is a quantitative phase image retrieved from a digital hologram using\n    the Python library ``qpformat``. The image shows a cell with high phase\n    value, above the background phase.\n\n    Because of a banding pattern artifact in the background, this image is a\n    good test of thresholding algorithms. The pixel spacing is 0.107 m.\n\n    These data were part of a comparison between several refractive index\n    retrieval techniques for spherical objects as part of [1]_.\n\n    This image is CC0, dedicated to the public domain. You may copy, modify, or\n    distribute it without asking permission.\n\n    Returns\n    -------\n    cell : (660, 550) uint8 array\n        Image of a cell.\n\n    References\n    ----------\n    .. [1] Paul Mller, Mirjam Schrmann, Salvatore Girardo, Gheorghe Cojoc,\n           and Jochen Guck. \"Accurate evaluation of size and refractive index\n           for spherical objects in quantitative phase imaging.\" Optics Express\n           26(8): 10729-10743 (2018). :DOI:`10.1364/OE.26.010729`\n    \"\"\"\n    return _load('data/cell.png')\n\n\ndef coins():\n    \"\"\"Greek coins from Pompeii.\n\n    This image shows several coins outlined against a gray background.\n    It is especially useful in, e.g. segmentation tests, where\n    individual objects need to be identified against a background.\n    The background shares enough grey levels with the coins that a\n    simple segmentation is not sufficient.\n\n    Notes\n    -----\n    This image was downloaded from the\n    `Brooklyn Museum Collection\n    <https://www.brooklynmuseum.org/opencollection/archives/image/51611>`__.\n\n    No known copyright restrictions.\n\n    Returns\n    -------\n    coins : (303, 384) uint8 ndarray\n        Coins image.\n    \"\"\"\n    return _load(\"data/coins.png\")\n\n\ndef kidney():\n    \"\"\"Mouse kidney tissue.\n\n    This biological tissue on a pre-prepared slide was imaged with confocal\n    fluorescence microscopy (Nikon C1 inverted microscope).\n    Image shape is (16, 512, 512, 3). That is 512x512 pixels in X-Y,\n    16 image slices in Z, and 3 color channels\n    (emission wavelengths 450nm, 515nm, and 605nm, respectively).\n    Real-space voxel size is 1.24 microns in X-Y, and 1.25 microns in Z.\n    Data type is unsigned 16-bit integers.\n\n    Notes\n    -----\n    This image was acquired by Genevieve Buckley at Monasoh Micro Imaging in\n    2018.\n    License: CC0\n\n    Returns\n    -------\n    kidney : (16, 512, 512, 3) uint16 ndarray\n        Kidney 3D multichannel image.\n    \"\"\"\n    return _load(\"data/kidney.tif\")\n\n\ndef lily():\n    \"\"\"Lily of the valley plant stem.\n\n    This plant stem on a pre-prepared slide was imaged with confocal\n    fluorescence microscopy (Nikon C1 inverted microscope).\n    Image shape is (922, 922, 4). That is 922x922 pixels in X-Y,\n    with 4 color channels.\n    Real-space voxel size is 1.24 microns in X-Y.\n    Data type is unsigned 16-bit integers.\n\n    Notes\n    -----\n    This image was acquired by Genevieve Buckley at Monasoh Micro Imaging in\n    2018.\n    License: CC0\n\n    Returns\n    -------\n    lily : (922, 922, 4) uint16 ndarray\n        Lily 2D multichannel image.\n    \"\"\"\n    return _load(\"data/lily.tif\")\n\n\ndef logo():\n    \"\"\"Scikit-image logo, a RGBA image.\n\n    Returns\n    -------\n    logo : (500, 500, 4) uint8 ndarray\n        Logo image.\n    \"\"\"\n    return _load(\"data/logo.png\")\n\n\ndef microaneurysms():\n    \"\"\"Gray-level \"microaneurysms\" image.\n\n    Detail from an image of the retina (green channel).\n    The image is a crop of image 07_dr.JPG from the\n    High-Resolution Fundus (HRF) Image Database:\n    https://www5.cs.fau.de/research/data/fundus-images/\n\n    Notes\n    -----\n    No copyright restrictions. CC0 given by owner (Andreas Maier).\n\n    Returns\n    -------\n    microaneurysms : (102, 102) uint8 ndarray\n        Retina image with lesions.\n\n    References\n    ----------\n    .. [1] Budai, A., Bock, R, Maier, A., Hornegger, J.,\n           Michelson, G. (2013).  Robust Vessel Segmentation in Fundus\n           Images. International Journal of Biomedical Imaging, vol. 2013,\n           2013.\n           :DOI:`10.1155/2013/154860`\n    \"\"\"\n    return _load(\"data/microaneurysms.png\")\n\n\ndef moon():\n    \"\"\"Surface of the moon.\n\n    This low-contrast image of the surface of the moon is useful for\n    illustrating histogram equalization and contrast stretching.\n\n    Returns\n    -------\n    moon : (512, 512) uint8 ndarray\n        Moon image.\n    \"\"\"\n    return _load(\"data/moon.png\")\n\n\ndef page():\n    \"\"\"Scanned page.\n\n    This image of printed text is useful for demonstrations requiring uneven\n    background illumination.\n\n    Returns\n    -------\n    page : (191, 384) uint8 ndarray\n        Page image.\n    \"\"\"\n    return _load(\"data/page.png\")\n\n\ndef horse():\n    \"\"\"Black and white silhouette of a horse.\n\n    This image was downloaded from\n    `openclipart <http://openclipart.org/detail/158377/horse-by-marauder>`\n\n    No copyright restrictions. CC0 given by owner (Andreas Preuss (marauder)).\n\n    Returns\n    -------\n    horse : (328, 400) bool ndarray\n        Horse image.\n    \"\"\"\n    return img_as_bool(_load(\"data/horse.png\", as_gray=True))\n\n\ndef clock():\n    \"\"\"Motion blurred clock.\n\n    This photograph of a wall clock was taken while moving the camera in an\n    approximately horizontal direction.  It may be used to illustrate\n    inverse filters and deconvolution.\n\n    Released into the public domain by the photographer (Stefan van der Walt).\n\n    Returns\n    -------\n    clock : (300, 400) uint8 ndarray\n        Clock image.\n    \"\"\"\n    return _load(\"data/clock_motion.png\")\n\n\ndef immunohistochemistry():\n    \"\"\"Immunohistochemical (IHC) staining with hematoxylin counterstaining.\n\n    This picture shows colonic glands where the IHC expression of FHL2 protein\n    is revealed with DAB. Hematoxylin counterstaining is applied to enhance the\n    negative parts of the tissue.\n\n    This image was acquired at the Center for Microscopy And Molecular Imaging\n    (CMMI).\n\n    No known copyright restrictions.\n\n    Returns\n    -------\n    immunohistochemistry : (512, 512, 3) uint8 ndarray\n        Immunohistochemistry image.\n    \"\"\"\n    return _load(\"data/ihc.png\")\n\n\ndef chelsea():\n    \"\"\"Chelsea the cat.\n\n    An example with texture, prominent edges in horizontal and diagonal\n    directions, as well as features of differing scales.\n\n    Notes\n    -----\n    No copyright restrictions.  CC0 by the photographer (Stefan van der Walt).\n\n    Returns\n    -------\n    chelsea : (300, 451, 3) uint8 ndarray\n        Chelsea image.\n    \"\"\"\n    return _load(\"data/chelsea.png\")\n\n\n# Define an alias for chelsea that is more descriptive.\ncat = chelsea\n\n\ndef coffee():\n    \"\"\"Coffee cup.\n\n    This photograph is courtesy of Pikolo Espresso Bar.\n    It contains several elliptical shapes as well as varying texture (smooth\n    porcelain to coarse wood grain).\n\n    Notes\n    -----\n    No copyright restrictions.  CC0 by the photographer (Rachel Michetti).\n\n    Returns\n    -------\n    coffee : (400, 600, 3) uint8 ndarray\n        Coffee image.\n    \"\"\"\n    return _load(\"data/coffee.png\")\n\n\ndef hubble_deep_field():\n    \"\"\"Hubble eXtreme Deep Field.\n\n    This photograph contains the Hubble Telescope's farthest ever view of\n    the universe. It can be useful as an example for multi-scale\n    detection.\n\n    Notes\n    -----\n    This image was downloaded from\n    `HubbleSite\n    <http://hubblesite.org/newscenter/archive/releases/2012/37/image/a/>`__.\n\n    The image was captured by NASA and `may be freely used in the public domain\n    <http://www.nasa.gov/audience/formedia/features/MP_Photo_Guidelines.html>`_.\n\n    Returns\n    -------\n    hubble_deep_field : (872, 1000, 3) uint8 ndarray\n        Hubble deep field image.\n    \"\"\"\n    return _load(\"data/hubble_deep_field.jpg\")\n\n\ndef retina():\n    \"\"\"Human retina.\n\n    This image of a retina is useful for demonstrations requiring circular\n    images.\n\n    Notes\n    -----\n    This image was downloaded from\n    `wikimedia <https://commons.wikimedia.org/wiki/File:Fundus_photograph_of_normal_left_eye.jpg>`.\n    This file is made available under the Creative Commons CC0 1.0 Universal\n    Public Domain Dedication.\n\n    References\n    ----------\n    .. [1] Hggstrm, Mikael (2014). \"Medical gallery of Mikael Hggstrm 2014\".\n           WikiJournal of Medicine 1 (2). :DOI:`10.15347/wjm/2014.008`.\n           ISSN 2002-4436. Public Domain\n\n    Returns\n    -------\n    retina : (1411, 1411, 3) uint8 ndarray\n        Retina image in RGB.\n    \"\"\"\n    return _load(\"data/retina.jpg\")\n\n\ndef shepp_logan_phantom():\n    \"\"\"Shepp Logan Phantom.\n\n    References\n    ----------\n    .. [1] L. A. Shepp and B. F. Logan, \"The Fourier reconstruction of a head\n           section,\" in IEEE Transactions on Nuclear Science, vol. 21,\n           no. 3, pp. 21-43, June 1974. :DOI:`10.1109/TNS.1974.6499235`\n\n    Returns\n    -------\n    phantom : (400, 400) float64 image\n        Image of the Shepp-Logan phantom in grayscale.\n    \"\"\"\n    return _load(\"data/phantom.png\", as_gray=True)\n\n\ndef colorwheel():\n    \"\"\"Color Wheel.\n\n    Returns\n    -------\n    colorwheel : (370, 371, 3) uint8 image\n        A colorwheel.\n    \"\"\"\n    return _load(\"data/color.png\")\n\n\ndef palisades_of_vogt():\n    \"\"\"Return image sequence of in-vivo tissue showing the palisades of Vogt.\n\n    In the human eye, the palisades of Vogt are normal features of the corneal\n    limbus, which is the border between the cornea and the sclera (i.e., the\n    white of the eye).\n    In the image sequence, there are some dark spots due to the presence of\n    dust on the reference mirror.\n\n    Returns\n    -------\n    palisades_of_vogt: (60, 1440, 1440) uint16 ndarray\n\n    Notes\n    -----\n    See info under `in-vivo-cornea-spots.tif` at\n    https://gitlab.com/scikit-image/data/-/blob/master/README.md#data.\n\n    \"\"\"\n    return _load('data/palisades_of_vogt.tif')\n\n\ndef rocket():\n    \"\"\"Launch photo of DSCOVR on Falcon 9 by SpaceX.\n\n    This is the launch photo of Falcon 9 carrying DSCOVR lifted off from\n    SpaceX's Launch Complex 40 at Cape Canaveral Air Force Station, FL.\n\n    Notes\n    -----\n    This image was downloaded from\n    `SpaceX Photos\n    <https://www.flickr.com/photos/spacexphotos/16511594820/in/photostream/>`__.\n\n    The image was captured by SpaceX and `released in the public domain\n    <http://arstechnica.com/tech-policy/2015/03/elon-musk-puts-spacex-photos-into-the-public-domain/>`_.\n\n    Returns\n    -------\n    rocket : (427, 640, 3) uint8 ndarray\n        Rocket image.\n    \"\"\"\n    return _load(\"data/rocket.jpg\")\n\n\ndef stereo_motorcycle():\n    \"\"\"Rectified stereo image pair with ground-truth disparities.\n\n    The two images are rectified such that every pixel in the left image has\n    its corresponding pixel on the same scanline in the right image. That means\n    that both images are warped such that they have the same orientation but a\n    horizontal spatial offset (baseline). The ground-truth pixel offset in\n    column direction is specified by the included disparity map.\n\n    The two images are part of the Middlebury 2014 stereo benchmark. The\n    dataset was created by Nera Nesic, Porter Westling, Xi Wang, York Kitajima,\n    Greg Krathwohl, and Daniel Scharstein at Middlebury College. A detailed\n    description of the acquisition process can be found in [1]_.\n\n    The images included here are down-sampled versions of the default exposure\n    images in the benchmark. The images are down-sampled by a factor of 4 using\n    the function `skimage.transform.downscale_local_mean`. The calibration data\n    in the following and the included ground-truth disparity map are valid for\n    the down-sampled images::\n\n        Focal length:           994.978px\n        Principal point x:      311.193px\n        Principal point y:      254.877px\n        Principal point dx:      31.086px\n        Baseline:               193.001mm\n\n    Returns\n    -------\n    img_left : (500, 741, 3) uint8 ndarray\n        Left stereo image.\n    img_right : (500, 741, 3) uint8 ndarray\n        Right stereo image.\n    disp : (500, 741, 3) float ndarray\n        Ground-truth disparity map, where each value describes the offset in\n        column direction between corresponding pixels in the left and the right\n        stereo images. E.g. the corresponding pixel of\n        ``img_left[10, 10 + disp[10, 10]]`` is ``img_right[10, 10]``.\n        NaNs denote pixels in the left image that do not have ground-truth.\n\n    Notes\n    -----\n    The original resolution images, images with different exposure and\n    lighting, and ground-truth depth maps can be found at the Middlebury\n    website [2]_.\n\n    References\n    ----------\n    .. [1] D. Scharstein, H. Hirschmueller, Y. Kitajima, G. Krathwohl, N.\n           Nesic, X. Wang, and P. Westling. High-resolution stereo datasets\n           with subpixel-accurate ground truth. In German Conference on Pattern\n           Recognition (GCPR 2014), Muenster, Germany, September 2014.\n    .. [2] http://vision.middlebury.edu/stereo/data/scenes2014/\n\n    \"\"\"\n    filename = _fetch(\"data/motorcycle_disp.npz\")\n    disp = np.load(filename)['arr_0']\n    return (_load(\"data/motorcycle_left.png\"),\n            _load(\"data/motorcycle_right.png\"),\n            disp)\n\n\ndef lfw_subset():\n    \"\"\"Subset of data from the LFW dataset.\n\n    This database is a subset of the LFW database containing:\n\n    * 100 faces\n    * 100 non-faces\n\n    The full dataset is available at [2]_.\n\n    Returns\n    -------\n    images : (200, 25, 25) uint8 ndarray\n        100 first images are faces and subsequent 100 are non-faces.\n\n    Notes\n    -----\n    The faces were randomly selected from the LFW dataset and the non-faces\n    were extracted from the background of the same dataset. The cropped ROIs\n    have been resized to a 25 x 25 pixels.\n\n    References\n    ----------\n    .. [1] Huang, G., Mattar, M., Lee, H., & Learned-Miller, E. G. (2012).\n           Learning to align from scratch. In Advances in Neural Information\n           Processing Systems (pp. 764-772).\n    .. [2] http://vis-www.cs.umass.edu/lfw/\n\n    \"\"\"\n    return np.load(_fetch('data/lfw_subset.npy'))\n\n\ndef skin():\n    \"\"\"Microscopy image of dermis and epidermis (skin layers).\n\n    Hematoxylin and eosin stained slide at 10x of normal epidermis and dermis\n    with a benign intradermal nevus.\n\n    Notes\n    -----\n    This image requires an Internet connection the first time it is called,\n    and to have the ``pooch`` package installed, in order to fetch the image\n    file from the scikit-image datasets repository.\n\n    The source of this image is\n    https://en.wikipedia.org/wiki/File:Normal_Epidermis_and_Dermis_with_Intradermal_Nevus_10x.JPG\n\n    The image was released in the public domain by its author Kilbad.\n\n    Returns\n    -------\n    skin : (960, 1280, 3) RGB image of uint8\n    \"\"\"\n    return _load('data/skin.jpg')\n\n\ndef nickel_solidification():\n    \"\"\"Image sequence of synchrotron x-radiographs showing the rapid\n    solidification of a nickel alloy sample.\n\n    Returns\n    -------\n    nickel_solidification: (11, 384, 512) uint16 ndarray\n\n    Notes\n    -----\n    See info under `nickel_solidification.tif` at\n    https://gitlab.com/scikit-image/data/-/blob/master/README.md#data.\n\n    \"\"\"\n    return _load('data/solidification.tif')\n\n\ndef protein_transport():\n    \"\"\"Microscopy image sequence with fluorescence tagging of proteins\n    re-localizing from the cytoplasmic area to the nuclear envelope.\n\n    Returns\n    -------\n    protein_transport: (15, 2, 180, 183) uint8 ndarray\n\n    Notes\n    -----\n    See info under `NPCsingleNucleus.tif` at\n    https://gitlab.com/scikit-image/data/-/blob/master/README.md#data.\n\n    \"\"\"\n    return _load('data/protein_transport.tif')\n\n\ndef brain():\n    \"\"\"Subset of data from the University of North Carolina Volume Rendering\n    Test Data Set.\n\n    The full dataset is available at [1]_.\n\n    Returns\n    -------\n    image : (10, 256, 256) uint16 ndarray\n\n    Notes\n    -----\n    The 3D volume consists of 10 layers from the larger volume.\n\n    References\n    ----------\n    .. [1] https://graphics.stanford.edu/data/voldata/\n\n    \"\"\"\n    return _load(\"data/brain.tiff\")\n\n\ndef vortex():\n    \"\"\"Case B1 image pair from the first PIV challenge.\n\n    Returns\n    -------\n    image0, image1 : (512, 512) grayscale images\n        A pair of images featuring synthetic moving particles.\n\n    Notes\n    -----\n    This image was licensed as CC0 by its author, Prof. Koji Okamoto, with\n    thanks to Prof. Jun Sakakibara, who maintains the PIV Challenge site.\n\n    References\n    ----------\n    .. [1] Particle Image Velocimetry (PIV) Challenge site\n           http://pivchallenge.org\n    .. [2] 1st PIV challenge Case B: http://pivchallenge.org/pub/index.html#b\n    \"\"\"\n    return (_load('data/pivchallenge-B-B001_1.tif'),\n            _load('data/pivchallenge-B-B001_2.tif'))\n",1246],"C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py":["\"\"\"Utilities for with-statement contexts.  See PEP 343.\"\"\"\nimport abc\nimport os\nimport sys\nimport _collections_abc\nfrom collections import deque\nfrom functools import wraps\nfrom types import MethodType, GenericAlias\n\n__all__ = [\"asynccontextmanager\", \"contextmanager\", \"closing\", \"nullcontext\",\n           \"AbstractContextManager\", \"AbstractAsyncContextManager\",\n           \"AsyncExitStack\", \"ContextDecorator\", \"ExitStack\",\n           \"redirect_stdout\", \"redirect_stderr\", \"suppress\", \"aclosing\",\n           \"chdir\"]\n\n\nclass AbstractContextManager(abc.ABC):\n\n    \"\"\"An abstract base class for context managers.\"\"\"\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n    def __enter__(self):\n        \"\"\"Return `self` upon entering the runtime context.\"\"\"\n        return self\n\n    @abc.abstractmethod\n    def __exit__(self, exc_type, exc_value, traceback):\n        \"\"\"Raise any exception triggered within the runtime context.\"\"\"\n        return None\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is AbstractContextManager:\n            return _collections_abc._check_methods(C, \"__enter__\", \"__exit__\")\n        return NotImplemented\n\n\nclass AbstractAsyncContextManager(abc.ABC):\n\n    \"\"\"An abstract base class for asynchronous context managers.\"\"\"\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n    async def __aenter__(self):\n        \"\"\"Return `self` upon entering the runtime context.\"\"\"\n        return self\n\n    @abc.abstractmethod\n    async def __aexit__(self, exc_type, exc_value, traceback):\n        \"\"\"Raise any exception triggered within the runtime context.\"\"\"\n        return None\n\n    @classmethod\n    def __subclasshook__(cls, C):\n        if cls is AbstractAsyncContextManager:\n            return _collections_abc._check_methods(C, \"__aenter__\",\n                                                   \"__aexit__\")\n        return NotImplemented\n\n\nclass ContextDecorator(object):\n    \"A base class or mixin that enables context managers to work as decorators.\"\n\n    def _recreate_cm(self):\n        \"\"\"Return a recreated instance of self.\n\n        Allows an otherwise one-shot context manager like\n        _GeneratorContextManager to support use as\n        a decorator via implicit recreation.\n\n        This is a private interface just for _GeneratorContextManager.\n        See issue #11647 for details.\n        \"\"\"\n        return self\n\n    def __call__(self, func):\n        @wraps(func)\n        def inner(*args, **kwds):\n            with self._recreate_cm():\n                return func(*args, **kwds)\n        return inner\n\n\nclass AsyncContextDecorator(object):\n    \"A base class or mixin that enables async context managers to work as decorators.\"\n\n    def _recreate_cm(self):\n        \"\"\"Return a recreated instance of self.\n        \"\"\"\n        return self\n\n    def __call__(self, func):\n        @wraps(func)\n        async def inner(*args, **kwds):\n            async with self._recreate_cm():\n                return await func(*args, **kwds)\n        return inner\n\n\nclass _GeneratorContextManagerBase:\n    \"\"\"Shared functionality for @contextmanager and @asynccontextmanager.\"\"\"\n\n    def __init__(self, func, args, kwds):\n        self.gen = func(*args, **kwds)\n        self.func, self.args, self.kwds = func, args, kwds\n        # Issue 19330: ensure context manager instances have good docstrings\n        doc = getattr(func, \"__doc__\", None)\n        if doc is None:\n            doc = type(self).__doc__\n        self.__doc__ = doc\n        # Unfortunately, this still doesn't provide good help output when\n        # inspecting the created context manager instances, since pydoc\n        # currently bypasses the instance docstring and shows the docstring\n        # for the class instead.\n        # See http://bugs.python.org/issue19404 for more details.\n\n    def _recreate_cm(self):\n        # _GCMB instances are one-shot context managers, so the\n        # CM must be recreated each time a decorated function is\n        # called\n        return self.__class__(self.func, self.args, self.kwds)\n\n\nclass _GeneratorContextManager(\n    _GeneratorContextManagerBase,\n    AbstractContextManager,\n    ContextDecorator,\n):\n    \"\"\"Helper for @contextmanager decorator.\"\"\"\n\n    def __enter__(self):\n        # do not keep args and kwds alive unnecessarily\n        # they are only needed for recreation, which is not possible anymore\n        del self.args, self.kwds, self.func\n        try:\n            return next(self.gen)\n        except StopIteration:\n            raise RuntimeError(\"generator didn't yield\") from None\n\n    def __exit__(self, typ, value, traceback):\n        if typ is None:\n            try:\n                next(self.gen)\n            except StopIteration:\n                return False\n            else:\n                raise RuntimeError(\"generator didn't stop\")\n        else:\n            if value is None:\n                # Need to force instantiation so we can reliably\n                # tell if we get the same exception back\n                value = typ()\n            try:\n                self.gen.throw(typ, value, traceback)\n            except StopIteration as exc:\n                # Suppress StopIteration *unless* it's the same exception that\n                # was passed to throw().  This prevents a StopIteration\n                # raised inside the \"with\" statement from being suppressed.\n                return exc is not value\n            except RuntimeError as exc:\n                # Don't re-raise the passed in exception. (issue27122)\n                if exc is value:\n                    exc.__traceback__ = traceback\n                    return False\n                # Avoid suppressing if a StopIteration exception\n                # was passed to throw() and later wrapped into a RuntimeError\n                # (see PEP 479 for sync generators; async generators also\n                # have this behavior). But do this only if the exception wrapped\n                # by the RuntimeError is actually Stop(Async)Iteration (see\n                # issue29692).\n                if (\n                    isinstance(value, StopIteration)\n                    and exc.__cause__ is value\n                ):\n                    value.__traceback__ = traceback\n                    return False\n                raise\n            except BaseException as exc:\n                # only re-raise if it's *not* the exception that was\n                # passed to throw(), because __exit__() must not raise\n                # an exception unless __exit__() itself failed.  But throw()\n                # has to raise the exception to signal propagation, so this\n                # fixes the impedance mismatch between the throw() protocol\n                # and the __exit__() protocol.\n                if exc is not value:\n                    raise\n                exc.__traceback__ = traceback\n                return False\n            raise RuntimeError(\"generator didn't stop after throw()\")\n\nclass _AsyncGeneratorContextManager(\n    _GeneratorContextManagerBase,\n    AbstractAsyncContextManager,\n    AsyncContextDecorator,\n):\n    \"\"\"Helper for @asynccontextmanager decorator.\"\"\"\n\n    async def __aenter__(self):\n        # do not keep args and kwds alive unnecessarily\n        # they are only needed for recreation, which is not possible anymore\n        del self.args, self.kwds, self.func\n        try:\n            return await anext(self.gen)\n        except StopAsyncIteration:\n            raise RuntimeError(\"generator didn't yield\") from None\n\n    async def __aexit__(self, typ, value, traceback):\n        if typ is None:\n            try:\n                await anext(self.gen)\n            except StopAsyncIteration:\n                return False\n            else:\n                raise RuntimeError(\"generator didn't stop\")\n        else:\n            if value is None:\n                # Need to force instantiation so we can reliably\n                # tell if we get the same exception back\n                value = typ()\n            try:\n                await self.gen.athrow(typ, value, traceback)\n            except StopAsyncIteration as exc:\n                # Suppress StopIteration *unless* it's the same exception that\n                # was passed to throw().  This prevents a StopIteration\n                # raised inside the \"with\" statement from being suppressed.\n                return exc is not value\n            except RuntimeError as exc:\n                # Don't re-raise the passed in exception. (issue27122)\n                if exc is value:\n                    exc.__traceback__ = traceback\n                    return False\n                # Avoid suppressing if a Stop(Async)Iteration exception\n                # was passed to athrow() and later wrapped into a RuntimeError\n                # (see PEP 479 for sync generators; async generators also\n                # have this behavior). But do this only if the exception wrapped\n                # by the RuntimeError is actually Stop(Async)Iteration (see\n                # issue29692).\n                if (\n                    isinstance(value, (StopIteration, StopAsyncIteration))\n                    and exc.__cause__ is value\n                ):\n                    value.__traceback__ = traceback\n                    return False\n                raise\n            except BaseException as exc:\n                # only re-raise if it's *not* the exception that was\n                # passed to throw(), because __exit__() must not raise\n                # an exception unless __exit__() itself failed.  But throw()\n                # has to raise the exception to signal propagation, so this\n                # fixes the impedance mismatch between the throw() protocol\n                # and the __exit__() protocol.\n                if exc is not value:\n                    raise\n                exc.__traceback__ = traceback\n                return False\n            raise RuntimeError(\"generator didn't stop after athrow()\")\n\n\ndef contextmanager(func):\n    \"\"\"@contextmanager decorator.\n\n    Typical usage:\n\n        @contextmanager\n        def some_generator(<arguments>):\n            <setup>\n            try:\n                yield <value>\n            finally:\n                <cleanup>\n\n    This makes this:\n\n        with some_generator(<arguments>) as <variable>:\n            <body>\n\n    equivalent to this:\n\n        <setup>\n        try:\n            <variable> = <value>\n            <body>\n        finally:\n            <cleanup>\n    \"\"\"\n    @wraps(func)\n    def helper(*args, **kwds):\n        return _GeneratorContextManager(func, args, kwds)\n    return helper\n\n\ndef asynccontextmanager(func):\n    \"\"\"@asynccontextmanager decorator.\n\n    Typical usage:\n\n        @asynccontextmanager\n        async def some_async_generator(<arguments>):\n            <setup>\n            try:\n                yield <value>\n            finally:\n                <cleanup>\n\n    This makes this:\n\n        async with some_async_generator(<arguments>) as <variable>:\n            <body>\n\n    equivalent to this:\n\n        <setup>\n        try:\n            <variable> = <value>\n            <body>\n        finally:\n            <cleanup>\n    \"\"\"\n    @wraps(func)\n    def helper(*args, **kwds):\n        return _AsyncGeneratorContextManager(func, args, kwds)\n    return helper\n\n\nclass closing(AbstractContextManager):\n    \"\"\"Context to automatically close something at the end of a block.\n\n    Code like this:\n\n        with closing(<module>.open(<arguments>)) as f:\n            <block>\n\n    is equivalent to this:\n\n        f = <module>.open(<arguments>)\n        try:\n            <block>\n        finally:\n            f.close()\n\n    \"\"\"\n    def __init__(self, thing):\n        self.thing = thing\n    def __enter__(self):\n        return self.thing\n    def __exit__(self, *exc_info):\n        self.thing.close()\n\n\nclass aclosing(AbstractAsyncContextManager):\n    \"\"\"Async context manager for safely finalizing an asynchronously cleaned-up\n    resource such as an async generator, calling its ``aclose()`` method.\n\n    Code like this:\n\n        async with aclosing(<module>.fetch(<arguments>)) as agen:\n            <block>\n\n    is equivalent to this:\n\n        agen = <module>.fetch(<arguments>)\n        try:\n            <block>\n        finally:\n            await agen.aclose()\n\n    \"\"\"\n    def __init__(self, thing):\n        self.thing = thing\n    async def __aenter__(self):\n        return self.thing\n    async def __aexit__(self, *exc_info):\n        await self.thing.aclose()\n\n\nclass _RedirectStream(AbstractContextManager):\n\n    _stream = None\n\n    def __init__(self, new_target):\n        self._new_target = new_target\n        # We use a list of old targets to make this CM re-entrant\n        self._old_targets = []\n\n    def __enter__(self):\n        self._old_targets.append(getattr(sys, self._stream))\n        setattr(sys, self._stream, self._new_target)\n        return self._new_target\n\n    def __exit__(self, exctype, excinst, exctb):\n        setattr(sys, self._stream, self._old_targets.pop())\n\n\nclass redirect_stdout(_RedirectStream):\n    \"\"\"Context manager for temporarily redirecting stdout to another file.\n\n        # How to send help() to stderr\n        with redirect_stdout(sys.stderr):\n            help(dir)\n\n        # How to write help() to a file\n        with open('help.txt', 'w') as f:\n            with redirect_stdout(f):\n                help(pow)\n    \"\"\"\n\n    _stream = \"stdout\"\n\n\nclass redirect_stderr(_RedirectStream):\n    \"\"\"Context manager for temporarily redirecting stderr to another file.\"\"\"\n\n    _stream = \"stderr\"\n\n\nclass suppress(AbstractContextManager):\n    \"\"\"Context manager to suppress specified exceptions\n\n    After the exception is suppressed, execution proceeds with the next\n    statement following the with statement.\n\n         with suppress(FileNotFoundError):\n             os.remove(somefile)\n         # Execution still resumes here if the file was already removed\n    \"\"\"\n\n    def __init__(self, *exceptions):\n        self._exceptions = exceptions\n\n    def __enter__(self):\n        pass\n\n    def __exit__(self, exctype, excinst, exctb):\n        # Unlike isinstance and issubclass, CPython exception handling\n        # currently only looks at the concrete type hierarchy (ignoring\n        # the instance and subclass checking hooks). While Guido considers\n        # that a bug rather than a feature, it's a fairly hard one to fix\n        # due to various internal implementation details. suppress provides\n        # the simpler issubclass based semantics, rather than trying to\n        # exactly reproduce the limitations of the CPython interpreter.\n        #\n        # See http://bugs.python.org/issue12029 for more details\n        return exctype is not None and issubclass(exctype, self._exceptions)\n\n\nclass _BaseExitStack:\n    \"\"\"A base class for ExitStack and AsyncExitStack.\"\"\"\n\n    @staticmethod\n    def _create_exit_wrapper(cm, cm_exit):\n        return MethodType(cm_exit, cm)\n\n    @staticmethod\n    def _create_cb_wrapper(callback, /, *args, **kwds):\n        def _exit_wrapper(exc_type, exc, tb):\n            callback(*args, **kwds)\n        return _exit_wrapper\n\n    def __init__(self):\n        self._exit_callbacks = deque()\n\n    def pop_all(self):\n        \"\"\"Preserve the context stack by transferring it to a new instance.\"\"\"\n        new_stack = type(self)()\n        new_stack._exit_callbacks = self._exit_callbacks\n        self._exit_callbacks = deque()\n        return new_stack\n\n    def push(self, exit):\n        \"\"\"Registers a callback with the standard __exit__ method signature.\n\n        Can suppress exceptions the same way __exit__ method can.\n        Also accepts any object with an __exit__ method (registering a call\n        to the method instead of the object itself).\n        \"\"\"\n        # We use an unbound method rather than a bound method to follow\n        # the standard lookup behaviour for special methods.\n        _cb_type = type(exit)\n\n        try:\n            exit_method = _cb_type.__exit__\n        except AttributeError:\n            # Not a context manager, so assume it's a callable.\n            self._push_exit_callback(exit)\n        else:\n            self._push_cm_exit(exit, exit_method)\n        return exit  # Allow use as a decorator.\n\n    def enter_context(self, cm):\n        \"\"\"Enters the supplied context manager.\n\n        If successful, also pushes its __exit__ method as a callback and\n        returns the result of the __enter__ method.\n        \"\"\"\n        # We look up the special methods on the type to match the with\n        # statement.\n        cls = type(cm)\n        try:\n            _enter = cls.__enter__\n            _exit = cls.__exit__\n        except AttributeError:\n            raise TypeError(f\"'{cls.__module__}.{cls.__qualname__}' object does \"\n                            f\"not support the context manager protocol\") from None\n        result = _enter(cm)\n        self._push_cm_exit(cm, _exit)\n        return result\n\n    def callback(self, callback, /, *args, **kwds):\n        \"\"\"Registers an arbitrary callback and arguments.\n\n        Cannot suppress exceptions.\n        \"\"\"\n        _exit_wrapper = self._create_cb_wrapper(callback, *args, **kwds)\n\n        # We changed the signature, so using @wraps is not appropriate, but\n        # setting __wrapped__ may still help with introspection.\n        _exit_wrapper.__wrapped__ = callback\n        self._push_exit_callback(_exit_wrapper)\n        return callback  # Allow use as a decorator\n\n    def _push_cm_exit(self, cm, cm_exit):\n        \"\"\"Helper to correctly register callbacks to __exit__ methods.\"\"\"\n        _exit_wrapper = self._create_exit_wrapper(cm, cm_exit)\n        self._push_exit_callback(_exit_wrapper, True)\n\n    def _push_exit_callback(self, callback, is_sync=True):\n        self._exit_callbacks.append((is_sync, callback))\n\n\n# Inspired by discussions on http://bugs.python.org/issue13585\nclass ExitStack(_BaseExitStack, AbstractContextManager):\n    \"\"\"Context manager for dynamic management of a stack of exit callbacks.\n\n    For example:\n        with ExitStack() as stack:\n            files = [stack.enter_context(open(fname)) for fname in filenames]\n            # All opened files will automatically be closed at the end of\n            # the with statement, even if attempts to open files later\n            # in the list raise an exception.\n    \"\"\"\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc_details):\n        received_exc = exc_details[0] is not None\n\n        # We manipulate the exception state so it behaves as though\n        # we were actually nesting multiple with statements\n        frame_exc = sys.exc_info()[1]\n        def _fix_exception_context(new_exc, old_exc):\n            # Context may not be correct, so find the end of the chain\n            while 1:\n                exc_context = new_exc.__context__\n                if exc_context is None or exc_context is old_exc:\n                    # Context is already set correctly (see issue 20317)\n                    return\n                if exc_context is frame_exc:\n                    break\n                new_exc = exc_context\n            # Change the end of the chain to point to the exception\n            # we expect it to reference\n            new_exc.__context__ = old_exc\n\n        # Callbacks are invoked in LIFO order to match the behaviour of\n        # nested context managers\n        suppressed_exc = False\n        pending_raise = False\n        while self._exit_callbacks:\n            is_sync, cb = self._exit_callbacks.pop()\n            assert is_sync\n            try:\n                if cb(*exc_details):\n                    suppressed_exc = True\n                    pending_raise = False\n                    exc_details = (None, None, None)\n            except:\n                new_exc_details = sys.exc_info()\n                # simulate the stack of exceptions by setting the context\n                _fix_exception_context(new_exc_details[1], exc_details[1])\n                pending_raise = True\n                exc_details = new_exc_details\n        if pending_raise:\n            try:\n                # bare \"raise exc_details[1]\" replaces our carefully\n                # set-up context\n                fixed_ctx = exc_details[1].__context__\n                raise exc_details[1]\n            except BaseException:\n                exc_details[1].__context__ = fixed_ctx\n                raise\n        return received_exc and suppressed_exc\n\n    def close(self):\n        \"\"\"Immediately unwind the context stack.\"\"\"\n        self.__exit__(None, None, None)\n\n\n# Inspired by discussions on https://bugs.python.org/issue29302\nclass AsyncExitStack(_BaseExitStack, AbstractAsyncContextManager):\n    \"\"\"Async context manager for dynamic management of a stack of exit\n    callbacks.\n\n    For example:\n        async with AsyncExitStack() as stack:\n            connections = [await stack.enter_async_context(get_connection())\n                for i in range(5)]\n            # All opened connections will automatically be released at the\n            # end of the async with statement, even if attempts to open a\n            # connection later in the list raise an exception.\n    \"\"\"\n\n    @staticmethod\n    def _create_async_exit_wrapper(cm, cm_exit):\n        return MethodType(cm_exit, cm)\n\n    @staticmethod\n    def _create_async_cb_wrapper(callback, /, *args, **kwds):\n        async def _exit_wrapper(exc_type, exc, tb):\n            await callback(*args, **kwds)\n        return _exit_wrapper\n\n    async def enter_async_context(self, cm):\n        \"\"\"Enters the supplied async context manager.\n\n        If successful, also pushes its __aexit__ method as a callback and\n        returns the result of the __aenter__ method.\n        \"\"\"\n        cls = type(cm)\n        try:\n            _enter = cls.__aenter__\n            _exit = cls.__aexit__\n        except AttributeError:\n            raise TypeError(f\"'{cls.__module__}.{cls.__qualname__}' object does \"\n                            f\"not support the asynchronous context manager protocol\"\n                           ) from None\n        result = await _enter(cm)\n        self._push_async_cm_exit(cm, _exit)\n        return result\n\n    def push_async_exit(self, exit):\n        \"\"\"Registers a coroutine function with the standard __aexit__ method\n        signature.\n\n        Can suppress exceptions the same way __aexit__ method can.\n        Also accepts any object with an __aexit__ method (registering a call\n        to the method instead of the object itself).\n        \"\"\"\n        _cb_type = type(exit)\n        try:\n            exit_method = _cb_type.__aexit__\n        except AttributeError:\n            # Not an async context manager, so assume it's a coroutine function\n            self._push_exit_callback(exit, False)\n        else:\n            self._push_async_cm_exit(exit, exit_method)\n        return exit  # Allow use as a decorator\n\n    def push_async_callback(self, callback, /, *args, **kwds):\n        \"\"\"Registers an arbitrary coroutine function and arguments.\n\n        Cannot suppress exceptions.\n        \"\"\"\n        _exit_wrapper = self._create_async_cb_wrapper(callback, *args, **kwds)\n\n        # We changed the signature, so using @wraps is not appropriate, but\n        # setting __wrapped__ may still help with introspection.\n        _exit_wrapper.__wrapped__ = callback\n        self._push_exit_callback(_exit_wrapper, False)\n        return callback  # Allow use as a decorator\n\n    async def aclose(self):\n        \"\"\"Immediately unwind the context stack.\"\"\"\n        await self.__aexit__(None, None, None)\n\n    def _push_async_cm_exit(self, cm, cm_exit):\n        \"\"\"Helper to correctly register coroutine function to __aexit__\n        method.\"\"\"\n        _exit_wrapper = self._create_async_exit_wrapper(cm, cm_exit)\n        self._push_exit_callback(_exit_wrapper, False)\n\n    async def __aenter__(self):\n        return self\n\n    async def __aexit__(self, *exc_details):\n        received_exc = exc_details[0] is not None\n\n        # We manipulate the exception state so it behaves as though\n        # we were actually nesting multiple with statements\n        frame_exc = sys.exc_info()[1]\n        def _fix_exception_context(new_exc, old_exc):\n            # Context may not be correct, so find the end of the chain\n            while 1:\n                exc_context = new_exc.__context__\n                if exc_context is None or exc_context is old_exc:\n                    # Context is already set correctly (see issue 20317)\n                    return\n                if exc_context is frame_exc:\n                    break\n                new_exc = exc_context\n            # Change the end of the chain to point to the exception\n            # we expect it to reference\n            new_exc.__context__ = old_exc\n\n        # Callbacks are invoked in LIFO order to match the behaviour of\n        # nested context managers\n        suppressed_exc = False\n        pending_raise = False\n        while self._exit_callbacks:\n            is_sync, cb = self._exit_callbacks.pop()\n            try:\n                if is_sync:\n                    cb_suppress = cb(*exc_details)\n                else:\n                    cb_suppress = await cb(*exc_details)\n\n                if cb_suppress:\n                    suppressed_exc = True\n                    pending_raise = False\n                    exc_details = (None, None, None)\n            except:\n                new_exc_details = sys.exc_info()\n                # simulate the stack of exceptions by setting the context\n                _fix_exception_context(new_exc_details[1], exc_details[1])\n                pending_raise = True\n                exc_details = new_exc_details\n        if pending_raise:\n            try:\n                # bare \"raise exc_details[1]\" replaces our carefully\n                # set-up context\n                fixed_ctx = exc_details[1].__context__\n                raise exc_details[1]\n            except BaseException:\n                exc_details[1].__context__ = fixed_ctx\n                raise\n        return received_exc and suppressed_exc\n\n\nclass nullcontext(AbstractContextManager, AbstractAsyncContextManager):\n    \"\"\"Context manager that does no additional processing.\n\n    Used as a stand-in for a normal context manager, when a particular\n    block of code is only sometimes used with a normal context manager:\n\n    cm = optional_cm if condition else nullcontext()\n    with cm:\n        # Perform operation, using optional_cm if condition is True\n    \"\"\"\n\n    def __init__(self, enter_result=None):\n        self.enter_result = enter_result\n\n    def __enter__(self):\n        return self.enter_result\n\n    def __exit__(self, *excinfo):\n        pass\n\n    async def __aenter__(self):\n        return self.enter_result\n\n    async def __aexit__(self, *excinfo):\n        pass\n\n\nclass chdir(AbstractContextManager):\n    \"\"\"Non thread-safe context manager to change the current working directory.\"\"\"\n\n    def __init__(self, path):\n        self.path = path\n        self._old_cwd = []\n\n    def __enter__(self):\n        self._old_cwd.append(os.getcwd())\n        os.chdir(self.path)\n\n    def __exit__(self, *excinfo):\n        os.chdir(self._old_cwd.pop())\n",779],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\util.py":["import urllib.parse\nimport urllib.request\nfrom urllib.error import URLError, HTTPError\n\nimport os\nimport re\nimport tempfile\nfrom contextlib import contextmanager\n\n\nURL_REGEX = re.compile(r'http://|https://|ftp://|file://|file:\\\\')\n\n\ndef is_url(filename):\n    \"\"\"Return True if string is an http or ftp path.\"\"\"\n    return (isinstance(filename, str) and\n            URL_REGEX.match(filename) is not None)\n\n\n@contextmanager\ndef file_or_url_context(resource_name):\n    \"\"\"Yield name of file from the given resource (i.e. file or url).\"\"\"\n    if is_url(resource_name):\n        url_components = urllib.parse.urlparse(resource_name)\n        _, ext = os.path.splitext(url_components.path)\n        try:\n            with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as f:\n                with urllib.request.urlopen(resource_name) as u:\n                    f.write(u.read())\n            # f must be closed before yielding\n            yield f.name\n        except (URLError, HTTPError):\n            # could not open URL\n            os.remove(f.name)\n            raise\n        except (FileNotFoundError, FileExistsError,\n                PermissionError, BaseException):\n            # could not create temporary file\n            raise\n        else:\n            os.remove(f.name)\n    else:\n        yield resource_name\n",43],"C:\\Users\\adam\\miniconda3\\Lib\\enum.py":["import sys\nimport builtins as bltns\nfrom types import MappingProxyType, DynamicClassAttribute\nfrom operator import or_ as _or_\nfrom functools import reduce\n\n\n__all__ = [\n        'EnumType', 'EnumMeta',\n        'Enum', 'IntEnum', 'StrEnum', 'Flag', 'IntFlag', 'ReprEnum',\n        'auto', 'unique', 'property', 'verify', 'member', 'nonmember',\n        'FlagBoundary', 'STRICT', 'CONFORM', 'EJECT', 'KEEP',\n        'global_flag_repr', 'global_enum_repr', 'global_str', 'global_enum',\n        'EnumCheck', 'CONTINUOUS', 'NAMED_FLAGS', 'UNIQUE',\n        'pickle_by_global_name', 'pickle_by_enum_name',\n        ]\n\n\n# Dummy value for Enum and Flag as there are explicit checks for them\n# before they have been created.\n# This is also why there are checks in EnumType like `if Enum is not None`\nEnum = Flag = EJECT = _stdlib_enums = ReprEnum = None\n\nclass nonmember(object):\n    \"\"\"\n    Protects item from becoming an Enum member during class creation.\n    \"\"\"\n    def __init__(self, value):\n        self.value = value\n\nclass member(object):\n    \"\"\"\n    Forces item to become an Enum member during class creation.\n    \"\"\"\n    def __init__(self, value):\n        self.value = value\n\ndef _is_descriptor(obj):\n    \"\"\"\n    Returns True if obj is a descriptor, False otherwise.\n    \"\"\"\n    return (\n            hasattr(obj, '__get__') or\n            hasattr(obj, '__set__') or\n            hasattr(obj, '__delete__')\n            )\n\ndef _is_dunder(name):\n    \"\"\"\n    Returns True if a __dunder__ name, False otherwise.\n    \"\"\"\n    return (\n            len(name) > 4 and\n            name[:2] == name[-2:] == '__' and\n            name[2] != '_' and\n            name[-3] != '_'\n            )\n\ndef _is_sunder(name):\n    \"\"\"\n    Returns True if a _sunder_ name, False otherwise.\n    \"\"\"\n    return (\n            len(name) > 2 and\n            name[0] == name[-1] == '_' and\n            name[1:2] != '_' and\n            name[-2:-1] != '_'\n            )\n\ndef _is_internal_class(cls_name, obj):\n    # do not use `re` as `re` imports `enum`\n    if not isinstance(obj, type):\n        return False\n    qualname = getattr(obj, '__qualname__', '')\n    s_pattern = cls_name + '.' + getattr(obj, '__name__', '')\n    e_pattern = '.' + s_pattern\n    return qualname == s_pattern or qualname.endswith(e_pattern)\n\ndef _is_private(cls_name, name):\n    # do not use `re` as `re` imports `enum`\n    pattern = '_%s__' % (cls_name, )\n    pat_len = len(pattern)\n    if (\n            len(name) > pat_len\n            and name.startswith(pattern)\n            and name[pat_len:pat_len+1] != ['_']\n            and (name[-1] != '_' or name[-2] != '_')\n        ):\n        return True\n    else:\n        return False\n\ndef _is_single_bit(num):\n    \"\"\"\n    True if only one bit set in num (should be an int)\n    \"\"\"\n    if num == 0:\n        return False\n    num &= num - 1\n    return num == 0\n\ndef _make_class_unpicklable(obj):\n    \"\"\"\n    Make the given obj un-picklable.\n\n    obj should be either a dictionary, or an Enum\n    \"\"\"\n    def _break_on_call_reduce(self, proto):\n        raise TypeError('%r cannot be pickled' % self)\n    if isinstance(obj, dict):\n        obj['__reduce_ex__'] = _break_on_call_reduce\n        obj['__module__'] = '<unknown>'\n    else:\n        setattr(obj, '__reduce_ex__', _break_on_call_reduce)\n        setattr(obj, '__module__', '<unknown>')\n\ndef _iter_bits_lsb(num):\n    # num must be a positive integer\n    original = num\n    if isinstance(num, Enum):\n        num = num.value\n    if num < 0:\n        raise ValueError('%r is not a positive integer' % original)\n    while num:\n        b = num & (~num + 1)\n        yield b\n        num ^= b\n\ndef show_flag_values(value):\n    return list(_iter_bits_lsb(value))\n\ndef bin(num, max_bits=None):\n    \"\"\"\n    Like built-in bin(), except negative values are represented in\n    twos-compliment, and the leading bit always indicates sign\n    (0=positive, 1=negative).\n\n    >>> bin(10)\n    '0b0 1010'\n    >>> bin(~10)   # ~10 is -11\n    '0b1 0101'\n    \"\"\"\n\n    ceiling = 2 ** (num).bit_length()\n    if num >= 0:\n        s = bltns.bin(num + ceiling).replace('1', '0', 1)\n    else:\n        s = bltns.bin(~num ^ (ceiling - 1) + ceiling)\n    sign = s[:3]\n    digits = s[3:]\n    if max_bits is not None:\n        if len(digits) < max_bits:\n            digits = (sign[-1] * max_bits + digits)[-max_bits:]\n    return \"%s %s\" % (sign, digits)\n\ndef _dedent(text):\n    \"\"\"\n    Like textwrap.dedent.  Rewritten because we cannot import textwrap.\n    \"\"\"\n    lines = text.split('\\n')\n    blanks = 0\n    for i, ch in enumerate(lines[0]):\n        if ch != ' ':\n            break\n    for j, l in enumerate(lines):\n        lines[j] = l[i:]\n    return '\\n'.join(lines)\n\nclass _auto_null:\n    def __repr__(self):\n        return '_auto_null'\n_auto_null = _auto_null()\n\nclass auto:\n    \"\"\"\n    Instances are replaced with an appropriate value in Enum class suites.\n    \"\"\"\n    def __init__(self, value=_auto_null):\n        self.value = value\n\n    def __repr__(self):\n        return \"auto(%r)\" % self.value\n\nclass property(DynamicClassAttribute):\n    \"\"\"\n    This is a descriptor, used to define attributes that act differently\n    when accessed through an enum member and through an enum class.\n    Instance access is the same as property(), but access to an attribute\n    through the enum class will instead look in the class' _member_map_ for\n    a corresponding enum member.\n    \"\"\"\n\n    def __get__(self, instance, ownerclass=None):\n        if instance is None:\n            try:\n                return ownerclass._member_map_[self.name]\n            except KeyError:\n                raise AttributeError(\n                        '%r has no attribute %r' % (ownerclass, self.name)\n                        )\n        else:\n            if self.fget is None:\n                # look for a member by this name.\n                try:\n                    return ownerclass._member_map_[self.name]\n                except KeyError:\n                    raise AttributeError(\n                            '%r has no attribute %r' % (ownerclass, self.name)\n                            ) from None\n            else:\n                return self.fget(instance)\n\n    def __set__(self, instance, value):\n        if self.fset is None:\n            raise AttributeError(\n                    \"<enum %r> cannot set attribute %r\" % (self.clsname, self.name)\n                    )\n        else:\n            return self.fset(instance, value)\n\n    def __delete__(self, instance):\n        if self.fdel is None:\n            raise AttributeError(\n                    \"<enum %r> cannot delete attribute %r\" % (self.clsname, self.name)\n                    )\n        else:\n            return self.fdel(instance)\n\n    def __set_name__(self, ownerclass, name):\n        self.name = name\n        self.clsname = ownerclass.__name__\n\n\nclass _proto_member:\n    \"\"\"\n    intermediate step for enum members between class execution and final creation\n    \"\"\"\n\n    def __init__(self, value):\n        self.value = value\n\n    def __set_name__(self, enum_class, member_name):\n        \"\"\"\n        convert each quasi-member into an instance of the new enum class\n        \"\"\"\n        # first step: remove ourself from enum_class\n        delattr(enum_class, member_name)\n        # second step: create member based on enum_class\n        value = self.value\n        if not isinstance(value, tuple):\n            args = (value, )\n        else:\n            args = value\n        if enum_class._member_type_ is tuple:   # special case for tuple enums\n            args = (args, )     # wrap it one more time\n        if not enum_class._use_args_:\n            enum_member = enum_class._new_member_(enum_class)\n        else:\n            enum_member = enum_class._new_member_(enum_class, *args)\n        if not hasattr(enum_member, '_value_'):\n            if enum_class._member_type_ is object:\n                enum_member._value_ = value\n            else:\n                try:\n                    enum_member._value_ = enum_class._member_type_(*args)\n                except Exception as exc:\n                    new_exc = TypeError(\n                            '_value_ not set in __new__, unable to create it'\n                            )\n                    new_exc.__cause__ = exc\n                    raise new_exc\n        value = enum_member._value_\n        enum_member._name_ = member_name\n        enum_member.__objclass__ = enum_class\n        enum_member.__init__(*args)\n        enum_member._sort_order_ = len(enum_class._member_names_)\n\n        if Flag is not None and issubclass(enum_class, Flag):\n            enum_class._flag_mask_ |= value\n            if _is_single_bit(value):\n                enum_class._singles_mask_ |= value\n            enum_class._all_bits_ = 2 ** ((enum_class._flag_mask_).bit_length()) - 1\n\n        # If another member with the same value was already defined, the\n        # new member becomes an alias to the existing one.\n        try:\n            try:\n                # try to do a fast lookup to avoid the quadratic loop\n                enum_member = enum_class._value2member_map_[value]\n            except TypeError:\n                for name, canonical_member in enum_class._member_map_.items():\n                    if canonical_member._value_ == value:\n                        enum_member = canonical_member\n                        break\n                else:\n                    raise KeyError\n        except KeyError:\n            # this could still be an alias if the value is multi-bit and the\n            # class is a flag class\n            if (\n                    Flag is None\n                    or not issubclass(enum_class, Flag)\n                ):\n                # no other instances found, record this member in _member_names_\n                enum_class._member_names_.append(member_name)\n            elif (\n                    Flag is not None\n                    and issubclass(enum_class, Flag)\n                    and _is_single_bit(value)\n                ):\n                # no other instances found, record this member in _member_names_\n                enum_class._member_names_.append(member_name)\n        # if necessary, get redirect in place and then add it to _member_map_\n        found_descriptor = None\n        for base in enum_class.__mro__[1:]:\n            descriptor = base.__dict__.get(member_name)\n            if descriptor is not None:\n                if isinstance(descriptor, (property, DynamicClassAttribute)):\n                    found_descriptor = descriptor\n                    break\n                elif (\n                        hasattr(descriptor, 'fget') and\n                        hasattr(descriptor, 'fset') and\n                        hasattr(descriptor, 'fdel')\n                    ):\n                    found_descriptor = descriptor\n                    continue\n        if found_descriptor:\n            redirect = property()\n            redirect.member = enum_member\n            redirect.__set_name__(enum_class, member_name)\n            # earlier descriptor found; copy fget, fset, fdel to this one.\n            redirect.fget = found_descriptor.fget\n            redirect.fset = found_descriptor.fset\n            redirect.fdel = found_descriptor.fdel\n            setattr(enum_class, member_name, redirect)\n        else:\n            setattr(enum_class, member_name, enum_member)\n        # now add to _member_map_ (even aliases)\n        enum_class._member_map_[member_name] = enum_member\n        try:\n            # This may fail if value is not hashable. We can't add the value\n            # to the map, and by-value lookups for this value will be\n            # linear.\n            enum_class._value2member_map_.setdefault(value, enum_member)\n        except TypeError:\n            # keep track of the value in a list so containment checks are quick\n            enum_class._unhashable_values_.append(value)\n\n\nclass _EnumDict(dict):\n    \"\"\"\n    Track enum member order and ensure member names are not reused.\n\n    EnumType will use the names found in self._member_names as the\n    enumeration member names.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self._member_names = {} # use a dict to keep insertion order\n        self._last_values = []\n        self._ignore = []\n        self._auto_called = False\n\n    def __setitem__(self, key, value):\n        \"\"\"\n        Changes anything not dundered or not a descriptor.\n\n        If an enum member name is used twice, an error is raised; duplicate\n        values are not checked for.\n\n        Single underscore (sunder) names are reserved.\n        \"\"\"\n        if _is_internal_class(self._cls_name, value):\n            import warnings\n            warnings.warn(\n                    \"In 3.13 classes created inside an enum will not become a member.  \"\n                    \"Use the `member` decorator to keep the current behavior.\",\n                    DeprecationWarning,\n                    stacklevel=2,\n                    )\n        if _is_private(self._cls_name, key):\n            # also do nothing, name will be a normal attribute\n            pass\n        elif _is_sunder(key):\n            if key not in (\n                    '_order_',\n                    '_generate_next_value_', '_numeric_repr_', '_missing_', '_ignore_',\n                    '_iter_member_', '_iter_member_by_value_', '_iter_member_by_def_',\n                    ):\n                raise ValueError(\n                        '_sunder_ names, such as %r, are reserved for future Enum use'\n                        % (key, )\n                        )\n            if key == '_generate_next_value_':\n                # check if members already defined as auto()\n                if self._auto_called:\n                    raise TypeError(\"_generate_next_value_ must be defined before members\")\n                _gnv = value.__func__ if isinstance(value, staticmethod) else value\n                setattr(self, '_generate_next_value', _gnv)\n            elif key == '_ignore_':\n                if isinstance(value, str):\n                    value = value.replace(',',' ').split()\n                else:\n                    value = list(value)\n                self._ignore = value\n                already = set(value) & set(self._member_names)\n                if already:\n                    raise ValueError(\n                            '_ignore_ cannot specify already set names: %r'\n                            % (already, )\n                            )\n        elif _is_dunder(key):\n            if key == '__order__':\n                key = '_order_'\n        elif key in self._member_names:\n            # descriptor overwriting an enum?\n            raise TypeError('%r already defined as %r' % (key, self[key]))\n        elif key in self._ignore:\n            pass\n        elif isinstance(value, nonmember):\n            # unwrap value here; it won't be processed by the below `else`\n            value = value.value\n        elif _is_descriptor(value):\n            pass\n        # TODO: uncomment next three lines in 3.13\n        # elif _is_internal_class(self._cls_name, value):\n        #     # do nothing, name will be a normal attribute\n        #     pass\n        else:\n            if key in self:\n                # enum overwriting a descriptor?\n                raise TypeError('%r already defined as %r' % (key, self[key]))\n            elif isinstance(value, member):\n                # unwrap value here -- it will become a member\n                value = value.value\n            non_auto_store = True\n            single = False\n            if isinstance(value, auto):\n                single = True\n                value = (value, )\n            if type(value) is tuple and any(isinstance(v, auto) for v in value):\n                # insist on an actual tuple, no subclasses, in keeping with only supporting\n                # top-level auto() usage (not contained in any other data structure)\n                auto_valued = []\n                for v in value:\n                    if isinstance(v, auto):\n                        non_auto_store = False\n                        if v.value == _auto_null:\n                            v.value = self._generate_next_value(\n                                    key, 1, len(self._member_names), self._last_values[:],\n                                    )\n                            self._auto_called = True\n                        v = v.value\n                        self._last_values.append(v)\n                    auto_valued.append(v)\n                if single:\n                    value = auto_valued[0]\n                else:\n                    value = tuple(auto_valued)\n            self._member_names[key] = None\n            if non_auto_store:\n                self._last_values.append(value)\n        super().__setitem__(key, value)\n\n    def update(self, members, **more_members):\n        try:\n            for name in members.keys():\n                self[name] = members[name]\n        except AttributeError:\n            for name, value in members:\n                self[name] = value\n        for name, value in more_members.items():\n            self[name] = value\n\n\nclass EnumType(type):\n    \"\"\"\n    Metaclass for Enum\n    \"\"\"\n\n    @classmethod\n    def __prepare__(metacls, cls, bases, **kwds):\n        # check that previous enum members do not exist\n        metacls._check_for_existing_members_(cls, bases)\n        # create the namespace dict\n        enum_dict = _EnumDict()\n        enum_dict._cls_name = cls\n        # inherit previous flags and _generate_next_value_ function\n        member_type, first_enum = metacls._get_mixins_(cls, bases)\n        if first_enum is not None:\n            enum_dict['_generate_next_value_'] = getattr(\n                    first_enum, '_generate_next_value_', None,\n                    )\n        return enum_dict\n\n    def __new__(metacls, cls, bases, classdict, *, boundary=None, _simple=False, **kwds):\n        # an Enum class is final once enumeration items have been defined; it\n        # cannot be mixed with other types (int, float, etc.) if it has an\n        # inherited __new__ unless a new __new__ is defined (or the resulting\n        # class will fail).\n        #\n        if _simple:\n            return super().__new__(metacls, cls, bases, classdict, **kwds)\n        #\n        # remove any keys listed in _ignore_\n        classdict.setdefault('_ignore_', []).append('_ignore_')\n        ignore = classdict['_ignore_']\n        for key in ignore:\n            classdict.pop(key, None)\n        #\n        # grab member names\n        member_names = classdict._member_names\n        #\n        # check for illegal enum names (any others?)\n        invalid_names = set(member_names) & {'mro', ''}\n        if invalid_names:\n            raise ValueError('invalid enum member name(s) %s'  % (\n                    ','.join(repr(n) for n in invalid_names)\n                    ))\n        #\n        # adjust the sunders\n        _order_ = classdict.pop('_order_', None)\n        # convert to normal dict\n        classdict = dict(classdict.items())\n        #\n        # data type of member and the controlling Enum class\n        member_type, first_enum = metacls._get_mixins_(cls, bases)\n        __new__, save_new, use_args = metacls._find_new_(\n                classdict, member_type, first_enum,\n                )\n        classdict['_new_member_'] = __new__\n        classdict['_use_args_'] = use_args\n        #\n        # convert future enum members into temporary _proto_members\n        for name in member_names:\n            value = classdict[name]\n            classdict[name] = _proto_member(value)\n        #\n        # house-keeping structures\n        classdict['_member_names_'] = []\n        classdict['_member_map_'] = {}\n        classdict['_value2member_map_'] = {}\n        classdict['_unhashable_values_'] = []\n        classdict['_member_type_'] = member_type\n        # now set the __repr__ for the value\n        classdict['_value_repr_'] = metacls._find_data_repr_(cls, bases)\n        #\n        # Flag structures (will be removed if final class is not a Flag\n        classdict['_boundary_'] = (\n                boundary\n                or getattr(first_enum, '_boundary_', None)\n                )\n        classdict['_flag_mask_'] = 0\n        classdict['_singles_mask_'] = 0\n        classdict['_all_bits_'] = 0\n        classdict['_inverted_'] = None\n        try:\n            exc = None\n            enum_class = super().__new__(metacls, cls, bases, classdict, **kwds)\n        except RuntimeError as e:\n            # any exceptions raised by member.__new__ will get converted to a\n            # RuntimeError, so get that original exception back and raise it instead\n            exc = e.__cause__ or e\n        if exc is not None:\n            raise exc\n        #\n        # update classdict with any changes made by __init_subclass__\n        classdict.update(enum_class.__dict__)\n        #\n        # double check that repr and friends are not the mixin's or various\n        # things break (such as pickle)\n        # however, if the method is defined in the Enum itself, don't replace\n        # it\n        #\n        # Also, special handling for ReprEnum\n        if ReprEnum is not None and ReprEnum in bases:\n            if member_type is object:\n                raise TypeError(\n                        'ReprEnum subclasses must be mixed with a data type (i.e.'\n                        ' int, str, float, etc.)'\n                        )\n            if '__format__' not in classdict:\n                enum_class.__format__ = member_type.__format__\n                classdict['__format__'] = enum_class.__format__\n            if '__str__' not in classdict:\n                method = member_type.__str__\n                if method is object.__str__:\n                    # if member_type does not define __str__, object.__str__ will use\n                    # its __repr__ instead, so we'll also use its __repr__\n                    method = member_type.__repr__\n                enum_class.__str__ = method\n                classdict['__str__'] = enum_class.__str__\n        for name in ('__repr__', '__str__', '__format__', '__reduce_ex__'):\n            if name not in classdict:\n                # check for mixin overrides before replacing\n                enum_method = getattr(first_enum, name)\n                found_method = getattr(enum_class, name)\n                object_method = getattr(object, name)\n                data_type_method = getattr(member_type, name)\n                if found_method in (data_type_method, object_method):\n                    setattr(enum_class, name, enum_method)\n        #\n        # for Flag, add __or__, __and__, __xor__, and __invert__\n        if Flag is not None and issubclass(enum_class, Flag):\n            for name in (\n                    '__or__', '__and__', '__xor__',\n                    '__ror__', '__rand__', '__rxor__',\n                    '__invert__'\n                ):\n                if name not in classdict:\n                    enum_method = getattr(Flag, name)\n                    setattr(enum_class, name, enum_method)\n                    classdict[name] = enum_method\n        #\n        # replace any other __new__ with our own (as long as Enum is not None,\n        # anyway) -- again, this is to support pickle\n        if Enum is not None:\n            # if the user defined their own __new__, save it before it gets\n            # clobbered in case they subclass later\n            if save_new:\n                enum_class.__new_member__ = __new__\n            enum_class.__new__ = Enum.__new__\n        #\n        # py3 support for definition order (helps keep py2/py3 code in sync)\n        #\n        # _order_ checking is spread out into three/four steps\n        # - if enum_class is a Flag:\n        #   - remove any non-single-bit flags from _order_\n        # - remove any aliases from _order_\n        # - check that _order_ and _member_names_ match\n        #\n        # step 1: ensure we have a list\n        if _order_ is not None:\n            if isinstance(_order_, str):\n                _order_ = _order_.replace(',', ' ').split()\n        #\n        # remove Flag structures if final class is not a Flag\n        if (\n                Flag is None and cls != 'Flag'\n                or Flag is not None and not issubclass(enum_class, Flag)\n            ):\n            delattr(enum_class, '_boundary_')\n            delattr(enum_class, '_flag_mask_')\n            delattr(enum_class, '_singles_mask_')\n            delattr(enum_class, '_all_bits_')\n            delattr(enum_class, '_inverted_')\n        elif Flag is not None and issubclass(enum_class, Flag):\n            # set correct __iter__\n            member_list = [m._value_ for m in enum_class]\n            if member_list != sorted(member_list):\n                enum_class._iter_member_ = enum_class._iter_member_by_def_\n            if _order_:\n                # _order_ step 2: remove any items from _order_ that are not single-bit\n                _order_ = [\n                        o\n                        for o in _order_\n                        if o not in enum_class._member_map_ or _is_single_bit(enum_class[o]._value_)\n                        ]\n        #\n        if _order_:\n            # _order_ step 3: remove aliases from _order_\n            _order_ = [\n                    o\n                    for o in _order_\n                    if (\n                        o not in enum_class._member_map_\n                        or\n                        (o in enum_class._member_map_ and o in enum_class._member_names_)\n                        )]\n            # _order_ step 4: verify that _order_ and _member_names_ match\n            if _order_ != enum_class._member_names_:\n                raise TypeError(\n                        'member order does not match _order_:\\n  %r\\n  %r'\n                        % (enum_class._member_names_, _order_)\n                        )\n\n        return enum_class\n\n    def __bool__(cls):\n        \"\"\"\n        classes/types should always be True.\n        \"\"\"\n        return True\n\n    def __call__(cls, value, names=None, *, module=None, qualname=None, type=None, start=1, boundary=None):\n        \"\"\"\n        Either returns an existing member, or creates a new enum class.\n\n        This method is used both when an enum class is given a value to match\n        to an enumeration member (i.e. Color(3)) and for the functional API\n        (i.e. Color = Enum('Color', names='RED GREEN BLUE')).\n\n        When used for the functional API:\n\n        `value` will be the name of the new class.\n\n        `names` should be either a string of white-space/comma delimited names\n        (values will start at `start`), or an iterator/mapping of name, value pairs.\n\n        `module` should be set to the module this class is being created in;\n        if it is not set, an attempt to find that module will be made, but if\n        it fails the class will not be picklable.\n\n        `qualname` should be set to the actual location this class can be found\n        at in its module; by default it is set to the global scope.  If this is\n        not correct, unpickling will fail in some circumstances.\n\n        `type`, if set, will be mixed in as the first base class.\n        \"\"\"\n        if names is None:  # simple value lookup\n            return cls.__new__(cls, value)\n        # otherwise, functional API: we're creating a new Enum type\n        return cls._create_(\n                value,\n                names,\n                module=module,\n                qualname=qualname,\n                type=type,\n                start=start,\n                boundary=boundary,\n                )\n\n    def __contains__(cls, member):\n        \"\"\"\n        Return True if member is a member of this enum\n        raises TypeError if member is not an enum member\n\n        note: in 3.12 TypeError will no longer be raised, and True will also be\n        returned if member is the value of a member in this enum\n        \"\"\"\n        if not isinstance(member, Enum):\n            import warnings\n            warnings.warn(\n                    \"in 3.12 __contains__ will no longer raise TypeError, but will return True or\\n\"\n                    \"False depending on whether the value is a member or the value of a member\",\n                    DeprecationWarning,\n                    stacklevel=2,\n                    )\n            raise TypeError(\n                \"unsupported operand type(s) for 'in': '%s' and '%s'\" % (\n                    type(member).__qualname__, cls.__class__.__qualname__))\n        return isinstance(member, cls) and member._name_ in cls._member_map_\n\n    def __delattr__(cls, attr):\n        # nicer error message when someone tries to delete an attribute\n        # (see issue19025).\n        if attr in cls._member_map_:\n            raise AttributeError(\"%r cannot delete member %r.\" % (cls.__name__, attr))\n        super().__delattr__(attr)\n\n    def __dir__(cls):\n        interesting = set([\n                '__class__', '__contains__', '__doc__', '__getitem__',\n                '__iter__', '__len__', '__members__', '__module__',\n                '__name__', '__qualname__',\n                ]\n                + cls._member_names_\n                )\n        if cls._new_member_ is not object.__new__:\n            interesting.add('__new__')\n        if cls.__init_subclass__ is not object.__init_subclass__:\n            interesting.add('__init_subclass__')\n        if cls._member_type_ is object:\n            return sorted(interesting)\n        else:\n            # return whatever mixed-in data type has\n            return sorted(set(dir(cls._member_type_)) | interesting)\n\n    def __getattr__(cls, name):\n        \"\"\"\n        Return the enum member matching `name`\n\n        We use __getattr__ instead of descriptors or inserting into the enum\n        class' __dict__ in order to support `name` and `value` being both\n        properties for enum members (which live in the class' __dict__) and\n        enum members themselves.\n        \"\"\"\n        if _is_dunder(name):\n            raise AttributeError(name)\n        try:\n            return cls._member_map_[name]\n        except KeyError:\n            raise AttributeError(name) from None\n\n    def __getitem__(cls, name):\n        \"\"\"\n        Return the member matching `name`.\n        \"\"\"\n        return cls._member_map_[name]\n\n    def __iter__(cls):\n        \"\"\"\n        Return members in definition order.\n        \"\"\"\n        return (cls._member_map_[name] for name in cls._member_names_)\n\n    def __len__(cls):\n        \"\"\"\n        Return the number of members (no aliases)\n        \"\"\"\n        return len(cls._member_names_)\n\n    @bltns.property\n    def __members__(cls):\n        \"\"\"\n        Returns a mapping of member name->value.\n\n        This mapping lists all enum members, including aliases. Note that this\n        is a read-only view of the internal mapping.\n        \"\"\"\n        return MappingProxyType(cls._member_map_)\n\n    def __repr__(cls):\n        if Flag is not None and issubclass(cls, Flag):\n            return \"<flag %r>\" % cls.__name__\n        else:\n            return \"<enum %r>\" % cls.__name__\n\n    def __reversed__(cls):\n        \"\"\"\n        Return members in reverse definition order.\n        \"\"\"\n        return (cls._member_map_[name] for name in reversed(cls._member_names_))\n\n    def __setattr__(cls, name, value):\n        \"\"\"\n        Block attempts to reassign Enum members.\n\n        A simple assignment to the class namespace only changes one of the\n        several possible ways to get an Enum member from the Enum class,\n        resulting in an inconsistent Enumeration.\n        \"\"\"\n        member_map = cls.__dict__.get('_member_map_', {})\n        if name in member_map:\n            raise AttributeError('cannot reassign member %r' % (name, ))\n        super().__setattr__(name, value)\n\n    def _create_(cls, class_name, names, *, module=None, qualname=None, type=None, start=1, boundary=None):\n        \"\"\"\n        Convenience method to create a new Enum class.\n\n        `names` can be:\n\n        * A string containing member names, separated either with spaces or\n          commas.  Values are incremented by 1 from `start`.\n        * An iterable of member names.  Values are incremented by 1 from `start`.\n        * An iterable of (member name, value) pairs.\n        * A mapping of member name -> value pairs.\n        \"\"\"\n        metacls = cls.__class__\n        bases = (cls, ) if type is None else (type, cls)\n        _, first_enum = cls._get_mixins_(class_name, bases)\n        classdict = metacls.__prepare__(class_name, bases)\n\n        # special processing needed for names?\n        if isinstance(names, str):\n            names = names.replace(',', ' ').split()\n        if isinstance(names, (tuple, list)) and names and isinstance(names[0], str):\n            original_names, names = names, []\n            last_values = []\n            for count, name in enumerate(original_names):\n                value = first_enum._generate_next_value_(name, start, count, last_values[:])\n                last_values.append(value)\n                names.append((name, value))\n\n        # Here, names is either an iterable of (name, value) or a mapping.\n        for item in names:\n            if isinstance(item, str):\n                member_name, member_value = item, names[item]\n            else:\n                member_name, member_value = item\n            classdict[member_name] = member_value\n\n        # TODO: replace the frame hack if a blessed way to know the calling\n        # module is ever developed\n        if module is None:\n            try:\n                module = sys._getframe(2).f_globals['__name__']\n            except (AttributeError, ValueError, KeyError):\n                pass\n        if module is None:\n            _make_class_unpicklable(classdict)\n        else:\n            classdict['__module__'] = module\n        if qualname is not None:\n            classdict['__qualname__'] = qualname\n\n        return metacls.__new__(metacls, class_name, bases, classdict, boundary=boundary)\n\n    def _convert_(cls, name, module, filter, source=None, *, boundary=None, as_global=False):\n        \"\"\"\n        Create a new Enum subclass that replaces a collection of global constants\n        \"\"\"\n        # convert all constants from source (or module) that pass filter() to\n        # a new Enum called name, and export the enum and its members back to\n        # module;\n        # also, replace the __reduce_ex__ method so unpickling works in\n        # previous Python versions\n        module_globals = sys.modules[module].__dict__\n        if source:\n            source = source.__dict__\n        else:\n            source = module_globals\n        # _value2member_map_ is populated in the same order every time\n        # for a consistent reverse mapping of number to name when there\n        # are multiple names for the same number.\n        members = [\n                (name, value)\n                for name, value in source.items()\n                if filter(name)]\n        try:\n            # sort by value\n            members.sort(key=lambda t: (t[1], t[0]))\n        except TypeError:\n            # unless some values aren't comparable, in which case sort by name\n            members.sort(key=lambda t: t[0])\n        body = {t[0]: t[1] for t in members}\n        body['__module__'] = module\n        tmp_cls = type(name, (object, ), body)\n        cls = _simple_enum(etype=cls, boundary=boundary or KEEP)(tmp_cls)\n        if as_global:\n            global_enum(cls)\n        else:\n            sys.modules[cls.__module__].__dict__.update(cls.__members__)\n        module_globals[name] = cls\n        return cls\n\n    @classmethod\n    def _check_for_existing_members_(mcls, class_name, bases):\n        for chain in bases:\n            for base in chain.__mro__:\n                if isinstance(base, EnumType) and base._member_names_:\n                    raise TypeError(\n                            \"<enum %r> cannot extend %r\"\n                            % (class_name, base)\n                            )\n\n    @classmethod\n    def _get_mixins_(mcls, class_name, bases):\n        \"\"\"\n        Returns the type for creating enum members, and the first inherited\n        enum class.\n\n        bases: the tuple of bases that was given to __new__\n        \"\"\"\n        if not bases:\n            return object, Enum\n\n        mcls._check_for_existing_members_(class_name, bases)\n\n        # ensure final parent class is an Enum derivative, find any concrete\n        # data type, and check that Enum has no members\n        first_enum = bases[-1]\n        if not isinstance(first_enum, EnumType):\n            raise TypeError(\"new enumerations should be created as \"\n                    \"`EnumName([mixin_type, ...] [data_type,] enum_type)`\")\n        member_type = mcls._find_data_type_(class_name, bases) or object\n        return member_type, first_enum\n\n    @classmethod\n    def _find_data_repr_(mcls, class_name, bases):\n        for chain in bases:\n            for base in chain.__mro__:\n                if base is object:\n                    continue\n                elif isinstance(base, EnumType):\n                    # if we hit an Enum, use it's _value_repr_\n                    return base._value_repr_\n                elif '__repr__' in base.__dict__:\n                    # this is our data repr\n                    return base.__dict__['__repr__']\n        return None\n\n    @classmethod\n    def _find_data_type_(mcls, class_name, bases):\n        # a datatype has a __new__ method\n        data_types = set()\n        base_chain = set()\n        for chain in bases:\n            candidate = None\n            for base in chain.__mro__:\n                base_chain.add(base)\n                if base is object:\n                    continue\n                elif isinstance(base, EnumType):\n                    if base._member_type_ is not object:\n                        data_types.add(base._member_type_)\n                        break\n                elif '__new__' in base.__dict__ or '__dataclass_fields__' in base.__dict__:\n                    if isinstance(base, EnumType):\n                        continue\n                    data_types.add(candidate or base)\n                    break\n                else:\n                    candidate = candidate or base\n        if len(data_types) > 1:\n            raise TypeError('too many data types for %r: %r' % (class_name, data_types))\n        elif data_types:\n            return data_types.pop()\n        else:\n            return None\n\n    @classmethod\n    def _find_new_(mcls, classdict, member_type, first_enum):\n        \"\"\"\n        Returns the __new__ to be used for creating the enum members.\n\n        classdict: the class dictionary given to __new__\n        member_type: the data type whose __new__ will be used by default\n        first_enum: enumeration to check for an overriding __new__\n        \"\"\"\n        # now find the correct __new__, checking to see of one was defined\n        # by the user; also check earlier enum classes in case a __new__ was\n        # saved as __new_member__\n        __new__ = classdict.get('__new__', None)\n\n        # should __new__ be saved as __new_member__ later?\n        save_new = first_enum is not None and __new__ is not None\n\n        if __new__ is None:\n            # check all possibles for __new_member__ before falling back to\n            # __new__\n            for method in ('__new_member__', '__new__'):\n                for possible in (member_type, first_enum):\n                    target = getattr(possible, method, None)\n                    if target not in {\n                            None,\n                            None.__new__,\n                            object.__new__,\n                            Enum.__new__,\n                            }:\n                        __new__ = target\n                        break\n                if __new__ is not None:\n                    break\n            else:\n                __new__ = object.__new__\n\n        # if a non-object.__new__ is used then whatever value/tuple was\n        # assigned to the enum member name will be passed to __new__ and to the\n        # new enum member's __init__\n        if first_enum is None or __new__ in (Enum.__new__, object.__new__):\n            use_args = False\n        else:\n            use_args = True\n        return __new__, save_new, use_args\nEnumMeta = EnumType\n\n\nclass Enum(metaclass=EnumType):\n    \"\"\"\n    Create a collection of name/value pairs.\n\n    Example enumeration:\n\n    >>> class Color(Enum):\n    ...     RED = 1\n    ...     BLUE = 2\n    ...     GREEN = 3\n\n    Access them by:\n\n    - attribute access::\n\n    >>> Color.RED\n    <Color.RED: 1>\n\n    - value lookup:\n\n    >>> Color(1)\n    <Color.RED: 1>\n\n    - name lookup:\n\n    >>> Color['RED']\n    <Color.RED: 1>\n\n    Enumerations can be iterated over, and know how many members they have:\n\n    >>> len(Color)\n    3\n\n    >>> list(Color)\n    [<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]\n\n    Methods can be added to enumerations, and members can have their own\n    attributes -- see the documentation for details.\n    \"\"\"\n\n    def __new__(cls, value):\n        # all enum instances are actually created during class construction\n        # without calling this method; this method is called by the metaclass'\n        # __call__ (i.e. Color(3) ), and by pickle\n        if type(value) is cls:\n            # For lookups like Color(Color.RED)\n            return value\n        # by-value search for a matching enum member\n        # see if it's in the reverse mapping (for hashable values)\n        try:\n            return cls._value2member_map_[value]\n        except KeyError:\n            # Not found, no need to do long O(n) search\n            pass\n        except TypeError:\n            # not there, now do long search -- O(n) behavior\n            for member in cls._member_map_.values():\n                if member._value_ == value:\n                    return member\n        # still not found -- try _missing_ hook\n        try:\n            exc = None\n            result = cls._missing_(value)\n        except Exception as e:\n            exc = e\n            result = None\n        try:\n            if isinstance(result, cls):\n                return result\n            elif (\n                    Flag is not None and issubclass(cls, Flag)\n                    and cls._boundary_ is EJECT and isinstance(result, int)\n                ):\n                return result\n            else:\n                ve_exc = ValueError(\"%r is not a valid %s\" % (value, cls.__qualname__))\n                if result is None and exc is None:\n                    raise ve_exc\n                elif exc is None:\n                    exc = TypeError(\n                            'error in %s._missing_: returned %r instead of None or a valid member'\n                            % (cls.__name__, result)\n                            )\n                if not isinstance(exc, ValueError):\n                    exc.__context__ = ve_exc\n                raise exc\n        finally:\n            # ensure all variables that could hold an exception are destroyed\n            exc = None\n            ve_exc = None\n\n    def __init__(self, *args, **kwds):\n        pass\n\n    def _generate_next_value_(name, start, count, last_values):\n        \"\"\"\n        Generate the next value when not given.\n\n        name: the name of the member\n        start: the initial start value or None\n        count: the number of existing members\n        last_values: the list of values assigned\n        \"\"\"\n        if not last_values:\n            return start\n        try:\n            last = last_values[-1]\n            last_values.sort()\n            if last == last_values[-1]:\n                # no difference between old and new methods\n                return last + 1\n            else:\n                # trigger old method (with warning)\n                raise TypeError\n        except TypeError:\n            import warnings\n            warnings.warn(\n                    \"In 3.13 the default `auto()`/`_generate_next_value_` will require all values to be sortable and support adding +1\\n\"\n                    \"and the value returned will be the largest value in the enum incremented by 1\",\n                    DeprecationWarning,\n                    stacklevel=3,\n                    )\n            for v in reversed(last_values):\n                try:\n                    return v + 1\n                except TypeError:\n                    pass\n            return start\n\n    @classmethod\n    def _missing_(cls, value):\n        return None\n\n    def __repr__(self):\n        v_repr = self.__class__._value_repr_ or repr\n        return \"<%s.%s: %s>\" % (self.__class__.__name__, self._name_, v_repr(self._value_))\n\n    def __str__(self):\n        return \"%s.%s\" % (self.__class__.__name__, self._name_, )\n\n    def __dir__(self):\n        \"\"\"\n        Returns all members and all public methods\n        \"\"\"\n        if self.__class__._member_type_ is object:\n            interesting = set(['__class__', '__doc__', '__eq__', '__hash__', '__module__', 'name', 'value'])\n        else:\n            interesting = set(object.__dir__(self))\n        for name in getattr(self, '__dict__', []):\n            if name[0] != '_':\n                interesting.add(name)\n        for cls in self.__class__.mro():\n            for name, obj in cls.__dict__.items():\n                if name[0] == '_':\n                    continue\n                if isinstance(obj, property):\n                    # that's an enum.property\n                    if obj.fget is not None or name not in self._member_map_:\n                        interesting.add(name)\n                    else:\n                        # in case it was added by `dir(self)`\n                        interesting.discard(name)\n                else:\n                    interesting.add(name)\n        names = sorted(\n                set(['__class__', '__doc__', '__eq__', '__hash__', '__module__'])\n                | interesting\n                )\n        return names\n\n    def __format__(self, format_spec):\n        return str.__format__(str(self), format_spec)\n\n    def __hash__(self):\n        return hash(self._name_)\n\n    def __reduce_ex__(self, proto):\n        return self.__class__, (self._value_, )\n\n    def __deepcopy__(self,memo):\n        return self\n\n    def __copy__(self):\n        return self\n\n    # enum.property is used to provide access to the `name` and\n    # `value` attributes of enum members while keeping some measure of\n    # protection from modification, while still allowing for an enumeration\n    # to have members named `name` and `value`.  This works because enumeration\n    # members are not set directly on the enum class; they are kept in a\n    # separate structure, _member_map_, which is where enum.property looks for\n    # them\n\n    @property\n    def name(self):\n        \"\"\"The name of the Enum member.\"\"\"\n        return self._name_\n\n    @property\n    def value(self):\n        \"\"\"The value of the Enum member.\"\"\"\n        return self._value_\n\n\nclass ReprEnum(Enum):\n    \"\"\"\n    Only changes the repr(), leaving str() and format() to the mixed-in type.\n    \"\"\"\n\n\nclass IntEnum(int, ReprEnum):\n    \"\"\"\n    Enum where members are also (and must be) ints\n    \"\"\"\n\n\nclass StrEnum(str, ReprEnum):\n    \"\"\"\n    Enum where members are also (and must be) strings\n    \"\"\"\n\n    def __new__(cls, *values):\n        \"values must already be of type `str`\"\n        if len(values) > 3:\n            raise TypeError('too many arguments for str(): %r' % (values, ))\n        if len(values) == 1:\n            # it must be a string\n            if not isinstance(values[0], str):\n                raise TypeError('%r is not a string' % (values[0], ))\n        if len(values) >= 2:\n            # check that encoding argument is a string\n            if not isinstance(values[1], str):\n                raise TypeError('encoding must be a string, not %r' % (values[1], ))\n        if len(values) == 3:\n            # check that errors argument is a string\n            if not isinstance(values[2], str):\n                raise TypeError('errors must be a string, not %r' % (values[2]))\n        value = str(*values)\n        member = str.__new__(cls, value)\n        member._value_ = value\n        return member\n\n    def _generate_next_value_(name, start, count, last_values):\n        \"\"\"\n        Return the lower-cased version of the member name.\n        \"\"\"\n        return name.lower()\n\n\ndef pickle_by_global_name(self, proto):\n    # should not be used with Flag-type enums\n    return self.name\n_reduce_ex_by_global_name = pickle_by_global_name\n\ndef pickle_by_enum_name(self, proto):\n    # should not be used with Flag-type enums\n    return getattr, (self.__class__, self._name_)\n\nclass FlagBoundary(StrEnum):\n    \"\"\"\n    control how out of range values are handled\n    \"strict\" -> error is raised             [default for Flag]\n    \"conform\" -> extra bits are discarded\n    \"eject\" -> lose flag status\n    \"keep\" -> keep flag status and all bits [default for IntFlag]\n    \"\"\"\n    STRICT = auto()\n    CONFORM = auto()\n    EJECT = auto()\n    KEEP = auto()\nSTRICT, CONFORM, EJECT, KEEP = FlagBoundary\n\n\nclass Flag(Enum, boundary=STRICT):\n    \"\"\"\n    Support for flags\n    \"\"\"\n\n    _numeric_repr_ = repr\n\n    def _generate_next_value_(name, start, count, last_values):\n        \"\"\"\n        Generate the next value when not given.\n\n        name: the name of the member\n        start: the initial start value or None\n        count: the number of existing members\n        last_values: the last value assigned or None\n        \"\"\"\n        if not count:\n            return start if start is not None else 1\n        last_value = max(last_values)\n        try:\n            high_bit = _high_bit(last_value)\n        except Exception:\n            raise TypeError('invalid flag value %r' % last_value) from None\n        return 2 ** (high_bit+1)\n\n    @classmethod\n    def _iter_member_by_value_(cls, value):\n        \"\"\"\n        Extract all members from the value in definition (i.e. increasing value) order.\n        \"\"\"\n        for val in _iter_bits_lsb(value & cls._flag_mask_):\n            yield cls._value2member_map_.get(val)\n\n    _iter_member_ = _iter_member_by_value_\n\n    @classmethod\n    def _iter_member_by_def_(cls, value):\n        \"\"\"\n        Extract all members from the value in definition order.\n        \"\"\"\n        yield from sorted(\n                cls._iter_member_by_value_(value),\n                key=lambda m: m._sort_order_,\n                )\n\n    @classmethod\n    def _missing_(cls, value):\n        \"\"\"\n        Create a composite member containing all canonical members present in `value`.\n\n        If non-member values are present, result depends on `_boundary_` setting.\n        \"\"\"\n        if not isinstance(value, int):\n            raise ValueError(\n                    \"%r is not a valid %s\" % (value, cls.__qualname__)\n                    )\n        # check boundaries\n        # - value must be in range (e.g. -16 <-> +15, i.e. ~15 <-> 15)\n        # - value must not include any skipped flags (e.g. if bit 2 is not\n        #   defined, then 0d10 is invalid)\n        flag_mask = cls._flag_mask_\n        singles_mask = cls._singles_mask_\n        all_bits = cls._all_bits_\n        neg_value = None\n        if (\n                not ~all_bits <= value <= all_bits\n                or value & (all_bits ^ flag_mask)\n            ):\n            if cls._boundary_ is STRICT:\n                max_bits = max(value.bit_length(), flag_mask.bit_length())\n                raise ValueError(\n                        \"%r invalid value %r\\n    given %s\\n  allowed %s\" % (\n                            cls, value, bin(value, max_bits), bin(flag_mask, max_bits),\n                            ))\n            elif cls._boundary_ is CONFORM:\n                value = value & flag_mask\n            elif cls._boundary_ is EJECT:\n                return value\n            elif cls._boundary_ is KEEP:\n                if value < 0:\n                    value = (\n                            max(all_bits+1, 2**(value.bit_length()))\n                            + value\n                            )\n            else:\n                raise ValueError(\n                        '%r unknown flag boundary %r' % (cls, cls._boundary_, )\n                        )\n        if value < 0:\n            neg_value = value\n            value = all_bits + 1 + value\n        # get members and unknown\n        unknown = value & ~flag_mask\n        aliases = value & ~singles_mask\n        member_value = value & singles_mask\n        if unknown and cls._boundary_ is not KEEP:\n            raise ValueError(\n                    '%s(%r) -->  unknown values %r [%s]'\n                    % (cls.__name__, value, unknown, bin(unknown))\n                    )\n        # normal Flag?\n        if cls._member_type_ is object:\n            # construct a singleton enum pseudo-member\n            pseudo_member = object.__new__(cls)\n        else:\n            pseudo_member = cls._member_type_.__new__(cls, value)\n        if not hasattr(pseudo_member, '_value_'):\n            pseudo_member._value_ = value\n        if member_value or aliases:\n            members = []\n            combined_value = 0\n            for m in cls._iter_member_(member_value):\n                members.append(m)\n                combined_value |= m._value_\n            if aliases:\n                value = member_value | aliases\n                for n, pm in cls._member_map_.items():\n                    if pm not in members and pm._value_ and pm._value_ & value == pm._value_:\n                        members.append(pm)\n                        combined_value |= pm._value_\n            unknown = value ^ combined_value\n            pseudo_member._name_ = '|'.join([m._name_ for m in members])\n            if not combined_value:\n                pseudo_member._name_ = None\n            elif unknown and cls._boundary_ is STRICT:\n                raise ValueError('%r: no members with value %r' % (cls, unknown))\n            elif unknown:\n                pseudo_member._name_ += '|%s' % cls._numeric_repr_(unknown)\n        else:\n            pseudo_member._name_ = None\n        # use setdefault in case another thread already created a composite\n        # with this value\n        # note: zero is a special case -- always add it\n        pseudo_member = cls._value2member_map_.setdefault(value, pseudo_member)\n        if neg_value is not None:\n            cls._value2member_map_[neg_value] = pseudo_member\n        return pseudo_member\n\n    def __contains__(self, other):\n        \"\"\"\n        Returns True if self has at least the same flags set as other.\n        \"\"\"\n        if not isinstance(other, self.__class__):\n            raise TypeError(\n                \"unsupported operand type(s) for 'in': %r and %r\" % (\n                    type(other).__qualname__, self.__class__.__qualname__))\n        return other._value_ & self._value_ == other._value_\n\n    def __iter__(self):\n        \"\"\"\n        Returns flags in definition order.\n        \"\"\"\n        yield from self._iter_member_(self._value_)\n\n    def __len__(self):\n        return self._value_.bit_count()\n\n    def __repr__(self):\n        cls_name = self.__class__.__name__\n        v_repr = self.__class__._value_repr_ or repr\n        if self._name_ is None:\n            return \"<%s: %s>\" % (cls_name, v_repr(self._value_))\n        else:\n            return \"<%s.%s: %s>\" % (cls_name, self._name_, v_repr(self._value_))\n\n    def __str__(self):\n        cls_name = self.__class__.__name__\n        if self._name_ is None:\n            return '%s(%r)' % (cls_name, self._value_)\n        else:\n            return \"%s.%s\" % (cls_name, self._name_)\n\n    def __bool__(self):\n        return bool(self._value_)\n\n    def __or__(self, other):\n        if isinstance(other, self.__class__):\n            other = other._value_\n        elif self._member_type_ is not object and isinstance(other, self._member_type_):\n            other = other\n        else:\n            return NotImplemented\n        value = self._value_\n        return self.__class__(value | other)\n\n    def __and__(self, other):\n        if isinstance(other, self.__class__):\n            other = other._value_\n        elif self._member_type_ is not object and isinstance(other, self._member_type_):\n            other = other\n        else:\n            return NotImplemented\n        value = self._value_\n        return self.__class__(value & other)\n\n    def __xor__(self, other):\n        if isinstance(other, self.__class__):\n            other = other._value_\n        elif self._member_type_ is not object and isinstance(other, self._member_type_):\n            other = other\n        else:\n            return NotImplemented\n        value = self._value_\n        return self.__class__(value ^ other)\n\n    def __invert__(self):\n        if self._inverted_ is None:\n            if self._boundary_ in (EJECT, KEEP):\n                self._inverted_ = self.__class__(~self._value_)\n            else:\n                self._inverted_ = self.__class__(self._singles_mask_ & ~self._value_)\n        return self._inverted_\n\n    __rand__ = __and__\n    __ror__ = __or__\n    __rxor__ = __xor__\n\n\nclass IntFlag(int, ReprEnum, Flag, boundary=KEEP):\n    \"\"\"\n    Support for integer-based Flags\n    \"\"\"\n\n\ndef _high_bit(value):\n    \"\"\"\n    returns index of highest bit, or -1 if value is zero or negative\n    \"\"\"\n    return value.bit_length() - 1\n\ndef unique(enumeration):\n    \"\"\"\n    Class decorator for enumerations ensuring unique member values.\n    \"\"\"\n    duplicates = []\n    for name, member in enumeration.__members__.items():\n        if name != member.name:\n            duplicates.append((name, member.name))\n    if duplicates:\n        alias_details = ', '.join(\n                [\"%s -> %s\" % (alias, name) for (alias, name) in duplicates])\n        raise ValueError('duplicate values found in %r: %s' %\n                (enumeration, alias_details))\n    return enumeration\n\ndef _power_of_two(value):\n    if value < 1:\n        return False\n    return value == 2 ** _high_bit(value)\n\ndef global_enum_repr(self):\n    \"\"\"\n    use module.enum_name instead of class.enum_name\n\n    the module is the last module in case of a multi-module name\n    \"\"\"\n    module = self.__class__.__module__.split('.')[-1]\n    return '%s.%s' % (module, self._name_)\n\ndef global_flag_repr(self):\n    \"\"\"\n    use module.flag_name instead of class.flag_name\n\n    the module is the last module in case of a multi-module name\n    \"\"\"\n    module = self.__class__.__module__.split('.')[-1]\n    cls_name = self.__class__.__name__\n    if self._name_ is None:\n        return \"%s.%s(%r)\" % (module, cls_name, self._value_)\n    if _is_single_bit(self):\n        return '%s.%s' % (module, self._name_)\n    if self._boundary_ is not FlagBoundary.KEEP:\n        return '|'.join(['%s.%s' % (module, name) for name in self.name.split('|')])\n    else:\n        name = []\n        for n in self._name_.split('|'):\n            if n[0].isdigit():\n                name.append(n)\n            else:\n                name.append('%s.%s' % (module, n))\n        return '|'.join(name)\n\ndef global_str(self):\n    \"\"\"\n    use enum_name instead of class.enum_name\n    \"\"\"\n    if self._name_ is None:\n        cls_name = self.__class__.__name__\n        return \"%s(%r)\" % (cls_name, self._value_)\n    else:\n        return self._name_\n\ndef global_enum(cls, update_str=False):\n    \"\"\"\n    decorator that makes the repr() of an enum member reference its module\n    instead of its class; also exports all members to the enum's module's\n    global namespace\n    \"\"\"\n    if issubclass(cls, Flag):\n        cls.__repr__ = global_flag_repr\n    else:\n        cls.__repr__ = global_enum_repr\n    if not issubclass(cls, ReprEnum) or update_str:\n        cls.__str__ = global_str\n    sys.modules[cls.__module__].__dict__.update(cls.__members__)\n    return cls\n\ndef _simple_enum(etype=Enum, *, boundary=None, use_args=None):\n    \"\"\"\n    Class decorator that converts a normal class into an :class:`Enum`.  No\n    safety checks are done, and some advanced behavior (such as\n    :func:`__init_subclass__`) is not available.  Enum creation can be faster\n    using :func:`simple_enum`.\n\n        >>> from enum import Enum, _simple_enum\n        >>> @_simple_enum(Enum)\n        ... class Color:\n        ...     RED = auto()\n        ...     GREEN = auto()\n        ...     BLUE = auto()\n        >>> Color\n        <enum 'Color'>\n    \"\"\"\n    def convert_class(cls):\n        nonlocal use_args\n        cls_name = cls.__name__\n        if use_args is None:\n            use_args = etype._use_args_\n        __new__ = cls.__dict__.get('__new__')\n        if __new__ is not None:\n            new_member = __new__.__func__\n        else:\n            new_member = etype._member_type_.__new__\n        attrs = {}\n        body = {}\n        if __new__ is not None:\n            body['__new_member__'] = new_member\n        body['_new_member_'] = new_member\n        body['_use_args_'] = use_args\n        body['_generate_next_value_'] = gnv = etype._generate_next_value_\n        body['_member_names_'] = member_names = []\n        body['_member_map_'] = member_map = {}\n        body['_value2member_map_'] = value2member_map = {}\n        body['_unhashable_values_'] = []\n        body['_member_type_'] = member_type = etype._member_type_\n        body['_value_repr_'] = etype._value_repr_\n        if issubclass(etype, Flag):\n            body['_boundary_'] = boundary or etype._boundary_\n            body['_flag_mask_'] = None\n            body['_all_bits_'] = None\n            body['_singles_mask_'] = None\n            body['_inverted_'] = None\n            body['__or__'] = Flag.__or__\n            body['__xor__'] = Flag.__xor__\n            body['__and__'] = Flag.__and__\n            body['__ror__'] = Flag.__ror__\n            body['__rxor__'] = Flag.__rxor__\n            body['__rand__'] = Flag.__rand__\n            body['__invert__'] = Flag.__invert__\n        for name, obj in cls.__dict__.items():\n            if name in ('__dict__', '__weakref__'):\n                continue\n            if _is_dunder(name) or _is_private(cls_name, name) or _is_sunder(name) or _is_descriptor(obj):\n                body[name] = obj\n            else:\n                attrs[name] = obj\n        if cls.__dict__.get('__doc__') is None:\n            body['__doc__'] = 'An enumeration.'\n        #\n        # double check that repr and friends are not the mixin's or various\n        # things break (such as pickle)\n        # however, if the method is defined in the Enum itself, don't replace\n        # it\n        enum_class = type(cls_name, (etype, ), body, boundary=boundary, _simple=True)\n        for name in ('__repr__', '__str__', '__format__', '__reduce_ex__'):\n            if name not in body:\n                # check for mixin overrides before replacing\n                enum_method = getattr(etype, name)\n                found_method = getattr(enum_class, name)\n                object_method = getattr(object, name)\n                data_type_method = getattr(member_type, name)\n                if found_method in (data_type_method, object_method):\n                    setattr(enum_class, name, enum_method)\n        gnv_last_values = []\n        if issubclass(enum_class, Flag):\n            # Flag / IntFlag\n            single_bits = multi_bits = 0\n            for name, value in attrs.items():\n                if isinstance(value, auto) and auto.value is _auto_null:\n                    value = gnv(name, 1, len(member_names), gnv_last_values)\n                if value in value2member_map:\n                    # an alias to an existing member\n                    redirect = property()\n                    redirect.__set_name__(enum_class, name)\n                    setattr(enum_class, name, redirect)\n                    member_map[name] = value2member_map[value]\n                else:\n                    # create the member\n                    if use_args:\n                        if not isinstance(value, tuple):\n                            value = (value, )\n                        member = new_member(enum_class, *value)\n                        value = value[0]\n                    else:\n                        member = new_member(enum_class)\n                    if __new__ is None:\n                        member._value_ = value\n                    member._name_ = name\n                    member.__objclass__ = enum_class\n                    member.__init__(value)\n                    redirect = property()\n                    redirect.__set_name__(enum_class, name)\n                    setattr(enum_class, name, redirect)\n                    member_map[name] = member\n                    member._sort_order_ = len(member_names)\n                    value2member_map[value] = member\n                    if _is_single_bit(value):\n                        # not a multi-bit alias, record in _member_names_ and _flag_mask_\n                        member_names.append(name)\n                        single_bits |= value\n                    else:\n                        multi_bits |= value\n                    gnv_last_values.append(value)\n            enum_class._flag_mask_ = single_bits | multi_bits\n            enum_class._singles_mask_ = single_bits\n            enum_class._all_bits_ = 2 ** ((single_bits|multi_bits).bit_length()) - 1\n            # set correct __iter__\n            member_list = [m._value_ for m in enum_class]\n            if member_list != sorted(member_list):\n                enum_class._iter_member_ = enum_class._iter_member_by_def_\n        else:\n            # Enum / IntEnum / StrEnum\n            for name, value in attrs.items():\n                if isinstance(value, auto):\n                    if value.value is _auto_null:\n                        value.value = gnv(name, 1, len(member_names), gnv_last_values)\n                    value = value.value\n                if value in value2member_map:\n                    # an alias to an existing member\n                    redirect = property()\n                    redirect.__set_name__(enum_class, name)\n                    setattr(enum_class, name, redirect)\n                    member_map[name] = value2member_map[value]\n                else:\n                    # create the member\n                    if use_args:\n                        if not isinstance(value, tuple):\n                            value = (value, )\n                        member = new_member(enum_class, *value)\n                        value = value[0]\n                    else:\n                        member = new_member(enum_class)\n                    if __new__ is None:\n                        member._value_ = value\n                    member._name_ = name\n                    member.__objclass__ = enum_class\n                    member.__init__(value)\n                    member._sort_order_ = len(member_names)\n                    redirect = property()\n                    redirect.__set_name__(enum_class, name)\n                    setattr(enum_class, name, redirect)\n                    member_map[name] = member\n                    value2member_map[value] = member\n                    member_names.append(name)\n                    gnv_last_values.append(value)\n        if '__new__' in body:\n            enum_class.__new_member__ = enum_class.__new__\n        enum_class.__new__ = Enum.__new__\n        return enum_class\n    return convert_class\n\n@_simple_enum(StrEnum)\nclass EnumCheck:\n    \"\"\"\n    various conditions to check an enumeration for\n    \"\"\"\n    CONTINUOUS = \"no skipped integer values\"\n    NAMED_FLAGS = \"multi-flag aliases may not contain unnamed flags\"\n    UNIQUE = \"one name per value\"\nCONTINUOUS, NAMED_FLAGS, UNIQUE = EnumCheck\n\n\nclass verify:\n    \"\"\"\n    Check an enumeration for various constraints. (see EnumCheck)\n    \"\"\"\n    def __init__(self, *checks):\n        self.checks = checks\n    def __call__(self, enumeration):\n        checks = self.checks\n        cls_name = enumeration.__name__\n        if Flag is not None and issubclass(enumeration, Flag):\n            enum_type = 'flag'\n        elif issubclass(enumeration, Enum):\n            enum_type = 'enum'\n        else:\n            raise TypeError(\"the 'verify' decorator only works with Enum and Flag\")\n        for check in checks:\n            if check is UNIQUE:\n                # check for duplicate names\n                duplicates = []\n                for name, member in enumeration.__members__.items():\n                    if name != member.name:\n                        duplicates.append((name, member.name))\n                if duplicates:\n                    alias_details = ', '.join(\n                            [\"%s -> %s\" % (alias, name) for (alias, name) in duplicates])\n                    raise ValueError('aliases found in %r: %s' %\n                            (enumeration, alias_details))\n            elif check is CONTINUOUS:\n                values = set(e.value for e in enumeration)\n                if len(values) < 2:\n                    continue\n                low, high = min(values), max(values)\n                missing = []\n                if enum_type == 'flag':\n                    # check for powers of two\n                    for i in range(_high_bit(low)+1, _high_bit(high)):\n                        if 2**i not in values:\n                            missing.append(2**i)\n                elif enum_type == 'enum':\n                    # check for powers of one\n                    for i in range(low+1, high):\n                        if i not in values:\n                            missing.append(i)\n                else:\n                    raise Exception('verify: unknown type %r' % enum_type)\n                if missing:\n                    raise ValueError(('invalid %s %r: missing values %s' % (\n                            enum_type, cls_name, ', '.join((str(m) for m in missing)))\n                            )[:256])\n                            # limit max length to protect against DOS attacks\n            elif check is NAMED_FLAGS:\n                # examine each alias and check for unnamed flags\n                member_names = enumeration._member_names_\n                member_values = [m.value for m in enumeration]\n                missing_names = []\n                missing_value = 0\n                for name, alias in enumeration._member_map_.items():\n                    if name in member_names:\n                        # not an alias\n                        continue\n                    if alias.value < 0:\n                        # negative numbers are not checked\n                        continue\n                    values = list(_iter_bits_lsb(alias.value))\n                    missed = [v for v in values if v not in member_values]\n                    if missed:\n                        missing_names.append(name)\n                        missing_value |= reduce(_or_, missed)\n                if missing_names:\n                    if len(missing_names) == 1:\n                        alias = 'alias %s is missing' % missing_names[0]\n                    else:\n                        alias = 'aliases %s and %s are missing' % (\n                                ', '.join(missing_names[:-1]), missing_names[-1]\n                                )\n                    if _is_single_bit(missing_value):\n                        value = 'value 0x%x' % missing_value\n                    else:\n                        value = 'combined values of 0x%x' % missing_value\n                    raise ValueError(\n                            'invalid Flag %r: %s %s [use enum.show_flag_values(value) for details]'\n                            % (cls_name, alias, value)\n                            )\n        return enumeration\n\ndef _test_simple_enum(checked_enum, simple_enum):\n    \"\"\"\n    A function that can be used to test an enum created with :func:`_simple_enum`\n    against the version created by subclassing :class:`Enum`::\n\n        >>> from enum import Enum, _simple_enum, _test_simple_enum\n        >>> @_simple_enum(Enum)\n        ... class Color:\n        ...     RED = auto()\n        ...     GREEN = auto()\n        ...     BLUE = auto()\n        >>> class CheckedColor(Enum):\n        ...     RED = auto()\n        ...     GREEN = auto()\n        ...     BLUE = auto()\n        >>> _test_simple_enum(CheckedColor, Color)\n\n    If differences are found, a :exc:`TypeError` is raised.\n    \"\"\"\n    failed = []\n    if checked_enum.__dict__ != simple_enum.__dict__:\n        checked_dict = checked_enum.__dict__\n        checked_keys = list(checked_dict.keys())\n        simple_dict = simple_enum.__dict__\n        simple_keys = list(simple_dict.keys())\n        member_names = set(\n                list(checked_enum._member_map_.keys())\n                + list(simple_enum._member_map_.keys())\n                )\n        for key in set(checked_keys + simple_keys):\n            if key in ('__module__', '_member_map_', '_value2member_map_', '__doc__'):\n                # keys known to be different, or very long\n                continue\n            elif key in member_names:\n                # members are checked below\n                continue\n            elif key not in simple_keys:\n                failed.append(\"missing key: %r\" % (key, ))\n            elif key not in checked_keys:\n                failed.append(\"extra key:   %r\" % (key, ))\n            else:\n                checked_value = checked_dict[key]\n                simple_value = simple_dict[key]\n                if callable(checked_value) or isinstance(checked_value, bltns.property):\n                    continue\n                if key == '__doc__':\n                    # remove all spaces/tabs\n                    compressed_checked_value = checked_value.replace(' ','').replace('\\t','')\n                    compressed_simple_value = simple_value.replace(' ','').replace('\\t','')\n                    if compressed_checked_value != compressed_simple_value:\n                        failed.append(\"%r:\\n         %s\\n         %s\" % (\n                                key,\n                                \"checked -> %r\" % (checked_value, ),\n                                \"simple  -> %r\" % (simple_value, ),\n                                ))\n                elif checked_value != simple_value:\n                    failed.append(\"%r:\\n         %s\\n         %s\" % (\n                            key,\n                            \"checked -> %r\" % (checked_value, ),\n                            \"simple  -> %r\" % (simple_value, ),\n                            ))\n        failed.sort()\n        for name in member_names:\n            failed_member = []\n            if name not in simple_keys:\n                failed.append('missing member from simple enum: %r' % name)\n            elif name not in checked_keys:\n                failed.append('extra member in simple enum: %r' % name)\n            else:\n                checked_member_dict = checked_enum[name].__dict__\n                checked_member_keys = list(checked_member_dict.keys())\n                simple_member_dict = simple_enum[name].__dict__\n                simple_member_keys = list(simple_member_dict.keys())\n                for key in set(checked_member_keys + simple_member_keys):\n                    if key in ('__module__', '__objclass__', '_inverted_'):\n                        # keys known to be different or absent\n                        continue\n                    elif key not in simple_member_keys:\n                        failed_member.append(\"missing key %r not in the simple enum member %r\" % (key, name))\n                    elif key not in checked_member_keys:\n                        failed_member.append(\"extra key %r in simple enum member %r\" % (key, name))\n                    else:\n                        checked_value = checked_member_dict[key]\n                        simple_value = simple_member_dict[key]\n                        if checked_value != simple_value:\n                            failed_member.append(\"%r:\\n         %s\\n         %s\" % (\n                                    key,\n                                    \"checked member -> %r\" % (checked_value, ),\n                                    \"simple member  -> %r\" % (simple_value, ),\n                                    ))\n            if failed_member:\n                failed.append('%r member mismatch:\\n      %s' % (\n                        name, '\\n      '.join(failed_member),\n                        ))\n        for method in (\n                '__str__', '__repr__', '__reduce_ex__', '__format__',\n                '__getnewargs_ex__', '__getnewargs__', '__reduce_ex__', '__reduce__'\n            ):\n            if method in simple_keys and method in checked_keys:\n                # cannot compare functions, and it exists in both, so we're good\n                continue\n            elif method not in simple_keys and method not in checked_keys:\n                # method is inherited -- check it out\n                checked_method = getattr(checked_enum, method, None)\n                simple_method = getattr(simple_enum, method, None)\n                if hasattr(checked_method, '__func__'):\n                    checked_method = checked_method.__func__\n                    simple_method = simple_method.__func__\n                if checked_method != simple_method:\n                    failed.append(\"%r:  %-30s %s\" % (\n                            method,\n                            \"checked -> %r\" % (checked_method, ),\n                            \"simple -> %r\" % (simple_method, ),\n                            ))\n            else:\n                # if the method existed in only one of the enums, it will have been caught\n                # in the first checks above\n                pass\n    if failed:\n        raise TypeError('enum mismatch:\\n   %s' % '\\n   '.join(failed))\n\ndef _old_convert_(etype, name, module, filter, source=None, *, boundary=None):\n    \"\"\"\n    Create a new Enum subclass that replaces a collection of global constants\n    \"\"\"\n    # convert all constants from source (or module) that pass filter() to\n    # a new Enum called name, and export the enum and its members back to\n    # module;\n    # also, replace the __reduce_ex__ method so unpickling works in\n    # previous Python versions\n    module_globals = sys.modules[module].__dict__\n    if source:\n        source = source.__dict__\n    else:\n        source = module_globals\n    # _value2member_map_ is populated in the same order every time\n    # for a consistent reverse mapping of number to name when there\n    # are multiple names for the same number.\n    members = [\n            (name, value)\n            for name, value in source.items()\n            if filter(name)]\n    try:\n        # sort by value\n        members.sort(key=lambda t: (t[1], t[0]))\n    except TypeError:\n        # unless some values aren't comparable, in which case sort by name\n        members.sort(key=lambda t: t[0])\n    cls = etype(name, members, module=module, boundary=boundary or KEEP)\n    return cls\n\n_stdlib_enums = IntEnum, StrEnum, IntFlag\n",2042],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py":["# -*- coding: utf-8 -*-\n# imageio is distributed under the terms of the (new) BSD License.\n\n\"\"\"\nDefinition of the Request object, which acts as a kind of bridge between\nwhat the user wants and what the plugins can.\n\"\"\"\n\nimport os\nfrom io import BytesIO\nimport zipfile\nimport tempfile\nimport shutil\nimport enum\nimport warnings\n\nfrom ..core import urlopen, get_remote_file\n\nfrom pathlib import Path\nfrom urllib.parse import urlparse\nfrom typing import Optional\n\n# URI types\nURI_BYTES = 1\nURI_FILE = 2\nURI_FILENAME = 3\nURI_ZIPPED = 4\nURI_HTTP = 5\nURI_FTP = 6\n\n\nclass IOMode(str, enum.Enum):\n    \"\"\"Available Image modes\n\n    This is a helper enum for ``Request.Mode`` which is a composite of a\n    ``Request.ImageMode`` and ``Request.IOMode``. The IOMode that tells the\n    plugin if the resource should be read from or written to. Available values are\n\n    - read (\"r\"): Read from the specified resource\n    - write (\"w\"): Write to the specified resource\n\n    \"\"\"\n\n    read = \"r\"\n    write = \"w\"\n\n\nclass ImageMode(str, enum.Enum):\n    \"\"\"Available Image modes\n\n    This is a helper enum for ``Request.Mode`` which is a composite of a\n    ``Request.ImageMode`` and ``Request.IOMode``. The image mode that tells the\n    plugin the desired (and expected) image shape. Available values are\n\n    - single_image (\"i\"): Return a single image extending in two spacial\n      dimensions\n    - multi_image (\"I\"): Return a list of images extending in two spacial\n      dimensions\n    - single_volume (\"v\"): Return an image extending into multiple dimensions.\n      E.g. three spacial dimensions for image stacks, or two spatial and one\n      time dimension for videos\n    - multi_volume (\"V\"): Return a list of images extending into multiple\n      dimensions.\n    - any_mode (\"?\"): Return an image in any format (the plugin decides the\n      appropriate action).\n\n    \"\"\"\n\n    single_image = \"i\"\n    multi_image = \"I\"\n    single_volume = \"v\"\n    multi_volume = \"V\"\n    any_mode = \"?\"\n\n\n@enum.unique\nclass Mode(str, enum.Enum):\n    \"\"\"The mode to use when interacting with the resource\n\n    ``Request.Mode`` is a composite of ``Request.ImageMode`` and\n    ``Request.IOMode``. The image mode that tells the plugin the desired (and\n    expected) image shape and the ``Request.IOMode`` tells the plugin the way\n    the resource should be interacted with. For a detailed description of the\n    available modes, see the documentation for ``Request.ImageMode`` and\n    ``Request.IOMode`` respectively.\n\n    Available modes are all combinations of ``Request.IOMode`` and ``Request.ImageMode``:\n\n    - read_single_image (\"ri\")\n    - read_multi_image (\"rI\")\n    - read_single_volume (\"rv\")\n    - read_multi_volume (\"rV\")\n    - read_any (\"r?\")\n    - write_single_image (\"wi\")\n    - write_multi_image (\"wI\")\n    - write_single_volume (\"wv\")\n    - write_multi_volume (\"wV\")\n    - write_any (\"w?\")\n\n    Examples\n    --------\n    >>> Request.Mode(\"rI\")  # a list of simple images should be read from the resource\n    >>> Request.Mode(\"wv\")  # a single volume should be written to the resource\n\n    \"\"\"\n\n    read_single_image = \"ri\"\n    read_multi_image = \"rI\"\n    read_single_volume = \"rv\"\n    read_multi_volume = \"rV\"\n    read_any = \"r?\"\n    write_single_image = \"wi\"\n    write_multi_image = \"wI\"\n    write_single_volume = \"wv\"\n    write_multi_volume = \"wV\"\n    write_any = \"w?\"\n\n    @classmethod\n    def _missing_(cls, value):\n        \"\"\"Enable Mode(\"r\") and Mode(\"w\")\n\n        The sunder method ``_missing_`` is called whenever the constructor fails\n        to directly look up the corresponding enum value from the given input.\n        In our case, we use it to convert the modes \"r\" and \"w\" (from the v3\n        API) into their legacy versions \"r?\" and \"w?\".\n\n        More info on _missing_:\n        https://docs.python.org/3/library/enum.html#supported-sunder-names\n        \"\"\"\n\n        if value == \"r\":\n            return cls(\"r?\")\n        elif value == \"w\":\n            return cls(\"w?\")\n        else:\n            raise ValueError(f\"{value} is no valid Mode.\")\n\n    @property\n    def io_mode(self) -> IOMode:\n        return IOMode(self.value[0])\n\n    @property\n    def image_mode(self) -> ImageMode:\n        return ImageMode(self.value[1])\n\n    def __getitem__(self, key):\n        \"\"\"For backwards compatibility with the old non-enum modes\"\"\"\n        if key == 0:\n            return self.io_mode\n        elif key == 1:\n            return self.image_mode\n        else:\n            raise IndexError(f\"Mode has no item {key}\")\n\n\nSPECIAL_READ_URIS = \"<video\", \"<screen>\", \"<clipboard>\"\n\n# The user can use this string in a write call to get the data back as bytes.\nRETURN_BYTES = \"<bytes>\"\n\n# Example images that will be auto-downloaded\nEXAMPLE_IMAGES = {\n    \"astronaut.png\": \"Image of the astronaut Eileen Collins\",\n    \"camera.png\": \"A grayscale image of a photographer\",\n    \"checkerboard.png\": \"Black and white image of a chekerboard\",\n    \"wood.jpg\": \"A (repeatable) texture of wooden planks\",\n    \"bricks.jpg\": \"A (repeatable) texture of stone bricks\",\n    \"clock.png\": \"Photo of a clock with motion blur (Stefan van der Walt)\",\n    \"coffee.png\": \"Image of a cup of coffee (Rachel Michetti)\",\n    \"chelsea.png\": \"Image of Stefan's cat\",\n    \"wikkie.png\": \"Image of Almar's cat\",\n    \"coins.png\": \"Image showing greek coins from Pompeii\",\n    \"horse.png\": \"Image showing the silhouette of a horse (Andreas Preuss)\",\n    \"hubble_deep_field.png\": \"Photograph taken by Hubble telescope (NASA)\",\n    \"immunohistochemistry.png\": \"Immunohistochemical (IHC) staining\",\n    \"moon.png\": \"Image showing a portion of the surface of the moon\",\n    \"page.png\": \"A scanned page of text\",\n    \"text.png\": \"A photograph of handdrawn text\",\n    \"chelsea.zip\": \"The chelsea.png in a zipfile (for testing)\",\n    \"chelsea.bsdf\": \"The chelsea.png in a BSDF file(for testing)\",\n    \"newtonscradle.gif\": \"Animated GIF of a newton's cradle\",\n    \"cockatoo.mp4\": \"Video file of a cockatoo\",\n    \"stent.npz\": \"Volumetric image showing a stented abdominal aorta\",\n    \"meadow_cube.jpg\": \"A cubemap image of a meadow, e.g. to render a skybox.\",\n}\n\n\nclass Request(object):\n    \"\"\"ImageResource handling utility.\n\n    Represents a request for reading or saving an image resource. This\n    object wraps information to that request and acts as an interface\n    for the plugins to several resources; it allows the user to read\n    from filenames, files, http, zipfiles, raw bytes, etc., but offer\n    a simple interface to the plugins via ``get_file()`` and\n    ``get_local_filename()``.\n\n    For each read/write operation a single Request instance is used and passed\n    to the can_read/can_write method of a format, and subsequently to\n    the Reader/Writer class. This allows rudimentary passing of\n    information between different formats and between a format and\n    associated reader/writer.\n\n    Parameters\n    ----------\n    uri : {str, bytes, file}\n        The resource to load the image from.\n    mode : str\n        The first character is \"r\" or \"w\", indicating a read or write\n        request. The second character is used to indicate the kind of data:\n        \"i\" for an image, \"I\" for multiple images, \"v\" for a volume,\n        \"V\" for multiple volumes, \"?\" for don't care.\n\n    \"\"\"\n\n    def __init__(self, uri, mode, *, extension=None, format_hint: str = None, **kwargs):\n        # General\n        self.raw_uri = uri\n        self._uri_type = None\n        self._filename = None\n        self._extension = None\n        self._format_hint = None\n        self._kwargs = kwargs\n        self._result = None  # Some write actions may have a result\n\n        # To handle the user-side\n        self._filename_zip = None  # not None if a zipfile is used\n        self._bytes = None  # Incoming bytes\n        self._zipfile = None  # To store a zipfile instance (if used)\n\n        # To handle the plugin side\n        self._file = None  # To store the file instance\n        self._file_is_local = False  # whether the data needs to be copied at end\n        self._filename_local = None  # not None if using tempfile on this FS\n        self._firstbytes = None  # For easy header parsing\n\n        # To store formats that may be able to fulfil this request\n        # self._potential_formats = []\n\n        # Check mode\n        try:\n            self._mode = Mode(mode)\n        except ValueError:\n            raise ValueError(f\"Invalid Request.Mode: {mode}\")\n\n        # Parse what was given\n        self._parse_uri(uri)\n\n        # Set extension\n        if extension is not None:\n            if extension[0] != \".\":\n                raise ValueError(\n                    \"`extension` should be a file extension starting with a `.`,\"\n                    f\" but is `{extension}`.\"\n                )\n            self._extension = extension\n        elif self._filename is not None:\n            if self._uri_type in (URI_FILENAME, URI_ZIPPED):\n                path = self._filename\n            else:\n                path = urlparse(self._filename).path\n            ext = Path(path).suffix.lower()\n            self._extension = ext if ext != \"\" else None\n\n        if format_hint is not None:\n            warnings.warn(\n                \"The usage of `format_hint` is deprecated and will be removed \"\n                \"in ImageIO v3. Use `extension` instead.\",\n                DeprecationWarning,\n            )\n\n        if format_hint is not None and format_hint[0] != \".\":\n            raise ValueError(\n                \"`format_hint` should be a file extension starting with a `.`,\"\n                f\" but is `{format_hint}`.\"\n            )\n\n        self.format_hint = format_hint\n\n    def _parse_uri(self, uri):\n        \"\"\"Try to figure our what we were given\"\"\"\n        is_read_request = self.mode.io_mode is IOMode.read\n        is_write_request = self.mode.io_mode is IOMode.write\n\n        if isinstance(uri, str):\n            # Explicit\n            if uri.startswith(\"imageio:\"):\n                if is_write_request:\n                    raise RuntimeError(\"Cannot write to the standard images.\")\n                fn = uri.split(\":\", 1)[-1].lower()\n                fn, _, zip_part = fn.partition(\".zip/\")\n                if zip_part:\n                    fn += \".zip\"\n                if fn not in EXAMPLE_IMAGES:\n                    raise ValueError(\"Unknown standard image %r.\" % fn)\n                self._uri_type = URI_FILENAME\n                self._filename = get_remote_file(\"images/\" + fn, auto=True)\n                if zip_part:\n                    self._filename += \"/\" + zip_part\n            elif uri.startswith(\"http://\") or uri.startswith(\"https://\"):\n                self._uri_type = URI_HTTP\n                self._filename = uri\n            elif uri.startswith(\"ftp://\") or uri.startswith(\"ftps://\"):\n                self._uri_type = URI_FTP\n                self._filename = uri\n            elif uri.startswith(\"file://\"):\n                self._uri_type = URI_FILENAME\n                self._filename = uri[7:]\n            elif uri.startswith(SPECIAL_READ_URIS) and is_read_request:\n                self._uri_type = URI_BYTES\n                self._filename = uri\n            elif uri.startswith(RETURN_BYTES) and is_write_request:\n                self._uri_type = URI_BYTES\n                self._filename = uri\n            else:\n                self._uri_type = URI_FILENAME\n                self._filename = uri\n\n        elif isinstance(uri, memoryview) and is_read_request:\n            self._uri_type = URI_BYTES\n            self._filename = \"<bytes>\"\n            self._bytes = uri.tobytes()\n        elif isinstance(uri, bytes) and is_read_request:\n            self._uri_type = URI_BYTES\n            self._filename = \"<bytes>\"\n            self._bytes = uri\n        elif isinstance(uri, Path):\n            self._uri_type = URI_FILENAME\n            self._filename = str(uri)\n        # Files\n        elif is_read_request:\n            if hasattr(uri, \"read\") and hasattr(uri, \"close\"):\n                self._uri_type = URI_FILE\n                self._filename = \"<file>\"\n                self._file = uri  # Data must be read from here\n        elif is_write_request:\n            if hasattr(uri, \"write\") and hasattr(uri, \"close\"):\n                self._uri_type = URI_FILE\n                self._filename = \"<file>\"\n                self._file = uri  # Data must be written here\n\n        # Expand user dir\n        if self._uri_type == URI_FILENAME and self._filename.startswith(\"~\"):\n            self._filename = os.path.expanduser(self._filename)\n\n        # Check if a zipfile\n        if self._uri_type == URI_FILENAME:\n            # Search for zip extension followed by a path separator\n            for needle in [\".zip/\", \".zip\\\\\"]:\n                zip_i = self._filename.lower().find(needle)\n                if zip_i > 0:\n                    zip_i += 4\n                    zip_path = self._filename[:zip_i]\n                    if os.path.isdir(zip_path):\n                        pass  # is an existing dir (see #548)\n                    elif is_write_request or os.path.isfile(zip_path):\n                        self._uri_type = URI_ZIPPED\n                        self._filename_zip = (\n                            zip_path,\n                            self._filename[zip_i:].lstrip(\"/\\\\\"),\n                        )\n                        break\n\n        # Check if we could read it\n        if self._uri_type is None:\n            uri_r = repr(uri)\n            if len(uri_r) > 60:\n                uri_r = uri_r[:57] + \"...\"\n            raise IOError(\"Cannot understand given URI: %s.\" % uri_r)\n\n        # Check if this is supported\n        noWriting = [URI_HTTP, URI_FTP]\n        if is_write_request and self._uri_type in noWriting:\n            raise IOError(\"imageio does not support writing to http/ftp.\")\n\n        # Deprecated way to load standard images, give a sensible error message\n        if is_read_request and self._uri_type in [URI_FILENAME, URI_ZIPPED]:\n            fn = self._filename\n            if self._filename_zip:\n                fn = self._filename_zip[0]\n            if (not os.path.exists(fn)) and (fn in EXAMPLE_IMAGES):\n                raise IOError(\n                    \"No such file: %r. This file looks like one of \"\n                    \"the standard images, but from imageio 2.1, \"\n                    \"standard images have to be specified using \"\n                    '\"imageio:%s\".' % (fn, fn)\n                )\n\n        # Make filename absolute\n        if self._uri_type in [URI_FILENAME, URI_ZIPPED]:\n            if self._filename_zip:\n                self._filename_zip = (\n                    os.path.abspath(self._filename_zip[0]),\n                    self._filename_zip[1],\n                )\n            else:\n                self._filename = os.path.abspath(self._filename)\n\n        # Check whether file name is valid\n        if self._uri_type in [URI_FILENAME, URI_ZIPPED]:\n            fn = self._filename\n            if self._filename_zip:\n                fn = self._filename_zip[0]\n            if is_read_request:\n                # Reading: check that the file exists (but is allowed a dir)\n                if not os.path.exists(fn):\n                    raise FileNotFoundError(\"No such file: '%s'\" % fn)\n            else:\n                # Writing: check that the directory to write to does exist\n                dn = os.path.dirname(fn)\n                if not os.path.exists(dn):\n                    raise FileNotFoundError(\"The directory %r does not exist\" % dn)\n\n    @property\n    def filename(self):\n        \"\"\"Name of the ImageResource.\n\n\n        The uri for which reading/saving was requested. This\n        can be a filename, an http address, or other resource\n        identifier. Do not rely on the filename to obtain the data,\n        but use ``get_file()`` or ``get_local_filename()`` instead.\n        \"\"\"\n        return self._filename\n\n    @property\n    def extension(self) -> str:\n        \"\"\"The (lowercase) extension of the requested filename.\n        Suffixes in url's are stripped. Can be None if the request is\n        not based on a filename.\n        \"\"\"\n        return self._extension\n\n    @property\n    def format_hint(self) -> Optional[str]:\n        return self._format_hint\n\n    @format_hint.setter\n    def format_hint(self, format: str) -> None:\n        self._format_hint = format\n        if self._extension is None:\n            self._extension = format\n\n    @property\n    def mode(self):\n        \"\"\"The mode of the request. The first character is \"r\" or \"w\",\n        indicating a read or write request. The second character is\n        used to indicate the kind of data:\n        \"i\" for an image, \"I\" for multiple images, \"v\" for a volume,\n        \"V\" for multiple volumes, \"?\" for don't care.\n        \"\"\"\n        return self._mode\n\n    @property\n    def kwargs(self):\n        \"\"\"The dict of keyword arguments supplied by the user.\"\"\"\n        return self._kwargs\n\n    # For obtaining data\n\n    def get_file(self):\n        \"\"\"get_file()\n        Get a file object for the resource associated with this request.\n        If this is a reading request, the file is in read mode,\n        otherwise in write mode. This method is not thread safe. Plugins\n        should not close the file when done.\n\n        This is the preferred way to read/write the data. But if a\n        format cannot handle file-like objects, they should use\n        ``get_local_filename()``.\n        \"\"\"\n        want_to_write = self.mode.io_mode is IOMode.write\n\n        # Is there already a file?\n        # Either _uri_type == URI_FILE, or we already opened the file,\n        # e.g. by using firstbytes\n        if self._file is not None:\n            return self._file\n\n        if self._uri_type == URI_BYTES:\n            if want_to_write:\n                # Create new file object, we catch the bytes in finish()\n                self._file = BytesIO()\n                self._file_is_local = True\n            else:\n                self._file = BytesIO(self._bytes)\n\n        elif self._uri_type == URI_FILENAME:\n            if want_to_write:\n                self._file = open(self.filename, \"wb\")\n            else:\n                self._file = open(self.filename, \"rb\")\n\n        elif self._uri_type == URI_ZIPPED:\n            # Get the correct filename\n            filename, name = self._filename_zip\n            if want_to_write:\n                # Create new file object, we catch the bytes in finish()\n                self._file = BytesIO()\n                self._file_is_local = True\n            else:\n                # Open zipfile and open new file object for specific file\n                self._zipfile = zipfile.ZipFile(filename, \"r\")\n                self._file = self._zipfile.open(name, \"r\")\n                self._file = SeekableFileObject(self._file)\n\n        elif self._uri_type in [URI_HTTP or URI_FTP]:\n            assert not want_to_write  # This should have been tested in init\n            timeout = os.getenv(\"IMAGEIO_REQUEST_TIMEOUT\")\n            if timeout is None or not timeout.isdigit():\n                timeout = 5\n            self._file = urlopen(self.filename, timeout=float(timeout))\n            self._file = SeekableFileObject(self._file)\n\n        return self._file\n\n    def get_local_filename(self):\n        \"\"\"get_local_filename()\n        If the filename is an existing file on this filesystem, return\n        that. Otherwise a temporary file is created on the local file\n        system which can be used by the format to read from or write to.\n        \"\"\"\n\n        if self._uri_type == URI_FILENAME:\n            return self._filename\n        else:\n            # Get filename\n            if self.extension is not None:\n                ext = self.extension\n            else:\n                ext = os.path.splitext(self._filename)[1]\n            fd, self._filename_local = tempfile.mkstemp(ext, \"imageio_\")\n            os.close(fd)\n            # Write stuff to it?\n            if self.mode.io_mode == IOMode.read:\n                with open(self._filename_local, \"wb\") as file:\n                    shutil.copyfileobj(self.get_file(), file)\n            return self._filename_local\n\n    def finish(self) -> None:\n        \"\"\"Wrap up this request.\n\n        Finishes any pending reads or writes, closes any open files and frees\n        any resources allocated by this request.\n        \"\"\"\n\n        if self.mode.io_mode == IOMode.write:\n            # See if we \"own\" the data and must put it somewhere\n            bytes = None\n            if self._filename_local:\n                bytes = Path(self._filename_local).read_bytes()\n            elif self._file_is_local:\n                self._file_is_local = False\n                bytes = self._file.getvalue()\n\n            # Put the data in the right place\n            if bytes is not None:\n                if self._uri_type == URI_BYTES:\n                    self._result = bytes  # Picked up by imread function\n                elif self._uri_type == URI_FILE:\n                    self._file.write(bytes)\n                elif self._uri_type == URI_ZIPPED:\n                    zf = zipfile.ZipFile(self._filename_zip[0], \"a\")\n                    zf.writestr(self._filename_zip[1], bytes)\n                    zf.close()\n                # elif self._uri_type == URI_FILENAME: -> is always direct\n                # elif self._uri_type == URI_FTP/HTTP: -> write not supported\n\n        # Close open files that we know of (and are responsible for)\n        if self._file and self._uri_type != URI_FILE:\n            self._file.close()\n            self._file = None\n        if self._zipfile:\n            self._zipfile.close()\n            self._zipfile = None\n\n        # Remove temp file\n        if self._filename_local:\n            try:\n                os.remove(self._filename_local)\n            except Exception:  # pragma: no cover\n                warnings.warn(\n                    \"Failed to delete the temporary file at \"\n                    f\"`{self._filename_local}`. Please report this issue.\"\n                )\n            self._filename_local = None\n\n        # Detach so gc can clean even if a reference of self lingers\n        self._bytes = None\n\n    def get_result(self):\n        \"\"\"For internal use. In some situations a write action can have\n        a result (bytes data). That is obtained with this function.\n        \"\"\"\n        # Is there a reason to disallow reading multiple times?\n        self._result, res = None, self._result\n        return res\n\n    @property\n    def firstbytes(self):\n        \"\"\"The first 256 bytes of the file. These can be used to\n        parse the header to determine the file-format.\n        \"\"\"\n        if self._firstbytes is None:\n            self._read_first_bytes()\n        return self._firstbytes\n\n    def _read_first_bytes(self, N=256):\n        if self._bytes is not None:\n            self._firstbytes = self._bytes[:N]\n        else:\n            # Prepare\n            try:\n                f = self.get_file()\n            except IOError:\n                if os.path.isdir(self.filename):  # A directory, e.g. for DICOM\n                    self._firstbytes = bytes()\n                    return\n                raise\n            try:\n                i = f.tell()\n            except Exception:\n                i = None\n            # Read\n            self._firstbytes = read_n_bytes(f, N)\n            # Set back\n            try:\n                if i is None:\n                    raise Exception(\"cannot seek with None\")\n                f.seek(i)\n            except Exception:\n                # Prevent get_file() from reusing the file\n                self._file = None\n                # If the given URI was a file object, we have a problem,\n                if self._uri_type == URI_FILE:\n                    raise IOError(\"Cannot seek back after getting firstbytes!\")\n\n\ndef read_n_bytes(f, N):\n    \"\"\"read_n_bytes(file, n)\n\n    Read n bytes from the given file, or less if the file has less\n    bytes. Returns zero bytes if the file is closed.\n    \"\"\"\n    bb = bytes()\n    while len(bb) < N:\n        extra_bytes = f.read(N - len(bb))\n        if not extra_bytes:\n            break\n        bb += extra_bytes\n    return bb\n\n\nclass SeekableFileObject:\n    \"\"\"A readonly wrapper file object that add support for seeking, even if\n    the wrapped file object does not. The allows us to stream from http and\n    still use Pillow.\n    \"\"\"\n\n    def __init__(self, f):\n        self.f = f\n        self._i = 0  # >=0 but can exceed buffer\n        self._buffer = b\"\"\n        self._have_all = False\n        self.closed = False\n\n    def read(self, n=None):\n        # Fix up n\n        if n is None:\n            pass\n        else:\n            n = int(n)\n            if n < 0:\n                n = None\n\n        # Can and must we read more?\n        if not self._have_all:\n            more = b\"\"\n            if n is None:\n                more = self.f.read()\n                self._have_all = True\n            else:\n                want_i = self._i + n\n                want_more = want_i - len(self._buffer)\n                if want_more > 0:\n                    more = self.f.read(want_more)\n                    if len(more) < want_more:\n                        self._have_all = True\n            self._buffer += more\n\n        # Read data from buffer and update pointer\n        if n is None:\n            res = self._buffer[self._i :]\n        else:\n            res = self._buffer[self._i : self._i + n]\n        self._i += len(res)\n\n        return res\n\n    def tell(self):\n        return self._i\n\n    def seek(self, i, mode=0):\n        # Mimic BytesIO behavior\n\n        # Get the absolute new position\n        i = int(i)\n        if mode == 0:\n            if i < 0:\n                raise ValueError(\"negative seek value \" + str(i))\n            real_i = i\n        elif mode == 1:\n            real_i = max(0, self._i + i)  # negative ok here\n        elif mode == 2:\n            if not self._have_all:\n                self.read()\n            real_i = max(0, len(self._buffer) + i)\n        else:\n            raise ValueError(\"invalid whence (%s, should be 0, 1 or 2)\" % i)\n\n        # Read some?\n        if real_i <= len(self._buffer):\n            pass  # no need to read\n        elif not self._have_all:\n            assert real_i > self._i  # if we don't have all, _i cannot be > _buffer\n            self.read(real_i - self._i)  # sets self._i\n\n        self._i = real_i\n        return self._i\n\n    def close(self):\n        self.closed = True\n        self.f.close()\n\n    def isatty(self):\n        return False\n\n    def seekable(self):\n        return True\n\n\nclass InitializationError(Exception):\n    \"\"\"The plugin could not initialize from the given request.\n\n    This is a _internal_ error that is raised by plugins that fail to handle\n    a given request. We use this to differentiate incompatibility between\n    a plugin and a request from an actual error/bug inside a plugin.\n\n    \"\"\"\n\n    pass\n",751],"C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py":["import fnmatch\nimport functools\nimport io\nimport ntpath\nimport os\nimport posixpath\nimport re\nimport sys\nimport warnings\nfrom _collections_abc import Sequence\nfrom errno import ENOENT, ENOTDIR, EBADF, ELOOP\nfrom operator import attrgetter\nfrom stat import S_ISDIR, S_ISLNK, S_ISREG, S_ISSOCK, S_ISBLK, S_ISCHR, S_ISFIFO\nfrom urllib.parse import quote_from_bytes as urlquote_from_bytes\n\n\n__all__ = [\n    \"PurePath\", \"PurePosixPath\", \"PureWindowsPath\",\n    \"Path\", \"PosixPath\", \"WindowsPath\",\n    ]\n\n#\n# Internals\n#\n\n_WINERROR_NOT_READY = 21  # drive exists but is not accessible\n_WINERROR_INVALID_NAME = 123  # fix for bpo-35306\n_WINERROR_CANT_RESOLVE_FILENAME = 1921  # broken symlink pointing to itself\n\n# EBADF - guard against macOS `stat` throwing EBADF\n_IGNORED_ERRNOS = (ENOENT, ENOTDIR, EBADF, ELOOP)\n\n_IGNORED_WINERRORS = (\n    _WINERROR_NOT_READY,\n    _WINERROR_INVALID_NAME,\n    _WINERROR_CANT_RESOLVE_FILENAME)\n\ndef _ignore_error(exception):\n    return (getattr(exception, 'errno', None) in _IGNORED_ERRNOS or\n            getattr(exception, 'winerror', None) in _IGNORED_WINERRORS)\n\n\ndef _is_wildcard_pattern(pat):\n    # Whether this pattern needs actual matching using fnmatch, or can\n    # be looked up directly as a file.\n    return \"*\" in pat or \"?\" in pat or \"[\" in pat\n\n\nclass _Flavour(object):\n    \"\"\"A flavour implements a particular (platform-specific) set of path\n    semantics.\"\"\"\n\n    def __init__(self):\n        self.join = self.sep.join\n\n    def parse_parts(self, parts):\n        parsed = []\n        sep = self.sep\n        altsep = self.altsep\n        drv = root = ''\n        it = reversed(parts)\n        for part in it:\n            if not part:\n                continue\n            if altsep:\n                part = part.replace(altsep, sep)\n            drv, root, rel = self.splitroot(part)\n            if sep in rel:\n                for x in reversed(rel.split(sep)):\n                    if x and x != '.':\n                        parsed.append(sys.intern(x))\n            else:\n                if rel and rel != '.':\n                    parsed.append(sys.intern(rel))\n            if drv or root:\n                if not drv:\n                    # If no drive is present, try to find one in the previous\n                    # parts. This makes the result of parsing e.g.\n                    # (\"C:\", \"/\", \"a\") reasonably intuitive.\n                    for part in it:\n                        if not part:\n                            continue\n                        if altsep:\n                            part = part.replace(altsep, sep)\n                        drv = self.splitroot(part)[0]\n                        if drv:\n                            break\n                break\n        if drv or root:\n            parsed.append(drv + root)\n        parsed.reverse()\n        return drv, root, parsed\n\n    def join_parsed_parts(self, drv, root, parts, drv2, root2, parts2):\n        \"\"\"\n        Join the two paths represented by the respective\n        (drive, root, parts) tuples.  Return a new (drive, root, parts) tuple.\n        \"\"\"\n        if root2:\n            if not drv2 and drv:\n                return drv, root2, [drv + root2] + parts2[1:]\n        elif drv2:\n            if drv2 == drv or self.casefold(drv2) == self.casefold(drv):\n                # Same drive => second path is relative to the first\n                return drv, root, parts + parts2[1:]\n        else:\n            # Second path is non-anchored (common case)\n            return drv, root, parts + parts2\n        return drv2, root2, parts2\n\n\nclass _WindowsFlavour(_Flavour):\n    # Reference for Windows paths can be found at\n    # http://msdn.microsoft.com/en-us/library/aa365247%28v=vs.85%29.aspx\n\n    sep = '\\\\'\n    altsep = '/'\n    has_drv = True\n    pathmod = ntpath\n\n    is_supported = (os.name == 'nt')\n\n    drive_letters = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n    ext_namespace_prefix = '\\\\\\\\?\\\\'\n\n    reserved_names = (\n        {'CON', 'PRN', 'AUX', 'NUL', 'CONIN$', 'CONOUT$'} |\n        {'COM%s' % c for c in '123456789\\xb9\\xb2\\xb3'} |\n        {'LPT%s' % c for c in '123456789\\xb9\\xb2\\xb3'}\n        )\n\n    # Interesting findings about extended paths:\n    # * '\\\\?\\c:\\a' is an extended path, which bypasses normal Windows API\n    #   path processing. Thus relative paths are not resolved and slash is not\n    #   translated to backslash. It has the native NT path limit of 32767\n    #   characters, but a bit less after resolving device symbolic links,\n    #   such as '\\??\\C:' => '\\Device\\HarddiskVolume2'.\n    # * '\\\\?\\c:/a' looks for a device named 'C:/a' because slash is a\n    #   regular name character in the object namespace.\n    # * '\\\\?\\c:\\foo/bar' is invalid because '/' is illegal in NT filesystems.\n    #   The only path separator at the filesystem level is backslash.\n    # * '//?/c:\\a' and '//?/c:/a' are effectively equivalent to '\\\\.\\c:\\a' and\n    #   thus limited to MAX_PATH.\n    # * Prior to Windows 8, ANSI API bytes paths are limited to MAX_PATH,\n    #   even with the '\\\\?\\' prefix.\n\n    def splitroot(self, part, sep=sep):\n        first = part[0:1]\n        second = part[1:2]\n        if (second == sep and first == sep):\n            # XXX extended paths should also disable the collapsing of \".\"\n            # components (according to MSDN docs).\n            prefix, part = self._split_extended_path(part)\n            first = part[0:1]\n            second = part[1:2]\n        else:\n            prefix = ''\n        third = part[2:3]\n        if (second == sep and first == sep and third != sep):\n            # is a UNC path:\n            # vvvvvvvvvvvvvvvvvvvvv root\n            # \\\\machine\\mountpoint\\directory\\etc\\...\n            #            directory ^^^^^^^^^^^^^^\n            index = part.find(sep, 2)\n            if index != -1:\n                index2 = part.find(sep, index + 1)\n                # a UNC path can't have two slashes in a row\n                # (after the initial two)\n                if index2 != index + 1:\n                    if index2 == -1:\n                        index2 = len(part)\n                    if prefix:\n                        return prefix + part[1:index2], sep, part[index2+1:]\n                    else:\n                        return part[:index2], sep, part[index2+1:]\n        drv = root = ''\n        if second == ':' and first in self.drive_letters:\n            drv = part[:2]\n            part = part[2:]\n            first = third\n        if first == sep:\n            root = first\n            part = part.lstrip(sep)\n        return prefix + drv, root, part\n\n    def casefold(self, s):\n        return s.lower()\n\n    def casefold_parts(self, parts):\n        return [p.lower() for p in parts]\n\n    def compile_pattern(self, pattern):\n        return re.compile(fnmatch.translate(pattern), re.IGNORECASE).fullmatch\n\n    def _split_extended_path(self, s, ext_prefix=ext_namespace_prefix):\n        prefix = ''\n        if s.startswith(ext_prefix):\n            prefix = s[:4]\n            s = s[4:]\n            if s.startswith('UNC\\\\'):\n                prefix += s[:3]\n                s = '\\\\' + s[3:]\n        return prefix, s\n\n    def is_reserved(self, parts):\n        # NOTE: the rules for reserved names seem somewhat complicated\n        # (e.g. r\"..\\NUL\" is reserved but not r\"foo\\NUL\" if \"foo\" does not\n        # exist). We err on the side of caution and return True for paths\n        # which are not considered reserved by Windows.\n        if not parts:\n            return False\n        if parts[0].startswith('\\\\\\\\'):\n            # UNC paths are never reserved\n            return False\n        name = parts[-1].partition('.')[0].partition(':')[0].rstrip(' ')\n        return name.upper() in self.reserved_names\n\n    def make_uri(self, path):\n        # Under Windows, file URIs use the UTF-8 encoding.\n        drive = path.drive\n        if len(drive) == 2 and drive[1] == ':':\n            # It's a path on a local drive => 'file:///c:/a/b'\n            rest = path.as_posix()[2:].lstrip('/')\n            return 'file:///%s/%s' % (\n                drive, urlquote_from_bytes(rest.encode('utf-8')))\n        else:\n            # It's a path on a network drive => 'file://host/share/a/b'\n            return 'file:' + urlquote_from_bytes(path.as_posix().encode('utf-8'))\n\n\nclass _PosixFlavour(_Flavour):\n    sep = '/'\n    altsep = ''\n    has_drv = False\n    pathmod = posixpath\n\n    is_supported = (os.name != 'nt')\n\n    def splitroot(self, part, sep=sep):\n        if part and part[0] == sep:\n            stripped_part = part.lstrip(sep)\n            # According to POSIX path resolution:\n            # http://pubs.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap04.html#tag_04_11\n            # \"A pathname that begins with two successive slashes may be\n            # interpreted in an implementation-defined manner, although more\n            # than two leading slashes shall be treated as a single slash\".\n            if len(part) - len(stripped_part) == 2:\n                return '', sep * 2, stripped_part\n            else:\n                return '', sep, stripped_part\n        else:\n            return '', '', part\n\n    def casefold(self, s):\n        return s\n\n    def casefold_parts(self, parts):\n        return parts\n\n    def compile_pattern(self, pattern):\n        return re.compile(fnmatch.translate(pattern)).fullmatch\n\n    def is_reserved(self, parts):\n        return False\n\n    def make_uri(self, path):\n        # We represent the path using the local filesystem encoding,\n        # for portability to other applications.\n        bpath = bytes(path)\n        return 'file://' + urlquote_from_bytes(bpath)\n\n\n_windows_flavour = _WindowsFlavour()\n_posix_flavour = _PosixFlavour()\n\n\n#\n# Globbing helpers\n#\n\ndef _make_selector(pattern_parts, flavour):\n    pat = pattern_parts[0]\n    child_parts = pattern_parts[1:]\n    if not pat:\n        return _TerminatingSelector()\n    if pat == '**':\n        cls = _RecursiveWildcardSelector\n    elif '**' in pat:\n        raise ValueError(\"Invalid pattern: '**' can only be an entire path component\")\n    elif _is_wildcard_pattern(pat):\n        cls = _WildcardSelector\n    else:\n        cls = _PreciseSelector\n    return cls(pat, child_parts, flavour)\n\nif hasattr(functools, \"lru_cache\"):\n    _make_selector = functools.lru_cache()(_make_selector)\n\n\nclass _Selector:\n    \"\"\"A selector matches a specific glob pattern part against the children\n    of a given path.\"\"\"\n\n    def __init__(self, child_parts, flavour):\n        self.child_parts = child_parts\n        if child_parts:\n            self.successor = _make_selector(child_parts, flavour)\n            self.dironly = True\n        else:\n            self.successor = _TerminatingSelector()\n            self.dironly = False\n\n    def select_from(self, parent_path):\n        \"\"\"Iterate over all child paths of `parent_path` matched by this\n        selector.  This can contain parent_path itself.\"\"\"\n        path_cls = type(parent_path)\n        is_dir = path_cls.is_dir\n        exists = path_cls.exists\n        scandir = path_cls._scandir\n        if not is_dir(parent_path):\n            return iter([])\n        return self._select_from(parent_path, is_dir, exists, scandir)\n\n\nclass _TerminatingSelector:\n\n    def _select_from(self, parent_path, is_dir, exists, scandir):\n        yield parent_path\n\n\nclass _PreciseSelector(_Selector):\n\n    def __init__(self, name, child_parts, flavour):\n        self.name = name\n        _Selector.__init__(self, child_parts, flavour)\n\n    def _select_from(self, parent_path, is_dir, exists, scandir):\n        try:\n            path = parent_path._make_child_relpath(self.name)\n            if (is_dir if self.dironly else exists)(path):\n                for p in self.successor._select_from(path, is_dir, exists, scandir):\n                    yield p\n        except PermissionError:\n            return\n\n\nclass _WildcardSelector(_Selector):\n\n    def __init__(self, pat, child_parts, flavour):\n        self.match = flavour.compile_pattern(pat)\n        _Selector.__init__(self, child_parts, flavour)\n\n    def _select_from(self, parent_path, is_dir, exists, scandir):\n        try:\n            with scandir(parent_path) as scandir_it:\n                entries = list(scandir_it)\n            for entry in entries:\n                if self.dironly:\n                    try:\n                        # \"entry.is_dir()\" can raise PermissionError\n                        # in some cases (see bpo-38894), which is not\n                        # among the errors ignored by _ignore_error()\n                        if not entry.is_dir():\n                            continue\n                    except OSError as e:\n                        if not _ignore_error(e):\n                            raise\n                        continue\n                name = entry.name\n                if self.match(name):\n                    path = parent_path._make_child_relpath(name)\n                    for p in self.successor._select_from(path, is_dir, exists, scandir):\n                        yield p\n        except PermissionError:\n            return\n\n\nclass _RecursiveWildcardSelector(_Selector):\n\n    def __init__(self, pat, child_parts, flavour):\n        _Selector.__init__(self, child_parts, flavour)\n\n    def _iterate_directories(self, parent_path, is_dir, scandir):\n        yield parent_path\n        try:\n            with scandir(parent_path) as scandir_it:\n                entries = list(scandir_it)\n            for entry in entries:\n                entry_is_dir = False\n                try:\n                    entry_is_dir = entry.is_dir(follow_symlinks=False)\n                except OSError as e:\n                    if not _ignore_error(e):\n                        raise\n                if entry_is_dir:\n                    path = parent_path._make_child_relpath(entry.name)\n                    for p in self._iterate_directories(path, is_dir, scandir):\n                        yield p\n        except PermissionError:\n            return\n\n    def _select_from(self, parent_path, is_dir, exists, scandir):\n        try:\n            yielded = set()\n            try:\n                successor_select = self.successor._select_from\n                for starting_point in self._iterate_directories(parent_path, is_dir, scandir):\n                    for p in successor_select(starting_point, is_dir, exists, scandir):\n                        if p not in yielded:\n                            yield p\n                            yielded.add(p)\n            finally:\n                yielded.clear()\n        except PermissionError:\n            return\n\n\n#\n# Public API\n#\n\nclass _PathParents(Sequence):\n    \"\"\"This object provides sequence-like access to the logical ancestors\n    of a path.  Don't try to construct it yourself.\"\"\"\n    __slots__ = ('_pathcls', '_drv', '_root', '_parts')\n\n    def __init__(self, path):\n        # We don't store the instance to avoid reference cycles\n        self._pathcls = type(path)\n        self._drv = path._drv\n        self._root = path._root\n        self._parts = path._parts\n\n    def __len__(self):\n        if self._drv or self._root:\n            return len(self._parts) - 1\n        else:\n            return len(self._parts)\n\n    def __getitem__(self, idx):\n        if isinstance(idx, slice):\n            return tuple(self[i] for i in range(*idx.indices(len(self))))\n\n        if idx >= len(self) or idx < -len(self):\n            raise IndexError(idx)\n        if idx < 0:\n            idx += len(self)\n        return self._pathcls._from_parsed_parts(self._drv, self._root,\n                                                self._parts[:-idx - 1])\n\n    def __repr__(self):\n        return \"<{}.parents>\".format(self._pathcls.__name__)\n\n\nclass PurePath(object):\n    \"\"\"Base class for manipulating paths without I/O.\n\n    PurePath represents a filesystem path and offers operations which\n    don't imply any actual filesystem I/O.  Depending on your system,\n    instantiating a PurePath will return either a PurePosixPath or a\n    PureWindowsPath object.  You can also instantiate either of these classes\n    directly, regardless of your system.\n    \"\"\"\n    __slots__ = (\n        '_drv', '_root', '_parts',\n        '_str', '_hash', '_pparts', '_cached_cparts',\n    )\n\n    def __new__(cls, *args):\n        \"\"\"Construct a PurePath from one or several strings and or existing\n        PurePath objects.  The strings and path objects are combined so as\n        to yield a canonicalized path, which is incorporated into the\n        new PurePath object.\n        \"\"\"\n        if cls is PurePath:\n            cls = PureWindowsPath if os.name == 'nt' else PurePosixPath\n        return cls._from_parts(args)\n\n    def __reduce__(self):\n        # Using the parts tuple helps share interned path parts\n        # when pickling related paths.\n        return (self.__class__, tuple(self._parts))\n\n    @classmethod\n    def _parse_args(cls, args):\n        # This is useful when you don't want to create an instance, just\n        # canonicalize some constructor arguments.\n        parts = []\n        for a in args:\n            if isinstance(a, PurePath):\n                parts += a._parts\n            else:\n                a = os.fspath(a)\n                if isinstance(a, str):\n                    # Force-cast str subclasses to str (issue #21127)\n                    parts.append(str(a))\n                else:\n                    raise TypeError(\n                        \"argument should be a str object or an os.PathLike \"\n                        \"object returning str, not %r\"\n                        % type(a))\n        return cls._flavour.parse_parts(parts)\n\n    @classmethod\n    def _from_parts(cls, args):\n        # We need to call _parse_args on the instance, so as to get the\n        # right flavour.\n        self = object.__new__(cls)\n        drv, root, parts = self._parse_args(args)\n        self._drv = drv\n        self._root = root\n        self._parts = parts\n        return self\n\n    @classmethod\n    def _from_parsed_parts(cls, drv, root, parts):\n        self = object.__new__(cls)\n        self._drv = drv\n        self._root = root\n        self._parts = parts\n        return self\n\n    @classmethod\n    def _format_parsed_parts(cls, drv, root, parts):\n        if drv or root:\n            return drv + root + cls._flavour.join(parts[1:])\n        else:\n            return cls._flavour.join(parts)\n\n    def _make_child(self, args):\n        drv, root, parts = self._parse_args(args)\n        drv, root, parts = self._flavour.join_parsed_parts(\n            self._drv, self._root, self._parts, drv, root, parts)\n        return self._from_parsed_parts(drv, root, parts)\n\n    def __str__(self):\n        \"\"\"Return the string representation of the path, suitable for\n        passing to system calls.\"\"\"\n        try:\n            return self._str\n        except AttributeError:\n            self._str = self._format_parsed_parts(self._drv, self._root,\n                                                  self._parts) or '.'\n            return self._str\n\n    def __fspath__(self):\n        return str(self)\n\n    def as_posix(self):\n        \"\"\"Return the string representation of the path with forward (/)\n        slashes.\"\"\"\n        f = self._flavour\n        return str(self).replace(f.sep, '/')\n\n    def __bytes__(self):\n        \"\"\"Return the bytes representation of the path.  This is only\n        recommended to use under Unix.\"\"\"\n        return os.fsencode(self)\n\n    def __repr__(self):\n        return \"{}({!r})\".format(self.__class__.__name__, self.as_posix())\n\n    def as_uri(self):\n        \"\"\"Return the path as a 'file' URI.\"\"\"\n        if not self.is_absolute():\n            raise ValueError(\"relative path can't be expressed as a file URI\")\n        return self._flavour.make_uri(self)\n\n    @property\n    def _cparts(self):\n        # Cached casefolded parts, for hashing and comparison\n        try:\n            return self._cached_cparts\n        except AttributeError:\n            self._cached_cparts = self._flavour.casefold_parts(self._parts)\n            return self._cached_cparts\n\n    def __eq__(self, other):\n        if not isinstance(other, PurePath):\n            return NotImplemented\n        return self._cparts == other._cparts and self._flavour is other._flavour\n\n    def __hash__(self):\n        try:\n            return self._hash\n        except AttributeError:\n            self._hash = hash(tuple(self._cparts))\n            return self._hash\n\n    def __lt__(self, other):\n        if not isinstance(other, PurePath) or self._flavour is not other._flavour:\n            return NotImplemented\n        return self._cparts < other._cparts\n\n    def __le__(self, other):\n        if not isinstance(other, PurePath) or self._flavour is not other._flavour:\n            return NotImplemented\n        return self._cparts <= other._cparts\n\n    def __gt__(self, other):\n        if not isinstance(other, PurePath) or self._flavour is not other._flavour:\n            return NotImplemented\n        return self._cparts > other._cparts\n\n    def __ge__(self, other):\n        if not isinstance(other, PurePath) or self._flavour is not other._flavour:\n            return NotImplemented\n        return self._cparts >= other._cparts\n\n    drive = property(attrgetter('_drv'),\n                     doc=\"\"\"The drive prefix (letter or UNC path), if any.\"\"\")\n\n    root = property(attrgetter('_root'),\n                    doc=\"\"\"The root of the path, if any.\"\"\")\n\n    @property\n    def anchor(self):\n        \"\"\"The concatenation of the drive and root, or ''.\"\"\"\n        anchor = self._drv + self._root\n        return anchor\n\n    @property\n    def name(self):\n        \"\"\"The final path component, if any.\"\"\"\n        parts = self._parts\n        if len(parts) == (1 if (self._drv or self._root) else 0):\n            return ''\n        return parts[-1]\n\n    @property\n    def suffix(self):\n        \"\"\"\n        The final component's last suffix, if any.\n\n        This includes the leading period. For example: '.txt'\n        \"\"\"\n        name = self.name\n        i = name.rfind('.')\n        if 0 < i < len(name) - 1:\n            return name[i:]\n        else:\n            return ''\n\n    @property\n    def suffixes(self):\n        \"\"\"\n        A list of the final component's suffixes, if any.\n\n        These include the leading periods. For example: ['.tar', '.gz']\n        \"\"\"\n        name = self.name\n        if name.endswith('.'):\n            return []\n        name = name.lstrip('.')\n        return ['.' + suffix for suffix in name.split('.')[1:]]\n\n    @property\n    def stem(self):\n        \"\"\"The final path component, minus its last suffix.\"\"\"\n        name = self.name\n        i = name.rfind('.')\n        if 0 < i < len(name) - 1:\n            return name[:i]\n        else:\n            return name\n\n    def with_name(self, name):\n        \"\"\"Return a new path with the file name changed.\"\"\"\n        if not self.name:\n            raise ValueError(\"%r has an empty name\" % (self,))\n        drv, root, parts = self._flavour.parse_parts((name,))\n        if (not name or name[-1] in [self._flavour.sep, self._flavour.altsep]\n            or drv or root or len(parts) != 1):\n            raise ValueError(\"Invalid name %r\" % (name))\n        return self._from_parsed_parts(self._drv, self._root,\n                                       self._parts[:-1] + [name])\n\n    def with_stem(self, stem):\n        \"\"\"Return a new path with the stem changed.\"\"\"\n        return self.with_name(stem + self.suffix)\n\n    def with_suffix(self, suffix):\n        \"\"\"Return a new path with the file suffix changed.  If the path\n        has no suffix, add given suffix.  If the given suffix is an empty\n        string, remove the suffix from the path.\n        \"\"\"\n        f = self._flavour\n        if f.sep in suffix or f.altsep and f.altsep in suffix:\n            raise ValueError(\"Invalid suffix %r\" % (suffix,))\n        if suffix and not suffix.startswith('.') or suffix == '.':\n            raise ValueError(\"Invalid suffix %r\" % (suffix))\n        name = self.name\n        if not name:\n            raise ValueError(\"%r has an empty name\" % (self,))\n        old_suffix = self.suffix\n        if not old_suffix:\n            name = name + suffix\n        else:\n            name = name[:-len(old_suffix)] + suffix\n        return self._from_parsed_parts(self._drv, self._root,\n                                       self._parts[:-1] + [name])\n\n    def relative_to(self, *other):\n        \"\"\"Return the relative path to another path identified by the passed\n        arguments.  If the operation is not possible (because this is not\n        a subpath of the other path), raise ValueError.\n        \"\"\"\n        # For the purpose of this method, drive and root are considered\n        # separate parts, i.e.:\n        #   Path('c:/').relative_to('c:')  gives Path('/')\n        #   Path('c:/').relative_to('/')   raise ValueError\n        if not other:\n            raise TypeError(\"need at least one argument\")\n        parts = self._parts\n        drv = self._drv\n        root = self._root\n        if root:\n            abs_parts = [drv, root] + parts[1:]\n        else:\n            abs_parts = parts\n        to_drv, to_root, to_parts = self._parse_args(other)\n        if to_root:\n            to_abs_parts = [to_drv, to_root] + to_parts[1:]\n        else:\n            to_abs_parts = to_parts\n        n = len(to_abs_parts)\n        cf = self._flavour.casefold_parts\n        if (root or drv) if n == 0 else cf(abs_parts[:n]) != cf(to_abs_parts):\n            formatted = self._format_parsed_parts(to_drv, to_root, to_parts)\n            raise ValueError(\"{!r} is not in the subpath of {!r}\"\n                    \" OR one path is relative and the other is absolute.\"\n                             .format(str(self), str(formatted)))\n        return self._from_parsed_parts('', root if n == 1 else '',\n                                       abs_parts[n:])\n\n    def is_relative_to(self, *other):\n        \"\"\"Return True if the path is relative to another path or False.\n        \"\"\"\n        try:\n            self.relative_to(*other)\n            return True\n        except ValueError:\n            return False\n\n    @property\n    def parts(self):\n        \"\"\"An object providing sequence-like access to the\n        components in the filesystem path.\"\"\"\n        # We cache the tuple to avoid building a new one each time .parts\n        # is accessed.  XXX is this necessary?\n        try:\n            return self._pparts\n        except AttributeError:\n            self._pparts = tuple(self._parts)\n            return self._pparts\n\n    def joinpath(self, *args):\n        \"\"\"Combine this path with one or several arguments, and return a\n        new path representing either a subpath (if all arguments are relative\n        paths) or a totally different path (if one of the arguments is\n        anchored).\n        \"\"\"\n        return self._make_child(args)\n\n    def __truediv__(self, key):\n        try:\n            return self._make_child((key,))\n        except TypeError:\n            return NotImplemented\n\n    def __rtruediv__(self, key):\n        try:\n            return self._from_parts([key] + self._parts)\n        except TypeError:\n            return NotImplemented\n\n    @property\n    def parent(self):\n        \"\"\"The logical parent of the path.\"\"\"\n        drv = self._drv\n        root = self._root\n        parts = self._parts\n        if len(parts) == 1 and (drv or root):\n            return self\n        return self._from_parsed_parts(drv, root, parts[:-1])\n\n    @property\n    def parents(self):\n        \"\"\"A sequence of this path's logical parents.\"\"\"\n        return _PathParents(self)\n\n    def is_absolute(self):\n        \"\"\"True if the path is absolute (has both a root and, if applicable,\n        a drive).\"\"\"\n        if not self._root:\n            return False\n        return not self._flavour.has_drv or bool(self._drv)\n\n    def is_reserved(self):\n        \"\"\"Return True if the path contains one of the special names reserved\n        by the system, if any.\"\"\"\n        return self._flavour.is_reserved(self._parts)\n\n    def match(self, path_pattern):\n        \"\"\"\n        Return True if this path matches the given pattern.\n        \"\"\"\n        cf = self._flavour.casefold\n        path_pattern = cf(path_pattern)\n        drv, root, pat_parts = self._flavour.parse_parts((path_pattern,))\n        if not pat_parts:\n            raise ValueError(\"empty pattern\")\n        if drv and drv != cf(self._drv):\n            return False\n        if root and root != cf(self._root):\n            return False\n        parts = self._cparts\n        if drv or root:\n            if len(pat_parts) != len(parts):\n                return False\n            pat_parts = pat_parts[1:]\n        elif len(pat_parts) > len(parts):\n            return False\n        for part, pat in zip(reversed(parts), reversed(pat_parts)):\n            if not fnmatch.fnmatchcase(part, pat):\n                return False\n        return True\n\n# Can't subclass os.PathLike from PurePath and keep the constructor\n# optimizations in PurePath._parse_args().\nos.PathLike.register(PurePath)\n\n\nclass PurePosixPath(PurePath):\n    \"\"\"PurePath subclass for non-Windows systems.\n\n    On a POSIX system, instantiating a PurePath should return this object.\n    However, you can also instantiate it directly on any system.\n    \"\"\"\n    _flavour = _posix_flavour\n    __slots__ = ()\n\n\nclass PureWindowsPath(PurePath):\n    \"\"\"PurePath subclass for Windows systems.\n\n    On a Windows system, instantiating a PurePath should return this object.\n    However, you can also instantiate it directly on any system.\n    \"\"\"\n    _flavour = _windows_flavour\n    __slots__ = ()\n\n\n# Filesystem-accessing classes\n\n\nclass Path(PurePath):\n    \"\"\"PurePath subclass that can make system calls.\n\n    Path represents a filesystem path but unlike PurePath, also offers\n    methods to do system calls on path objects. Depending on your system,\n    instantiating a Path will return either a PosixPath or a WindowsPath\n    object. You can also instantiate a PosixPath or WindowsPath directly,\n    but cannot instantiate a WindowsPath on a POSIX system or vice versa.\n    \"\"\"\n    __slots__ = ()\n\n    def __new__(cls, *args, **kwargs):\n        if cls is Path:\n            cls = WindowsPath if os.name == 'nt' else PosixPath\n        self = cls._from_parts(args)\n        if not self._flavour.is_supported:\n            raise NotImplementedError(\"cannot instantiate %r on your system\"\n                                      % (cls.__name__,))\n        return self\n\n    def _make_child_relpath(self, part):\n        # This is an optimization used for dir walking.  `part` must be\n        # a single part relative to this path.\n        parts = self._parts + [part]\n        return self._from_parsed_parts(self._drv, self._root, parts)\n\n    def __enter__(self):\n        # In previous versions of pathlib, __exit__() marked this path as\n        # closed; subsequent attempts to perform I/O would raise an IOError.\n        # This functionality was never documented, and had the effect of\n        # making Path objects mutable, contrary to PEP 428.\n        # In Python 3.9 __exit__() was made a no-op.\n        # In Python 3.11 __enter__() began emitting DeprecationWarning.\n        # In Python 3.13 __enter__() and __exit__() should be removed.\n        warnings.warn(\"pathlib.Path.__enter__() is deprecated and scheduled \"\n                      \"for removal in Python 3.13; Path objects as a context \"\n                      \"manager is a no-op\",\n                      DeprecationWarning, stacklevel=2)\n        return self\n\n    def __exit__(self, t, v, tb):\n        pass\n\n    # Public API\n\n    @classmethod\n    def cwd(cls):\n        \"\"\"Return a new path pointing to the current working directory\n        (as returned by os.getcwd()).\n        \"\"\"\n        return cls(os.getcwd())\n\n    @classmethod\n    def home(cls):\n        \"\"\"Return a new path pointing to the user's home directory (as\n        returned by os.path.expanduser('~')).\n        \"\"\"\n        return cls(\"~\").expanduser()\n\n    def samefile(self, other_path):\n        \"\"\"Return whether other_path is the same or not as this file\n        (as returned by os.path.samefile()).\n        \"\"\"\n        st = self.stat()\n        try:\n            other_st = other_path.stat()\n        except AttributeError:\n            other_st = self.__class__(other_path).stat()\n        return os.path.samestat(st, other_st)\n\n    def iterdir(self):\n        \"\"\"Iterate over the files in this directory.  Does not yield any\n        result for the special paths '.' and '..'.\n        \"\"\"\n        for name in os.listdir(self):\n            yield self._make_child_relpath(name)\n\n    def _scandir(self):\n        # bpo-24132: a future version of pathlib will support subclassing of\n        # pathlib.Path to customize how the filesystem is accessed. This\n        # includes scandir(), which is used to implement glob().\n        return os.scandir(self)\n\n    def glob(self, pattern):\n        \"\"\"Iterate over this subtree and yield all existing files (of any\n        kind, including directories) matching the given relative pattern.\n        \"\"\"\n        sys.audit(\"pathlib.Path.glob\", self, pattern)\n        if not pattern:\n            raise ValueError(\"Unacceptable pattern: {!r}\".format(pattern))\n        drv, root, pattern_parts = self._flavour.parse_parts((pattern,))\n        if drv or root:\n            raise NotImplementedError(\"Non-relative patterns are unsupported\")\n        if pattern[-1] in (self._flavour.sep, self._flavour.altsep):\n            pattern_parts.append('')\n        selector = _make_selector(tuple(pattern_parts), self._flavour)\n        for p in selector.select_from(self):\n            yield p\n\n    def rglob(self, pattern):\n        \"\"\"Recursively yield all existing files (of any kind, including\n        directories) matching the given relative pattern, anywhere in\n        this subtree.\n        \"\"\"\n        sys.audit(\"pathlib.Path.rglob\", self, pattern)\n        drv, root, pattern_parts = self._flavour.parse_parts((pattern,))\n        if drv or root:\n            raise NotImplementedError(\"Non-relative patterns are unsupported\")\n        if pattern and pattern[-1] in (self._flavour.sep, self._flavour.altsep):\n            pattern_parts.append('')\n        selector = _make_selector((\"**\",) + tuple(pattern_parts), self._flavour)\n        for p in selector.select_from(self):\n            yield p\n\n    def absolute(self):\n        \"\"\"Return an absolute version of this path by prepending the current\n        working directory. No normalization or symlink resolution is performed.\n\n        Use resolve() to get the canonical path to a file.\n        \"\"\"\n        if self.is_absolute():\n            return self\n        return self._from_parts([self.cwd()] + self._parts)\n\n    def resolve(self, strict=False):\n        \"\"\"\n        Make the path absolute, resolving all symlinks on the way and also\n        normalizing it.\n        \"\"\"\n\n        def check_eloop(e):\n            winerror = getattr(e, 'winerror', 0)\n            if e.errno == ELOOP or winerror == _WINERROR_CANT_RESOLVE_FILENAME:\n                raise RuntimeError(\"Symlink loop from %r\" % e.filename)\n\n        try:\n            s = os.path.realpath(self, strict=strict)\n        except OSError as e:\n            check_eloop(e)\n            raise\n        p = self._from_parts((s,))\n\n        # In non-strict mode, realpath() doesn't raise on symlink loops.\n        # Ensure we get an exception by calling stat()\n        if not strict:\n            try:\n                p.stat()\n            except OSError as e:\n                check_eloop(e)\n        return p\n\n    def stat(self, *, follow_symlinks=True):\n        \"\"\"\n        Return the result of the stat() system call on this path, like\n        os.stat() does.\n        \"\"\"\n        return os.stat(self, follow_symlinks=follow_symlinks)\n\n    def owner(self):\n        \"\"\"\n        Return the login name of the file owner.\n        \"\"\"\n        try:\n            import pwd\n            return pwd.getpwuid(self.stat().st_uid).pw_name\n        except ImportError:\n            raise NotImplementedError(\"Path.owner() is unsupported on this system\")\n\n    def group(self):\n        \"\"\"\n        Return the group name of the file gid.\n        \"\"\"\n\n        try:\n            import grp\n            return grp.getgrgid(self.stat().st_gid).gr_name\n        except ImportError:\n            raise NotImplementedError(\"Path.group() is unsupported on this system\")\n\n    def open(self, mode='r', buffering=-1, encoding=None,\n             errors=None, newline=None):\n        \"\"\"\n        Open the file pointed by this path and return a file object, as\n        the built-in open() function does.\n        \"\"\"\n        if \"b\" not in mode:\n            encoding = io.text_encoding(encoding)\n        return io.open(self, mode, buffering, encoding, errors, newline)\n\n    def read_bytes(self):\n        \"\"\"\n        Open the file in bytes mode, read it, and close the file.\n        \"\"\"\n        with self.open(mode='rb') as f:\n            return f.read()\n\n    def read_text(self, encoding=None, errors=None):\n        \"\"\"\n        Open the file in text mode, read it, and close the file.\n        \"\"\"\n        encoding = io.text_encoding(encoding)\n        with self.open(mode='r', encoding=encoding, errors=errors) as f:\n            return f.read()\n\n    def write_bytes(self, data):\n        \"\"\"\n        Open the file in bytes mode, write to it, and close the file.\n        \"\"\"\n        # type-check for the buffer interface before truncating the file\n        view = memoryview(data)\n        with self.open(mode='wb') as f:\n            return f.write(view)\n\n    def write_text(self, data, encoding=None, errors=None, newline=None):\n        \"\"\"\n        Open the file in text mode, write to it, and close the file.\n        \"\"\"\n        if not isinstance(data, str):\n            raise TypeError('data must be str, not %s' %\n                            data.__class__.__name__)\n        encoding = io.text_encoding(encoding)\n        with self.open(mode='w', encoding=encoding, errors=errors, newline=newline) as f:\n            return f.write(data)\n\n    def readlink(self):\n        \"\"\"\n        Return the path to which the symbolic link points.\n        \"\"\"\n        if not hasattr(os, \"readlink\"):\n            raise NotImplementedError(\"os.readlink() not available on this system\")\n        return self._from_parts((os.readlink(self),))\n\n    def touch(self, mode=0o666, exist_ok=True):\n        \"\"\"\n        Create this file with the given access mode, if it doesn't exist.\n        \"\"\"\n\n        if exist_ok:\n            # First try to bump modification time\n            # Implementation note: GNU touch uses the UTIME_NOW option of\n            # the utimensat() / futimens() functions.\n            try:\n                os.utime(self, None)\n            except OSError:\n                # Avoid exception chaining\n                pass\n            else:\n                return\n        flags = os.O_CREAT | os.O_WRONLY\n        if not exist_ok:\n            flags |= os.O_EXCL\n        fd = os.open(self, flags, mode)\n        os.close(fd)\n\n    def mkdir(self, mode=0o777, parents=False, exist_ok=False):\n        \"\"\"\n        Create a new directory at this given path.\n        \"\"\"\n        try:\n            os.mkdir(self, mode)\n        except FileNotFoundError:\n            if not parents or self.parent == self:\n                raise\n            self.parent.mkdir(parents=True, exist_ok=True)\n            self.mkdir(mode, parents=False, exist_ok=exist_ok)\n        except OSError:\n            # Cannot rely on checking for EEXIST, since the operating system\n            # could give priority to other errors like EACCES or EROFS\n            if not exist_ok or not self.is_dir():\n                raise\n\n    def chmod(self, mode, *, follow_symlinks=True):\n        \"\"\"\n        Change the permissions of the path, like os.chmod().\n        \"\"\"\n        os.chmod(self, mode, follow_symlinks=follow_symlinks)\n\n    def lchmod(self, mode):\n        \"\"\"\n        Like chmod(), except if the path points to a symlink, the symlink's\n        permissions are changed, rather than its target's.\n        \"\"\"\n        self.chmod(mode, follow_symlinks=False)\n\n    def unlink(self, missing_ok=False):\n        \"\"\"\n        Remove this file or link.\n        If the path is a directory, use rmdir() instead.\n        \"\"\"\n        try:\n            os.unlink(self)\n        except FileNotFoundError:\n            if not missing_ok:\n                raise\n\n    def rmdir(self):\n        \"\"\"\n        Remove this directory.  The directory must be empty.\n        \"\"\"\n        os.rmdir(self)\n\n    def lstat(self):\n        \"\"\"\n        Like stat(), except if the path points to a symlink, the symlink's\n        status information is returned, rather than its target's.\n        \"\"\"\n        return self.stat(follow_symlinks=False)\n\n    def rename(self, target):\n        \"\"\"\n        Rename this path to the target path.\n\n        The target path may be absolute or relative. Relative paths are\n        interpreted relative to the current working directory, *not* the\n        directory of the Path object.\n\n        Returns the new Path instance pointing to the target path.\n        \"\"\"\n        os.rename(self, target)\n        return self.__class__(target)\n\n    def replace(self, target):\n        \"\"\"\n        Rename this path to the target path, overwriting if that path exists.\n\n        The target path may be absolute or relative. Relative paths are\n        interpreted relative to the current working directory, *not* the\n        directory of the Path object.\n\n        Returns the new Path instance pointing to the target path.\n        \"\"\"\n        os.replace(self, target)\n        return self.__class__(target)\n\n    def symlink_to(self, target, target_is_directory=False):\n        \"\"\"\n        Make this path a symlink pointing to the target path.\n        Note the order of arguments (link, target) is the reverse of os.symlink.\n        \"\"\"\n        if not hasattr(os, \"symlink\"):\n            raise NotImplementedError(\"os.symlink() not available on this system\")\n        os.symlink(target, self, target_is_directory)\n\n    def hardlink_to(self, target):\n        \"\"\"\n        Make this path a hard link pointing to the same file as *target*.\n\n        Note the order of arguments (self, target) is the reverse of os.link's.\n        \"\"\"\n        if not hasattr(os, \"link\"):\n            raise NotImplementedError(\"os.link() not available on this system\")\n        os.link(target, self)\n\n    def link_to(self, target):\n        \"\"\"\n        Make the target path a hard link pointing to this path.\n\n        Note this function does not make this path a hard link to *target*,\n        despite the implication of the function and argument names. The order\n        of arguments (target, link) is the reverse of Path.symlink_to, but\n        matches that of os.link.\n\n        Deprecated since Python 3.10 and scheduled for removal in Python 3.12.\n        Use `hardlink_to()` instead.\n        \"\"\"\n        warnings.warn(\"pathlib.Path.link_to() is deprecated and is scheduled \"\n                      \"for removal in Python 3.12. \"\n                      \"Use pathlib.Path.hardlink_to() instead.\",\n                      DeprecationWarning, stacklevel=2)\n        self.__class__(target).hardlink_to(self)\n\n    # Convenience functions for querying the stat results\n\n    def exists(self):\n        \"\"\"\n        Whether this path exists.\n        \"\"\"\n        try:\n            self.stat()\n        except OSError as e:\n            if not _ignore_error(e):\n                raise\n            return False\n        except ValueError:\n            # Non-encodable path\n            return False\n        return True\n\n    def is_dir(self):\n        \"\"\"\n        Whether this path is a directory.\n        \"\"\"\n        try:\n            return S_ISDIR(self.stat().st_mode)\n        except OSError as e:\n            if not _ignore_error(e):\n                raise\n            # Path doesn't exist or is a broken symlink\n            # (see http://web.archive.org/web/20200623061726/https://bitbucket.org/pitrou/pathlib/issues/12/ )\n            return False\n        except ValueError:\n            # Non-encodable path\n            return False\n\n    def is_file(self):\n        \"\"\"\n        Whether this path is a regular file (also True for symlinks pointing\n        to regular files).\n        \"\"\"\n        try:\n            return S_ISREG(self.stat().st_mode)\n        except OSError as e:\n            if not _ignore_error(e):\n                raise\n            # Path doesn't exist or is a broken symlink\n            # (see http://web.archive.org/web/20200623061726/https://bitbucket.org/pitrou/pathlib/issues/12/ )\n            return False\n        except ValueError:\n            # Non-encodable path\n            return False\n\n    def is_mount(self):\n        \"\"\"\n        Check if this path is a POSIX mount point\n        \"\"\"\n        # Need to exist and be a dir\n        if not self.exists() or not self.is_dir():\n            return False\n\n        try:\n            parent_dev = self.parent.stat().st_dev\n        except OSError:\n            return False\n\n        dev = self.stat().st_dev\n        if dev != parent_dev:\n            return True\n        ino = self.stat().st_ino\n        parent_ino = self.parent.stat().st_ino\n        return ino == parent_ino\n\n    def is_symlink(self):\n        \"\"\"\n        Whether this path is a symbolic link.\n        \"\"\"\n        try:\n            return S_ISLNK(self.lstat().st_mode)\n        except OSError as e:\n            if not _ignore_error(e):\n                raise\n            # Path doesn't exist\n            return False\n        except ValueError:\n            # Non-encodable path\n            return False\n\n    def is_block_device(self):\n        \"\"\"\n        Whether this path is a block device.\n        \"\"\"\n        try:\n            return S_ISBLK(self.stat().st_mode)\n        except OSError as e:\n            if not _ignore_error(e):\n                raise\n            # Path doesn't exist or is a broken symlink\n            # (see http://web.archive.org/web/20200623061726/https://bitbucket.org/pitrou/pathlib/issues/12/ )\n            return False\n        except ValueError:\n            # Non-encodable path\n            return False\n\n    def is_char_device(self):\n        \"\"\"\n        Whether this path is a character device.\n        \"\"\"\n        try:\n            return S_ISCHR(self.stat().st_mode)\n        except OSError as e:\n            if not _ignore_error(e):\n                raise\n            # Path doesn't exist or is a broken symlink\n            # (see http://web.archive.org/web/20200623061726/https://bitbucket.org/pitrou/pathlib/issues/12/ )\n            return False\n        except ValueError:\n            # Non-encodable path\n            return False\n\n    def is_fifo(self):\n        \"\"\"\n        Whether this path is a FIFO.\n        \"\"\"\n        try:\n            return S_ISFIFO(self.stat().st_mode)\n        except OSError as e:\n            if not _ignore_error(e):\n                raise\n            # Path doesn't exist or is a broken symlink\n            # (see http://web.archive.org/web/20200623061726/https://bitbucket.org/pitrou/pathlib/issues/12/ )\n            return False\n        except ValueError:\n            # Non-encodable path\n            return False\n\n    def is_socket(self):\n        \"\"\"\n        Whether this path is a socket.\n        \"\"\"\n        try:\n            return S_ISSOCK(self.stat().st_mode)\n        except OSError as e:\n            if not _ignore_error(e):\n                raise\n            # Path doesn't exist or is a broken symlink\n            # (see http://web.archive.org/web/20200623061726/https://bitbucket.org/pitrou/pathlib/issues/12/ )\n            return False\n        except ValueError:\n            # Non-encodable path\n            return False\n\n    def expanduser(self):\n        \"\"\" Return a new path with expanded ~ and ~user constructs\n        (as returned by os.path.expanduser)\n        \"\"\"\n        if (not (self._drv or self._root) and\n            self._parts and self._parts[0][:1] == '~'):\n            homedir = os.path.expanduser(self._parts[0])\n            if homedir[:1] == \"~\":\n                raise RuntimeError(\"Could not determine home directory.\")\n            return self._from_parts([homedir] + self._parts[1:])\n\n        return self\n\n\nclass PosixPath(Path, PurePosixPath):\n    \"\"\"Path subclass for non-Windows systems.\n\n    On a POSIX system, instantiating a Path should return this object.\n    \"\"\"\n    __slots__ = ()\n\nclass WindowsPath(Path, PureWindowsPath):\n    \"\"\"Path subclass for Windows systems.\n\n    On a Windows system, instantiating a Path should return this object.\n    \"\"\"\n    __slots__ = ()\n\n    def is_mount(self):\n        raise NotImplementedError(\"Path.is_mount() is unsupported on this system\")\n",1406],"C:\\Users\\adam\\miniconda3\\Lib\\importlib\\__init__.py":["\"\"\"A pure Python implementation of import.\"\"\"\n__all__ = ['__import__', 'import_module', 'invalidate_caches', 'reload']\n\n# Bootstrap help #####################################################\n\n# Until bootstrapping is complete, DO NOT import any modules that attempt\n# to import importlib._bootstrap (directly or indirectly). Since this\n# partially initialised package would be present in sys.modules, those\n# modules would get an uninitialised copy of the source version, instead\n# of a fully initialised version (either the frozen one or the one\n# initialised below if the frozen one is not available).\nimport _imp  # Just the builtin component, NOT the full Python module\nimport sys\n\ntry:\n    import _frozen_importlib as _bootstrap\nexcept ImportError:\n    from . import _bootstrap\n    _bootstrap._setup(sys, _imp)\nelse:\n    # importlib._bootstrap is the built-in import, ensure we don't create\n    # a second copy of the module.\n    _bootstrap.__name__ = 'importlib._bootstrap'\n    _bootstrap.__package__ = 'importlib'\n    try:\n        _bootstrap.__file__ = __file__.replace('__init__.py', '_bootstrap.py')\n    except NameError:\n        # __file__ is not guaranteed to be defined, e.g. if this code gets\n        # frozen by a tool like cx_Freeze.\n        pass\n    sys.modules['importlib._bootstrap'] = _bootstrap\n\ntry:\n    import _frozen_importlib_external as _bootstrap_external\nexcept ImportError:\n    from . import _bootstrap_external\n    _bootstrap_external._set_bootstrap_module(_bootstrap)\n    _bootstrap._bootstrap_external = _bootstrap_external\nelse:\n    _bootstrap_external.__name__ = 'importlib._bootstrap_external'\n    _bootstrap_external.__package__ = 'importlib'\n    try:\n        _bootstrap_external.__file__ = __file__.replace('__init__.py', '_bootstrap_external.py')\n    except NameError:\n        # __file__ is not guaranteed to be defined, e.g. if this code gets\n        # frozen by a tool like cx_Freeze.\n        pass\n    sys.modules['importlib._bootstrap_external'] = _bootstrap_external\n\n# To simplify imports in test code\n_pack_uint32 = _bootstrap_external._pack_uint32\n_unpack_uint32 = _bootstrap_external._unpack_uint32\n\n# Fully bootstrapped at this point, import whatever you like, circular\n# dependencies and startup overhead minimisation permitting :)\n\nimport warnings\n\n\n# Public API #########################################################\n\nfrom ._bootstrap import __import__\n\n\ndef invalidate_caches():\n    \"\"\"Call the invalidate_caches() method on all meta path finders stored in\n    sys.meta_path (where implemented).\"\"\"\n    for finder in sys.meta_path:\n        if hasattr(finder, 'invalidate_caches'):\n            finder.invalidate_caches()\n\n\ndef find_loader(name, path=None):\n    \"\"\"Return the loader for the specified module.\n\n    This is a backward-compatible wrapper around find_spec().\n\n    This function is deprecated in favor of importlib.util.find_spec().\n\n    \"\"\"\n    warnings.warn('Deprecated since Python 3.4 and slated for removal in '\n                  'Python 3.12; use importlib.util.find_spec() instead',\n                  DeprecationWarning, stacklevel=2)\n    try:\n        loader = sys.modules[name].__loader__\n        if loader is None:\n            raise ValueError('{}.__loader__ is None'.format(name))\n        else:\n            return loader\n    except KeyError:\n        pass\n    except AttributeError:\n        raise ValueError('{}.__loader__ is not set'.format(name)) from None\n\n    spec = _bootstrap._find_spec(name, path)\n    # We won't worry about malformed specs (missing attributes).\n    if spec is None:\n        return None\n    if spec.loader is None:\n        if spec.submodule_search_locations is None:\n            raise ImportError('spec for {} missing loader'.format(name),\n                              name=name)\n        raise ImportError('namespace packages do not have loaders',\n                          name=name)\n    return spec.loader\n\n\ndef import_module(name, package=None):\n    \"\"\"Import a module.\n\n    The 'package' argument is required when performing a relative import. It\n    specifies the package to use as the anchor point from which to resolve the\n    relative import to an absolute import.\n\n    \"\"\"\n    level = 0\n    if name.startswith('.'):\n        if not package:\n            msg = (\"the 'package' argument is required to perform a relative \"\n                   \"import for {!r}\")\n            raise TypeError(msg.format(name))\n        for character in name:\n            if character != '.':\n                break\n            level += 1\n    return _bootstrap._gcd_import(name[level:], package, level)\n\n\n_RELOADING = {}\n\n\ndef reload(module):\n    \"\"\"Reload the module and return it.\n\n    The module must have been successfully imported before.\n\n    \"\"\"\n    try:\n        name = module.__spec__.name\n    except AttributeError:\n        try:\n            name = module.__name__\n        except AttributeError:\n            raise TypeError(\"reload() argument must be a module\")\n\n    if sys.modules.get(name) is not module:\n        msg = \"module {} not in sys.modules\"\n        raise ImportError(msg.format(name), name=name)\n    if name in _RELOADING:\n        return _RELOADING[name]\n    _RELOADING[name] = module\n    try:\n        parent_name = name.rpartition('.')[0]\n        if parent_name:\n            try:\n                parent = sys.modules[parent_name]\n            except KeyError:\n                msg = \"parent {!r} not in sys.modules\"\n                raise ImportError(msg.format(parent_name),\n                                  name=parent_name) from None\n            else:\n                pkgpath = parent.__path__\n        else:\n            pkgpath = None\n        target = module\n        spec = module.__spec__ = _bootstrap._find_spec(name, pkgpath, target)\n        if spec is None:\n            raise ModuleNotFoundError(f\"spec not found for the module {name!r}\", name=name)\n        _bootstrap._exec(spec, module)\n        # The module may have replaced itself in sys.modules!\n        return sys.modules[name]\n    finally:\n        try:\n            del _RELOADING[name]\n        except KeyError:\n            pass\n",176],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\config\\plugins.py":["import importlib\n\nfrom ..core.legacy_plugin_wrapper import LegacyPlugin\n\n\nclass PluginConfig:\n    \"\"\"Plugin Configuration Metadata\n\n    This class holds the information needed to lazy-import plugins.\n\n    Parameters\n    ----------\n    name : str\n        The name of the plugin.\n    class_name : str\n        The name of the plugin class inside the plugin module.\n    module_name : str\n        The name of the module/package from which to import the plugin.\n    is_legacy : bool\n        If True, this plugin is a v2 plugin and will be wrapped in a\n        LegacyPlugin. Default: False.\n    package_name : str\n        If the given module name points to a relative module, then the package\n        name determines the package it is relative to.\n    install_name : str\n        The name of the optional dependency that can be used to install this\n        plugin if it is missing.\n    legacy_args : Dict\n        A dictionary of kwargs to pass to the v2 plugin (Format) upon construction.\n\n    Examples\n    --------\n    >>> PluginConfig(\n            name=\"TIFF\",\n            class_name=\"TiffFormat\",\n            module_name=\"imageio.plugins.tifffile\",\n            is_legacy=True,\n            install_name=\"tifffile\",\n            legacy_args={\n                \"description\": \"TIFF format\",\n                \"extensions\": \".tif .tiff .stk .lsm\",\n                \"modes\": \"iIvV\",\n            },\n        )\n    >>> PluginConfig(\n            name=\"pillow\",\n            class_name=\"PillowPlugin\",\n            module_name=\"imageio.plugins.pillow\"\n        )\n\n    \"\"\"\n\n    def __init__(\n        self,\n        name,\n        class_name,\n        module_name,\n        *,\n        is_legacy=False,\n        package_name=None,\n        install_name=None,\n        legacy_args=None,\n    ):\n        legacy_args = legacy_args or dict()\n\n        self.name = name\n        self.class_name = class_name\n        self.module_name = module_name\n        self.package_name = package_name\n\n        self.is_legacy = is_legacy\n        self.install_name = install_name or self.name\n        self.legacy_args = {\"name\": name, \"description\": \"A legacy plugin\"}\n        self.legacy_args.update(legacy_args)\n\n    @property\n    def format(self):\n        \"\"\"For backwards compatibility with FormatManager\n\n        Delete when migrating to v3\n        \"\"\"\n        if not self.is_legacy:\n            raise RuntimeError(\"Can only get format for legacy plugins.\")\n\n        module = importlib.import_module(self.module_name, self.package_name)\n        clazz = getattr(module, self.class_name)\n        return clazz(**self.legacy_args)\n\n    @property\n    def plugin_class(self):\n        \"\"\"Get the plugin class (import if needed)\n\n        Returns\n        -------\n        plugin_class : Any\n            The class that can be used to instantiate plugins.\n\n        \"\"\"\n\n        module = importlib.import_module(self.module_name, self.package_name)\n        clazz = getattr(module, self.class_name)\n\n        if self.is_legacy:\n            legacy_plugin = clazz(**self.legacy_args)\n\n            def partial_legacy_plugin(request):\n                return LegacyPlugin(request, legacy_plugin)\n\n            clazz = partial_legacy_plugin\n\n        return clazz\n\n\nknown_plugins = dict()\nknown_plugins[\"pillow\"] = PluginConfig(\n    name=\"pillow\", class_name=\"PillowPlugin\", module_name=\"imageio.plugins.pillow\"\n)\nknown_plugins[\"pyav\"] = PluginConfig(\n    name=\"pyav\", class_name=\"PyAVPlugin\", module_name=\"imageio.plugins.pyav\"\n)\nknown_plugins[\"opencv\"] = PluginConfig(\n    name=\"opencv\", class_name=\"OpenCVPlugin\", module_name=\"imageio.plugins.opencv\"\n)\nknown_plugins[\"tifffile\"] = PluginConfig(\n    name=\"tifffile\",\n    class_name=\"TifffilePlugin\",\n    module_name=\"imageio.plugins.tifffile_v3\",\n)\nknown_plugins[\"SPE\"] = PluginConfig(\n    name=\"spe\", class_name=\"SpePlugin\", module_name=\"imageio.plugins.spe\"\n)\n\n\n# Legacy plugins\n# ==============\n#\n# Which are partly registered by format, partly by plugin, and partly by a mix\n# of both. We keep the naming here for backwards compatibility.\n# In v3 this should become a single entry per plugin named after the plugin\n# We can choose extension-specific priority in ``config.extensions``.\n#\n# Note: Since python 3.7 order of insertion determines the order of dict().keys()\n# This means that the order here determines the order by which plugins are\n# checked during the full fallback search. We don't advertise this downstream,\n# but it could be a useful thing to keep in mind to choose a sensible default\n# search order.\n\nknown_plugins[\"TIFF\"] = PluginConfig(\n    name=\"TIFF\",\n    class_name=\"TiffFormat\",\n    module_name=\"imageio.plugins.tifffile\",\n    is_legacy=True,\n    install_name=\"tifffile\",\n    legacy_args={\n        \"description\": \"TIFF format\",\n        \"extensions\": \".tif .tiff .stk .lsm\",\n        \"modes\": \"iIvV\",\n    },\n)\n\n# PILLOW plugin formats (legacy)\nPILLOW_FORMATS = [\n    (\"BMP\", \"Windows Bitmap\", \".bmp\", \"PillowFormat\"),\n    (\"BUFR\", \"BUFR\", \".bufr\", \"PillowFormat\"),\n    (\"CUR\", \"Windows Cursor\", \".cur\", \"PillowFormat\"),\n    (\"DCX\", \"Intel DCX\", \".dcx\", \"PillowFormat\"),\n    (\"DDS\", \"DirectDraw Surface\", \".dds\", \"PillowFormat\"),\n    (\"DIB\", \"Windows Bitmap\", \"\", \"PillowFormat\"),\n    (\"EPS\", \"Encapsulated Postscript\", \".ps .eps\", \"PillowFormat\"),\n    (\"FITS\", \"FITS\", \".fit .fits\", \"PillowFormat\"),\n    (\"FLI\", \"Autodesk FLI/FLC Animation\", \".fli .flc\", \"PillowFormat\"),\n    (\"FPX\", \"FlashPix\", \".fpx\", \"PillowFormat\"),\n    (\"FTEX\", \"Texture File Format (IW2:EOC)\", \".ftc .ftu\", \"PillowFormat\"),\n    (\"GBR\", \"GIMP brush file\", \".gbr\", \"PillowFormat\"),\n    (\"GIF\", \"Compuserve GIF\", \".gif\", \"GIFFormat\"),\n    (\"GRIB\", \"GRIB\", \".grib\", \"PillowFormat\"),\n    (\"HDF5\", \"HDF5\", \".h5 .hdf\", \"PillowFormat\"),\n    (\"ICNS\", \"Mac OS icns resource\", \".icns\", \"PillowFormat\"),\n    (\"ICO\", \"Windows Icon\", \".ico\", \"PillowFormat\"),\n    (\"IM\", \"IFUNC Image Memory\", \".im\", \"PillowFormat\"),\n    (\"IMT\", \"IM Tools\", \"\", \"PillowFormat\"),\n    (\"IPTC\", \"IPTC/NAA\", \".iim\", \"PillowFormat\"),\n    (\"JPEG\", \"JPEG (ISO 10918)\", \".jfif .jpe .jpg .jpeg\", \"JPEGFormat\"),\n    (\n        \"JPEG2000\",\n        \"JPEG 2000 (ISO 15444)\",\n        \".jp2 .j2k .jpc .jpf .jpx .j2c\",\n        \"JPEG2000Format\",\n    ),\n    (\"MCIDAS\", \"McIdas area file\", \"\", \"PillowFormat\"),\n    (\"MIC\", \"Microsoft Image Composer\", \".mic\", \"PillowFormat\"),\n    # skipped in legacy pillow\n    # (\"MPEG\", \"MPEG\", \".mpg .mpeg\", \"PillowFormat\"),\n    (\"MPO\", \"MPO (CIPA DC-007)\", \".mpo\", \"PillowFormat\"),\n    (\"MSP\", \"Windows Paint\", \".msp\", \"PillowFormat\"),\n    (\"PCD\", \"Kodak PhotoCD\", \".pcd\", \"PillowFormat\"),\n    (\"PCX\", \"Paintbrush\", \".pcx\", \"PillowFormat\"),\n    (\"PIXAR\", \"PIXAR raster image\", \".pxr\", \"PillowFormat\"),\n    (\"PNG\", \"Portable network graphics\", \".png\", \"PNGFormat\"),\n    (\"PPM\", \"Pbmplus image\", \".pbm .pgm .ppm\", \"PillowFormat\"),\n    (\"PSD\", \"Adobe Photoshop\", \".psd\", \"PillowFormat\"),\n    (\"SGI\", \"SGI Image File Format\", \".bw .rgb .rgba .sgi\", \"PillowFormat\"),\n    (\"SPIDER\", \"Spider 2D image\", \"\", \"PillowFormat\"),\n    (\"SUN\", \"Sun Raster File\", \".ras\", \"PillowFormat\"),\n    (\"TGA\", \"Targa\", \".tga\", \"PillowFormat\"),\n    (\"TIFF\", \"Adobe TIFF\", \".tif .tiff\", \"TIFFFormat\"),\n    (\"WMF\", \"Windows Metafile\", \".wmf .emf\", \"PillowFormat\"),\n    (\"XBM\", \"X11 Bitmap\", \".xbm\", \"PillowFormat\"),\n    (\"XPM\", \"X11 Pixel Map\", \".xpm\", \"PillowFormat\"),\n    (\"XVTHUMB\", \"XV thumbnail image\", \"\", \"PillowFormat\"),\n]\nfor id, summary, ext, class_name in PILLOW_FORMATS:\n    config = PluginConfig(\n        name=id.upper() + \"-PIL\",\n        class_name=class_name,\n        module_name=\"imageio.plugins.pillow_legacy\",\n        is_legacy=True,\n        install_name=\"pillow\",\n        legacy_args={\n            \"description\": summary + \" via Pillow\",\n            \"extensions\": ext,\n            \"modes\": \"iI\" if class_name == \"GIFFormat\" else \"i\",\n            \"plugin_id\": id,\n        },\n    )\n    known_plugins[config.name] = config\n\nknown_plugins[\"FFMPEG\"] = PluginConfig(\n    name=\"FFMPEG\",\n    class_name=\"FfmpegFormat\",\n    module_name=\"imageio.plugins.ffmpeg\",\n    is_legacy=True,\n    install_name=\"ffmpeg\",\n    legacy_args={\n        \"description\": \"Many video formats and cameras (via ffmpeg)\",\n        \"extensions\": \".mov .avi .mpg .mpeg .mp4 .mkv .webm .wmv .h264\",\n        \"modes\": \"I\",\n    },\n)\n\nknown_plugins[\"BSDF\"] = PluginConfig(\n    name=\"BSDF\",\n    class_name=\"BsdfFormat\",\n    module_name=\"imageio.plugins.bsdf\",\n    is_legacy=True,\n    install_name=\"bsdf\",\n    legacy_args={\n        \"description\": \"Format based on the Binary Structured Data Format\",\n        \"extensions\": \".bsdf\",\n        \"modes\": \"iIvV\",\n    },\n)\n\nknown_plugins[\"DICOM\"] = PluginConfig(\n    name=\"DICOM\",\n    class_name=\"DicomFormat\",\n    module_name=\"imageio.plugins.dicom\",\n    is_legacy=True,\n    install_name=\"dicom\",\n    legacy_args={\n        \"description\": \"Digital Imaging and Communications in Medicine\",\n        \"extensions\": \".dcm .ct .mri\",\n        \"modes\": \"iIvV\",\n    },\n)\n\nknown_plugins[\"FEI\"] = PluginConfig(\n    name=\"FEI\",\n    class_name=\"FEISEMFormat\",\n    module_name=\"imageio.plugins.feisem\",\n    is_legacy=True,\n    install_name=\"feisem\",\n    legacy_args={\n        \"description\": \"FEI-SEM TIFF format\",\n        \"extensions\": [\".tif\", \".tiff\"],\n        \"modes\": \"iv\",\n    },\n)\n\nknown_plugins[\"FITS\"] = PluginConfig(\n    name=\"FITS\",\n    class_name=\"FitsFormat\",\n    module_name=\"imageio.plugins.fits\",\n    is_legacy=True,\n    install_name=\"fits\",\n    legacy_args={\n        \"description\": \"Flexible Image Transport System (FITS) format\",\n        \"extensions\": \".fits .fit .fts .fz\",\n        \"modes\": \"iIvV\",\n    },\n)\n\nknown_plugins[\"GDAL\"] = PluginConfig(\n    name=\"GDAL\",\n    class_name=\"GdalFormat\",\n    module_name=\"imageio.plugins.gdal\",\n    is_legacy=True,\n    install_name=\"gdal\",\n    legacy_args={\n        \"description\": \"Geospatial Data Abstraction Library\",\n        \"extensions\": \".tiff  .tif .img .ecw .jpg .jpeg\",\n        \"modes\": \"iIvV\",\n    },\n)\n\nknown_plugins[\"ITK\"] = PluginConfig(\n    name=\"ITK\",\n    class_name=\"ItkFormat\",\n    module_name=\"imageio.plugins.simpleitk\",\n    is_legacy=True,\n    install_name=\"simpleitk\",\n    legacy_args={\n        \"description\": \"Insight Segmentation and Registration Toolkit (ITK) format\",\n        \"extensions\": \" \".join(\n            (\n                \".gipl\",\n                \".ipl\",\n                \".mha\",\n                \".mhd\",\n                \".nhdr\",\n                \".nia\",\n                \".hdr\",\n                \".nrrd\",\n                \".nii\",\n                \".nii.gz\",\n                \".img\",\n                \".img.gz\",\n                \".vtk\",\n                \".hdf5\",\n                \".lsm\",\n                \".mnc\",\n                \".mnc2\",\n                \".mgh\",\n                \".mnc\",\n                \".pic\",\n                \".bmp\",\n                \".jpeg\",\n                \".jpg\",\n                \".png\",\n                \".tiff\",\n                \".tif\",\n                \".dicom\",\n                \".dcm\",\n                \".gdcm\",\n            )\n        ),\n        \"modes\": \"iIvV\",\n    },\n)\n\nknown_plugins[\"NPZ\"] = PluginConfig(\n    name=\"NPZ\",\n    class_name=\"NpzFormat\",\n    module_name=\"imageio.plugins.npz\",\n    is_legacy=True,\n    install_name=\"numpy\",\n    legacy_args={\n        \"description\": \"Numpy's compressed array format\",\n        \"extensions\": \".npz\",\n        \"modes\": \"iIvV\",\n    },\n)\n\nknown_plugins[\"SWF\"] = PluginConfig(\n    name=\"SWF\",\n    class_name=\"SWFFormat\",\n    module_name=\"imageio.plugins.swf\",\n    is_legacy=True,\n    install_name=\"swf\",\n    legacy_args={\n        \"description\": \"Shockwave flash\",\n        \"extensions\": \".swf\",\n        \"modes\": \"I\",\n    },\n)\n\nknown_plugins[\"SCREENGRAB\"] = PluginConfig(\n    name=\"SCREENGRAB\",\n    class_name=\"ScreenGrabFormat\",\n    module_name=\"imageio.plugins.grab\",\n    is_legacy=True,\n    install_name=\"pillow\",\n    legacy_args={\n        \"description\": \"Grab screenshots (Windows and OS X only)\",\n        \"extensions\": [],\n        \"modes\": \"i\",\n    },\n)\n\nknown_plugins[\"CLIPBOARDGRAB\"] = PluginConfig(\n    name=\"CLIPBOARDGRAB\",\n    class_name=\"ClipboardGrabFormat\",\n    module_name=\"imageio.plugins.grab\",\n    is_legacy=True,\n    install_name=\"pillow\",\n    legacy_args={\n        \"description\": \"Grab from clipboard (Windows only)\",\n        \"extensions\": [],\n        \"modes\": \"i\",\n    },\n)\n\n# LYTRO plugin (legacy)\nlytro_formats = [\n    (\"lytro-lfr\", \"Lytro Illum lfr image file\", \".lfr\", \"i\", \"LytroLfrFormat\"),\n    (\n        \"lytro-illum-raw\",\n        \"Lytro Illum raw image file\",\n        \".raw\",\n        \"i\",\n        \"LytroIllumRawFormat\",\n    ),\n    (\"lytro-lfp\", \"Lytro F01 lfp image file\", \".lfp\", \"i\", \"LytroLfpFormat\"),\n    (\"lytro-f01-raw\", \"Lytro F01 raw image file\", \".raw\", \"i\", \"LytroF01RawFormat\"),\n]\nfor name, des, ext, mode, class_name in lytro_formats:\n    config = PluginConfig(\n        name=name.upper(),\n        class_name=class_name,\n        module_name=\"imageio.plugins.lytro\",\n        is_legacy=True,\n        install_name=\"lytro\",\n        legacy_args={\n            \"description\": des,\n            \"extensions\": ext,\n            \"modes\": mode,\n        },\n    )\n    known_plugins[config.name] = config\n\n# FreeImage plugin (legacy)\nFREEIMAGE_FORMATS = [\n    (\n        \"BMP\",\n        0,\n        \"Windows or OS/2 Bitmap\",\n        \".bmp\",\n        \"i\",\n        \"FreeimageBmpFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"CUT\",\n        21,\n        \"Dr. Halo\",\n        \".cut\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"DDS\",\n        24,\n        \"DirectX Surface\",\n        \".dds\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"EXR\",\n        29,\n        \"ILM OpenEXR\",\n        \".exr\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"G3\",\n        27,\n        \"Raw fax format CCITT G.3\",\n        \".g3\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"GIF\",\n        25,\n        \"Static and animated gif (FreeImage)\",\n        \".gif\",\n        \"iI\",\n        \"GifFormat\",\n        \"imageio.plugins.freeimagemulti\",\n    ),\n    (\n        \"HDR\",\n        26,\n        \"High Dynamic Range Image\",\n        \".hdr\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"ICO\",\n        1,\n        \"Windows Icon\",\n        \".ico\",\n        \"iI\",\n        \"IcoFormat\",\n        \"imageio.plugins.freeimagemulti\",\n    ),\n    (\n        \"IFF\",\n        5,\n        \"IFF Interleaved Bitmap\",\n        \".iff .lbm\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"J2K\",\n        30,\n        \"JPEG-2000 codestream\",\n        \".j2k .j2c\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"JNG\",\n        3,\n        \"JPEG Network Graphics\",\n        \".jng\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"JP2\",\n        31,\n        \"JPEG-2000 File Format\",\n        \".jp2\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"JPEG\",\n        2,\n        \"JPEG - JFIF Compliant\",\n        \".jpg .jif .jpeg .jpe\",\n        \"i\",\n        \"FreeimageJpegFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"JPEG-XR\",\n        36,\n        \"JPEG XR image format\",\n        \".jxr .wdp .hdp\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"KOALA\",\n        4,\n        \"C64 Koala Graphics\",\n        \".koa\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    # not registered in legacy pillow\n    # (\"MNG\", 6, \"Multiple-image Network Graphics\", \".mng\", \"i\", \"FreeimageFormat\", \"imageio.plugins.freeimage\"),\n    (\n        \"PBM\",\n        7,\n        \"Portable Bitmap (ASCII)\",\n        \".pbm\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PBMRAW\",\n        8,\n        \"Portable Bitmap (RAW)\",\n        \".pbm\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PCD\",\n        9,\n        \"Kodak PhotoCD\",\n        \".pcd\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PCX\",\n        10,\n        \"Zsoft Paintbrush\",\n        \".pcx\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PFM\",\n        32,\n        \"Portable floatmap\",\n        \".pfm\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PGM\",\n        11,\n        \"Portable Greymap (ASCII)\",\n        \".pgm\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PGMRAW\",\n        12,\n        \"Portable Greymap (RAW)\",\n        \".pgm\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PICT\",\n        33,\n        \"Macintosh PICT\",\n        \".pct .pict .pic\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PNG\",\n        13,\n        \"Portable Network Graphics\",\n        \".png\",\n        \"i\",\n        \"FreeimagePngFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PPM\",\n        14,\n        \"Portable Pixelmap (ASCII)\",\n        \".ppm\",\n        \"i\",\n        \"FreeimagePnmFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PPMRAW\",\n        15,\n        \"Portable Pixelmap (RAW)\",\n        \".ppm\",\n        \"i\",\n        \"FreeimagePnmFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"PSD\",\n        20,\n        \"Adobe Photoshop\",\n        \".psd\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"RAS\",\n        16,\n        \"Sun Raster Image\",\n        \".ras\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"RAW\",\n        34,\n        \"RAW camera image\",\n        \".3fr .arw .bay .bmq .cap .cine .cr2 .crw .cs1 .dc2 \"\n        \".dcr .drf .dsc .dng .erf .fff .ia .iiq .k25 .kc2 .kdc .mdc .mef .mos .mrw .nef .nrw .orf \"\n        \".pef .ptx .pxn .qtk .raf .raw .rdc .rw2 .rwl .rwz .sr2 .srf .srw .sti\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"SGI\",\n        28,\n        \"SGI Image Format\",\n        \".sgi .rgb .rgba .bw\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"TARGA\",\n        17,\n        \"Truevision Targa\",\n        \".tga .targa\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"TIFF\",\n        18,\n        \"Tagged Image File Format\",\n        \".tif .tiff\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"WBMP\",\n        19,\n        \"Wireless Bitmap\",\n        \".wap .wbmp .wbm\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"WebP\",\n        35,\n        \"Google WebP image format\",\n        \".webp\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"XBM\",\n        22,\n        \"X11 Bitmap Format\",\n        \".xbm\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n    (\n        \"XPM\",\n        23,\n        \"X11 Pixmap Format\",\n        \".xpm\",\n        \"i\",\n        \"FreeimageFormat\",\n        \"imageio.plugins.freeimage\",\n    ),\n]\nfor name, i, des, ext, mode, class_name, module_name in FREEIMAGE_FORMATS:\n    config = PluginConfig(\n        name=name.upper() + \"-FI\",\n        class_name=class_name,\n        module_name=module_name,\n        is_legacy=True,\n        install_name=\"freeimage\",\n        legacy_args={\n            \"description\": des,\n            \"extensions\": ext,\n            \"modes\": mode,\n            \"fif\": i,\n        },\n    )\n    known_plugins[config.name] = config\n\n# exists for backwards compatibility with FormatManager\n# delete in V3\n_original_order = [x for x, config in known_plugins.items() if config.is_legacy]\n",780],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py":["from . import Request\nfrom ..typing import ArrayLike\nimport numpy as np\nfrom typing import Optional, Dict, Any, Tuple, Union, List, Iterator\nfrom dataclasses import dataclass\n\n\n@dataclass\nclass ImageProperties:\n    \"\"\"Standardized Metadata\n\n    ImageProperties represent a set of standardized metadata that is available\n    under the same name for every supported format. If the ImageResource (or\n    format) does not specify the value, a sensible default value is chosen\n    instead.\n\n    Attributes\n    ----------\n    shape : Tuple[int, ...]\n        The shape of the loaded ndimage.\n    dtype : np.dtype\n        The dtype of the loaded ndimage.\n    n_images : int\n        Number of images in the file if ``index=...``, `None` for single images.\n    is_batch : bool\n        If True, the first dimension of the ndimage represents a batch dimension\n        along which several images are stacked.\n    spacing : Tuple\n        A tuple describing the spacing between pixels along each axis of the\n        ndimage. If the spacing is uniform along an axis the value corresponding\n        to that axis is a single float. If the spacing is non-uniform, the value\n        corresponding to that axis is a tuple in which the i-th element\n        indicates the spacing between the i-th and (i+1)-th pixel along that\n        axis.\n\n    \"\"\"\n\n    shape: Tuple[int, ...]\n    dtype: np.dtype\n    n_images: Optional[int] = None\n    is_batch: bool = False\n    spacing: Optional[tuple] = None\n\n\nclass PluginV3:\n    \"\"\"A ImageIO Plugin.\n\n    This is an abstract plugin that documents the v3 plugin API interface. A\n    plugin is an adapter/wrapper around a backend that converts a request from\n    iio.core (e.g., read an image from file) into a sequence of instructions for\n    the backend that fulfill the request.\n\n    Plugin authors may choose to subclass this class when implementing a new\n    plugin, but aren't obliged to do so. As long as the plugin class implements\n    the interface (methods) described below the ImageIO core will treat it just\n    like any other plugin.\n\n\n    Parameters\n    ----------\n    request : iio.Request\n        A request object that represents the users intent. It provides a\n        standard interface to access the various ImageResources and serves them\n        to the plugin as a file object (or file). Check the docs for details.\n    **kwargs : Any\n        Additional configuration arguments for the plugin or backend. Usually\n        these match the configuration arguments available on the backend and\n        are forwarded to it.\n\n\n    Raises\n    ------\n    InitializationError\n        During ``__init__`` the plugin tests if it can fulfill the request. If\n        it can't, e.g., because the request points to a file in the wrong\n        format, then it should raise an ``InitializationError`` and provide a\n        reason for failure. This reason may be reported to the user.\n    ImportError\n        Plugins will be imported dynamically when listed in\n        ``iio.config.known_plugins`` to fulfill requests. This way, users only\n        have to load plugins/backends they actually use. If this plugin's backend\n        is not installed, it should raise an ``ImportError`` either during\n        module import or during class construction.\n\n    Notes\n    -----\n    Upon successful construction the plugin takes ownership of the provided\n    request. This means that it is the plugin's responsibility to call\n    request.finish() to close the resource when it is no longer needed.\n\n    Plugins _must_ implement a context manager that closes and cleans any\n    resources held by the plugin upon exit.\n\n    \"\"\"\n\n    def __init__(self, request: Request) -> None:\n        \"\"\"Initialize a new Plugin Instance.\n\n        See Plugin's docstring for detailed documentation.\n\n        Notes\n        -----\n        The implementation here stores the request as a local variable that is\n        exposed using a @property below. If you inherit from PluginV3, remember\n        to call ``super().__init__(request)``.\n\n        \"\"\"\n\n        self._request = request\n\n    def read(self, *, index: int = 0) -> np.ndarray:\n        \"\"\"Read a ndimage.\n\n        The ``read`` method loads a (single) ndimage, located at ``index`` from\n        the requested ImageResource.\n\n        It is at the plugin's descretion to decide (and document) what\n        constitutes a single ndimage. A sensible way to make this decision is to\n        choose based on the ImageResource's format and on what users will expect\n        from such a format. For example, a sensible choice for a TIFF file\n        produced by an ImageJ hyperstack is to read it as a volumetric ndimage\n        (1 color dimension followed by 3 spatial dimensions). On the other hand,\n        a sensible choice for a MP4 file produced by Davinci Resolve is to treat\n        each frame as a ndimage (2 spatial dimensions followed by 1 color\n        dimension).\n\n        The value ``index=None`` is special. It requests the plugin to load all\n        ndimages in the file and stack them along a new first axis. For example,\n        if a MP4 file is read with ``index=None`` and the plugin identifies\n        single frames as ndimages, then the plugin should read all frames and\n        stack them into a new ndimage which now contains a time axis as its\n        first axis. If a PNG file (single image format) is read with\n        ``index=None`` the plugin does a very similar thing: It loads all\n        ndimages in the file (here it's just one) and stacks them along a new\n        first axis, effectively prepending an axis with size 1 to the image. If\n        a plugin does not wish to support ``index=None`` it should set a more\n        sensible default and raise a ``ValueError`` when requested to read using\n        ``index=None``.\n\n        Parameters\n        ----------\n        index : int\n            If the ImageResource contains multiple ndimages, and index is an\n            integer, select the index-th ndimage from among them and return it.\n            If index is an ellipsis (...), read all ndimages in the file and\n            stack them along a new batch dimension. If index is None, let the\n            plugin decide. If the index is out of bounds a ``ValueError`` is\n            raised.\n        **kwargs : Any\n            The read method may accept any number of plugin-specific keyword\n            arguments to further customize the read behavior. Usually these\n            match the arguments available on the backend and are forwarded to\n            it.\n\n        Returns\n        -------\n        ndimage : np.ndarray\n            A ndimage containing decoded pixel data (sometimes called bitmap).\n\n        Notes\n        -----\n        The ImageResource from which the plugin should read is managed by the\n        provided request object. Directly accessing the managed ImageResource is\n        _not_ permitted. Instead, you can get FileLike access to the\n        ImageResource via request.get_file().\n\n        If the backend doesn't support reading from FileLike objects, you can\n        request a temporary file to pass to the backend via\n        ``request.get_local_filename()``. This is, however, not very performant\n        (involves copying the Request's content into a temporary file), so you\n        should avoid doing this whenever possible. Consider it a fallback method\n        in case all else fails.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def write(self, ndimage: Union[ArrayLike, List[ArrayLike]]) -> Optional[bytes]:\n        \"\"\"Write a ndimage to a ImageResource.\n\n        The ``write`` method encodes the given ndimage into the format handled\n        by the backend and writes it to the ImageResource. It overwrites\n        any content that may have been previously stored in the file.\n\n        If the backend supports only a single format then it must check if\n        the ImageResource matches that format and raise an exception if not.\n        Typically, this should be done during initialization in the form of a\n        ``InitializationError``.\n\n        If the backend supports more than one format it must determine the\n        requested/desired format. Usually this can be done by inspecting the\n        ImageResource (e.g., by checking ``request.extension``), or by providing\n        a mechanism to explicitly set the format (perhaps with a - sensible -\n        default value). If the plugin can not determine the desired format, it\n        **must not** write to the ImageResource, but raise an exception instead.\n\n        If the backend supports at least one format that can hold multiple\n        ndimages it should be capable of handling ndimage batches and lists of\n        ndimages. If the ``ndimage`` input is a list of ndimages, the plugin\n        should not assume that the ndimages are not stackable, i.e., ndimages\n        may have different shapes. Otherwise, the ``ndimage`` may be a batch of\n        multiple ndimages stacked along the first axis of the array. The plugin\n        must be able to discover this, either automatically or via additional\n        `kwargs`. If there is ambiguity in the process, the plugin must clearly\n        document what happens in such cases and, if possible, describe how to\n        resolve this ambiguity.\n\n        Parameters\n        ----------\n        ndimage : ArrayLike\n            The ndimage to encode and write to the current ImageResource.\n        **kwargs : Any\n            The write method may accept any number of plugin-specific keyword\n            arguments to customize the writing behavior. Usually these match the\n            arguments available on the backend and are forwarded to it.\n\n        Returns\n        -------\n        encoded_image : bytes or None\n            If the chosen ImageResource is the special target ``\"<bytes>\"`` then\n            write should return a byte string containing the encoded image data.\n            Otherwise, it returns None.\n\n        Notes\n        -----\n        The ImageResource to which the plugin should write to is managed by the\n        provided request object. Directly accessing the managed ImageResource is\n        _not_ permitted. Instead, you can get FileLike access to the\n        ImageResource via request.get_file().\n\n        If the backend doesn't support writing to FileLike objects, you can\n        request a temporary file to pass to the backend via\n        ``request.get_local_filename()``. This is, however, not very performant\n        (involves copying the Request's content from a temporary file), so you\n        should avoid doing this whenever possible. Consider it a fallback method\n        in case all else fails.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def iter(self) -> Iterator[np.ndarray]:\n        \"\"\"Iterate the ImageResource.\n\n        This method returns a generator that yields ndimages in the order in which\n        they appear in the file. This is roughly equivalent to::\n\n            idx = 0\n            while True:\n                try:\n                    yield self.read(index=idx)\n                except ValueError:\n                    break\n\n        It works very similar to ``read``, and you can consult the documentation\n        of that method for additional information on desired behavior.\n\n        Parameters\n        ----------\n        **kwargs : Any\n            The iter method may accept any number of plugin-specific keyword\n            arguments to further customize the reading/iteration behavior.\n            Usually these match the arguments available on the backend and are\n            forwarded to it.\n\n        Yields\n        ------\n        ndimage : np.ndarray\n            A ndimage containing decoded pixel data (sometimes called bitmap).\n\n        See Also\n        --------\n        PluginV3.read\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def properties(self, index: int = 0) -> ImageProperties:\n        \"\"\"Standardized ndimage metadata.\n\n        Parameters\n        ----------\n        index : int\n            If the ImageResource contains multiple ndimages, and index is an\n        integer, select the index-th ndimage from among them and return its\n        properties. If index is an ellipsis (...), read all ndimages in the file\n        and stack them along a new batch dimension and return their properties.\n        If index is None, the plugin decides the default.\n\n        Returns\n        -------\n        properties : ImageProperties\n            A dataclass filled with standardized image metadata.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def metadata(self, index: int = 0, exclude_applied: bool = True) -> Dict[str, Any]:\n        \"\"\"Format-Specific ndimage metadata.\n\n        The method reads metadata stored in the ImageResource and returns it as\n        a python dict. The plugin is free to choose which name to give a piece\n        of metadata; however, if possible, it should match the name given by the\n        format. There is no requirement regarding the fields a plugin must\n        expose; however, if a plugin does expose any,``exclude_applied`` applies\n        to these fields.\n\n        If the plugin does return metadata items, it must check the value of\n        ``exclude_applied`` before returning them. If ``exclude applied`` is\n        True, then any metadata item that would be applied to an ndimage\n        returned by ``read`` (or ``iter``) must not be returned. This is done to\n        avoid confusion; for example, if an ImageResource defines the ExIF\n        rotation tag, and the plugin applies the rotation to the data before\n        returning it, then ``exclude_applied`` prevents confusion on whether the\n        tag was already applied or not.\n\n        The `kwarg` ``index`` behaves similar to its counterpart in ``read``\n        with one exception: If the ``index`` is None, then global metadata is\n        returned instead of returning a combination of all metadata items. If\n        there is no global metadata, the Plugin should return an empty dict or\n        raise an exception.\n\n        Parameters\n        ----------\n        index : int\n            If the ImageResource contains multiple ndimages, and index is an\n            integer, select the index-th ndimage from among them and return its\n            metadata. If index is an ellipsis (...), return global metadata. If\n            index is None, the plugin decides the default.\n        exclude_applied : bool\n            If True (default), do not report metadata fields that the plugin\n            would apply/consume while reading the image.\n\n        Returns\n        -------\n        metadata : dict\n            A dictionary filled with format-specific metadata fields and their\n            values.\n\n        \"\"\"\n        raise NotImplementedError()\n\n    def close(self) -> None:\n        \"\"\"Close the ImageResource.\n\n        This method allows a plugin to behave similar to the python built-in ``open``::\n\n            image_file = my_plugin(Request, \"r\")\n            ...\n            image_file.close()\n\n        It is used by the context manager and deconstructor below to avoid leaking\n        ImageResources. If the plugin has no other cleanup to do it doesn't have\n        to overwrite this method itself and can rely on the implementation\n        below.\n\n        \"\"\"\n\n        self.request.finish()\n\n    @property\n    def request(self) -> Request:\n        return self._request\n\n    def __enter__(self) -> \"PluginV3\":\n        return self\n\n    def __exit__(self, type, value, traceback) -> None:\n        self.close()\n\n    def __del__(self) -> None:\n        self.close()\n",370],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py":["# don't import any costly modules\nimport sys\nimport os\n\n\nis_pypy = '__pypy__' in sys.builtin_module_names\n\n\ndef warn_distutils_present():\n    if 'distutils' not in sys.modules:\n        return\n    if is_pypy and sys.version_info < (3, 7):\n        # PyPy for 3.6 unconditionally imports distutils, so bypass the warning\n        # https://foss.heptapod.net/pypy/pypy/-/blob/be829135bc0d758997b3566062999ee8b23872b4/lib-python/3/site.py#L250\n        return\n    import warnings\n\n    warnings.warn(\n        \"Distutils was imported before Setuptools, but importing Setuptools \"\n        \"also replaces the `distutils` module in `sys.modules`. This may lead \"\n        \"to undesirable behaviors or errors. To avoid these issues, avoid \"\n        \"using distutils directly, ensure that setuptools is installed in the \"\n        \"traditional way (e.g. not an editable install), and/or make sure \"\n        \"that setuptools is always imported before distutils.\"\n    )\n\n\ndef clear_distutils():\n    if 'distutils' not in sys.modules:\n        return\n    import warnings\n\n    warnings.warn(\"Setuptools is replacing distutils.\")\n    mods = [\n        name\n        for name in sys.modules\n        if name == \"distutils\" or name.startswith(\"distutils.\")\n    ]\n    for name in mods:\n        del sys.modules[name]\n\n\ndef enabled():\n    \"\"\"\n    Allow selection of distutils by environment variable.\n    \"\"\"\n    which = os.environ.get('SETUPTOOLS_USE_DISTUTILS', 'local')\n    return which == 'local'\n\n\ndef ensure_local_distutils():\n    import importlib\n\n    clear_distutils()\n\n    # With the DistutilsMetaFinder in place,\n    # perform an import to cause distutils to be\n    # loaded from setuptools._distutils. Ref #2906.\n    with shim():\n        importlib.import_module('distutils')\n\n    # check that submodules load as expected\n    core = importlib.import_module('distutils.core')\n    assert '_distutils' in core.__file__, core.__file__\n    assert 'setuptools._distutils.log' not in sys.modules\n\n\ndef do_override():\n    \"\"\"\n    Ensure that the local copy of distutils is preferred over stdlib.\n\n    See https://github.com/pypa/setuptools/issues/417#issuecomment-392298401\n    for more motivation.\n    \"\"\"\n    if enabled():\n        warn_distutils_present()\n        ensure_local_distutils()\n\n\nclass _TrivialRe:\n    def __init__(self, *patterns):\n        self._patterns = patterns\n\n    def match(self, string):\n        return all(pat in string for pat in self._patterns)\n\n\nclass DistutilsMetaFinder:\n    def find_spec(self, fullname, path, target=None):\n        # optimization: only consider top level modules and those\n        # found in the CPython test suite.\n        if path is not None and not fullname.startswith('test.'):\n            return\n\n        method_name = 'spec_for_{fullname}'.format(**locals())\n        method = getattr(self, method_name, lambda: None)\n        return method()\n\n    def spec_for_distutils(self):\n        if self.is_cpython():\n            return\n\n        import importlib\n        import importlib.abc\n        import importlib.util\n\n        try:\n            mod = importlib.import_module('setuptools._distutils')\n        except Exception:\n            # There are a couple of cases where setuptools._distutils\n            # may not be present:\n            # - An older Setuptools without a local distutils is\n            #   taking precedence. Ref #2957.\n            # - Path manipulation during sitecustomize removes\n            #   setuptools from the path but only after the hook\n            #   has been loaded. Ref #2980.\n            # In either case, fall back to stdlib behavior.\n            return\n\n        class DistutilsLoader(importlib.abc.Loader):\n            def create_module(self, spec):\n                mod.__name__ = 'distutils'\n                return mod\n\n            def exec_module(self, module):\n                pass\n\n        return importlib.util.spec_from_loader(\n            'distutils', DistutilsLoader(), origin=mod.__file__\n        )\n\n    @staticmethod\n    def is_cpython():\n        \"\"\"\n        Suppress supplying distutils for CPython (build and tests).\n        Ref #2965 and #3007.\n        \"\"\"\n        return os.path.isfile('pybuilddir.txt')\n\n    def spec_for_pip(self):\n        \"\"\"\n        Ensure stdlib distutils when running under pip.\n        See pypa/pip#8761 for rationale.\n        \"\"\"\n        if self.pip_imported_during_build():\n            return\n        clear_distutils()\n        self.spec_for_distutils = lambda: None\n\n    @classmethod\n    def pip_imported_during_build(cls):\n        \"\"\"\n        Detect if pip is being imported in a build script. Ref #2355.\n        \"\"\"\n        import traceback\n\n        return any(\n            cls.frame_file_is_setup(frame) for frame, line in traceback.walk_stack(None)\n        )\n\n    @staticmethod\n    def frame_file_is_setup(frame):\n        \"\"\"\n        Return True if the indicated frame suggests a setup.py file.\n        \"\"\"\n        # some frames may not have __file__ (#2940)\n        return frame.f_globals.get('__file__', '').endswith('setup.py')\n\n    def spec_for_sensitive_tests(self):\n        \"\"\"\n        Ensure stdlib distutils when running select tests under CPython.\n\n        python/cpython#91169\n        \"\"\"\n        clear_distutils()\n        self.spec_for_distutils = lambda: None\n\n    sensitive_tests = (\n        [\n            'test.test_distutils',\n            'test.test_peg_generator',\n            'test.test_importlib',\n        ]\n        if sys.version_info < (3, 10)\n        else [\n            'test.test_distutils',\n        ]\n    )\n\n\nfor name in DistutilsMetaFinder.sensitive_tests:\n    setattr(\n        DistutilsMetaFinder,\n        f'spec_for_{name}',\n        DistutilsMetaFinder.spec_for_sensitive_tests,\n    )\n\n\nDISTUTILS_FINDER = DistutilsMetaFinder()\n\n\ndef add_shim():\n    DISTUTILS_FINDER in sys.meta_path or insert_shim()\n\n\nclass shim:\n    def __enter__(self):\n        insert_shim()\n\n    def __exit__(self, exc, value, tb):\n        remove_shim()\n\n\ndef insert_shim():\n    sys.meta_path.insert(0, DISTUTILS_FINDER)\n\n\ndef remove_shim():\n    try:\n        sys.meta_path.remove(DISTUTILS_FINDER)\n    except ValueError:\n        pass\n",222],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\six.py":["# Copyright (c) 2010-2020 Benjamin Peterson\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\n\"\"\"Utilities for writing code that runs on Python 2 and 3\"\"\"\n\nfrom __future__ import absolute_import\n\nimport functools\nimport itertools\nimport operator\nimport sys\nimport types\n\n__author__ = \"Benjamin Peterson <benjamin@python.org>\"\n__version__ = \"1.16.0\"\n\n\n# Useful for very coarse version differentiation.\nPY2 = sys.version_info[0] == 2\nPY3 = sys.version_info[0] == 3\nPY34 = sys.version_info[0:2] >= (3, 4)\n\nif PY3:\n    string_types = str,\n    integer_types = int,\n    class_types = type,\n    text_type = str\n    binary_type = bytes\n\n    MAXSIZE = sys.maxsize\nelse:\n    string_types = basestring,\n    integer_types = (int, long)\n    class_types = (type, types.ClassType)\n    text_type = unicode\n    binary_type = str\n\n    if sys.platform.startswith(\"java\"):\n        # Jython always uses 32 bits.\n        MAXSIZE = int((1 << 31) - 1)\n    else:\n        # It's possible to have sizeof(long) != sizeof(Py_ssize_t).\n        class X(object):\n\n            def __len__(self):\n                return 1 << 31\n        try:\n            len(X())\n        except OverflowError:\n            # 32-bit\n            MAXSIZE = int((1 << 31) - 1)\n        else:\n            # 64-bit\n            MAXSIZE = int((1 << 63) - 1)\n        del X\n\nif PY34:\n    from importlib.util import spec_from_loader\nelse:\n    spec_from_loader = None\n\n\ndef _add_doc(func, doc):\n    \"\"\"Add documentation to a function.\"\"\"\n    func.__doc__ = doc\n\n\ndef _import_module(name):\n    \"\"\"Import module, returning the module after the last dot.\"\"\"\n    __import__(name)\n    return sys.modules[name]\n\n\nclass _LazyDescr(object):\n\n    def __init__(self, name):\n        self.name = name\n\n    def __get__(self, obj, tp):\n        result = self._resolve()\n        setattr(obj, self.name, result)  # Invokes __set__.\n        try:\n            # This is a bit ugly, but it avoids running this again by\n            # removing this descriptor.\n            delattr(obj.__class__, self.name)\n        except AttributeError:\n            pass\n        return result\n\n\nclass MovedModule(_LazyDescr):\n\n    def __init__(self, name, old, new=None):\n        super(MovedModule, self).__init__(name)\n        if PY3:\n            if new is None:\n                new = name\n            self.mod = new\n        else:\n            self.mod = old\n\n    def _resolve(self):\n        return _import_module(self.mod)\n\n    def __getattr__(self, attr):\n        _module = self._resolve()\n        value = getattr(_module, attr)\n        setattr(self, attr, value)\n        return value\n\n\nclass _LazyModule(types.ModuleType):\n\n    def __init__(self, name):\n        super(_LazyModule, self).__init__(name)\n        self.__doc__ = self.__class__.__doc__\n\n    def __dir__(self):\n        attrs = [\"__doc__\", \"__name__\"]\n        attrs += [attr.name for attr in self._moved_attributes]\n        return attrs\n\n    # Subclasses should override this\n    _moved_attributes = []\n\n\nclass MovedAttribute(_LazyDescr):\n\n    def __init__(self, name, old_mod, new_mod, old_attr=None, new_attr=None):\n        super(MovedAttribute, self).__init__(name)\n        if PY3:\n            if new_mod is None:\n                new_mod = name\n            self.mod = new_mod\n            if new_attr is None:\n                if old_attr is None:\n                    new_attr = name\n                else:\n                    new_attr = old_attr\n            self.attr = new_attr\n        else:\n            self.mod = old_mod\n            if old_attr is None:\n                old_attr = name\n            self.attr = old_attr\n\n    def _resolve(self):\n        module = _import_module(self.mod)\n        return getattr(module, self.attr)\n\n\nclass _SixMetaPathImporter(object):\n\n    \"\"\"\n    A meta path importer to import six.moves and its submodules.\n\n    This class implements a PEP302 finder and loader. It should be compatible\n    with Python 2.5 and all existing versions of Python3\n    \"\"\"\n\n    def __init__(self, six_module_name):\n        self.name = six_module_name\n        self.known_modules = {}\n\n    def _add_module(self, mod, *fullnames):\n        for fullname in fullnames:\n            self.known_modules[self.name + \".\" + fullname] = mod\n\n    def _get_module(self, fullname):\n        return self.known_modules[self.name + \".\" + fullname]\n\n    def find_module(self, fullname, path=None):\n        if fullname in self.known_modules:\n            return self\n        return None\n\n    def find_spec(self, fullname, path, target=None):\n        if fullname in self.known_modules:\n            return spec_from_loader(fullname, self)\n        return None\n\n    def __get_module(self, fullname):\n        try:\n            return self.known_modules[fullname]\n        except KeyError:\n            raise ImportError(\"This loader does not know module \" + fullname)\n\n    def load_module(self, fullname):\n        try:\n            # in case of a reload\n            return sys.modules[fullname]\n        except KeyError:\n            pass\n        mod = self.__get_module(fullname)\n        if isinstance(mod, MovedModule):\n            mod = mod._resolve()\n        else:\n            mod.__loader__ = self\n        sys.modules[fullname] = mod\n        return mod\n\n    def is_package(self, fullname):\n        \"\"\"\n        Return true, if the named module is a package.\n\n        We need this method to get correct spec objects with\n        Python 3.4 (see PEP451)\n        \"\"\"\n        return hasattr(self.__get_module(fullname), \"__path__\")\n\n    def get_code(self, fullname):\n        \"\"\"Return None\n\n        Required, if is_package is implemented\"\"\"\n        self.__get_module(fullname)  # eventually raises ImportError\n        return None\n    get_source = get_code  # same as get_code\n\n    def create_module(self, spec):\n        return self.load_module(spec.name)\n\n    def exec_module(self, module):\n        pass\n\n_importer = _SixMetaPathImporter(__name__)\n\n\nclass _MovedItems(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects\"\"\"\n    __path__ = []  # mark as package\n\n\n_moved_attributes = [\n    MovedAttribute(\"cStringIO\", \"cStringIO\", \"io\", \"StringIO\"),\n    MovedAttribute(\"filter\", \"itertools\", \"builtins\", \"ifilter\", \"filter\"),\n    MovedAttribute(\"filterfalse\", \"itertools\", \"itertools\", \"ifilterfalse\", \"filterfalse\"),\n    MovedAttribute(\"input\", \"__builtin__\", \"builtins\", \"raw_input\", \"input\"),\n    MovedAttribute(\"intern\", \"__builtin__\", \"sys\"),\n    MovedAttribute(\"map\", \"itertools\", \"builtins\", \"imap\", \"map\"),\n    MovedAttribute(\"getcwd\", \"os\", \"os\", \"getcwdu\", \"getcwd\"),\n    MovedAttribute(\"getcwdb\", \"os\", \"os\", \"getcwd\", \"getcwdb\"),\n    MovedAttribute(\"getoutput\", \"commands\", \"subprocess\"),\n    MovedAttribute(\"range\", \"__builtin__\", \"builtins\", \"xrange\", \"range\"),\n    MovedAttribute(\"reload_module\", \"__builtin__\", \"importlib\" if PY34 else \"imp\", \"reload\"),\n    MovedAttribute(\"reduce\", \"__builtin__\", \"functools\"),\n    MovedAttribute(\"shlex_quote\", \"pipes\", \"shlex\", \"quote\"),\n    MovedAttribute(\"StringIO\", \"StringIO\", \"io\"),\n    MovedAttribute(\"UserDict\", \"UserDict\", \"collections\"),\n    MovedAttribute(\"UserList\", \"UserList\", \"collections\"),\n    MovedAttribute(\"UserString\", \"UserString\", \"collections\"),\n    MovedAttribute(\"xrange\", \"__builtin__\", \"builtins\", \"xrange\", \"range\"),\n    MovedAttribute(\"zip\", \"itertools\", \"builtins\", \"izip\", \"zip\"),\n    MovedAttribute(\"zip_longest\", \"itertools\", \"itertools\", \"izip_longest\", \"zip_longest\"),\n    MovedModule(\"builtins\", \"__builtin__\"),\n    MovedModule(\"configparser\", \"ConfigParser\"),\n    MovedModule(\"collections_abc\", \"collections\", \"collections.abc\" if sys.version_info >= (3, 3) else \"collections\"),\n    MovedModule(\"copyreg\", \"copy_reg\"),\n    MovedModule(\"dbm_gnu\", \"gdbm\", \"dbm.gnu\"),\n    MovedModule(\"dbm_ndbm\", \"dbm\", \"dbm.ndbm\"),\n    MovedModule(\"_dummy_thread\", \"dummy_thread\", \"_dummy_thread\" if sys.version_info < (3, 9) else \"_thread\"),\n    MovedModule(\"http_cookiejar\", \"cookielib\", \"http.cookiejar\"),\n    MovedModule(\"http_cookies\", \"Cookie\", \"http.cookies\"),\n    MovedModule(\"html_entities\", \"htmlentitydefs\", \"html.entities\"),\n    MovedModule(\"html_parser\", \"HTMLParser\", \"html.parser\"),\n    MovedModule(\"http_client\", \"httplib\", \"http.client\"),\n    MovedModule(\"email_mime_base\", \"email.MIMEBase\", \"email.mime.base\"),\n    MovedModule(\"email_mime_image\", \"email.MIMEImage\", \"email.mime.image\"),\n    MovedModule(\"email_mime_multipart\", \"email.MIMEMultipart\", \"email.mime.multipart\"),\n    MovedModule(\"email_mime_nonmultipart\", \"email.MIMENonMultipart\", \"email.mime.nonmultipart\"),\n    MovedModule(\"email_mime_text\", \"email.MIMEText\", \"email.mime.text\"),\n    MovedModule(\"BaseHTTPServer\", \"BaseHTTPServer\", \"http.server\"),\n    MovedModule(\"CGIHTTPServer\", \"CGIHTTPServer\", \"http.server\"),\n    MovedModule(\"SimpleHTTPServer\", \"SimpleHTTPServer\", \"http.server\"),\n    MovedModule(\"cPickle\", \"cPickle\", \"pickle\"),\n    MovedModule(\"queue\", \"Queue\"),\n    MovedModule(\"reprlib\", \"repr\"),\n    MovedModule(\"socketserver\", \"SocketServer\"),\n    MovedModule(\"_thread\", \"thread\", \"_thread\"),\n    MovedModule(\"tkinter\", \"Tkinter\"),\n    MovedModule(\"tkinter_dialog\", \"Dialog\", \"tkinter.dialog\"),\n    MovedModule(\"tkinter_filedialog\", \"FileDialog\", \"tkinter.filedialog\"),\n    MovedModule(\"tkinter_scrolledtext\", \"ScrolledText\", \"tkinter.scrolledtext\"),\n    MovedModule(\"tkinter_simpledialog\", \"SimpleDialog\", \"tkinter.simpledialog\"),\n    MovedModule(\"tkinter_tix\", \"Tix\", \"tkinter.tix\"),\n    MovedModule(\"tkinter_ttk\", \"ttk\", \"tkinter.ttk\"),\n    MovedModule(\"tkinter_constants\", \"Tkconstants\", \"tkinter.constants\"),\n    MovedModule(\"tkinter_dnd\", \"Tkdnd\", \"tkinter.dnd\"),\n    MovedModule(\"tkinter_colorchooser\", \"tkColorChooser\",\n                \"tkinter.colorchooser\"),\n    MovedModule(\"tkinter_commondialog\", \"tkCommonDialog\",\n                \"tkinter.commondialog\"),\n    MovedModule(\"tkinter_tkfiledialog\", \"tkFileDialog\", \"tkinter.filedialog\"),\n    MovedModule(\"tkinter_font\", \"tkFont\", \"tkinter.font\"),\n    MovedModule(\"tkinter_messagebox\", \"tkMessageBox\", \"tkinter.messagebox\"),\n    MovedModule(\"tkinter_tksimpledialog\", \"tkSimpleDialog\",\n                \"tkinter.simpledialog\"),\n    MovedModule(\"urllib_parse\", __name__ + \".moves.urllib_parse\", \"urllib.parse\"),\n    MovedModule(\"urllib_error\", __name__ + \".moves.urllib_error\", \"urllib.error\"),\n    MovedModule(\"urllib\", __name__ + \".moves.urllib\", __name__ + \".moves.urllib\"),\n    MovedModule(\"urllib_robotparser\", \"robotparser\", \"urllib.robotparser\"),\n    MovedModule(\"xmlrpc_client\", \"xmlrpclib\", \"xmlrpc.client\"),\n    MovedModule(\"xmlrpc_server\", \"SimpleXMLRPCServer\", \"xmlrpc.server\"),\n]\n# Add windows specific modules.\nif sys.platform == \"win32\":\n    _moved_attributes += [\n        MovedModule(\"winreg\", \"_winreg\"),\n    ]\n\nfor attr in _moved_attributes:\n    setattr(_MovedItems, attr.name, attr)\n    if isinstance(attr, MovedModule):\n        _importer._add_module(attr, \"moves.\" + attr.name)\ndel attr\n\n_MovedItems._moved_attributes = _moved_attributes\n\nmoves = _MovedItems(__name__ + \".moves\")\n_importer._add_module(moves, \"moves\")\n\n\nclass Module_six_moves_urllib_parse(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_parse\"\"\"\n\n\n_urllib_parse_moved_attributes = [\n    MovedAttribute(\"ParseResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"SplitResult\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qs\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"parse_qsl\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urldefrag\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urljoin\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlparse\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlsplit\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlunparse\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"urlunsplit\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"quote\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"quote_plus\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"unquote\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"unquote_plus\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"unquote_to_bytes\", \"urllib\", \"urllib.parse\", \"unquote\", \"unquote_to_bytes\"),\n    MovedAttribute(\"urlencode\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"splitquery\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"splittag\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"splituser\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"splitvalue\", \"urllib\", \"urllib.parse\"),\n    MovedAttribute(\"uses_fragment\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"uses_netloc\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"uses_params\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"uses_query\", \"urlparse\", \"urllib.parse\"),\n    MovedAttribute(\"uses_relative\", \"urlparse\", \"urllib.parse\"),\n]\nfor attr in _urllib_parse_moved_attributes:\n    setattr(Module_six_moves_urllib_parse, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_parse(__name__ + \".moves.urllib_parse\"),\n                      \"moves.urllib_parse\", \"moves.urllib.parse\")\n\n\nclass Module_six_moves_urllib_error(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_error\"\"\"\n\n\n_urllib_error_moved_attributes = [\n    MovedAttribute(\"URLError\", \"urllib2\", \"urllib.error\"),\n    MovedAttribute(\"HTTPError\", \"urllib2\", \"urllib.error\"),\n    MovedAttribute(\"ContentTooShortError\", \"urllib\", \"urllib.error\"),\n]\nfor attr in _urllib_error_moved_attributes:\n    setattr(Module_six_moves_urllib_error, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_error(__name__ + \".moves.urllib.error\"),\n                      \"moves.urllib_error\", \"moves.urllib.error\")\n\n\nclass Module_six_moves_urllib_request(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_request\"\"\"\n\n\n_urllib_request_moved_attributes = [\n    MovedAttribute(\"urlopen\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"install_opener\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"build_opener\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"pathname2url\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"url2pathname\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"getproxies\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"Request\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"OpenerDirector\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPDefaultErrorHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPRedirectHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPCookieProcessor\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"ProxyHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"BaseHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPPasswordMgr\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPPasswordMgrWithDefaultRealm\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"AbstractBasicAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPBasicAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"ProxyBasicAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"AbstractDigestAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPDigestAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"ProxyDigestAuthHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPSHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"FileHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"FTPHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"CacheFTPHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"UnknownHandler\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"HTTPErrorProcessor\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"urlretrieve\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"urlcleanup\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"URLopener\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"FancyURLopener\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"proxy_bypass\", \"urllib\", \"urllib.request\"),\n    MovedAttribute(\"parse_http_list\", \"urllib2\", \"urllib.request\"),\n    MovedAttribute(\"parse_keqv_list\", \"urllib2\", \"urllib.request\"),\n]\nfor attr in _urllib_request_moved_attributes:\n    setattr(Module_six_moves_urllib_request, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_request(__name__ + \".moves.urllib.request\"),\n                      \"moves.urllib_request\", \"moves.urllib.request\")\n\n\nclass Module_six_moves_urllib_response(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_response\"\"\"\n\n\n_urllib_response_moved_attributes = [\n    MovedAttribute(\"addbase\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addclosehook\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addinfo\", \"urllib\", \"urllib.response\"),\n    MovedAttribute(\"addinfourl\", \"urllib\", \"urllib.response\"),\n]\nfor attr in _urllib_response_moved_attributes:\n    setattr(Module_six_moves_urllib_response, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_response(__name__ + \".moves.urllib.response\"),\n                      \"moves.urllib_response\", \"moves.urllib.response\")\n\n\nclass Module_six_moves_urllib_robotparser(_LazyModule):\n\n    \"\"\"Lazy loading of moved objects in six.moves.urllib_robotparser\"\"\"\n\n\n_urllib_robotparser_moved_attributes = [\n    MovedAttribute(\"RobotFileParser\", \"robotparser\", \"urllib.robotparser\"),\n]\nfor attr in _urllib_robotparser_moved_attributes:\n    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)\ndel attr\n\nModule_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes\n\n_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + \".moves.urllib.robotparser\"),\n                      \"moves.urllib_robotparser\", \"moves.urllib.robotparser\")\n\n\nclass Module_six_moves_urllib(types.ModuleType):\n\n    \"\"\"Create a six.moves.urllib namespace that resembles the Python 3 namespace\"\"\"\n    __path__ = []  # mark as package\n    parse = _importer._get_module(\"moves.urllib_parse\")\n    error = _importer._get_module(\"moves.urllib_error\")\n    request = _importer._get_module(\"moves.urllib_request\")\n    response = _importer._get_module(\"moves.urllib_response\")\n    robotparser = _importer._get_module(\"moves.urllib_robotparser\")\n\n    def __dir__(self):\n        return ['parse', 'error', 'request', 'response', 'robotparser']\n\n_importer._add_module(Module_six_moves_urllib(__name__ + \".moves.urllib\"),\n                      \"moves.urllib\")\n\n\ndef add_move(move):\n    \"\"\"Add an item to six.moves.\"\"\"\n    setattr(_MovedItems, move.name, move)\n\n\ndef remove_move(name):\n    \"\"\"Remove item from six.moves.\"\"\"\n    try:\n        delattr(_MovedItems, name)\n    except AttributeError:\n        try:\n            del moves.__dict__[name]\n        except KeyError:\n            raise AttributeError(\"no such move, %r\" % (name,))\n\n\nif PY3:\n    _meth_func = \"__func__\"\n    _meth_self = \"__self__\"\n\n    _func_closure = \"__closure__\"\n    _func_code = \"__code__\"\n    _func_defaults = \"__defaults__\"\n    _func_globals = \"__globals__\"\nelse:\n    _meth_func = \"im_func\"\n    _meth_self = \"im_self\"\n\n    _func_closure = \"func_closure\"\n    _func_code = \"func_code\"\n    _func_defaults = \"func_defaults\"\n    _func_globals = \"func_globals\"\n\n\ntry:\n    advance_iterator = next\nexcept NameError:\n    def advance_iterator(it):\n        return it.next()\nnext = advance_iterator\n\n\ntry:\n    callable = callable\nexcept NameError:\n    def callable(obj):\n        return any(\"__call__\" in klass.__dict__ for klass in type(obj).__mro__)\n\n\nif PY3:\n    def get_unbound_function(unbound):\n        return unbound\n\n    create_bound_method = types.MethodType\n\n    def create_unbound_method(func, cls):\n        return func\n\n    Iterator = object\nelse:\n    def get_unbound_function(unbound):\n        return unbound.im_func\n\n    def create_bound_method(func, obj):\n        return types.MethodType(func, obj, obj.__class__)\n\n    def create_unbound_method(func, cls):\n        return types.MethodType(func, None, cls)\n\n    class Iterator(object):\n\n        def next(self):\n            return type(self).__next__(self)\n\n    callable = callable\n_add_doc(get_unbound_function,\n         \"\"\"Get the function out of a possibly unbound function\"\"\")\n\n\nget_method_function = operator.attrgetter(_meth_func)\nget_method_self = operator.attrgetter(_meth_self)\nget_function_closure = operator.attrgetter(_func_closure)\nget_function_code = operator.attrgetter(_func_code)\nget_function_defaults = operator.attrgetter(_func_defaults)\nget_function_globals = operator.attrgetter(_func_globals)\n\n\nif PY3:\n    def iterkeys(d, **kw):\n        return iter(d.keys(**kw))\n\n    def itervalues(d, **kw):\n        return iter(d.values(**kw))\n\n    def iteritems(d, **kw):\n        return iter(d.items(**kw))\n\n    def iterlists(d, **kw):\n        return iter(d.lists(**kw))\n\n    viewkeys = operator.methodcaller(\"keys\")\n\n    viewvalues = operator.methodcaller(\"values\")\n\n    viewitems = operator.methodcaller(\"items\")\nelse:\n    def iterkeys(d, **kw):\n        return d.iterkeys(**kw)\n\n    def itervalues(d, **kw):\n        return d.itervalues(**kw)\n\n    def iteritems(d, **kw):\n        return d.iteritems(**kw)\n\n    def iterlists(d, **kw):\n        return d.iterlists(**kw)\n\n    viewkeys = operator.methodcaller(\"viewkeys\")\n\n    viewvalues = operator.methodcaller(\"viewvalues\")\n\n    viewitems = operator.methodcaller(\"viewitems\")\n\n_add_doc(iterkeys, \"Return an iterator over the keys of a dictionary.\")\n_add_doc(itervalues, \"Return an iterator over the values of a dictionary.\")\n_add_doc(iteritems,\n         \"Return an iterator over the (key, value) pairs of a dictionary.\")\n_add_doc(iterlists,\n         \"Return an iterator over the (key, [values]) pairs of a dictionary.\")\n\n\nif PY3:\n    def b(s):\n        return s.encode(\"latin-1\")\n\n    def u(s):\n        return s\n    unichr = chr\n    import struct\n    int2byte = struct.Struct(\">B\").pack\n    del struct\n    byte2int = operator.itemgetter(0)\n    indexbytes = operator.getitem\n    iterbytes = iter\n    import io\n    StringIO = io.StringIO\n    BytesIO = io.BytesIO\n    del io\n    _assertCountEqual = \"assertCountEqual\"\n    if sys.version_info[1] <= 1:\n        _assertRaisesRegex = \"assertRaisesRegexp\"\n        _assertRegex = \"assertRegexpMatches\"\n        _assertNotRegex = \"assertNotRegexpMatches\"\n    else:\n        _assertRaisesRegex = \"assertRaisesRegex\"\n        _assertRegex = \"assertRegex\"\n        _assertNotRegex = \"assertNotRegex\"\nelse:\n    def b(s):\n        return s\n    # Workaround for standalone backslash\n\n    def u(s):\n        return unicode(s.replace(r'\\\\', r'\\\\\\\\'), \"unicode_escape\")\n    unichr = unichr\n    int2byte = chr\n\n    def byte2int(bs):\n        return ord(bs[0])\n\n    def indexbytes(buf, i):\n        return ord(buf[i])\n    iterbytes = functools.partial(itertools.imap, ord)\n    import StringIO\n    StringIO = BytesIO = StringIO.StringIO\n    _assertCountEqual = \"assertItemsEqual\"\n    _assertRaisesRegex = \"assertRaisesRegexp\"\n    _assertRegex = \"assertRegexpMatches\"\n    _assertNotRegex = \"assertNotRegexpMatches\"\n_add_doc(b, \"\"\"Byte literal\"\"\")\n_add_doc(u, \"\"\"Text literal\"\"\")\n\n\ndef assertCountEqual(self, *args, **kwargs):\n    return getattr(self, _assertCountEqual)(*args, **kwargs)\n\n\ndef assertRaisesRegex(self, *args, **kwargs):\n    return getattr(self, _assertRaisesRegex)(*args, **kwargs)\n\n\ndef assertRegex(self, *args, **kwargs):\n    return getattr(self, _assertRegex)(*args, **kwargs)\n\n\ndef assertNotRegex(self, *args, **kwargs):\n    return getattr(self, _assertNotRegex)(*args, **kwargs)\n\n\nif PY3:\n    exec_ = getattr(moves.builtins, \"exec\")\n\n    def reraise(tp, value, tb=None):\n        try:\n            if value is None:\n                value = tp()\n            if value.__traceback__ is not tb:\n                raise value.with_traceback(tb)\n            raise value\n        finally:\n            value = None\n            tb = None\n\nelse:\n    def exec_(_code_, _globs_=None, _locs_=None):\n        \"\"\"Execute code in a namespace.\"\"\"\n        if _globs_ is None:\n            frame = sys._getframe(1)\n            _globs_ = frame.f_globals\n            if _locs_ is None:\n                _locs_ = frame.f_locals\n            del frame\n        elif _locs_ is None:\n            _locs_ = _globs_\n        exec(\"\"\"exec _code_ in _globs_, _locs_\"\"\")\n\n    exec_(\"\"\"def reraise(tp, value, tb=None):\n    try:\n        raise tp, value, tb\n    finally:\n        tb = None\n\"\"\")\n\n\nif sys.version_info[:2] > (3,):\n    exec_(\"\"\"def raise_from(value, from_value):\n    try:\n        raise value from from_value\n    finally:\n        value = None\n\"\"\")\nelse:\n    def raise_from(value, from_value):\n        raise value\n\n\nprint_ = getattr(moves.builtins, \"print\", None)\nif print_ is None:\n    def print_(*args, **kwargs):\n        \"\"\"The new-style print function for Python 2.4 and 2.5.\"\"\"\n        fp = kwargs.pop(\"file\", sys.stdout)\n        if fp is None:\n            return\n\n        def write(data):\n            if not isinstance(data, basestring):\n                data = str(data)\n            # If the file has an encoding, encode unicode with it.\n            if (isinstance(fp, file) and\n                    isinstance(data, unicode) and\n                    fp.encoding is not None):\n                errors = getattr(fp, \"errors\", None)\n                if errors is None:\n                    errors = \"strict\"\n                data = data.encode(fp.encoding, errors)\n            fp.write(data)\n        want_unicode = False\n        sep = kwargs.pop(\"sep\", None)\n        if sep is not None:\n            if isinstance(sep, unicode):\n                want_unicode = True\n            elif not isinstance(sep, str):\n                raise TypeError(\"sep must be None or a string\")\n        end = kwargs.pop(\"end\", None)\n        if end is not None:\n            if isinstance(end, unicode):\n                want_unicode = True\n            elif not isinstance(end, str):\n                raise TypeError(\"end must be None or a string\")\n        if kwargs:\n            raise TypeError(\"invalid keyword arguments to print()\")\n        if not want_unicode:\n            for arg in args:\n                if isinstance(arg, unicode):\n                    want_unicode = True\n                    break\n        if want_unicode:\n            newline = unicode(\"\\n\")\n            space = unicode(\" \")\n        else:\n            newline = \"\\n\"\n            space = \" \"\n        if sep is None:\n            sep = space\n        if end is None:\n            end = newline\n        for i, arg in enumerate(args):\n            if i:\n                write(sep)\n            write(arg)\n        write(end)\nif sys.version_info[:2] < (3, 3):\n    _print = print_\n\n    def print_(*args, **kwargs):\n        fp = kwargs.get(\"file\", sys.stdout)\n        flush = kwargs.pop(\"flush\", False)\n        _print(*args, **kwargs)\n        if flush and fp is not None:\n            fp.flush()\n\n_add_doc(reraise, \"\"\"Reraise an exception.\"\"\")\n\nif sys.version_info[0:2] < (3, 4):\n    # This does exactly the same what the :func:`py3:functools.update_wrapper`\n    # function does on Python versions after 3.2. It sets the ``__wrapped__``\n    # attribute on ``wrapper`` object and it doesn't raise an error if any of\n    # the attributes mentioned in ``assigned`` and ``updated`` are missing on\n    # ``wrapped`` object.\n    def _update_wrapper(wrapper, wrapped,\n                        assigned=functools.WRAPPER_ASSIGNMENTS,\n                        updated=functools.WRAPPER_UPDATES):\n        for attr in assigned:\n            try:\n                value = getattr(wrapped, attr)\n            except AttributeError:\n                continue\n            else:\n                setattr(wrapper, attr, value)\n        for attr in updated:\n            getattr(wrapper, attr).update(getattr(wrapped, attr, {}))\n        wrapper.__wrapped__ = wrapped\n        return wrapper\n    _update_wrapper.__doc__ = functools.update_wrapper.__doc__\n\n    def wraps(wrapped, assigned=functools.WRAPPER_ASSIGNMENTS,\n              updated=functools.WRAPPER_UPDATES):\n        return functools.partial(_update_wrapper, wrapped=wrapped,\n                                 assigned=assigned, updated=updated)\n    wraps.__doc__ = functools.wraps.__doc__\n\nelse:\n    wraps = functools.wraps\n\n\ndef with_metaclass(meta, *bases):\n    \"\"\"Create a base class with a metaclass.\"\"\"\n    # This requires a bit of explanation: the basic idea is to make a dummy\n    # metaclass for one level of class instantiation that replaces itself with\n    # the actual metaclass.\n    class metaclass(type):\n\n        def __new__(cls, name, this_bases, d):\n            if sys.version_info[:2] >= (3, 7):\n                # This version introduced PEP 560 that requires a bit\n                # of extra care (we mimic what is done by __build_class__).\n                resolved_bases = types.resolve_bases(bases)\n                if resolved_bases is not bases:\n                    d['__orig_bases__'] = bases\n            else:\n                resolved_bases = bases\n            return meta(name, resolved_bases, d)\n\n        @classmethod\n        def __prepare__(cls, name, this_bases):\n            return meta.__prepare__(name, bases)\n    return type.__new__(metaclass, 'temporary_class', (), {})\n\n\ndef add_metaclass(metaclass):\n    \"\"\"Class decorator for creating a class with a metaclass.\"\"\"\n    def wrapper(cls):\n        orig_vars = cls.__dict__.copy()\n        slots = orig_vars.get('__slots__')\n        if slots is not None:\n            if isinstance(slots, str):\n                slots = [slots]\n            for slots_var in slots:\n                orig_vars.pop(slots_var)\n        orig_vars.pop('__dict__', None)\n        orig_vars.pop('__weakref__', None)\n        if hasattr(cls, '__qualname__'):\n            orig_vars['__qualname__'] = cls.__qualname__\n        return metaclass(cls.__name__, cls.__bases__, orig_vars)\n    return wrapper\n\n\ndef ensure_binary(s, encoding='utf-8', errors='strict'):\n    \"\"\"Coerce **s** to six.binary_type.\n\n    For Python 2:\n      - `unicode` -> encoded to `str`\n      - `str` -> `str`\n\n    For Python 3:\n      - `str` -> encoded to `bytes`\n      - `bytes` -> `bytes`\n    \"\"\"\n    if isinstance(s, binary_type):\n        return s\n    if isinstance(s, text_type):\n        return s.encode(encoding, errors)\n    raise TypeError(\"not expecting type '%s'\" % type(s))\n\n\ndef ensure_str(s, encoding='utf-8', errors='strict'):\n    \"\"\"Coerce *s* to `str`.\n\n    For Python 2:\n      - `unicode` -> encoded to `str`\n      - `str` -> `str`\n\n    For Python 3:\n      - `str` -> `str`\n      - `bytes` -> decoded to `str`\n    \"\"\"\n    # Optimization: Fast return for the common case.\n    if type(s) is str:\n        return s\n    if PY2 and isinstance(s, text_type):\n        return s.encode(encoding, errors)\n    elif PY3 and isinstance(s, binary_type):\n        return s.decode(encoding, errors)\n    elif not isinstance(s, (text_type, binary_type)):\n        raise TypeError(\"not expecting type '%s'\" % type(s))\n    return s\n\n\ndef ensure_text(s, encoding='utf-8', errors='strict'):\n    \"\"\"Coerce *s* to six.text_type.\n\n    For Python 2:\n      - `unicode` -> `unicode`\n      - `str` -> `unicode`\n\n    For Python 3:\n      - `str` -> `str`\n      - `bytes` -> decoded to `str`\n    \"\"\"\n    if isinstance(s, binary_type):\n        return s.decode(encoding, errors)\n    elif isinstance(s, text_type):\n        return s\n    else:\n        raise TypeError(\"not expecting type '%s'\" % type(s))\n\n\ndef python_2_unicode_compatible(klass):\n    \"\"\"\n    A class decorator that defines __unicode__ and __str__ methods under Python 2.\n    Under Python 3 it does nothing.\n\n    To support Python 2 and 3 with a single code base, define a __str__ method\n    returning text and apply this decorator to the class.\n    \"\"\"\n    if PY2:\n        if '__str__' not in klass.__dict__:\n            raise ValueError(\"@python_2_unicode_compatible cannot be applied \"\n                             \"to %s because it doesn't define __str__().\" %\n                             klass.__name__)\n        klass.__unicode__ = klass.__str__\n        klass.__str__ = lambda self: self.__unicode__().encode('utf-8')\n    return klass\n\n\n# Complete the moves implementation.\n# This code is at the end of this module to speed up module loading.\n# Turn this module into a package.\n__path__ = []  # required for PEP 302 and PEP 451\n__package__ = __name__  # see PEP 366 @ReservedAssignment\nif globals().get(\"__spec__\") is not None:\n    __spec__.submodule_search_locations = []  # PEP 451 @UndefinedVariable\n# Remove other six meta path importers, since they cause problems. This can\n# happen if six is removed from sys.modules and then reloaded. (Setuptools does\n# this for some reason.)\nif sys.meta_path:\n    for i, importer in enumerate(sys.meta_path):\n        # Here's some real nastiness: Another \"instance\" of the six module might\n        # be floating around. Therefore, we can't use isinstance() to check for\n        # the six meta path importer, since the other six instance will have\n        # inserted an importer with different class.\n        if (type(importer).__name__ == \"_SixMetaPathImporter\" and\n                importer.name == __name__):\n            del sys.meta_path[i]\n            break\n    del i, importer\n# Finally, add the importer to the meta path import hook.\nsys.meta_path.append(_importer)\n",998],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py":["from __future__ import annotations\n\nimport os\nfrom pathlib import Path\nfrom typing import Any, NoReturn\n\nfrom ._typing import TypeGuard\n\n\ndef is_path(f: Any) -> TypeGuard[bytes | str | Path]:\n    return isinstance(f, (bytes, str, Path))\n\n\ndef is_directory(f: Any) -> TypeGuard[bytes | str | Path]:\n    \"\"\"Checks if an object is a string, and that it points to a directory.\"\"\"\n    return is_path(f) and os.path.isdir(f)\n\n\nclass DeferredError:\n    def __init__(self, ex: BaseException):\n        self.ex = ex\n\n    def __getattr__(self, elt: str) -> NoReturn:\n        raise self.ex\n\n    @staticmethod\n    def new(ex: BaseException) -> Any:\n        \"\"\"\n        Creates an object that raises the wrapped exception ``ex`` when used,\n        and casts it to :py:obj:`~typing.Any` type.\n        \"\"\"\n        return DeferredError(ex)\n",32],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py":["#\n# The Python Imaging Library.\n# $Id$\n#\n# the Image class wrapper\n#\n# partial release history:\n# 1995-09-09 fl   Created\n# 1996-03-11 fl   PIL release 0.0 (proof of concept)\n# 1996-04-30 fl   PIL release 0.1b1\n# 1999-07-28 fl   PIL release 1.0 final\n# 2000-06-07 fl   PIL release 1.1\n# 2000-10-20 fl   PIL release 1.1.1\n# 2001-05-07 fl   PIL release 1.1.2\n# 2002-03-15 fl   PIL release 1.1.3\n# 2003-05-10 fl   PIL release 1.1.4\n# 2005-03-28 fl   PIL release 1.1.5\n# 2006-12-02 fl   PIL release 1.1.6\n# 2009-11-15 fl   PIL release 1.1.7\n#\n# Copyright (c) 1997-2009 by Secret Labs AB.  All rights reserved.\n# Copyright (c) 1995-2009 by Fredrik Lundh.\n#\n# See the README file for information on usage and redistribution.\n#\n\nfrom __future__ import annotations\n\nimport atexit\nimport builtins\nimport io\nimport logging\nimport math\nimport os\nimport re\nimport struct\nimport sys\nimport tempfile\nimport warnings\nfrom collections.abc import Callable, MutableMapping\nfrom enum import IntEnum\nfrom pathlib import Path\n\ntry:\n    from defusedxml import ElementTree\nexcept ImportError:\n    ElementTree = None\n\n# VERSION was removed in Pillow 6.0.0.\n# PILLOW_VERSION was removed in Pillow 9.0.0.\n# Use __version__ instead.\nfrom . import (\n    ExifTags,\n    ImageMode,\n    TiffTags,\n    UnidentifiedImageError,\n    __version__,\n    _plugins,\n)\nfrom ._binary import i32le, o32be, o32le\nfrom ._util import DeferredError, is_path\n\nlogger = logging.getLogger(__name__)\n\n\nclass DecompressionBombWarning(RuntimeWarning):\n    pass\n\n\nclass DecompressionBombError(Exception):\n    pass\n\n\n# Limit to around a quarter gigabyte for a 24-bit (3 bpp) image\nMAX_IMAGE_PIXELS = int(1024 * 1024 * 1024 // 4 // 3)\n\n\ntry:\n    # If the _imaging C module is not present, Pillow will not load.\n    # Note that other modules should not refer to _imaging directly;\n    # import Image and use the Image.core variable instead.\n    # Also note that Image.core is not a publicly documented interface,\n    # and should be considered private and subject to change.\n    from . import _imaging as core\n\n    if __version__ != getattr(core, \"PILLOW_VERSION\", None):\n        msg = (\n            \"The _imaging extension was built for another version of Pillow or PIL:\\n\"\n            f\"Core version: {getattr(core, 'PILLOW_VERSION', None)}\\n\"\n            f\"Pillow version: {__version__}\"\n        )\n        raise ImportError(msg)\n\nexcept ImportError as v:\n    core = DeferredError.new(ImportError(\"The _imaging C module is not installed.\"))\n    # Explanations for ways that we know we might have an import error\n    if str(v).startswith(\"Module use of python\"):\n        # The _imaging C module is present, but not compiled for\n        # the right version (windows only).  Print a warning, if\n        # possible.\n        warnings.warn(\n            \"The _imaging extension was built for another version of Python.\",\n            RuntimeWarning,\n        )\n    elif str(v).startswith(\"The _imaging extension\"):\n        warnings.warn(str(v), RuntimeWarning)\n    # Fail here anyway. Don't let people run with a mostly broken Pillow.\n    # see docs/porting.rst\n    raise\n\n\nUSE_CFFI_ACCESS = False\ntry:\n    import cffi\nexcept ImportError:\n    cffi = None\n\n\ndef isImageType(t):\n    \"\"\"\n    Checks if an object is an image object.\n\n    .. warning::\n\n       This function is for internal use only.\n\n    :param t: object to check if it's an image\n    :returns: True if the object is an image\n    \"\"\"\n    return hasattr(t, \"im\")\n\n\n#\n# Constants\n\n\n# transpose\nclass Transpose(IntEnum):\n    FLIP_LEFT_RIGHT = 0\n    FLIP_TOP_BOTTOM = 1\n    ROTATE_90 = 2\n    ROTATE_180 = 3\n    ROTATE_270 = 4\n    TRANSPOSE = 5\n    TRANSVERSE = 6\n\n\n# transforms (also defined in Imaging.h)\nclass Transform(IntEnum):\n    AFFINE = 0\n    EXTENT = 1\n    PERSPECTIVE = 2\n    QUAD = 3\n    MESH = 4\n\n\n# resampling filters (also defined in Imaging.h)\nclass Resampling(IntEnum):\n    NEAREST = 0\n    BOX = 4\n    BILINEAR = 2\n    HAMMING = 5\n    BICUBIC = 3\n    LANCZOS = 1\n\n\n_filters_support = {\n    Resampling.BOX: 0.5,\n    Resampling.BILINEAR: 1.0,\n    Resampling.HAMMING: 1.0,\n    Resampling.BICUBIC: 2.0,\n    Resampling.LANCZOS: 3.0,\n}\n\n\n# dithers\nclass Dither(IntEnum):\n    NONE = 0\n    ORDERED = 1  # Not yet implemented\n    RASTERIZE = 2  # Not yet implemented\n    FLOYDSTEINBERG = 3  # default\n\n\n# palettes/quantizers\nclass Palette(IntEnum):\n    WEB = 0\n    ADAPTIVE = 1\n\n\nclass Quantize(IntEnum):\n    MEDIANCUT = 0\n    MAXCOVERAGE = 1\n    FASTOCTREE = 2\n    LIBIMAGEQUANT = 3\n\n\nmodule = sys.modules[__name__]\nfor enum in (Transpose, Transform, Resampling, Dither, Palette, Quantize):\n    for item in enum:\n        setattr(module, item.name, item.value)\n\n\nif hasattr(core, \"DEFAULT_STRATEGY\"):\n    DEFAULT_STRATEGY = core.DEFAULT_STRATEGY\n    FILTERED = core.FILTERED\n    HUFFMAN_ONLY = core.HUFFMAN_ONLY\n    RLE = core.RLE\n    FIXED = core.FIXED\n\n\n# --------------------------------------------------------------------\n# Registries\n\nID = []\nOPEN = {}\nMIME = {}\nSAVE = {}\nSAVE_ALL = {}\nEXTENSION = {}\nDECODERS = {}\nENCODERS = {}\n\n# --------------------------------------------------------------------\n# Modes\n\n_ENDIAN = \"<\" if sys.byteorder == \"little\" else \">\"\n\n\ndef _conv_type_shape(im):\n    m = ImageMode.getmode(im.mode)\n    shape = (im.height, im.width)\n    extra = len(m.bands)\n    if extra != 1:\n        shape += (extra,)\n    return shape, m.typestr\n\n\nMODES = [\"1\", \"CMYK\", \"F\", \"HSV\", \"I\", \"L\", \"LAB\", \"P\", \"RGB\", \"RGBA\", \"RGBX\", \"YCbCr\"]\n\n# raw modes that may be memory mapped.  NOTE: if you change this, you\n# may have to modify the stride calculation in map.c too!\n_MAPMODES = (\"L\", \"P\", \"RGBX\", \"RGBA\", \"CMYK\", \"I;16\", \"I;16L\", \"I;16B\")\n\n\ndef getmodebase(mode):\n    \"\"\"\n    Gets the \"base\" mode for given mode.  This function returns \"L\" for\n    images that contain grayscale data, and \"RGB\" for images that\n    contain color data.\n\n    :param mode: Input mode.\n    :returns: \"L\" or \"RGB\".\n    :exception KeyError: If the input mode was not a standard mode.\n    \"\"\"\n    return ImageMode.getmode(mode).basemode\n\n\ndef getmodetype(mode):\n    \"\"\"\n    Gets the storage type mode.  Given a mode, this function returns a\n    single-layer mode suitable for storing individual bands.\n\n    :param mode: Input mode.\n    :returns: \"L\", \"I\", or \"F\".\n    :exception KeyError: If the input mode was not a standard mode.\n    \"\"\"\n    return ImageMode.getmode(mode).basetype\n\n\ndef getmodebandnames(mode):\n    \"\"\"\n    Gets a list of individual band names.  Given a mode, this function returns\n    a tuple containing the names of individual bands (use\n    :py:method:`~PIL.Image.getmodetype` to get the mode used to store each\n    individual band.\n\n    :param mode: Input mode.\n    :returns: A tuple containing band names.  The length of the tuple\n        gives the number of bands in an image of the given mode.\n    :exception KeyError: If the input mode was not a standard mode.\n    \"\"\"\n    return ImageMode.getmode(mode).bands\n\n\ndef getmodebands(mode):\n    \"\"\"\n    Gets the number of individual bands for this mode.\n\n    :param mode: Input mode.\n    :returns: The number of bands in this mode.\n    :exception KeyError: If the input mode was not a standard mode.\n    \"\"\"\n    return len(ImageMode.getmode(mode).bands)\n\n\n# --------------------------------------------------------------------\n# Helpers\n\n_initialized = 0\n\n\ndef preinit():\n    \"\"\"\n    Explicitly loads BMP, GIF, JPEG, PPM and PPM file format drivers.\n\n    It is called when opening or saving images.\n    \"\"\"\n\n    global _initialized\n    if _initialized >= 1:\n        return\n\n    try:\n        from . import BmpImagePlugin\n\n        assert BmpImagePlugin\n    except ImportError:\n        pass\n    try:\n        from . import GifImagePlugin\n\n        assert GifImagePlugin\n    except ImportError:\n        pass\n    try:\n        from . import JpegImagePlugin\n\n        assert JpegImagePlugin\n    except ImportError:\n        pass\n    try:\n        from . import PpmImagePlugin\n\n        assert PpmImagePlugin\n    except ImportError:\n        pass\n    try:\n        from . import PngImagePlugin\n\n        assert PngImagePlugin\n    except ImportError:\n        pass\n\n    _initialized = 1\n\n\ndef init():\n    \"\"\"\n    Explicitly initializes the Python Imaging Library. This function\n    loads all available file format drivers.\n\n    It is called when opening or saving images if :py:meth:`~preinit()` is\n    insufficient, and by :py:meth:`~PIL.features.pilinfo`.\n    \"\"\"\n\n    global _initialized\n    if _initialized >= 2:\n        return 0\n\n    parent_name = __name__.rpartition(\".\")[0]\n    for plugin in _plugins:\n        try:\n            logger.debug(\"Importing %s\", plugin)\n            __import__(f\"{parent_name}.{plugin}\", globals(), locals(), [])\n        except ImportError as e:\n            logger.debug(\"Image: failed to import %s: %s\", plugin, e)\n\n    if OPEN or SAVE:\n        _initialized = 2\n        return 1\n\n\n# --------------------------------------------------------------------\n# Codec factories (used by tobytes/frombytes and ImageFile.load)\n\n\ndef _getdecoder(mode, decoder_name, args, extra=()):\n    # tweak arguments\n    if args is None:\n        args = ()\n    elif not isinstance(args, tuple):\n        args = (args,)\n\n    try:\n        decoder = DECODERS[decoder_name]\n    except KeyError:\n        pass\n    else:\n        return decoder(mode, *args + extra)\n\n    try:\n        # get decoder\n        decoder = getattr(core, decoder_name + \"_decoder\")\n    except AttributeError as e:\n        msg = f\"decoder {decoder_name} not available\"\n        raise OSError(msg) from e\n    return decoder(mode, *args + extra)\n\n\ndef _getencoder(mode, encoder_name, args, extra=()):\n    # tweak arguments\n    if args is None:\n        args = ()\n    elif not isinstance(args, tuple):\n        args = (args,)\n\n    try:\n        encoder = ENCODERS[encoder_name]\n    except KeyError:\n        pass\n    else:\n        return encoder(mode, *args + extra)\n\n    try:\n        # get encoder\n        encoder = getattr(core, encoder_name + \"_encoder\")\n    except AttributeError as e:\n        msg = f\"encoder {encoder_name} not available\"\n        raise OSError(msg) from e\n    return encoder(mode, *args + extra)\n\n\n# --------------------------------------------------------------------\n# Simple expression analyzer\n\n\nclass _E:\n    def __init__(self, scale, offset):\n        self.scale = scale\n        self.offset = offset\n\n    def __neg__(self):\n        return _E(-self.scale, -self.offset)\n\n    def __add__(self, other):\n        if isinstance(other, _E):\n            return _E(self.scale + other.scale, self.offset + other.offset)\n        return _E(self.scale, self.offset + other)\n\n    __radd__ = __add__\n\n    def __sub__(self, other):\n        return self + -other\n\n    def __rsub__(self, other):\n        return other + -self\n\n    def __mul__(self, other):\n        if isinstance(other, _E):\n            return NotImplemented\n        return _E(self.scale * other, self.offset * other)\n\n    __rmul__ = __mul__\n\n    def __truediv__(self, other):\n        if isinstance(other, _E):\n            return NotImplemented\n        return _E(self.scale / other, self.offset / other)\n\n\ndef _getscaleoffset(expr):\n    a = expr(_E(1, 0))\n    return (a.scale, a.offset) if isinstance(a, _E) else (0, a)\n\n\n# --------------------------------------------------------------------\n# Implementation wrapper\n\n\nclass Image:\n    \"\"\"\n    This class represents an image object.  To create\n    :py:class:`~PIL.Image.Image` objects, use the appropriate factory\n    functions.  There's hardly ever any reason to call the Image constructor\n    directly.\n\n    * :py:func:`~PIL.Image.open`\n    * :py:func:`~PIL.Image.new`\n    * :py:func:`~PIL.Image.frombytes`\n    \"\"\"\n\n    format: str | None = None\n    format_description: str | None = None\n    _close_exclusive_fp_after_loading = True\n\n    def __init__(self):\n        # FIXME: take \"new\" parameters / other image?\n        # FIXME: turn mode and size into delegating properties?\n        self.im = None\n        self._mode = \"\"\n        self._size = (0, 0)\n        self.palette = None\n        self.info = {}\n        self.readonly = 0\n        self.pyaccess = None\n        self._exif = None\n\n    @property\n    def width(self):\n        return self.size[0]\n\n    @property\n    def height(self):\n        return self.size[1]\n\n    @property\n    def size(self):\n        return self._size\n\n    @property\n    def mode(self):\n        return self._mode\n\n    def _new(self, im):\n        new = Image()\n        new.im = im\n        new._mode = im.mode\n        new._size = im.size\n        if im.mode in (\"P\", \"PA\"):\n            if self.palette:\n                new.palette = self.palette.copy()\n            else:\n                from . import ImagePalette\n\n                new.palette = ImagePalette.ImagePalette()\n        new.info = self.info.copy()\n        return new\n\n    # Context manager support\n    def __enter__(self):\n        return self\n\n    def _close_fp(self):\n        if getattr(self, \"_fp\", False):\n            if self._fp != self.fp:\n                self._fp.close()\n            self._fp = DeferredError(ValueError(\"Operation on closed image\"))\n        if self.fp:\n            self.fp.close()\n\n    def __exit__(self, *args):\n        if hasattr(self, \"fp\"):\n            if getattr(self, \"_exclusive_fp\", False):\n                self._close_fp()\n            self.fp = None\n\n    def close(self):\n        \"\"\"\n        Closes the file pointer, if possible.\n\n        This operation will destroy the image core and release its memory.\n        The image data will be unusable afterward.\n\n        This function is required to close images that have multiple frames or\n        have not had their file read and closed by the\n        :py:meth:`~PIL.Image.Image.load` method. See :ref:`file-handling` for\n        more information.\n        \"\"\"\n        if hasattr(self, \"fp\"):\n            try:\n                self._close_fp()\n                self.fp = None\n            except Exception as msg:\n                logger.debug(\"Error closing: %s\", msg)\n\n        if getattr(self, \"map\", None):\n            self.map = None\n\n        # Instead of simply setting to None, we're setting up a\n        # deferred error that will better explain that the core image\n        # object is gone.\n        self.im = DeferredError(ValueError(\"Operation on closed image\"))\n\n    def _copy(self):\n        self.load()\n        self.im = self.im.copy()\n        self.pyaccess = None\n        self.readonly = 0\n\n    def _ensure_mutable(self):\n        if self.readonly:\n            self._copy()\n        else:\n            self.load()\n\n    def _dump(self, file=None, format=None, **options):\n        suffix = \"\"\n        if format:\n            suffix = \".\" + format\n\n        if not file:\n            f, filename = tempfile.mkstemp(suffix)\n            os.close(f)\n        else:\n            filename = file\n            if not filename.endswith(suffix):\n                filename = filename + suffix\n\n        self.load()\n\n        if not format or format == \"PPM\":\n            self.im.save_ppm(filename)\n        else:\n            self.save(filename, format, **options)\n\n        return filename\n\n    def __eq__(self, other):\n        return (\n            self.__class__ is other.__class__\n            and self.mode == other.mode\n            and self.size == other.size\n            and self.info == other.info\n            and self.getpalette() == other.getpalette()\n            and self.tobytes() == other.tobytes()\n        )\n\n    def __repr__(self):\n        return \"<%s.%s image mode=%s size=%dx%d at 0x%X>\" % (\n            self.__class__.__module__,\n            self.__class__.__name__,\n            self.mode,\n            self.size[0],\n            self.size[1],\n            id(self),\n        )\n\n    def _repr_pretty_(self, p, cycle):\n        \"\"\"IPython plain text display support\"\"\"\n\n        # Same as __repr__ but without unpredictable id(self),\n        # to keep Jupyter notebook `text/plain` output stable.\n        p.text(\n            \"<%s.%s image mode=%s size=%dx%d>\"\n            % (\n                self.__class__.__module__,\n                self.__class__.__name__,\n                self.mode,\n                self.size[0],\n                self.size[1],\n            )\n        )\n\n    def _repr_image(self, image_format, **kwargs):\n        \"\"\"Helper function for iPython display hook.\n\n        :param image_format: Image format.\n        :returns: image as bytes, saved into the given format.\n        \"\"\"\n        b = io.BytesIO()\n        try:\n            self.save(b, image_format, **kwargs)\n        except Exception:\n            return None\n        return b.getvalue()\n\n    def _repr_png_(self):\n        \"\"\"iPython display hook support for PNG format.\n\n        :returns: PNG version of the image as bytes\n        \"\"\"\n        return self._repr_image(\"PNG\", compress_level=1)\n\n    def _repr_jpeg_(self):\n        \"\"\"iPython display hook support for JPEG format.\n\n        :returns: JPEG version of the image as bytes\n        \"\"\"\n        return self._repr_image(\"JPEG\")\n\n    @property\n    def __array_interface__(self):\n        # numpy array interface support\n        new = {\"version\": 3}\n        try:\n            if self.mode == \"1\":\n                # Binary images need to be extended from bits to bytes\n                # See: https://github.com/python-pillow/Pillow/issues/350\n                new[\"data\"] = self.tobytes(\"raw\", \"L\")\n            else:\n                new[\"data\"] = self.tobytes()\n        except Exception as e:\n            if not isinstance(e, (MemoryError, RecursionError)):\n                try:\n                    import numpy\n                    from packaging.version import parse as parse_version\n                except ImportError:\n                    pass\n                else:\n                    if parse_version(numpy.__version__) < parse_version(\"1.23\"):\n                        warnings.warn(e)\n            raise\n        new[\"shape\"], new[\"typestr\"] = _conv_type_shape(self)\n        return new\n\n    def __getstate__(self):\n        im_data = self.tobytes()  # load image first\n        return [self.info, self.mode, self.size, self.getpalette(), im_data]\n\n    def __setstate__(self, state):\n        Image.__init__(self)\n        info, mode, size, palette, data = state\n        self.info = info\n        self._mode = mode\n        self._size = size\n        self.im = core.new(mode, size)\n        if mode in (\"L\", \"LA\", \"P\", \"PA\") and palette:\n            self.putpalette(palette)\n        self.frombytes(data)\n\n    def tobytes(self, encoder_name=\"raw\", *args):\n        \"\"\"\n        Return image as a bytes object.\n\n        .. warning::\n\n            This method returns the raw image data from the internal\n            storage.  For compressed image data (e.g. PNG, JPEG) use\n            :meth:`~.save`, with a BytesIO parameter for in-memory\n            data.\n\n        :param encoder_name: What encoder to use.  The default is to\n                             use the standard \"raw\" encoder.\n\n                             A list of C encoders can be seen under\n                             codecs section of the function array in\n                             :file:`_imaging.c`. Python encoders are\n                             registered within the relevant plugins.\n        :param args: Extra arguments to the encoder.\n        :returns: A :py:class:`bytes` object.\n        \"\"\"\n\n        # may pass tuple instead of argument list\n        if len(args) == 1 and isinstance(args[0], tuple):\n            args = args[0]\n\n        if encoder_name == \"raw\" and args == ():\n            args = self.mode\n\n        self.load()\n\n        if self.width == 0 or self.height == 0:\n            return b\"\"\n\n        # unpack data\n        e = _getencoder(self.mode, encoder_name, args)\n        e.setimage(self.im)\n\n        bufsize = max(65536, self.size[0] * 4)  # see RawEncode.c\n\n        output = []\n        while True:\n            bytes_consumed, errcode, data = e.encode(bufsize)\n            output.append(data)\n            if errcode:\n                break\n        if errcode < 0:\n            msg = f\"encoder error {errcode} in tobytes\"\n            raise RuntimeError(msg)\n\n        return b\"\".join(output)\n\n    def tobitmap(self, name=\"image\"):\n        \"\"\"\n        Returns the image converted to an X11 bitmap.\n\n        .. note:: This method only works for mode \"1\" images.\n\n        :param name: The name prefix to use for the bitmap variables.\n        :returns: A string containing an X11 bitmap.\n        :raises ValueError: If the mode is not \"1\"\n        \"\"\"\n\n        self.load()\n        if self.mode != \"1\":\n            msg = \"not a bitmap\"\n            raise ValueError(msg)\n        data = self.tobytes(\"xbm\")\n        return b\"\".join(\n            [\n                f\"#define {name}_width {self.size[0]}\\n\".encode(\"ascii\"),\n                f\"#define {name}_height {self.size[1]}\\n\".encode(\"ascii\"),\n                f\"static char {name}_bits[] = {{\\n\".encode(\"ascii\"),\n                data,\n                b\"};\",\n            ]\n        )\n\n    def frombytes(self, data, decoder_name=\"raw\", *args):\n        \"\"\"\n        Loads this image with pixel data from a bytes object.\n\n        This method is similar to the :py:func:`~PIL.Image.frombytes` function,\n        but loads data into this image instead of creating a new image object.\n        \"\"\"\n\n        if self.width == 0 or self.height == 0:\n            return\n\n        # may pass tuple instead of argument list\n        if len(args) == 1 and isinstance(args[0], tuple):\n            args = args[0]\n\n        # default format\n        if decoder_name == \"raw\" and args == ():\n            args = self.mode\n\n        # unpack data\n        d = _getdecoder(self.mode, decoder_name, args)\n        d.setimage(self.im)\n        s = d.decode(data)\n\n        if s[0] >= 0:\n            msg = \"not enough image data\"\n            raise ValueError(msg)\n        if s[1] != 0:\n            msg = \"cannot decode image data\"\n            raise ValueError(msg)\n\n    def load(self):\n        \"\"\"\n        Allocates storage for the image and loads the pixel data.  In\n        normal cases, you don't need to call this method, since the\n        Image class automatically loads an opened image when it is\n        accessed for the first time.\n\n        If the file associated with the image was opened by Pillow, then this\n        method will close it. The exception to this is if the image has\n        multiple frames, in which case the file will be left open for seek\n        operations. See :ref:`file-handling` for more information.\n\n        :returns: An image access object.\n        :rtype: :ref:`PixelAccess` or :py:class:`PIL.PyAccess`\n        \"\"\"\n        if self.im is not None and self.palette and self.palette.dirty:\n            # realize palette\n            mode, arr = self.palette.getdata()\n            self.im.putpalette(mode, arr)\n            self.palette.dirty = 0\n            self.palette.rawmode = None\n            if \"transparency\" in self.info and mode in (\"LA\", \"PA\"):\n                if isinstance(self.info[\"transparency\"], int):\n                    self.im.putpalettealpha(self.info[\"transparency\"], 0)\n                else:\n                    self.im.putpalettealphas(self.info[\"transparency\"])\n                self.palette.mode = \"RGBA\"\n            else:\n                palette_mode = \"RGBA\" if mode.startswith(\"RGBA\") else \"RGB\"\n                self.palette.mode = palette_mode\n                self.palette.palette = self.im.getpalette(palette_mode, palette_mode)\n\n        if self.im is not None:\n            if cffi and USE_CFFI_ACCESS:\n                if self.pyaccess:\n                    return self.pyaccess\n                from . import PyAccess\n\n                self.pyaccess = PyAccess.new(self, self.readonly)\n                if self.pyaccess:\n                    return self.pyaccess\n            return self.im.pixel_access(self.readonly)\n\n    def verify(self):\n        \"\"\"\n        Verifies the contents of a file. For data read from a file, this\n        method attempts to determine if the file is broken, without\n        actually decoding the image data.  If this method finds any\n        problems, it raises suitable exceptions.  If you need to load\n        the image after using this method, you must reopen the image\n        file.\n        \"\"\"\n        pass\n\n    def convert(\n        self, mode=None, matrix=None, dither=None, palette=Palette.WEB, colors=256\n    ):\n        \"\"\"\n        Returns a converted copy of this image. For the \"P\" mode, this\n        method translates pixels through the palette.  If mode is\n        omitted, a mode is chosen so that all information in the image\n        and the palette can be represented without a palette.\n\n        The current version supports all possible conversions between\n        \"L\", \"RGB\" and \"CMYK\". The ``matrix`` argument only supports \"L\"\n        and \"RGB\".\n\n        When translating a color image to grayscale (mode \"L\"),\n        the library uses the ITU-R 601-2 luma transform::\n\n            L = R * 299/1000 + G * 587/1000 + B * 114/1000\n\n        The default method of converting a grayscale (\"L\") or \"RGB\"\n        image into a bilevel (mode \"1\") image uses Floyd-Steinberg\n        dither to approximate the original image luminosity levels. If\n        dither is ``None``, all values larger than 127 are set to 255 (white),\n        all other values to 0 (black). To use other thresholds, use the\n        :py:meth:`~PIL.Image.Image.point` method.\n\n        When converting from \"RGBA\" to \"P\" without a ``matrix`` argument,\n        this passes the operation to :py:meth:`~PIL.Image.Image.quantize`,\n        and ``dither`` and ``palette`` are ignored.\n\n        When converting from \"PA\", if an \"RGBA\" palette is present, the alpha\n        channel from the image will be used instead of the values from the palette.\n\n        :param mode: The requested mode. See: :ref:`concept-modes`.\n        :param matrix: An optional conversion matrix.  If given, this\n           should be 4- or 12-tuple containing floating point values.\n        :param dither: Dithering method, used when converting from\n           mode \"RGB\" to \"P\" or from \"RGB\" or \"L\" to \"1\".\n           Available methods are :data:`Dither.NONE` or :data:`Dither.FLOYDSTEINBERG`\n           (default). Note that this is not used when ``matrix`` is supplied.\n        :param palette: Palette to use when converting from mode \"RGB\"\n           to \"P\".  Available palettes are :data:`Palette.WEB` or\n           :data:`Palette.ADAPTIVE`.\n        :param colors: Number of colors to use for the :data:`Palette.ADAPTIVE`\n           palette. Defaults to 256.\n        :rtype: :py:class:`~PIL.Image.Image`\n        :returns: An :py:class:`~PIL.Image.Image` object.\n        \"\"\"\n\n        self.load()\n\n        has_transparency = \"transparency\" in self.info\n        if not mode and self.mode == \"P\":\n            # determine default mode\n            if self.palette:\n                mode = self.palette.mode\n            else:\n                mode = \"RGB\"\n            if mode == \"RGB\" and has_transparency:\n                mode = \"RGBA\"\n        if not mode or (mode == self.mode and not matrix):\n            return self.copy()\n\n        if matrix:\n            # matrix conversion\n            if mode not in (\"L\", \"RGB\"):\n                msg = \"illegal conversion\"\n                raise ValueError(msg)\n            im = self.im.convert_matrix(mode, matrix)\n            new_im = self._new(im)\n            if has_transparency and self.im.bands == 3:\n                transparency = new_im.info[\"transparency\"]\n\n                def convert_transparency(m, v):\n                    v = m[0] * v[0] + m[1] * v[1] + m[2] * v[2] + m[3] * 0.5\n                    return max(0, min(255, int(v)))\n\n                if mode == \"L\":\n                    transparency = convert_transparency(matrix, transparency)\n                elif len(mode) == 3:\n                    transparency = tuple(\n                        convert_transparency(matrix[i * 4 : i * 4 + 4], transparency)\n                        for i in range(0, len(transparency))\n                    )\n                new_im.info[\"transparency\"] = transparency\n            return new_im\n\n        if mode == \"P\" and self.mode == \"RGBA\":\n            return self.quantize(colors)\n\n        trns = None\n        delete_trns = False\n        # transparency handling\n        if has_transparency:\n            if (self.mode in (\"1\", \"L\", \"I\") and mode in (\"LA\", \"RGBA\")) or (\n                self.mode == \"RGB\" and mode == \"RGBA\"\n            ):\n                # Use transparent conversion to promote from transparent\n                # color to an alpha channel.\n                new_im = self._new(\n                    self.im.convert_transparent(mode, self.info[\"transparency\"])\n                )\n                del new_im.info[\"transparency\"]\n                return new_im\n            elif self.mode in (\"L\", \"RGB\", \"P\") and mode in (\"L\", \"RGB\", \"P\"):\n                t = self.info[\"transparency\"]\n                if isinstance(t, bytes):\n                    # Dragons. This can't be represented by a single color\n                    warnings.warn(\n                        \"Palette images with Transparency expressed in bytes should be \"\n                        \"converted to RGBA images\"\n                    )\n                    delete_trns = True\n                else:\n                    # get the new transparency color.\n                    # use existing conversions\n                    trns_im = new(self.mode, (1, 1))\n                    if self.mode == \"P\":\n                        trns_im.putpalette(self.palette)\n                        if isinstance(t, tuple):\n                            err = \"Couldn't allocate a palette color for transparency\"\n                            try:\n                                t = trns_im.palette.getcolor(t, self)\n                            except ValueError as e:\n                                if str(e) == \"cannot allocate more than 256 colors\":\n                                    # If all 256 colors are in use,\n                                    # then there is no need for transparency\n                                    t = None\n                                else:\n                                    raise ValueError(err) from e\n                    if t is None:\n                        trns = None\n                    else:\n                        trns_im.putpixel((0, 0), t)\n\n                        if mode in (\"L\", \"RGB\"):\n                            trns_im = trns_im.convert(mode)\n                        else:\n                            # can't just retrieve the palette number, got to do it\n                            # after quantization.\n                            trns_im = trns_im.convert(\"RGB\")\n                        trns = trns_im.getpixel((0, 0))\n\n            elif self.mode == \"P\" and mode in (\"LA\", \"PA\", \"RGBA\"):\n                t = self.info[\"transparency\"]\n                delete_trns = True\n\n                if isinstance(t, bytes):\n                    self.im.putpalettealphas(t)\n                elif isinstance(t, int):\n                    self.im.putpalettealpha(t, 0)\n                else:\n                    msg = \"Transparency for P mode should be bytes or int\"\n                    raise ValueError(msg)\n\n        if mode == \"P\" and palette == Palette.ADAPTIVE:\n            im = self.im.quantize(colors)\n            new_im = self._new(im)\n            from . import ImagePalette\n\n            new_im.palette = ImagePalette.ImagePalette(\n                \"RGB\", new_im.im.getpalette(\"RGB\")\n            )\n            if delete_trns:\n                # This could possibly happen if we requantize to fewer colors.\n                # The transparency would be totally off in that case.\n                del new_im.info[\"transparency\"]\n            if trns is not None:\n                try:\n                    new_im.info[\"transparency\"] = new_im.palette.getcolor(trns, new_im)\n                except Exception:\n                    # if we can't make a transparent color, don't leave the old\n                    # transparency hanging around to mess us up.\n                    del new_im.info[\"transparency\"]\n                    warnings.warn(\"Couldn't allocate palette entry for transparency\")\n            return new_im\n\n        if \"LAB\" in (self.mode, mode):\n            other_mode = mode if self.mode == \"LAB\" else self.mode\n            if other_mode in (\"RGB\", \"RGBA\", \"RGBX\"):\n                from . import ImageCms\n\n                srgb = ImageCms.createProfile(\"sRGB\")\n                lab = ImageCms.createProfile(\"LAB\")\n                profiles = [lab, srgb] if self.mode == \"LAB\" else [srgb, lab]\n                transform = ImageCms.buildTransform(\n                    profiles[0], profiles[1], self.mode, mode\n                )\n                return transform.apply(self)\n\n        # colorspace conversion\n        if dither is None:\n            dither = Dither.FLOYDSTEINBERG\n\n        try:\n            im = self.im.convert(mode, dither)\n        except ValueError:\n            try:\n                # normalize source image and try again\n                modebase = getmodebase(self.mode)\n                if modebase == self.mode:\n                    raise\n                im = self.im.convert(modebase)\n                im = im.convert(mode, dither)\n            except KeyError as e:\n                msg = \"illegal conversion\"\n                raise ValueError(msg) from e\n\n        new_im = self._new(im)\n        if mode == \"P\" and palette != Palette.ADAPTIVE:\n            from . import ImagePalette\n\n            new_im.palette = ImagePalette.ImagePalette(\"RGB\", im.getpalette(\"RGB\"))\n        if delete_trns:\n            # crash fail if we leave a bytes transparency in an rgb/l mode.\n            del new_im.info[\"transparency\"]\n        if trns is not None:\n            if new_im.mode == \"P\":\n                try:\n                    new_im.info[\"transparency\"] = new_im.palette.getcolor(trns, new_im)\n                except ValueError as e:\n                    del new_im.info[\"transparency\"]\n                    if str(e) != \"cannot allocate more than 256 colors\":\n                        # If all 256 colors are in use,\n                        # then there is no need for transparency\n                        warnings.warn(\n                            \"Couldn't allocate palette entry for transparency\"\n                        )\n            else:\n                new_im.info[\"transparency\"] = trns\n        return new_im\n\n    def quantize(\n        self,\n        colors=256,\n        method=None,\n        kmeans=0,\n        palette=None,\n        dither=Dither.FLOYDSTEINBERG,\n    ):\n        \"\"\"\n        Convert the image to 'P' mode with the specified number\n        of colors.\n\n        :param colors: The desired number of colors, <= 256\n        :param method: :data:`Quantize.MEDIANCUT` (median cut),\n                       :data:`Quantize.MAXCOVERAGE` (maximum coverage),\n                       :data:`Quantize.FASTOCTREE` (fast octree),\n                       :data:`Quantize.LIBIMAGEQUANT` (libimagequant; check support\n                       using :py:func:`PIL.features.check_feature` with\n                       ``feature=\"libimagequant\"``).\n\n                       By default, :data:`Quantize.MEDIANCUT` will be used.\n\n                       The exception to this is RGBA images. :data:`Quantize.MEDIANCUT`\n                       and :data:`Quantize.MAXCOVERAGE` do not support RGBA images, so\n                       :data:`Quantize.FASTOCTREE` is used by default instead.\n        :param kmeans: Integer\n        :param palette: Quantize to the palette of given\n                        :py:class:`PIL.Image.Image`.\n        :param dither: Dithering method, used when converting from\n           mode \"RGB\" to \"P\" or from \"RGB\" or \"L\" to \"1\".\n           Available methods are :data:`Dither.NONE` or :data:`Dither.FLOYDSTEINBERG`\n           (default).\n        :returns: A new image\n        \"\"\"\n\n        self.load()\n\n        if method is None:\n            # defaults:\n            method = Quantize.MEDIANCUT\n            if self.mode == \"RGBA\":\n                method = Quantize.FASTOCTREE\n\n        if self.mode == \"RGBA\" and method not in (\n            Quantize.FASTOCTREE,\n            Quantize.LIBIMAGEQUANT,\n        ):\n            # Caller specified an invalid mode.\n            msg = (\n                \"Fast Octree (method == 2) and libimagequant (method == 3) \"\n                \"are the only valid methods for quantizing RGBA images\"\n            )\n            raise ValueError(msg)\n\n        if palette:\n            # use palette from reference image\n            palette.load()\n            if palette.mode != \"P\":\n                msg = \"bad mode for palette image\"\n                raise ValueError(msg)\n            if self.mode not in {\"RGB\", \"L\"}:\n                msg = \"only RGB or L mode images can be quantized to a palette\"\n                raise ValueError(msg)\n            im = self.im.convert(\"P\", dither, palette.im)\n            new_im = self._new(im)\n            new_im.palette = palette.palette.copy()\n            return new_im\n\n        im = self._new(self.im.quantize(colors, method, kmeans))\n\n        from . import ImagePalette\n\n        mode = im.im.getpalettemode()\n        palette = im.im.getpalette(mode, mode)[: colors * len(mode)]\n        im.palette = ImagePalette.ImagePalette(mode, palette)\n\n        return im\n\n    def copy(self) -> Image:\n        \"\"\"\n        Copies this image. Use this method if you wish to paste things\n        into an image, but still retain the original.\n\n        :rtype: :py:class:`~PIL.Image.Image`\n        :returns: An :py:class:`~PIL.Image.Image` object.\n        \"\"\"\n        self.load()\n        return self._new(self.im.copy())\n\n    __copy__ = copy\n\n    def crop(self, box=None) -> Image:\n        \"\"\"\n        Returns a rectangular region from this image. The box is a\n        4-tuple defining the left, upper, right, and lower pixel\n        coordinate. See :ref:`coordinate-system`.\n\n        Note: Prior to Pillow 3.4.0, this was a lazy operation.\n\n        :param box: The crop rectangle, as a (left, upper, right, lower)-tuple.\n        :rtype: :py:class:`~PIL.Image.Image`\n        :returns: An :py:class:`~PIL.Image.Image` object.\n        \"\"\"\n\n        if box is None:\n            return self.copy()\n\n        if box[2] < box[0]:\n            msg = \"Coordinate 'right' is less than 'left'\"\n            raise ValueError(msg)\n        elif box[3] < box[1]:\n            msg = \"Coordinate 'lower' is less than 'upper'\"\n            raise ValueError(msg)\n\n        self.load()\n        return self._new(self._crop(self.im, box))\n\n    def _crop(self, im, box):\n        \"\"\"\n        Returns a rectangular region from the core image object im.\n\n        This is equivalent to calling im.crop((x0, y0, x1, y1)), but\n        includes additional sanity checks.\n\n        :param im: a core image object\n        :param box: The crop rectangle, as a (left, upper, right, lower)-tuple.\n        :returns: A core image object.\n        \"\"\"\n\n        x0, y0, x1, y1 = map(int, map(round, box))\n\n        absolute_values = (abs(x1 - x0), abs(y1 - y0))\n\n        _decompression_bomb_check(absolute_values)\n\n        return im.crop((x0, y0, x1, y1))\n\n    def draft(self, mode, size):\n        \"\"\"\n        Configures the image file loader so it returns a version of the\n        image that as closely as possible matches the given mode and\n        size. For example, you can use this method to convert a color\n        JPEG to grayscale while loading it.\n\n        If any changes are made, returns a tuple with the chosen ``mode`` and\n        ``box`` with coordinates of the original image within the altered one.\n\n        Note that this method modifies the :py:class:`~PIL.Image.Image` object\n        in place. If the image has already been loaded, this method has no\n        effect.\n\n        Note: This method is not implemented for most images. It is\n        currently implemented only for JPEG and MPO images.\n\n        :param mode: The requested mode.\n        :param size: The requested size in pixels, as a 2-tuple:\n           (width, height).\n        \"\"\"\n        pass\n\n    def _expand(self, xmargin, ymargin=None):\n        if ymargin is None:\n            ymargin = xmargin\n        self.load()\n        return self._new(self.im.expand(xmargin, ymargin))\n\n    def filter(self, filter):\n        \"\"\"\n        Filters this image using the given filter.  For a list of\n        available filters, see the :py:mod:`~PIL.ImageFilter` module.\n\n        :param filter: Filter kernel.\n        :returns: An :py:class:`~PIL.Image.Image` object.\"\"\"\n\n        from . import ImageFilter\n\n        self.load()\n\n        if isinstance(filter, Callable):\n            filter = filter()\n        if not hasattr(filter, \"filter\"):\n            msg = \"filter argument should be ImageFilter.Filter instance or class\"\n            raise TypeError(msg)\n\n        multiband = isinstance(filter, ImageFilter.MultibandFilter)\n        if self.im.bands == 1 or multiband:\n            return self._new(filter.filter(self.im))\n\n        ims = [\n            self._new(filter.filter(self.im.getband(c))) for c in range(self.im.bands)\n        ]\n        return merge(self.mode, ims)\n\n    def getbands(self):\n        \"\"\"\n        Returns a tuple containing the name of each band in this image.\n        For example, ``getbands`` on an RGB image returns (\"R\", \"G\", \"B\").\n\n        :returns: A tuple containing band names.\n        :rtype: tuple\n        \"\"\"\n        return ImageMode.getmode(self.mode).bands\n\n    def getbbox(self, *, alpha_only=True):\n        \"\"\"\n        Calculates the bounding box of the non-zero regions in the\n        image.\n\n        :param alpha_only: Optional flag, defaulting to ``True``.\n           If ``True`` and the image has an alpha channel, trim transparent pixels.\n           Otherwise, trim pixels when all channels are zero.\n           Keyword-only argument.\n        :returns: The bounding box is returned as a 4-tuple defining the\n           left, upper, right, and lower pixel coordinate. See\n           :ref:`coordinate-system`. If the image is completely empty, this\n           method returns None.\n\n        \"\"\"\n\n        self.load()\n        return self.im.getbbox(alpha_only)\n\n    def getcolors(self, maxcolors=256):\n        \"\"\"\n        Returns a list of colors used in this image.\n\n        The colors will be in the image's mode. For example, an RGB image will\n        return a tuple of (red, green, blue) color values, and a P image will\n        return the index of the color in the palette.\n\n        :param maxcolors: Maximum number of colors.  If this number is\n           exceeded, this method returns None.  The default limit is\n           256 colors.\n        :returns: An unsorted list of (count, pixel) values.\n        \"\"\"\n\n        self.load()\n        if self.mode in (\"1\", \"L\", \"P\"):\n            h = self.im.histogram()\n            out = [(h[i], i) for i in range(256) if h[i]]\n            if len(out) > maxcolors:\n                return None\n            return out\n        return self.im.getcolors(maxcolors)\n\n    def getdata(self, band=None):\n        \"\"\"\n        Returns the contents of this image as a sequence object\n        containing pixel values.  The sequence object is flattened, so\n        that values for line one follow directly after the values of\n        line zero, and so on.\n\n        Note that the sequence object returned by this method is an\n        internal PIL data type, which only supports certain sequence\n        operations.  To convert it to an ordinary sequence (e.g. for\n        printing), use ``list(im.getdata())``.\n\n        :param band: What band to return.  The default is to return\n           all bands.  To return a single band, pass in the index\n           value (e.g. 0 to get the \"R\" band from an \"RGB\" image).\n        :returns: A sequence-like object.\n        \"\"\"\n\n        self.load()\n        if band is not None:\n            return self.im.getband(band)\n        return self.im  # could be abused\n\n    def getextrema(self):\n        \"\"\"\n        Gets the minimum and maximum pixel values for each band in\n        the image.\n\n        :returns: For a single-band image, a 2-tuple containing the\n           minimum and maximum pixel value.  For a multi-band image,\n           a tuple containing one 2-tuple for each band.\n        \"\"\"\n\n        self.load()\n        if self.im.bands > 1:\n            return tuple(self.im.getband(i).getextrema() for i in range(self.im.bands))\n        return self.im.getextrema()\n\n    def _getxmp(self, xmp_tags):\n        def get_name(tag):\n            return re.sub(\"^{[^}]+}\", \"\", tag)\n\n        def get_value(element):\n            value = {get_name(k): v for k, v in element.attrib.items()}\n            children = list(element)\n            if children:\n                for child in children:\n                    name = get_name(child.tag)\n                    child_value = get_value(child)\n                    if name in value:\n                        if not isinstance(value[name], list):\n                            value[name] = [value[name]]\n                        value[name].append(child_value)\n                    else:\n                        value[name] = child_value\n            elif value:\n                if element.text:\n                    value[\"text\"] = element.text\n            else:\n                return element.text\n            return value\n\n        if ElementTree is None:\n            warnings.warn(\"XMP data cannot be read without defusedxml dependency\")\n            return {}\n        else:\n            root = ElementTree.fromstring(xmp_tags)\n            return {get_name(root.tag): get_value(root)}\n\n    def getexif(self):\n        \"\"\"\n        Gets EXIF data from the image.\n\n        :returns: an :py:class:`~PIL.Image.Exif` object.\n        \"\"\"\n        if self._exif is None:\n            self._exif = Exif()\n            self._exif._loaded = False\n        elif self._exif._loaded:\n            return self._exif\n        self._exif._loaded = True\n\n        exif_info = self.info.get(\"exif\")\n        if exif_info is None:\n            if \"Raw profile type exif\" in self.info:\n                exif_info = bytes.fromhex(\n                    \"\".join(self.info[\"Raw profile type exif\"].split(\"\\n\")[3:])\n                )\n            elif hasattr(self, \"tag_v2\"):\n                self._exif.bigtiff = self.tag_v2._bigtiff\n                self._exif.endian = self.tag_v2._endian\n                self._exif.load_from_fp(self.fp, self.tag_v2._offset)\n        if exif_info is not None:\n            self._exif.load(exif_info)\n\n        # XMP tags\n        if ExifTags.Base.Orientation not in self._exif:\n            xmp_tags = self.info.get(\"XML:com.adobe.xmp\")\n            if xmp_tags:\n                match = re.search(r'tiff:Orientation(=\"|>)([0-9])', xmp_tags)\n                if match:\n                    self._exif[ExifTags.Base.Orientation] = int(match[2])\n\n        return self._exif\n\n    def _reload_exif(self):\n        if self._exif is None or not self._exif._loaded:\n            return\n        self._exif._loaded = False\n        self.getexif()\n\n    def get_child_images(self):\n        child_images = []\n        exif = self.getexif()\n        ifds = []\n        if ExifTags.Base.SubIFDs in exif:\n            subifd_offsets = exif[ExifTags.Base.SubIFDs]\n            if subifd_offsets:\n                if not isinstance(subifd_offsets, tuple):\n                    subifd_offsets = (subifd_offsets,)\n                for subifd_offset in subifd_offsets:\n                    ifds.append((exif._get_ifd_dict(subifd_offset), subifd_offset))\n        ifd1 = exif.get_ifd(ExifTags.IFD.IFD1)\n        if ifd1 and ifd1.get(513):\n            ifds.append((ifd1, exif._info.next))\n\n        offset = None\n        for ifd, ifd_offset in ifds:\n            current_offset = self.fp.tell()\n            if offset is None:\n                offset = current_offset\n\n            fp = self.fp\n            thumbnail_offset = ifd.get(513)\n            if thumbnail_offset is not None:\n                try:\n                    thumbnail_offset += self._exif_offset\n                except AttributeError:\n                    pass\n                self.fp.seek(thumbnail_offset)\n                data = self.fp.read(ifd.get(514))\n                fp = io.BytesIO(data)\n\n            with open(fp) as im:\n                if thumbnail_offset is None:\n                    im._frame_pos = [ifd_offset]\n                    im._seek(0)\n                im.load()\n                child_images.append(im)\n\n        if offset is not None:\n            self.fp.seek(offset)\n        return child_images\n\n    def getim(self):\n        \"\"\"\n        Returns a capsule that points to the internal image memory.\n\n        :returns: A capsule object.\n        \"\"\"\n\n        self.load()\n        return self.im.ptr\n\n    def getpalette(self, rawmode=\"RGB\"):\n        \"\"\"\n        Returns the image palette as a list.\n\n        :param rawmode: The mode in which to return the palette. ``None`` will\n           return the palette in its current mode.\n\n           .. versionadded:: 9.1.0\n\n        :returns: A list of color values [r, g, b, ...], or None if the\n           image has no palette.\n        \"\"\"\n\n        self.load()\n        try:\n            mode = self.im.getpalettemode()\n        except ValueError:\n            return None  # no palette\n        if rawmode is None:\n            rawmode = mode\n        return list(self.im.getpalette(mode, rawmode))\n\n    @property\n    def has_transparency_data(self) -> bool:\n        \"\"\"\n        Determine if an image has transparency data, whether in the form of an\n        alpha channel, a palette with an alpha channel, or a \"transparency\" key\n        in the info dictionary.\n\n        Note the image might still appear solid, if all of the values shown\n        within are opaque.\n\n        :returns: A boolean.\n        \"\"\"\n        return (\n            self.mode in (\"LA\", \"La\", \"PA\", \"RGBA\", \"RGBa\")\n            or (self.mode == \"P\" and self.palette.mode.endswith(\"A\"))\n            or \"transparency\" in self.info\n        )\n\n    def apply_transparency(self):\n        \"\"\"\n        If a P mode image has a \"transparency\" key in the info dictionary,\n        remove the key and instead apply the transparency to the palette.\n        Otherwise, the image is unchanged.\n        \"\"\"\n        if self.mode != \"P\" or \"transparency\" not in self.info:\n            return\n\n        from . import ImagePalette\n\n        palette = self.getpalette(\"RGBA\")\n        transparency = self.info[\"transparency\"]\n        if isinstance(transparency, bytes):\n            for i, alpha in enumerate(transparency):\n                palette[i * 4 + 3] = alpha\n        else:\n            palette[transparency * 4 + 3] = 0\n        self.palette = ImagePalette.ImagePalette(\"RGBA\", bytes(palette))\n        self.palette.dirty = 1\n\n        del self.info[\"transparency\"]\n\n    def getpixel(self, xy):\n        \"\"\"\n        Returns the pixel value at a given position.\n\n        :param xy: The coordinate, given as (x, y). See\n           :ref:`coordinate-system`.\n        :returns: The pixel value.  If the image is a multi-layer image,\n           this method returns a tuple.\n        \"\"\"\n\n        self.load()\n        if self.pyaccess:\n            return self.pyaccess.getpixel(xy)\n        return self.im.getpixel(tuple(xy))\n\n    def getprojection(self):\n        \"\"\"\n        Get projection to x and y axes\n\n        :returns: Two sequences, indicating where there are non-zero\n            pixels along the X-axis and the Y-axis, respectively.\n        \"\"\"\n\n        self.load()\n        x, y = self.im.getprojection()\n        return list(x), list(y)\n\n    def histogram(self, mask=None, extrema=None):\n        \"\"\"\n        Returns a histogram for the image. The histogram is returned as a\n        list of pixel counts, one for each pixel value in the source\n        image. Counts are grouped into 256 bins for each band, even if\n        the image has more than 8 bits per band. If the image has more\n        than one band, the histograms for all bands are concatenated (for\n        example, the histogram for an \"RGB\" image contains 768 values).\n\n        A bilevel image (mode \"1\") is treated as a grayscale (\"L\") image\n        by this method.\n\n        If a mask is provided, the method returns a histogram for those\n        parts of the image where the mask image is non-zero. The mask\n        image must have the same size as the image, and be either a\n        bi-level image (mode \"1\") or a grayscale image (\"L\").\n\n        :param mask: An optional mask.\n        :param extrema: An optional tuple of manually-specified extrema.\n        :returns: A list containing pixel counts.\n        \"\"\"\n        self.load()\n        if mask:\n            mask.load()\n            return self.im.histogram((0, 0), mask.im)\n        if self.mode in (\"I\", \"F\"):\n            if extrema is None:\n                extrema = self.getextrema()\n            return self.im.histogram(extrema)\n        return self.im.histogram()\n\n    def entropy(self, mask=None, extrema=None):\n        \"\"\"\n        Calculates and returns the entropy for the image.\n\n        A bilevel image (mode \"1\") is treated as a grayscale (\"L\")\n        image by this method.\n\n        If a mask is provided, the method employs the histogram for\n        those parts of the image where the mask image is non-zero.\n        The mask image must have the same size as the image, and be\n        either a bi-level image (mode \"1\") or a grayscale image (\"L\").\n\n        :param mask: An optional mask.\n        :param extrema: An optional tuple of manually-specified extrema.\n        :returns: A float value representing the image entropy\n        \"\"\"\n        self.load()\n        if mask:\n            mask.load()\n            return self.im.entropy((0, 0), mask.im)\n        if self.mode in (\"I\", \"F\"):\n            if extrema is None:\n                extrema = self.getextrema()\n            return self.im.entropy(extrema)\n        return self.im.entropy()\n\n    def paste(self, im, box=None, mask=None) -> None:\n        \"\"\"\n        Pastes another image into this image. The box argument is either\n        a 2-tuple giving the upper left corner, a 4-tuple defining the\n        left, upper, right, and lower pixel coordinate, or None (same as\n        (0, 0)). See :ref:`coordinate-system`. If a 4-tuple is given, the size\n        of the pasted image must match the size of the region.\n\n        If the modes don't match, the pasted image is converted to the mode of\n        this image (see the :py:meth:`~PIL.Image.Image.convert` method for\n        details).\n\n        Instead of an image, the source can be a integer or tuple\n        containing pixel values.  The method then fills the region\n        with the given color.  When creating RGB images, you can\n        also use color strings as supported by the ImageColor module.\n\n        If a mask is given, this method updates only the regions\n        indicated by the mask. You can use either \"1\", \"L\", \"LA\", \"RGBA\"\n        or \"RGBa\" images (if present, the alpha band is used as mask).\n        Where the mask is 255, the given image is copied as is.  Where\n        the mask is 0, the current value is preserved.  Intermediate\n        values will mix the two images together, including their alpha\n        channels if they have them.\n\n        See :py:meth:`~PIL.Image.Image.alpha_composite` if you want to\n        combine images with respect to their alpha channels.\n\n        :param im: Source image or pixel value (integer or tuple).\n        :param box: An optional 4-tuple giving the region to paste into.\n           If a 2-tuple is used instead, it's treated as the upper left\n           corner.  If omitted or None, the source is pasted into the\n           upper left corner.\n\n           If an image is given as the second argument and there is no\n           third, the box defaults to (0, 0), and the second argument\n           is interpreted as a mask image.\n        :param mask: An optional mask image.\n        \"\"\"\n\n        if isImageType(box) and mask is None:\n            # abbreviated paste(im, mask) syntax\n            mask = box\n            box = None\n\n        if box is None:\n            box = (0, 0)\n\n        if len(box) == 2:\n            # upper left corner given; get size from image or mask\n            if isImageType(im):\n                size = im.size\n            elif isImageType(mask):\n                size = mask.size\n            else:\n                # FIXME: use self.size here?\n                msg = \"cannot determine region size; use 4-item box\"\n                raise ValueError(msg)\n            box += (box[0] + size[0], box[1] + size[1])\n\n        if isinstance(im, str):\n            from . import ImageColor\n\n            im = ImageColor.getcolor(im, self.mode)\n\n        elif isImageType(im):\n            im.load()\n            if self.mode != im.mode:\n                if self.mode != \"RGB\" or im.mode not in (\"LA\", \"RGBA\", \"RGBa\"):\n                    # should use an adapter for this!\n                    im = im.convert(self.mode)\n            im = im.im\n\n        self._ensure_mutable()\n\n        if mask:\n            mask.load()\n            self.im.paste(im, box, mask.im)\n        else:\n            self.im.paste(im, box)\n\n    def alpha_composite(self, im, dest=(0, 0), source=(0, 0)):\n        \"\"\"'In-place' analog of Image.alpha_composite. Composites an image\n        onto this image.\n\n        :param im: image to composite over this one\n        :param dest: Optional 2 tuple (left, top) specifying the upper\n          left corner in this (destination) image.\n        :param source: Optional 2 (left, top) tuple for the upper left\n          corner in the overlay source image, or 4 tuple (left, top, right,\n          bottom) for the bounds of the source rectangle\n\n        Performance Note: Not currently implemented in-place in the core layer.\n        \"\"\"\n\n        if not isinstance(source, (list, tuple)):\n            msg = \"Source must be a tuple\"\n            raise ValueError(msg)\n        if not isinstance(dest, (list, tuple)):\n            msg = \"Destination must be a tuple\"\n            raise ValueError(msg)\n        if len(source) not in (2, 4):\n            msg = \"Source must be a 2 or 4-tuple\"\n            raise ValueError(msg)\n        if not len(dest) == 2:\n            msg = \"Destination must be a 2-tuple\"\n            raise ValueError(msg)\n        if min(source) < 0:\n            msg = \"Source must be non-negative\"\n            raise ValueError(msg)\n\n        if len(source) == 2:\n            source = source + im.size\n\n        # over image, crop if it's not the whole thing.\n        if source == (0, 0) + im.size:\n            overlay = im\n        else:\n            overlay = im.crop(source)\n\n        # target for the paste\n        box = dest + (dest[0] + overlay.width, dest[1] + overlay.height)\n\n        # destination image. don't copy if we're using the whole image.\n        if box == (0, 0) + self.size:\n            background = self\n        else:\n            background = self.crop(box)\n\n        result = alpha_composite(background, overlay)\n        self.paste(result, box)\n\n    def point(self, lut, mode=None):\n        \"\"\"\n        Maps this image through a lookup table or function.\n\n        :param lut: A lookup table, containing 256 (or 65536 if\n           self.mode==\"I\" and mode == \"L\") values per band in the\n           image.  A function can be used instead, it should take a\n           single argument. The function is called once for each\n           possible pixel value, and the resulting table is applied to\n           all bands of the image.\n\n           It may also be an :py:class:`~PIL.Image.ImagePointHandler`\n           object::\n\n               class Example(Image.ImagePointHandler):\n                 def point(self, data):\n                   # Return result\n        :param mode: Output mode (default is same as input).  In the\n           current version, this can only be used if the source image\n           has mode \"L\" or \"P\", and the output has mode \"1\" or the\n           source image mode is \"I\" and the output mode is \"L\".\n        :returns: An :py:class:`~PIL.Image.Image` object.\n        \"\"\"\n\n        self.load()\n\n        if isinstance(lut, ImagePointHandler):\n            return lut.point(self)\n\n        if callable(lut):\n            # if it isn't a list, it should be a function\n            if self.mode in (\"I\", \"I;16\", \"F\"):\n                # check if the function can be used with point_transform\n                # UNDONE wiredfool -- I think this prevents us from ever doing\n                # a gamma function point transform on > 8bit images.\n                scale, offset = _getscaleoffset(lut)\n                return self._new(self.im.point_transform(scale, offset))\n            # for other modes, convert the function to a table\n            lut = [lut(i) for i in range(256)] * self.im.bands\n\n        if self.mode == \"F\":\n            # FIXME: _imaging returns a confusing error message for this case\n            msg = \"point operation not supported for this mode\"\n            raise ValueError(msg)\n\n        if mode != \"F\":\n            lut = [round(i) for i in lut]\n        return self._new(self.im.point(lut, mode))\n\n    def putalpha(self, alpha):\n        \"\"\"\n        Adds or replaces the alpha layer in this image.  If the image\n        does not have an alpha layer, it's converted to \"LA\" or \"RGBA\".\n        The new layer must be either \"L\" or \"1\".\n\n        :param alpha: The new alpha layer.  This can either be an \"L\" or \"1\"\n           image having the same size as this image, or an integer or\n           other color value.\n        \"\"\"\n\n        self._ensure_mutable()\n\n        if self.mode not in (\"LA\", \"PA\", \"RGBA\"):\n            # attempt to promote self to a matching alpha mode\n            try:\n                mode = getmodebase(self.mode) + \"A\"\n                try:\n                    self.im.setmode(mode)\n                except (AttributeError, ValueError) as e:\n                    # do things the hard way\n                    im = self.im.convert(mode)\n                    if im.mode not in (\"LA\", \"PA\", \"RGBA\"):\n                        msg = \"alpha channel could not be added\"\n                        raise ValueError(msg) from e  # sanity check\n                    self.im = im\n                self.pyaccess = None\n                self._mode = self.im.mode\n            except KeyError as e:\n                msg = \"illegal image mode\"\n                raise ValueError(msg) from e\n\n        if self.mode in (\"LA\", \"PA\"):\n            band = 1\n        else:\n            band = 3\n\n        if isImageType(alpha):\n            # alpha layer\n            if alpha.mode not in (\"1\", \"L\"):\n                msg = \"illegal image mode\"\n                raise ValueError(msg)\n            alpha.load()\n            if alpha.mode == \"1\":\n                alpha = alpha.convert(\"L\")\n        else:\n            # constant alpha\n            try:\n                self.im.fillband(band, alpha)\n            except (AttributeError, ValueError):\n                # do things the hard way\n                alpha = new(\"L\", self.size, alpha)\n            else:\n                return\n\n        self.im.putband(alpha.im, band)\n\n    def putdata(self, data, scale=1.0, offset=0.0):\n        \"\"\"\n        Copies pixel data from a flattened sequence object into the image. The\n        values should start at the upper left corner (0, 0), continue to the\n        end of the line, followed directly by the first value of the second\n        line, and so on. Data will be read until either the image or the\n        sequence ends. The scale and offset values are used to adjust the\n        sequence values: **pixel = value*scale + offset**.\n\n        :param data: A flattened sequence object.\n        :param scale: An optional scale value.  The default is 1.0.\n        :param offset: An optional offset value.  The default is 0.0.\n        \"\"\"\n\n        self._ensure_mutable()\n\n        self.im.putdata(data, scale, offset)\n\n    def putpalette(self, data, rawmode=\"RGB\"):\n        \"\"\"\n        Attaches a palette to this image.  The image must be a \"P\", \"PA\", \"L\"\n        or \"LA\" image.\n\n        The palette sequence must contain at most 256 colors, made up of one\n        integer value for each channel in the raw mode.\n        For example, if the raw mode is \"RGB\", then it can contain at most 768\n        values, made up of red, green and blue values for the corresponding pixel\n        index in the 256 colors.\n        If the raw mode is \"RGBA\", then it can contain at most 1024 values,\n        containing red, green, blue and alpha values.\n\n        Alternatively, an 8-bit string may be used instead of an integer sequence.\n\n        :param data: A palette sequence (either a list or a string).\n        :param rawmode: The raw mode of the palette. Either \"RGB\", \"RGBA\", or a mode\n           that can be transformed to \"RGB\" or \"RGBA\" (e.g. \"R\", \"BGR;15\", \"RGBA;L\").\n        \"\"\"\n        from . import ImagePalette\n\n        if self.mode not in (\"L\", \"LA\", \"P\", \"PA\"):\n            msg = \"illegal image mode\"\n            raise ValueError(msg)\n        if isinstance(data, ImagePalette.ImagePalette):\n            palette = ImagePalette.raw(data.rawmode, data.palette)\n        else:\n            if not isinstance(data, bytes):\n                data = bytes(data)\n            palette = ImagePalette.raw(rawmode, data)\n        self._mode = \"PA\" if \"A\" in self.mode else \"P\"\n        self.palette = palette\n        self.palette.mode = \"RGB\"\n        self.load()  # install new palette\n\n    def putpixel(self, xy, value):\n        \"\"\"\n        Modifies the pixel at the given position. The color is given as\n        a single numerical value for single-band images, and a tuple for\n        multi-band images. In addition to this, RGB and RGBA tuples are\n        accepted for P and PA images.\n\n        Note that this method is relatively slow.  For more extensive changes,\n        use :py:meth:`~PIL.Image.Image.paste` or the :py:mod:`~PIL.ImageDraw`\n        module instead.\n\n        See:\n\n        * :py:meth:`~PIL.Image.Image.paste`\n        * :py:meth:`~PIL.Image.Image.putdata`\n        * :py:mod:`~PIL.ImageDraw`\n\n        :param xy: The pixel coordinate, given as (x, y). See\n           :ref:`coordinate-system`.\n        :param value: The pixel value.\n        \"\"\"\n\n        if self.readonly:\n            self._copy()\n        self.load()\n\n        if self.pyaccess:\n            return self.pyaccess.putpixel(xy, value)\n\n        if (\n            self.mode in (\"P\", \"PA\")\n            and isinstance(value, (list, tuple))\n            and len(value) in [3, 4]\n        ):\n            # RGB or RGBA value for a P or PA image\n            if self.mode == \"PA\":\n                alpha = value[3] if len(value) == 4 else 255\n                value = value[:3]\n            value = self.palette.getcolor(value, self)\n            if self.mode == \"PA\":\n                value = (value, alpha)\n        return self.im.putpixel(xy, value)\n\n    def remap_palette(self, dest_map, source_palette=None):\n        \"\"\"\n        Rewrites the image to reorder the palette.\n\n        :param dest_map: A list of indexes into the original palette.\n           e.g. ``[1,0]`` would swap a two item palette, and ``list(range(256))``\n           is the identity transform.\n        :param source_palette: Bytes or None.\n        :returns:  An :py:class:`~PIL.Image.Image` object.\n\n        \"\"\"\n        from . import ImagePalette\n\n        if self.mode not in (\"L\", \"P\"):\n            msg = \"illegal image mode\"\n            raise ValueError(msg)\n\n        bands = 3\n        palette_mode = \"RGB\"\n        if source_palette is None:\n            if self.mode == \"P\":\n                self.load()\n                palette_mode = self.im.getpalettemode()\n                if palette_mode == \"RGBA\":\n                    bands = 4\n                source_palette = self.im.getpalette(palette_mode, palette_mode)\n            else:  # L-mode\n                source_palette = bytearray(i // 3 for i in range(768))\n\n        palette_bytes = b\"\"\n        new_positions = [0] * 256\n\n        # pick only the used colors from the palette\n        for i, oldPosition in enumerate(dest_map):\n            palette_bytes += source_palette[\n                oldPosition * bands : oldPosition * bands + bands\n            ]\n            new_positions[oldPosition] = i\n\n        # replace the palette color id of all pixel with the new id\n\n        # Palette images are [0..255], mapped through a 1 or 3\n        # byte/color map.  We need to remap the whole image\n        # from palette 1 to palette 2. New_positions is\n        # an array of indexes into palette 1.  Palette 2 is\n        # palette 1 with any holes removed.\n\n        # We're going to leverage the convert mechanism to use the\n        # C code to remap the image from palette 1 to palette 2,\n        # by forcing the source image into 'L' mode and adding a\n        # mapping 'L' mode palette, then converting back to 'L'\n        # sans palette thus converting the image bytes, then\n        # assigning the optimized RGB palette.\n\n        # perf reference, 9500x4000 gif, w/~135 colors\n        # 14 sec prepatch, 1 sec postpatch with optimization forced.\n\n        mapping_palette = bytearray(new_positions)\n\n        m_im = self.copy()\n        m_im._mode = \"P\"\n\n        m_im.palette = ImagePalette.ImagePalette(\n            palette_mode, palette=mapping_palette * bands\n        )\n        # possibly set palette dirty, then\n        # m_im.putpalette(mapping_palette, 'L')  # converts to 'P'\n        # or just force it.\n        # UNDONE -- this is part of the general issue with palettes\n        m_im.im.putpalette(palette_mode + \";L\", m_im.palette.tobytes())\n\n        m_im = m_im.convert(\"L\")\n\n        m_im.putpalette(palette_bytes, palette_mode)\n        m_im.palette = ImagePalette.ImagePalette(palette_mode, palette=palette_bytes)\n\n        if \"transparency\" in self.info:\n            try:\n                m_im.info[\"transparency\"] = dest_map.index(self.info[\"transparency\"])\n            except ValueError:\n                if \"transparency\" in m_im.info:\n                    del m_im.info[\"transparency\"]\n\n        return m_im\n\n    def _get_safe_box(self, size, resample, box):\n        \"\"\"Expands the box so it includes adjacent pixels\n        that may be used by resampling with the given resampling filter.\n        \"\"\"\n        filter_support = _filters_support[resample] - 0.5\n        scale_x = (box[2] - box[0]) / size[0]\n        scale_y = (box[3] - box[1]) / size[1]\n        support_x = filter_support * scale_x\n        support_y = filter_support * scale_y\n\n        return (\n            max(0, int(box[0] - support_x)),\n            max(0, int(box[1] - support_y)),\n            min(self.size[0], math.ceil(box[2] + support_x)),\n            min(self.size[1], math.ceil(box[3] + support_y)),\n        )\n\n    def resize(self, size, resample=None, box=None, reducing_gap=None):\n        \"\"\"\n        Returns a resized copy of this image.\n\n        :param size: The requested size in pixels, as a 2-tuple:\n           (width, height).\n        :param resample: An optional resampling filter.  This can be\n           one of :py:data:`Resampling.NEAREST`, :py:data:`Resampling.BOX`,\n           :py:data:`Resampling.BILINEAR`, :py:data:`Resampling.HAMMING`,\n           :py:data:`Resampling.BICUBIC` or :py:data:`Resampling.LANCZOS`.\n           If the image has mode \"1\" or \"P\", it is always set to\n           :py:data:`Resampling.NEAREST`. If the image mode specifies a number\n           of bits, such as \"I;16\", then the default filter is\n           :py:data:`Resampling.NEAREST`. Otherwise, the default filter is\n           :py:data:`Resampling.BICUBIC`. See: :ref:`concept-filters`.\n        :param box: An optional 4-tuple of floats providing\n           the source image region to be scaled.\n           The values must be within (0, 0, width, height) rectangle.\n           If omitted or None, the entire source is used.\n        :param reducing_gap: Apply optimization by resizing the image\n           in two steps. First, reducing the image by integer times\n           using :py:meth:`~PIL.Image.Image.reduce`.\n           Second, resizing using regular resampling. The last step\n           changes size no less than by ``reducing_gap`` times.\n           ``reducing_gap`` may be None (no first step is performed)\n           or should be greater than 1.0. The bigger ``reducing_gap``,\n           the closer the result to the fair resampling.\n           The smaller ``reducing_gap``, the faster resizing.\n           With ``reducing_gap`` greater or equal to 3.0, the result is\n           indistinguishable from fair resampling in most cases.\n           The default value is None (no optimization).\n        :returns: An :py:class:`~PIL.Image.Image` object.\n        \"\"\"\n\n        if resample is None:\n            type_special = \";\" in self.mode\n            resample = Resampling.NEAREST if type_special else Resampling.BICUBIC\n        elif resample not in (\n            Resampling.NEAREST,\n            Resampling.BILINEAR,\n            Resampling.BICUBIC,\n            Resampling.LANCZOS,\n            Resampling.BOX,\n            Resampling.HAMMING,\n        ):\n            msg = f\"Unknown resampling filter ({resample}).\"\n\n            filters = [\n                f\"{filter[1]} ({filter[0]})\"\n                for filter in (\n                    (Resampling.NEAREST, \"Image.Resampling.NEAREST\"),\n                    (Resampling.LANCZOS, \"Image.Resampling.LANCZOS\"),\n                    (Resampling.BILINEAR, \"Image.Resampling.BILINEAR\"),\n                    (Resampling.BICUBIC, \"Image.Resampling.BICUBIC\"),\n                    (Resampling.BOX, \"Image.Resampling.BOX\"),\n                    (Resampling.HAMMING, \"Image.Resampling.HAMMING\"),\n                )\n            ]\n            msg += \" Use \" + \", \".join(filters[:-1]) + \" or \" + filters[-1]\n            raise ValueError(msg)\n\n        if reducing_gap is not None and reducing_gap < 1.0:\n            msg = \"reducing_gap must be 1.0 or greater\"\n            raise ValueError(msg)\n\n        size = tuple(size)\n\n        self.load()\n        if box is None:\n            box = (0, 0) + self.size\n        else:\n            box = tuple(box)\n\n        if self.size == size and box == (0, 0) + self.size:\n            return self.copy()\n\n        if self.mode in (\"1\", \"P\"):\n            resample = Resampling.NEAREST\n\n        if self.mode in [\"LA\", \"RGBA\"] and resample != Resampling.NEAREST:\n            im = self.convert({\"LA\": \"La\", \"RGBA\": \"RGBa\"}[self.mode])\n            im = im.resize(size, resample, box)\n            return im.convert(self.mode)\n\n        self.load()\n\n        if reducing_gap is not None and resample != Resampling.NEAREST:\n            factor_x = int((box[2] - box[0]) / size[0] / reducing_gap) or 1\n            factor_y = int((box[3] - box[1]) / size[1] / reducing_gap) or 1\n            if factor_x > 1 or factor_y > 1:\n                reduce_box = self._get_safe_box(size, resample, box)\n                factor = (factor_x, factor_y)\n                if callable(self.reduce):\n                    self = self.reduce(factor, box=reduce_box)\n                else:\n                    self = Image.reduce(self, factor, box=reduce_box)\n                box = (\n                    (box[0] - reduce_box[0]) / factor_x,\n                    (box[1] - reduce_box[1]) / factor_y,\n                    (box[2] - reduce_box[0]) / factor_x,\n                    (box[3] - reduce_box[1]) / factor_y,\n                )\n\n        return self._new(self.im.resize(size, resample, box))\n\n    def reduce(self, factor, box=None):\n        \"\"\"\n        Returns a copy of the image reduced ``factor`` times.\n        If the size of the image is not dividable by ``factor``,\n        the resulting size will be rounded up.\n\n        :param factor: A greater than 0 integer or tuple of two integers\n           for width and height separately.\n        :param box: An optional 4-tuple of ints providing\n           the source image region to be reduced.\n           The values must be within ``(0, 0, width, height)`` rectangle.\n           If omitted or ``None``, the entire source is used.\n        \"\"\"\n        if not isinstance(factor, (list, tuple)):\n            factor = (factor, factor)\n\n        if box is None:\n            box = (0, 0) + self.size\n        else:\n            box = tuple(box)\n\n        if factor == (1, 1) and box == (0, 0) + self.size:\n            return self.copy()\n\n        if self.mode in [\"LA\", \"RGBA\"]:\n            im = self.convert({\"LA\": \"La\", \"RGBA\": \"RGBa\"}[self.mode])\n            im = im.reduce(factor, box)\n            return im.convert(self.mode)\n\n        self.load()\n\n        return self._new(self.im.reduce(factor, box))\n\n    def rotate(\n        self,\n        angle,\n        resample=Resampling.NEAREST,\n        expand=0,\n        center=None,\n        translate=None,\n        fillcolor=None,\n    ):\n        \"\"\"\n        Returns a rotated copy of this image.  This method returns a\n        copy of this image, rotated the given number of degrees counter\n        clockwise around its centre.\n\n        :param angle: In degrees counter clockwise.\n        :param resample: An optional resampling filter.  This can be\n           one of :py:data:`Resampling.NEAREST` (use nearest neighbour),\n           :py:data:`Resampling.BILINEAR` (linear interpolation in a 2x2\n           environment), or :py:data:`Resampling.BICUBIC` (cubic spline\n           interpolation in a 4x4 environment). If omitted, or if the image has\n           mode \"1\" or \"P\", it is set to :py:data:`Resampling.NEAREST`.\n           See :ref:`concept-filters`.\n        :param expand: Optional expansion flag.  If true, expands the output\n           image to make it large enough to hold the entire rotated image.\n           If false or omitted, make the output image the same size as the\n           input image.  Note that the expand flag assumes rotation around\n           the center and no translation.\n        :param center: Optional center of rotation (a 2-tuple).  Origin is\n           the upper left corner.  Default is the center of the image.\n        :param translate: An optional post-rotate translation (a 2-tuple).\n        :param fillcolor: An optional color for area outside the rotated image.\n        :returns: An :py:class:`~PIL.Image.Image` object.\n        \"\"\"\n\n        angle = angle % 360.0\n\n        # Fast paths regardless of filter, as long as we're not\n        # translating or changing the center.\n        if not (center or translate):\n            if angle == 0:\n                return self.copy()\n            if angle == 180:\n                return self.transpose(Transpose.ROTATE_180)\n            if angle in (90, 270) and (expand or self.width == self.height):\n                return self.transpose(\n                    Transpose.ROTATE_90 if angle == 90 else Transpose.ROTATE_270\n                )\n\n        # Calculate the affine matrix.  Note that this is the reverse\n        # transformation (from destination image to source) because we\n        # want to interpolate the (discrete) destination pixel from\n        # the local area around the (floating) source pixel.\n\n        # The matrix we actually want (note that it operates from the right):\n        # (1, 0, tx)   (1, 0, cx)   ( cos a, sin a, 0)   (1, 0, -cx)\n        # (0, 1, ty) * (0, 1, cy) * (-sin a, cos a, 0) * (0, 1, -cy)\n        # (0, 0,  1)   (0, 0,  1)   (     0,     0, 1)   (0, 0,   1)\n\n        # The reverse matrix is thus:\n        # (1, 0, cx)   ( cos -a, sin -a, 0)   (1, 0, -cx)   (1, 0, -tx)\n        # (0, 1, cy) * (-sin -a, cos -a, 0) * (0, 1, -cy) * (0, 1, -ty)\n        # (0, 0,  1)   (      0,      0, 1)   (0, 0,   1)   (0, 0,   1)\n\n        # In any case, the final translation may be updated at the end to\n        # compensate for the expand flag.\n\n        w, h = self.size\n\n        if translate is None:\n            post_trans = (0, 0)\n        else:\n            post_trans = translate\n        if center is None:\n            # FIXME These should be rounded to ints?\n            rotn_center = (w / 2.0, h / 2.0)\n        else:\n            rotn_center = center\n\n        angle = -math.radians(angle)\n        matrix = [\n            round(math.cos(angle), 15),\n            round(math.sin(angle), 15),\n            0.0,\n            round(-math.sin(angle), 15),\n            round(math.cos(angle), 15),\n            0.0,\n        ]\n\n        def transform(x, y, matrix):\n            (a, b, c, d, e, f) = matrix\n            return a * x + b * y + c, d * x + e * y + f\n\n        matrix[2], matrix[5] = transform(\n            -rotn_center[0] - post_trans[0], -rotn_center[1] - post_trans[1], matrix\n        )\n        matrix[2] += rotn_center[0]\n        matrix[5] += rotn_center[1]\n\n        if expand:\n            # calculate output size\n            xx = []\n            yy = []\n            for x, y in ((0, 0), (w, 0), (w, h), (0, h)):\n                x, y = transform(x, y, matrix)\n                xx.append(x)\n                yy.append(y)\n            nw = math.ceil(max(xx)) - math.floor(min(xx))\n            nh = math.ceil(max(yy)) - math.floor(min(yy))\n\n            # We multiply a translation matrix from the right.  Because of its\n            # special form, this is the same as taking the image of the\n            # translation vector as new translation vector.\n            matrix[2], matrix[5] = transform(-(nw - w) / 2.0, -(nh - h) / 2.0, matrix)\n            w, h = nw, nh\n\n        return self.transform(\n            (w, h), Transform.AFFINE, matrix, resample, fillcolor=fillcolor\n        )\n\n    def save(self, fp, format=None, **params) -> None:\n        \"\"\"\n        Saves this image under the given filename.  If no format is\n        specified, the format to use is determined from the filename\n        extension, if possible.\n\n        Keyword options can be used to provide additional instructions\n        to the writer. If a writer doesn't recognise an option, it is\n        silently ignored. The available options are described in the\n        :doc:`image format documentation\n        <../handbook/image-file-formats>` for each writer.\n\n        You can use a file object instead of a filename. In this case,\n        you must always specify the format. The file object must\n        implement the ``seek``, ``tell``, and ``write``\n        methods, and be opened in binary mode.\n\n        :param fp: A filename (string), pathlib.Path object or file object.\n        :param format: Optional format override.  If omitted, the\n           format to use is determined from the filename extension.\n           If a file object was used instead of a filename, this\n           parameter should always be used.\n        :param params: Extra parameters to the image writer.\n        :returns: None\n        :exception ValueError: If the output format could not be determined\n           from the file name.  Use the format option to solve this.\n        :exception OSError: If the file could not be written.  The file\n           may have been created, and may contain partial data.\n        \"\"\"\n\n        filename = \"\"\n        open_fp = False\n        if isinstance(fp, Path):\n            filename = str(fp)\n            open_fp = True\n        elif is_path(fp):\n            filename = fp\n            open_fp = True\n        elif fp == sys.stdout:\n            try:\n                fp = sys.stdout.buffer\n            except AttributeError:\n                pass\n        if not filename and hasattr(fp, \"name\") and is_path(fp.name):\n            # only set the name for metadata purposes\n            filename = fp.name\n\n        # may mutate self!\n        self._ensure_mutable()\n\n        save_all = params.pop(\"save_all\", False)\n        self.encoderinfo = params\n        self.encoderconfig = ()\n\n        preinit()\n\n        ext = os.path.splitext(filename)[1].lower()\n\n        if not format:\n            if ext not in EXTENSION:\n                init()\n            try:\n                format = EXTENSION[ext]\n            except KeyError as e:\n                msg = f\"unknown file extension: {ext}\"\n                raise ValueError(msg) from e\n\n        if format.upper() not in SAVE:\n            init()\n        if save_all:\n            save_handler = SAVE_ALL[format.upper()]\n        else:\n            save_handler = SAVE[format.upper()]\n\n        created = False\n        if open_fp:\n            created = not os.path.exists(filename)\n            if params.get(\"append\", False):\n                # Open also for reading (\"+\"), because TIFF save_all\n                # writer needs to go back and edit the written data.\n                fp = builtins.open(filename, \"r+b\")\n            else:\n                fp = builtins.open(filename, \"w+b\")\n\n        try:\n            save_handler(self, fp, filename)\n        except Exception:\n            if open_fp:\n                fp.close()\n            if created:\n                try:\n                    os.remove(filename)\n                except PermissionError:\n                    pass\n            raise\n        if open_fp:\n            fp.close()\n\n    def seek(self, frame) -> Image:\n        \"\"\"\n        Seeks to the given frame in this sequence file. If you seek\n        beyond the end of the sequence, the method raises an\n        ``EOFError`` exception. When a sequence file is opened, the\n        library automatically seeks to frame 0.\n\n        See :py:meth:`~PIL.Image.Image.tell`.\n\n        If defined, :attr:`~PIL.Image.Image.n_frames` refers to the\n        number of available frames.\n\n        :param frame: Frame number, starting at 0.\n        :exception EOFError: If the call attempts to seek beyond the end\n            of the sequence.\n        \"\"\"\n\n        # overridden by file handlers\n        if frame != 0:\n            msg = \"no more images in file\"\n            raise EOFError(msg)\n\n    def show(self, title=None):\n        \"\"\"\n        Displays this image. This method is mainly intended for debugging purposes.\n\n        This method calls :py:func:`PIL.ImageShow.show` internally. You can use\n        :py:func:`PIL.ImageShow.register` to override its default behaviour.\n\n        The image is first saved to a temporary file. By default, it will be in\n        PNG format.\n\n        On Unix, the image is then opened using the **xdg-open**, **display**,\n        **gm**, **eog** or **xv** utility, depending on which one can be found.\n\n        On macOS, the image is opened with the native Preview application.\n\n        On Windows, the image is opened with the standard PNG display utility.\n\n        :param title: Optional title to use for the image window, where possible.\n        \"\"\"\n\n        _show(self, title=title)\n\n    def split(self):\n        \"\"\"\n        Split this image into individual bands. This method returns a\n        tuple of individual image bands from an image. For example,\n        splitting an \"RGB\" image creates three new images each\n        containing a copy of one of the original bands (red, green,\n        blue).\n\n        If you need only one band, :py:meth:`~PIL.Image.Image.getchannel`\n        method can be more convenient and faster.\n\n        :returns: A tuple containing bands.\n        \"\"\"\n\n        self.load()\n        if self.im.bands == 1:\n            ims = [self.copy()]\n        else:\n            ims = map(self._new, self.im.split())\n        return tuple(ims)\n\n    def getchannel(self, channel):\n        \"\"\"\n        Returns an image containing a single channel of the source image.\n\n        :param channel: What channel to return. Could be index\n          (0 for \"R\" channel of \"RGB\") or channel name\n          (\"A\" for alpha channel of \"RGBA\").\n        :returns: An image in \"L\" mode.\n\n        .. versionadded:: 4.3.0\n        \"\"\"\n        self.load()\n\n        if isinstance(channel, str):\n            try:\n                channel = self.getbands().index(channel)\n            except ValueError as e:\n                msg = f'The image has no channel \"{channel}\"'\n                raise ValueError(msg) from e\n\n        return self._new(self.im.getband(channel))\n\n    def tell(self) -> int:\n        \"\"\"\n        Returns the current frame number. See :py:meth:`~PIL.Image.Image.seek`.\n\n        If defined, :attr:`~PIL.Image.Image.n_frames` refers to the\n        number of available frames.\n\n        :returns: Frame number, starting with 0.\n        \"\"\"\n        return 0\n\n    def thumbnail(self, size, resample=Resampling.BICUBIC, reducing_gap=2.0):\n        \"\"\"\n        Make this image into a thumbnail.  This method modifies the\n        image to contain a thumbnail version of itself, no larger than\n        the given size.  This method calculates an appropriate thumbnail\n        size to preserve the aspect of the image, calls the\n        :py:meth:`~PIL.Image.Image.draft` method to configure the file reader\n        (where applicable), and finally resizes the image.\n\n        Note that this function modifies the :py:class:`~PIL.Image.Image`\n        object in place.  If you need to use the full resolution image as well,\n        apply this method to a :py:meth:`~PIL.Image.Image.copy` of the original\n        image.\n\n        :param size: The requested size in pixels, as a 2-tuple:\n           (width, height).\n        :param resample: Optional resampling filter.  This can be one\n           of :py:data:`Resampling.NEAREST`, :py:data:`Resampling.BOX`,\n           :py:data:`Resampling.BILINEAR`, :py:data:`Resampling.HAMMING`,\n           :py:data:`Resampling.BICUBIC` or :py:data:`Resampling.LANCZOS`.\n           If omitted, it defaults to :py:data:`Resampling.BICUBIC`.\n           (was :py:data:`Resampling.NEAREST` prior to version 2.5.0).\n           See: :ref:`concept-filters`.\n        :param reducing_gap: Apply optimization by resizing the image\n           in two steps. First, reducing the image by integer times\n           using :py:meth:`~PIL.Image.Image.reduce` or\n           :py:meth:`~PIL.Image.Image.draft` for JPEG images.\n           Second, resizing using regular resampling. The last step\n           changes size no less than by ``reducing_gap`` times.\n           ``reducing_gap`` may be None (no first step is performed)\n           or should be greater than 1.0. The bigger ``reducing_gap``,\n           the closer the result to the fair resampling.\n           The smaller ``reducing_gap``, the faster resizing.\n           With ``reducing_gap`` greater or equal to 3.0, the result is\n           indistinguishable from fair resampling in most cases.\n           The default value is 2.0 (very close to fair resampling\n           while still being faster in many cases).\n        :returns: None\n        \"\"\"\n\n        provided_size = tuple(map(math.floor, size))\n\n        def preserve_aspect_ratio():\n            def round_aspect(number, key):\n                return max(min(math.floor(number), math.ceil(number), key=key), 1)\n\n            x, y = provided_size\n            if x >= self.width and y >= self.height:\n                return\n\n            aspect = self.width / self.height\n            if x / y >= aspect:\n                x = round_aspect(y * aspect, key=lambda n: abs(aspect - n / y))\n            else:\n                y = round_aspect(\n                    x / aspect, key=lambda n: 0 if n == 0 else abs(aspect - x / n)\n                )\n            return x, y\n\n        box = None\n        if reducing_gap is not None:\n            size = preserve_aspect_ratio()\n            if size is None:\n                return\n\n            res = self.draft(None, (size[0] * reducing_gap, size[1] * reducing_gap))\n            if res is not None:\n                box = res[1]\n        if box is None:\n            self.load()\n\n            # load() may have changed the size of the image\n            size = preserve_aspect_ratio()\n            if size is None:\n                return\n\n        if self.size != size:\n            im = self.resize(size, resample, box=box, reducing_gap=reducing_gap)\n\n            self.im = im.im\n            self._size = size\n            self._mode = self.im.mode\n\n        self.readonly = 0\n        self.pyaccess = None\n\n    # FIXME: the different transform methods need further explanation\n    # instead of bloating the method docs, add a separate chapter.\n    def transform(\n        self,\n        size,\n        method,\n        data=None,\n        resample=Resampling.NEAREST,\n        fill=1,\n        fillcolor=None,\n    ) -> Image:\n        \"\"\"\n        Transforms this image.  This method creates a new image with the\n        given size, and the same mode as the original, and copies data\n        to the new image using the given transform.\n\n        :param size: The output size in pixels, as a 2-tuple:\n           (width, height).\n        :param method: The transformation method.  This is one of\n          :py:data:`Transform.EXTENT` (cut out a rectangular subregion),\n          :py:data:`Transform.AFFINE` (affine transform),\n          :py:data:`Transform.PERSPECTIVE` (perspective transform),\n          :py:data:`Transform.QUAD` (map a quadrilateral to a rectangle), or\n          :py:data:`Transform.MESH` (map a number of source quadrilaterals\n          in one operation).\n\n          It may also be an :py:class:`~PIL.Image.ImageTransformHandler`\n          object::\n\n            class Example(Image.ImageTransformHandler):\n                def transform(self, size, data, resample, fill=1):\n                    # Return result\n\n          It may also be an object with a ``method.getdata`` method\n          that returns a tuple supplying new ``method`` and ``data`` values::\n\n            class Example:\n                def getdata(self):\n                    method = Image.Transform.EXTENT\n                    data = (0, 0, 100, 100)\n                    return method, data\n        :param data: Extra data to the transformation method.\n        :param resample: Optional resampling filter.  It can be one of\n           :py:data:`Resampling.NEAREST` (use nearest neighbour),\n           :py:data:`Resampling.BILINEAR` (linear interpolation in a 2x2\n           environment), or :py:data:`Resampling.BICUBIC` (cubic spline\n           interpolation in a 4x4 environment). If omitted, or if the image\n           has mode \"1\" or \"P\", it is set to :py:data:`Resampling.NEAREST`.\n           See: :ref:`concept-filters`.\n        :param fill: If ``method`` is an\n          :py:class:`~PIL.Image.ImageTransformHandler` object, this is one of\n          the arguments passed to it. Otherwise, it is unused.\n        :param fillcolor: Optional fill color for the area outside the\n           transform in the output image.\n        :returns: An :py:class:`~PIL.Image.Image` object.\n        \"\"\"\n\n        if self.mode in (\"LA\", \"RGBA\") and resample != Resampling.NEAREST:\n            return (\n                self.convert({\"LA\": \"La\", \"RGBA\": \"RGBa\"}[self.mode])\n                .transform(size, method, data, resample, fill, fillcolor)\n                .convert(self.mode)\n            )\n\n        if isinstance(method, ImageTransformHandler):\n            return method.transform(size, self, resample=resample, fill=fill)\n\n        if hasattr(method, \"getdata\"):\n            # compatibility w. old-style transform objects\n            method, data = method.getdata()\n\n        if data is None:\n            msg = \"missing method data\"\n            raise ValueError(msg)\n\n        im = new(self.mode, size, fillcolor)\n        if self.mode == \"P\" and self.palette:\n            im.palette = self.palette.copy()\n        im.info = self.info.copy()\n        if method == Transform.MESH:\n            # list of quads\n            for box, quad in data:\n                im.__transformer(\n                    box, self, Transform.QUAD, quad, resample, fillcolor is None\n                )\n        else:\n            im.__transformer(\n                (0, 0) + size, self, method, data, resample, fillcolor is None\n            )\n\n        return im\n\n    def __transformer(\n        self, box, image, method, data, resample=Resampling.NEAREST, fill=1\n    ):\n        w = box[2] - box[0]\n        h = box[3] - box[1]\n\n        if method == Transform.AFFINE:\n            data = data[:6]\n\n        elif method == Transform.EXTENT:\n            # convert extent to an affine transform\n            x0, y0, x1, y1 = data\n            xs = (x1 - x0) / w\n            ys = (y1 - y0) / h\n            method = Transform.AFFINE\n            data = (xs, 0, x0, 0, ys, y0)\n\n        elif method == Transform.PERSPECTIVE:\n            data = data[:8]\n\n        elif method == Transform.QUAD:\n            # quadrilateral warp.  data specifies the four corners\n            # given as NW, SW, SE, and NE.\n            nw = data[:2]\n            sw = data[2:4]\n            se = data[4:6]\n            ne = data[6:8]\n            x0, y0 = nw\n            As = 1.0 / w\n            At = 1.0 / h\n            data = (\n                x0,\n                (ne[0] - x0) * As,\n                (sw[0] - x0) * At,\n                (se[0] - sw[0] - ne[0] + x0) * As * At,\n                y0,\n                (ne[1] - y0) * As,\n                (sw[1] - y0) * At,\n                (se[1] - sw[1] - ne[1] + y0) * As * At,\n            )\n\n        else:\n            msg = \"unknown transformation method\"\n            raise ValueError(msg)\n\n        if resample not in (\n            Resampling.NEAREST,\n            Resampling.BILINEAR,\n            Resampling.BICUBIC,\n        ):\n            if resample in (Resampling.BOX, Resampling.HAMMING, Resampling.LANCZOS):\n                msg = {\n                    Resampling.BOX: \"Image.Resampling.BOX\",\n                    Resampling.HAMMING: \"Image.Resampling.HAMMING\",\n                    Resampling.LANCZOS: \"Image.Resampling.LANCZOS\",\n                }[resample] + f\" ({resample}) cannot be used.\"\n            else:\n                msg = f\"Unknown resampling filter ({resample}).\"\n\n            filters = [\n                f\"{filter[1]} ({filter[0]})\"\n                for filter in (\n                    (Resampling.NEAREST, \"Image.Resampling.NEAREST\"),\n                    (Resampling.BILINEAR, \"Image.Resampling.BILINEAR\"),\n                    (Resampling.BICUBIC, \"Image.Resampling.BICUBIC\"),\n                )\n            ]\n            msg += \" Use \" + \", \".join(filters[:-1]) + \" or \" + filters[-1]\n            raise ValueError(msg)\n\n        image.load()\n\n        self.load()\n\n        if image.mode in (\"1\", \"P\"):\n            resample = Resampling.NEAREST\n\n        self.im.transform2(box, image.im, method, data, resample, fill)\n\n    def transpose(self, method):\n        \"\"\"\n        Transpose image (flip or rotate in 90 degree steps)\n\n        :param method: One of :py:data:`Transpose.FLIP_LEFT_RIGHT`,\n          :py:data:`Transpose.FLIP_TOP_BOTTOM`, :py:data:`Transpose.ROTATE_90`,\n          :py:data:`Transpose.ROTATE_180`, :py:data:`Transpose.ROTATE_270`,\n          :py:data:`Transpose.TRANSPOSE` or :py:data:`Transpose.TRANSVERSE`.\n        :returns: Returns a flipped or rotated copy of this image.\n        \"\"\"\n\n        self.load()\n        return self._new(self.im.transpose(method))\n\n    def effect_spread(self, distance):\n        \"\"\"\n        Randomly spread pixels in an image.\n\n        :param distance: Distance to spread pixels.\n        \"\"\"\n        self.load()\n        return self._new(self.im.effect_spread(distance))\n\n    def toqimage(self):\n        \"\"\"Returns a QImage copy of this image\"\"\"\n        from . import ImageQt\n\n        if not ImageQt.qt_is_installed:\n            msg = \"Qt bindings are not installed\"\n            raise ImportError(msg)\n        return ImageQt.toqimage(self)\n\n    def toqpixmap(self):\n        \"\"\"Returns a QPixmap copy of this image\"\"\"\n        from . import ImageQt\n\n        if not ImageQt.qt_is_installed:\n            msg = \"Qt bindings are not installed\"\n            raise ImportError(msg)\n        return ImageQt.toqpixmap(self)\n\n\n# --------------------------------------------------------------------\n# Abstract handlers.\n\n\nclass ImagePointHandler:\n    \"\"\"\n    Used as a mixin by point transforms\n    (for use with :py:meth:`~PIL.Image.Image.point`)\n    \"\"\"\n\n    pass\n\n\nclass ImageTransformHandler:\n    \"\"\"\n    Used as a mixin by geometry transforms\n    (for use with :py:meth:`~PIL.Image.Image.transform`)\n    \"\"\"\n\n    pass\n\n\n# --------------------------------------------------------------------\n# Factories\n\n#\n# Debugging\n\n\ndef _wedge():\n    \"\"\"Create grayscale wedge (for debugging only)\"\"\"\n\n    return Image()._new(core.wedge(\"L\"))\n\n\ndef _check_size(size):\n    \"\"\"\n    Common check to enforce type and sanity check on size tuples\n\n    :param size: Should be a 2 tuple of (width, height)\n    :returns: True, or raises a ValueError\n    \"\"\"\n\n    if not isinstance(size, (list, tuple)):\n        msg = \"Size must be a tuple\"\n        raise ValueError(msg)\n    if len(size) != 2:\n        msg = \"Size must be a tuple of length 2\"\n        raise ValueError(msg)\n    if size[0] < 0 or size[1] < 0:\n        msg = \"Width and height must be >= 0\"\n        raise ValueError(msg)\n\n    return True\n\n\ndef new(mode, size, color=0) -> Image:\n    \"\"\"\n    Creates a new image with the given mode and size.\n\n    :param mode: The mode to use for the new image. See:\n       :ref:`concept-modes`.\n    :param size: A 2-tuple, containing (width, height) in pixels.\n    :param color: What color to use for the image.  Default is black.\n       If given, this should be a single integer or floating point value\n       for single-band modes, and a tuple for multi-band modes (one value\n       per band).  When creating RGB or HSV images, you can also use color\n       strings as supported by the ImageColor module.  If the color is\n       None, the image is not initialised.\n    :returns: An :py:class:`~PIL.Image.Image` object.\n    \"\"\"\n\n    _check_size(size)\n\n    if color is None:\n        # don't initialize\n        return Image()._new(core.new(mode, size))\n\n    if isinstance(color, str):\n        # css3-style specifier\n\n        from . import ImageColor\n\n        color = ImageColor.getcolor(color, mode)\n\n    im = Image()\n    if mode == \"P\" and isinstance(color, (list, tuple)) and len(color) in [3, 4]:\n        # RGB or RGBA value for a P image\n        from . import ImagePalette\n\n        im.palette = ImagePalette.ImagePalette()\n        color = im.palette.getcolor(color)\n    return im._new(core.fill(mode, size, color))\n\n\ndef frombytes(mode, size, data, decoder_name=\"raw\", *args) -> Image:\n    \"\"\"\n    Creates a copy of an image memory from pixel data in a buffer.\n\n    In its simplest form, this function takes three arguments\n    (mode, size, and unpacked pixel data).\n\n    You can also use any pixel decoder supported by PIL. For more\n    information on available decoders, see the section\n    :ref:`Writing Your Own File Codec <file-codecs>`.\n\n    Note that this function decodes pixel data only, not entire images.\n    If you have an entire image in a string, wrap it in a\n    :py:class:`~io.BytesIO` object, and use :py:func:`~PIL.Image.open` to load\n    it.\n\n    :param mode: The image mode. See: :ref:`concept-modes`.\n    :param size: The image size.\n    :param data: A byte buffer containing raw data for the given mode.\n    :param decoder_name: What decoder to use.\n    :param args: Additional parameters for the given decoder.\n    :returns: An :py:class:`~PIL.Image.Image` object.\n    \"\"\"\n\n    _check_size(size)\n\n    im = new(mode, size)\n    if im.width != 0 and im.height != 0:\n        # may pass tuple instead of argument list\n        if len(args) == 1 and isinstance(args[0], tuple):\n            args = args[0]\n\n        if decoder_name == \"raw\" and args == ():\n            args = mode\n\n        im.frombytes(data, decoder_name, args)\n    return im\n\n\ndef frombuffer(mode, size, data, decoder_name=\"raw\", *args):\n    \"\"\"\n    Creates an image memory referencing pixel data in a byte buffer.\n\n    This function is similar to :py:func:`~PIL.Image.frombytes`, but uses data\n    in the byte buffer, where possible.  This means that changes to the\n    original buffer object are reflected in this image).  Not all modes can\n    share memory; supported modes include \"L\", \"RGBX\", \"RGBA\", and \"CMYK\".\n\n    Note that this function decodes pixel data only, not entire images.\n    If you have an entire image file in a string, wrap it in a\n    :py:class:`~io.BytesIO` object, and use :py:func:`~PIL.Image.open` to load it.\n\n    In the current version, the default parameters used for the \"raw\" decoder\n    differs from that used for :py:func:`~PIL.Image.frombytes`.  This is a\n    bug, and will probably be fixed in a future release.  The current release\n    issues a warning if you do this; to disable the warning, you should provide\n    the full set of parameters.  See below for details.\n\n    :param mode: The image mode. See: :ref:`concept-modes`.\n    :param size: The image size.\n    :param data: A bytes or other buffer object containing raw\n        data for the given mode.\n    :param decoder_name: What decoder to use.\n    :param args: Additional parameters for the given decoder.  For the\n        default encoder (\"raw\"), it's recommended that you provide the\n        full set of parameters::\n\n            frombuffer(mode, size, data, \"raw\", mode, 0, 1)\n\n    :returns: An :py:class:`~PIL.Image.Image` object.\n\n    .. versionadded:: 1.1.4\n    \"\"\"\n\n    _check_size(size)\n\n    # may pass tuple instead of argument list\n    if len(args) == 1 and isinstance(args[0], tuple):\n        args = args[0]\n\n    if decoder_name == \"raw\":\n        if args == ():\n            args = mode, 0, 1\n        if args[0] in _MAPMODES:\n            im = new(mode, (0, 0))\n            im = im._new(core.map_buffer(data, size, decoder_name, 0, args))\n            if mode == \"P\":\n                from . import ImagePalette\n\n                im.palette = ImagePalette.ImagePalette(\"RGB\", im.im.getpalette(\"RGB\"))\n            im.readonly = 1\n            return im\n\n    return frombytes(mode, size, data, decoder_name, args)\n\n\ndef fromarray(obj, mode=None):\n    \"\"\"\n    Creates an image memory from an object exporting the array interface\n    (using the buffer protocol)::\n\n      from PIL import Image\n      import numpy as np\n      a = np.zeros((5, 5))\n      im = Image.fromarray(a)\n\n    If ``obj`` is not contiguous, then the ``tobytes`` method is called\n    and :py:func:`~PIL.Image.frombuffer` is used.\n\n    In the case of NumPy, be aware that Pillow modes do not always correspond\n    to NumPy dtypes. Pillow modes only offer 1-bit pixels, 8-bit pixels,\n    32-bit signed integer pixels, and 32-bit floating point pixels.\n\n    Pillow images can also be converted to arrays::\n\n      from PIL import Image\n      import numpy as np\n      im = Image.open(\"hopper.jpg\")\n      a = np.asarray(im)\n\n    When converting Pillow images to arrays however, only pixel values are\n    transferred. This means that P and PA mode images will lose their palette.\n\n    :param obj: Object with array interface\n    :param mode: Optional mode to use when reading ``obj``. Will be determined from\n      type if ``None``.\n\n      This will not be used to convert the data after reading, but will be used to\n      change how the data is read::\n\n        from PIL import Image\n        import numpy as np\n        a = np.full((1, 1), 300)\n        im = Image.fromarray(a, mode=\"L\")\n        im.getpixel((0, 0))  # 44\n        im = Image.fromarray(a, mode=\"RGB\")\n        im.getpixel((0, 0))  # (44, 1, 0)\n\n      See: :ref:`concept-modes` for general information about modes.\n    :returns: An image object.\n\n    .. versionadded:: 1.1.6\n    \"\"\"\n    arr = obj.__array_interface__\n    shape = arr[\"shape\"]\n    ndim = len(shape)\n    strides = arr.get(\"strides\", None)\n    if mode is None:\n        try:\n            typekey = (1, 1) + shape[2:], arr[\"typestr\"]\n        except KeyError as e:\n            msg = \"Cannot handle this data type\"\n            raise TypeError(msg) from e\n        try:\n            mode, rawmode = _fromarray_typemap[typekey]\n        except KeyError as e:\n            typekey_shape, typestr = typekey\n            msg = f\"Cannot handle this data type: {typekey_shape}, {typestr}\"\n            raise TypeError(msg) from e\n    else:\n        rawmode = mode\n    if mode in [\"1\", \"L\", \"I\", \"P\", \"F\"]:\n        ndmax = 2\n    elif mode == \"RGB\":\n        ndmax = 3\n    else:\n        ndmax = 4\n    if ndim > ndmax:\n        msg = f\"Too many dimensions: {ndim} > {ndmax}.\"\n        raise ValueError(msg)\n\n    size = 1 if ndim == 1 else shape[1], shape[0]\n    if strides is not None:\n        if hasattr(obj, \"tobytes\"):\n            obj = obj.tobytes()\n        else:\n            obj = obj.tostring()\n\n    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n\n\ndef fromqimage(im):\n    \"\"\"Creates an image instance from a QImage image\"\"\"\n    from . import ImageQt\n\n    if not ImageQt.qt_is_installed:\n        msg = \"Qt bindings are not installed\"\n        raise ImportError(msg)\n    return ImageQt.fromqimage(im)\n\n\ndef fromqpixmap(im):\n    \"\"\"Creates an image instance from a QPixmap image\"\"\"\n    from . import ImageQt\n\n    if not ImageQt.qt_is_installed:\n        msg = \"Qt bindings are not installed\"\n        raise ImportError(msg)\n    return ImageQt.fromqpixmap(im)\n\n\n_fromarray_typemap = {\n    # (shape, typestr) => mode, rawmode\n    # first two members of shape are set to one\n    ((1, 1), \"|b1\"): (\"1\", \"1;8\"),\n    ((1, 1), \"|u1\"): (\"L\", \"L\"),\n    ((1, 1), \"|i1\"): (\"I\", \"I;8\"),\n    ((1, 1), \"<u2\"): (\"I\", \"I;16\"),\n    ((1, 1), \">u2\"): (\"I\", \"I;16B\"),\n    ((1, 1), \"<i2\"): (\"I\", \"I;16S\"),\n    ((1, 1), \">i2\"): (\"I\", \"I;16BS\"),\n    ((1, 1), \"<u4\"): (\"I\", \"I;32\"),\n    ((1, 1), \">u4\"): (\"I\", \"I;32B\"),\n    ((1, 1), \"<i4\"): (\"I\", \"I;32S\"),\n    ((1, 1), \">i4\"): (\"I\", \"I;32BS\"),\n    ((1, 1), \"<f4\"): (\"F\", \"F;32F\"),\n    ((1, 1), \">f4\"): (\"F\", \"F;32BF\"),\n    ((1, 1), \"<f8\"): (\"F\", \"F;64F\"),\n    ((1, 1), \">f8\"): (\"F\", \"F;64BF\"),\n    ((1, 1, 2), \"|u1\"): (\"LA\", \"LA\"),\n    ((1, 1, 3), \"|u1\"): (\"RGB\", \"RGB\"),\n    ((1, 1, 4), \"|u1\"): (\"RGBA\", \"RGBA\"),\n    # shortcuts:\n    ((1, 1), _ENDIAN + \"i4\"): (\"I\", \"I\"),\n    ((1, 1), _ENDIAN + \"f4\"): (\"F\", \"F\"),\n}\n\n\ndef _decompression_bomb_check(size):\n    if MAX_IMAGE_PIXELS is None:\n        return\n\n    pixels = max(1, size[0]) * max(1, size[1])\n\n    if pixels > 2 * MAX_IMAGE_PIXELS:\n        msg = (\n            f\"Image size ({pixels} pixels) exceeds limit of {2 * MAX_IMAGE_PIXELS} \"\n            \"pixels, could be decompression bomb DOS attack.\"\n        )\n        raise DecompressionBombError(msg)\n\n    if pixels > MAX_IMAGE_PIXELS:\n        warnings.warn(\n            f\"Image size ({pixels} pixels) exceeds limit of {MAX_IMAGE_PIXELS} pixels, \"\n            \"could be decompression bomb DOS attack.\",\n            DecompressionBombWarning,\n        )\n\n\ndef open(fp, mode=\"r\", formats=None) -> Image:\n    \"\"\"\n    Opens and identifies the given image file.\n\n    This is a lazy operation; this function identifies the file, but\n    the file remains open and the actual image data is not read from\n    the file until you try to process the data (or call the\n    :py:meth:`~PIL.Image.Image.load` method).  See\n    :py:func:`~PIL.Image.new`. See :ref:`file-handling`.\n\n    :param fp: A filename (string), pathlib.Path object or a file object.\n       The file object must implement ``file.read``,\n       ``file.seek``, and ``file.tell`` methods,\n       and be opened in binary mode. The file object will also seek to zero\n       before reading.\n    :param mode: The mode.  If given, this argument must be \"r\".\n    :param formats: A list or tuple of formats to attempt to load the file in.\n       This can be used to restrict the set of formats checked.\n       Pass ``None`` to try all supported formats. You can print the set of\n       available formats by running ``python3 -m PIL`` or using\n       the :py:func:`PIL.features.pilinfo` function.\n    :returns: An :py:class:`~PIL.Image.Image` object.\n    :exception FileNotFoundError: If the file cannot be found.\n    :exception PIL.UnidentifiedImageError: If the image cannot be opened and\n       identified.\n    :exception ValueError: If the ``mode`` is not \"r\", or if a ``StringIO``\n       instance is used for ``fp``.\n    :exception TypeError: If ``formats`` is not ``None``, a list or a tuple.\n    \"\"\"\n\n    if mode != \"r\":\n        msg = f\"bad mode {repr(mode)}\"\n        raise ValueError(msg)\n    elif isinstance(fp, io.StringIO):\n        msg = (\n            \"StringIO cannot be used to open an image. \"\n            \"Binary data must be used instead.\"\n        )\n        raise ValueError(msg)\n\n    if formats is None:\n        formats = ID\n    elif not isinstance(formats, (list, tuple)):\n        msg = \"formats must be a list or tuple\"\n        raise TypeError(msg)\n\n    exclusive_fp = False\n    filename = \"\"\n    if isinstance(fp, Path):\n        filename = str(fp.resolve())\n    elif is_path(fp):\n        filename = fp\n\n    if filename:\n        fp = builtins.open(filename, \"rb\")\n        exclusive_fp = True\n\n    try:\n        fp.seek(0)\n    except (AttributeError, io.UnsupportedOperation):\n        fp = io.BytesIO(fp.read())\n        exclusive_fp = True\n\n    prefix = fp.read(16)\n\n    preinit()\n\n    accept_warnings = []\n\n    def _open_core(fp, filename, prefix, formats):\n        for i in formats:\n            i = i.upper()\n            if i not in OPEN:\n                init()\n            try:\n                factory, accept = OPEN[i]\n                result = not accept or accept(prefix)\n                if type(result) in [str, bytes]:\n                    accept_warnings.append(result)\n                elif result:\n                    fp.seek(0)\n                    im = factory(fp, filename)\n                    _decompression_bomb_check(im.size)\n                    return im\n            except (SyntaxError, IndexError, TypeError, struct.error):\n                # Leave disabled by default, spams the logs with image\n                # opening failures that are entirely expected.\n                # logger.debug(\"\", exc_info=True)\n                continue\n            except BaseException:\n                if exclusive_fp:\n                    fp.close()\n                raise\n        return None\n\n    im = _open_core(fp, filename, prefix, formats)\n\n    if im is None and formats is ID:\n        checked_formats = formats.copy()\n        if init():\n            im = _open_core(\n                fp,\n                filename,\n                prefix,\n                tuple(format for format in formats if format not in checked_formats),\n            )\n\n    if im:\n        im._exclusive_fp = exclusive_fp\n        return im\n\n    if exclusive_fp:\n        fp.close()\n    for message in accept_warnings:\n        warnings.warn(message)\n    msg = \"cannot identify image file %r\" % (filename if filename else fp)\n    raise UnidentifiedImageError(msg)\n\n\n#\n# Image processing.\n\n\ndef alpha_composite(im1, im2):\n    \"\"\"\n    Alpha composite im2 over im1.\n\n    :param im1: The first image. Must have mode RGBA.\n    :param im2: The second image.  Must have mode RGBA, and the same size as\n       the first image.\n    :returns: An :py:class:`~PIL.Image.Image` object.\n    \"\"\"\n\n    im1.load()\n    im2.load()\n    return im1._new(core.alpha_composite(im1.im, im2.im))\n\n\ndef blend(im1, im2, alpha):\n    \"\"\"\n    Creates a new image by interpolating between two input images, using\n    a constant alpha::\n\n        out = image1 * (1.0 - alpha) + image2 * alpha\n\n    :param im1: The first image.\n    :param im2: The second image.  Must have the same mode and size as\n       the first image.\n    :param alpha: The interpolation alpha factor.  If alpha is 0.0, a\n       copy of the first image is returned. If alpha is 1.0, a copy of\n       the second image is returned. There are no restrictions on the\n       alpha value. If necessary, the result is clipped to fit into\n       the allowed output range.\n    :returns: An :py:class:`~PIL.Image.Image` object.\n    \"\"\"\n\n    im1.load()\n    im2.load()\n    return im1._new(core.blend(im1.im, im2.im, alpha))\n\n\ndef composite(image1, image2, mask):\n    \"\"\"\n    Create composite image by blending images using a transparency mask.\n\n    :param image1: The first image.\n    :param image2: The second image.  Must have the same mode and\n       size as the first image.\n    :param mask: A mask image.  This image can have mode\n       \"1\", \"L\", or \"RGBA\", and must have the same size as the\n       other two images.\n    \"\"\"\n\n    image = image2.copy()\n    image.paste(image1, None, mask)\n    return image\n\n\ndef eval(image, *args):\n    \"\"\"\n    Applies the function (which should take one argument) to each pixel\n    in the given image. If the image has more than one band, the same\n    function is applied to each band. Note that the function is\n    evaluated once for each possible pixel value, so you cannot use\n    random components or other generators.\n\n    :param image: The input image.\n    :param function: A function object, taking one integer argument.\n    :returns: An :py:class:`~PIL.Image.Image` object.\n    \"\"\"\n\n    return image.point(args[0])\n\n\ndef merge(mode, bands):\n    \"\"\"\n    Merge a set of single band images into a new multiband image.\n\n    :param mode: The mode to use for the output image. See:\n        :ref:`concept-modes`.\n    :param bands: A sequence containing one single-band image for\n        each band in the output image.  All bands must have the\n        same size.\n    :returns: An :py:class:`~PIL.Image.Image` object.\n    \"\"\"\n\n    if getmodebands(mode) != len(bands) or \"*\" in mode:\n        msg = \"wrong number of bands\"\n        raise ValueError(msg)\n    for band in bands[1:]:\n        if band.mode != getmodetype(mode):\n            msg = \"mode mismatch\"\n            raise ValueError(msg)\n        if band.size != bands[0].size:\n            msg = \"size mismatch\"\n            raise ValueError(msg)\n    for band in bands:\n        band.load()\n    return bands[0]._new(core.merge(mode, *[b.im for b in bands]))\n\n\n# --------------------------------------------------------------------\n# Plugin registry\n\n\ndef register_open(id, factory, accept=None) -> None:\n    \"\"\"\n    Register an image file plugin.  This function should not be used\n    in application code.\n\n    :param id: An image format identifier.\n    :param factory: An image file factory method.\n    :param accept: An optional function that can be used to quickly\n       reject images having another format.\n    \"\"\"\n    id = id.upper()\n    if id not in ID:\n        ID.append(id)\n    OPEN[id] = factory, accept\n\n\ndef register_mime(id, mimetype):\n    \"\"\"\n    Registers an image MIME type by populating ``Image.MIME``. This function\n    should not be used in application code.\n\n    ``Image.MIME`` provides a mapping from image format identifiers to mime\n    formats, but :py:meth:`~PIL.ImageFile.ImageFile.get_format_mimetype` can\n    provide a different result for specific images.\n\n    :param id: An image format identifier.\n    :param mimetype: The image MIME type for this format.\n    \"\"\"\n    MIME[id.upper()] = mimetype\n\n\ndef register_save(id, driver):\n    \"\"\"\n    Registers an image save function.  This function should not be\n    used in application code.\n\n    :param id: An image format identifier.\n    :param driver: A function to save images in this format.\n    \"\"\"\n    SAVE[id.upper()] = driver\n\n\ndef register_save_all(id, driver):\n    \"\"\"\n    Registers an image function to save all the frames\n    of a multiframe format.  This function should not be\n    used in application code.\n\n    :param id: An image format identifier.\n    :param driver: A function to save images in this format.\n    \"\"\"\n    SAVE_ALL[id.upper()] = driver\n\n\ndef register_extension(id, extension) -> None:\n    \"\"\"\n    Registers an image extension.  This function should not be\n    used in application code.\n\n    :param id: An image format identifier.\n    :param extension: An extension used for this format.\n    \"\"\"\n    EXTENSION[extension.lower()] = id.upper()\n\n\ndef register_extensions(id, extensions):\n    \"\"\"\n    Registers image extensions.  This function should not be\n    used in application code.\n\n    :param id: An image format identifier.\n    :param extensions: A list of extensions used for this format.\n    \"\"\"\n    for extension in extensions:\n        register_extension(id, extension)\n\n\ndef registered_extensions():\n    \"\"\"\n    Returns a dictionary containing all file extensions belonging\n    to registered plugins\n    \"\"\"\n    init()\n    return EXTENSION\n\n\ndef register_decoder(name, decoder):\n    \"\"\"\n    Registers an image decoder.  This function should not be\n    used in application code.\n\n    :param name: The name of the decoder\n    :param decoder: A callable(mode, args) that returns an\n                    ImageFile.PyDecoder object\n\n    .. versionadded:: 4.1.0\n    \"\"\"\n    DECODERS[name] = decoder\n\n\ndef register_encoder(name, encoder):\n    \"\"\"\n    Registers an image encoder.  This function should not be\n    used in application code.\n\n    :param name: The name of the encoder\n    :param encoder: A callable(mode, args) that returns an\n                    ImageFile.PyEncoder object\n\n    .. versionadded:: 4.1.0\n    \"\"\"\n    ENCODERS[name] = encoder\n\n\n# --------------------------------------------------------------------\n# Simple display support.\n\n\ndef _show(image, **options):\n    from . import ImageShow\n\n    ImageShow.show(image, **options)\n\n\n# --------------------------------------------------------------------\n# Effects\n\n\ndef effect_mandelbrot(size, extent, quality):\n    \"\"\"\n    Generate a Mandelbrot set covering the given extent.\n\n    :param size: The requested size in pixels, as a 2-tuple:\n       (width, height).\n    :param extent: The extent to cover, as a 4-tuple:\n       (x0, y0, x1, y1).\n    :param quality: Quality.\n    \"\"\"\n    return Image()._new(core.effect_mandelbrot(size, extent, quality))\n\n\ndef effect_noise(size, sigma):\n    \"\"\"\n    Generate Gaussian noise centered around 128.\n\n    :param size: The requested size in pixels, as a 2-tuple:\n       (width, height).\n    :param sigma: Standard deviation of noise.\n    \"\"\"\n    return Image()._new(core.effect_noise(size, sigma))\n\n\ndef linear_gradient(mode):\n    \"\"\"\n    Generate 256x256 linear gradient from black to white, top to bottom.\n\n    :param mode: Input mode.\n    \"\"\"\n    return Image()._new(core.linear_gradient(mode))\n\n\ndef radial_gradient(mode):\n    \"\"\"\n    Generate 256x256 radial gradient from black to white, centre to edge.\n\n    :param mode: Input mode.\n    \"\"\"\n    return Image()._new(core.radial_gradient(mode))\n\n\n# --------------------------------------------------------------------\n# Resources\n\n\ndef _apply_env_variables(env=None):\n    if env is None:\n        env = os.environ\n\n    for var_name, setter in [\n        (\"PILLOW_ALIGNMENT\", core.set_alignment),\n        (\"PILLOW_BLOCK_SIZE\", core.set_block_size),\n        (\"PILLOW_BLOCKS_MAX\", core.set_blocks_max),\n    ]:\n        if var_name not in env:\n            continue\n\n        var = env[var_name].lower()\n\n        units = 1\n        for postfix, mul in [(\"k\", 1024), (\"m\", 1024 * 1024)]:\n            if var.endswith(postfix):\n                units = mul\n                var = var[: -len(postfix)]\n\n        try:\n            var = int(var) * units\n        except ValueError:\n            warnings.warn(f\"{var_name} is not int\")\n            continue\n\n        try:\n            setter(var)\n        except ValueError as e:\n            warnings.warn(f\"{var_name}: {e}\")\n\n\n_apply_env_variables()\natexit.register(core.clear_cache)\n\n\nclass Exif(MutableMapping):\n    \"\"\"\n    This class provides read and write access to EXIF image data::\n\n      from PIL import Image\n      im = Image.open(\"exif.png\")\n      exif = im.getexif()  # Returns an instance of this class\n\n    Information can be read and written, iterated over or deleted::\n\n      print(exif[274])  # 1\n      exif[274] = 2\n      for k, v in exif.items():\n        print(\"Tag\", k, \"Value\", v)  # Tag 274 Value 2\n      del exif[274]\n\n    To access information beyond IFD0, :py:meth:`~PIL.Image.Exif.get_ifd`\n    returns a dictionary::\n\n      from PIL import ExifTags\n      im = Image.open(\"exif_gps.jpg\")\n      exif = im.getexif()\n      gps_ifd = exif.get_ifd(ExifTags.IFD.GPSInfo)\n      print(gps_ifd)\n\n    Other IFDs include ``ExifTags.IFD.Exif``, ``ExifTags.IFD.Makernote``,\n    ``ExifTags.IFD.Interop`` and ``ExifTags.IFD.IFD1``.\n\n    :py:mod:`~PIL.ExifTags` also has enum classes to provide names for data::\n\n      print(exif[ExifTags.Base.Software])  # PIL\n      print(gps_ifd[ExifTags.GPS.GPSDateStamp])  # 1999:99:99 99:99:99\n    \"\"\"\n\n    endian = None\n    bigtiff = False\n\n    def __init__(self):\n        self._data = {}\n        self._hidden_data = {}\n        self._ifds = {}\n        self._info = None\n        self._loaded_exif = None\n\n    def _fixup(self, value):\n        try:\n            if len(value) == 1 and isinstance(value, tuple):\n                return value[0]\n        except Exception:\n            pass\n        return value\n\n    def _fixup_dict(self, src_dict):\n        # Helper function\n        # returns a dict with any single item tuples/lists as individual values\n        return {k: self._fixup(v) for k, v in src_dict.items()}\n\n    def _get_ifd_dict(self, offset):\n        try:\n            # an offset pointer to the location of the nested embedded IFD.\n            # It should be a long, but may be corrupted.\n            self.fp.seek(offset)\n        except (KeyError, TypeError):\n            pass\n        else:\n            from . import TiffImagePlugin\n\n            info = TiffImagePlugin.ImageFileDirectory_v2(self.head)\n            info.load(self.fp)\n            return self._fixup_dict(info)\n\n    def _get_head(self):\n        version = b\"\\x2B\" if self.bigtiff else b\"\\x2A\"\n        if self.endian == \"<\":\n            head = b\"II\" + version + b\"\\x00\" + o32le(8)\n        else:\n            head = b\"MM\\x00\" + version + o32be(8)\n        if self.bigtiff:\n            head += o32le(8) if self.endian == \"<\" else o32be(8)\n            head += b\"\\x00\\x00\\x00\\x00\"\n        return head\n\n    def load(self, data):\n        # Extract EXIF information.  This is highly experimental,\n        # and is likely to be replaced with something better in a future\n        # version.\n\n        # The EXIF record consists of a TIFF file embedded in a JPEG\n        # application marker (!).\n        if data == self._loaded_exif:\n            return\n        self._loaded_exif = data\n        self._data.clear()\n        self._hidden_data.clear()\n        self._ifds.clear()\n        if data and data.startswith(b\"Exif\\x00\\x00\"):\n            data = data[6:]\n        if not data:\n            self._info = None\n            return\n\n        self.fp = io.BytesIO(data)\n        self.head = self.fp.read(8)\n        # process dictionary\n        from . import TiffImagePlugin\n\n        self._info = TiffImagePlugin.ImageFileDirectory_v2(self.head)\n        self.endian = self._info._endian\n        self.fp.seek(self._info.next)\n        self._info.load(self.fp)\n\n    def load_from_fp(self, fp, offset=None):\n        self._loaded_exif = None\n        self._data.clear()\n        self._hidden_data.clear()\n        self._ifds.clear()\n\n        # process dictionary\n        from . import TiffImagePlugin\n\n        self.fp = fp\n        if offset is not None:\n            self.head = self._get_head()\n        else:\n            self.head = self.fp.read(8)\n        self._info = TiffImagePlugin.ImageFileDirectory_v2(self.head)\n        if self.endian is None:\n            self.endian = self._info._endian\n        if offset is None:\n            offset = self._info.next\n        self.fp.tell()\n        self.fp.seek(offset)\n        self._info.load(self.fp)\n\n    def _get_merged_dict(self):\n        merged_dict = dict(self)\n\n        # get EXIF extension\n        if ExifTags.IFD.Exif in self:\n            ifd = self._get_ifd_dict(self[ExifTags.IFD.Exif])\n            if ifd:\n                merged_dict.update(ifd)\n\n        # GPS\n        if ExifTags.IFD.GPSInfo in self:\n            merged_dict[ExifTags.IFD.GPSInfo] = self._get_ifd_dict(\n                self[ExifTags.IFD.GPSInfo]\n            )\n\n        return merged_dict\n\n    def tobytes(self, offset=8):\n        from . import TiffImagePlugin\n\n        head = self._get_head()\n        ifd = TiffImagePlugin.ImageFileDirectory_v2(ifh=head)\n        for tag, value in self.items():\n            if tag in [\n                ExifTags.IFD.Exif,\n                ExifTags.IFD.GPSInfo,\n            ] and not isinstance(value, dict):\n                value = self.get_ifd(tag)\n                if (\n                    tag == ExifTags.IFD.Exif\n                    and ExifTags.IFD.Interop in value\n                    and not isinstance(value[ExifTags.IFD.Interop], dict)\n                ):\n                    value = value.copy()\n                    value[ExifTags.IFD.Interop] = self.get_ifd(ExifTags.IFD.Interop)\n            ifd[tag] = value\n        return b\"Exif\\x00\\x00\" + head + ifd.tobytes(offset)\n\n    def get_ifd(self, tag):\n        if tag not in self._ifds:\n            if tag == ExifTags.IFD.IFD1:\n                if self._info is not None and self._info.next != 0:\n                    self._ifds[tag] = self._get_ifd_dict(self._info.next)\n            elif tag in [ExifTags.IFD.Exif, ExifTags.IFD.GPSInfo]:\n                offset = self._hidden_data.get(tag, self.get(tag))\n                if offset is not None:\n                    self._ifds[tag] = self._get_ifd_dict(offset)\n            elif tag in [ExifTags.IFD.Interop, ExifTags.IFD.Makernote]:\n                if ExifTags.IFD.Exif not in self._ifds:\n                    self.get_ifd(ExifTags.IFD.Exif)\n                tag_data = self._ifds[ExifTags.IFD.Exif][tag]\n                if tag == ExifTags.IFD.Makernote:\n                    from .TiffImagePlugin import ImageFileDirectory_v2\n\n                    if tag_data[:8] == b\"FUJIFILM\":\n                        ifd_offset = i32le(tag_data, 8)\n                        ifd_data = tag_data[ifd_offset:]\n\n                        makernote = {}\n                        for i in range(0, struct.unpack(\"<H\", ifd_data[:2])[0]):\n                            ifd_tag, typ, count, data = struct.unpack(\n                                \"<HHL4s\", ifd_data[i * 12 + 2 : (i + 1) * 12 + 2]\n                            )\n                            try:\n                                (\n                                    unit_size,\n                                    handler,\n                                ) = ImageFileDirectory_v2._load_dispatch[typ]\n                            except KeyError:\n                                continue\n                            size = count * unit_size\n                            if size > 4:\n                                (offset,) = struct.unpack(\"<L\", data)\n                                data = ifd_data[offset - 12 : offset + size - 12]\n                            else:\n                                data = data[:size]\n\n                            if len(data) != size:\n                                warnings.warn(\n                                    \"Possibly corrupt EXIF MakerNote data.  \"\n                                    f\"Expecting to read {size} bytes but only got \"\n                                    f\"{len(data)}. Skipping tag {ifd_tag}\"\n                                )\n                                continue\n\n                            if not data:\n                                continue\n\n                            makernote[ifd_tag] = handler(\n                                ImageFileDirectory_v2(), data, False\n                            )\n                        self._ifds[tag] = dict(self._fixup_dict(makernote))\n                    elif self.get(0x010F) == \"Nintendo\":\n                        makernote = {}\n                        for i in range(0, struct.unpack(\">H\", tag_data[:2])[0]):\n                            ifd_tag, typ, count, data = struct.unpack(\n                                \">HHL4s\", tag_data[i * 12 + 2 : (i + 1) * 12 + 2]\n                            )\n                            if ifd_tag == 0x1101:\n                                # CameraInfo\n                                (offset,) = struct.unpack(\">L\", data)\n                                self.fp.seek(offset)\n\n                                camerainfo = {\"ModelID\": self.fp.read(4)}\n\n                                self.fp.read(4)\n                                # Seconds since 2000\n                                camerainfo[\"TimeStamp\"] = i32le(self.fp.read(12))\n\n                                self.fp.read(4)\n                                camerainfo[\"InternalSerialNumber\"] = self.fp.read(4)\n\n                                self.fp.read(12)\n                                parallax = self.fp.read(4)\n                                handler = ImageFileDirectory_v2._load_dispatch[\n                                    TiffTags.FLOAT\n                                ][1]\n                                camerainfo[\"Parallax\"] = handler(\n                                    ImageFileDirectory_v2(), parallax, False\n                                )\n\n                                self.fp.read(4)\n                                camerainfo[\"Category\"] = self.fp.read(2)\n\n                                makernote = {0x1101: dict(self._fixup_dict(camerainfo))}\n                        self._ifds[tag] = makernote\n                else:\n                    # Interop\n                    self._ifds[tag] = self._get_ifd_dict(tag_data)\n        ifd = self._ifds.get(tag, {})\n        if tag == ExifTags.IFD.Exif and self._hidden_data:\n            ifd = {\n                k: v\n                for (k, v) in ifd.items()\n                if k not in (ExifTags.IFD.Interop, ExifTags.IFD.Makernote)\n            }\n        return ifd\n\n    def hide_offsets(self):\n        for tag in (ExifTags.IFD.Exif, ExifTags.IFD.GPSInfo):\n            if tag in self:\n                self._hidden_data[tag] = self[tag]\n                del self[tag]\n\n    def __str__(self):\n        if self._info is not None:\n            # Load all keys into self._data\n            for tag in self._info:\n                self[tag]\n\n        return str(self._data)\n\n    def __len__(self):\n        keys = set(self._data)\n        if self._info is not None:\n            keys.update(self._info)\n        return len(keys)\n\n    def __getitem__(self, tag):\n        if self._info is not None and tag not in self._data and tag in self._info:\n            self._data[tag] = self._fixup(self._info[tag])\n            del self._info[tag]\n        return self._data[tag]\n\n    def __contains__(self, tag):\n        return tag in self._data or (self._info is not None and tag in self._info)\n\n    def __setitem__(self, tag, value):\n        if self._info is not None and tag in self._info:\n            del self._info[tag]\n        self._data[tag] = value\n\n    def __delitem__(self, tag):\n        if self._info is not None and tag in self._info:\n            del self._info[tag]\n        else:\n            del self._data[tag]\n\n    def __iter__(self):\n        keys = set(self._data)\n        if self._info is not None:\n            keys.update(self._info)\n        return iter(keys)\n",3944],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\GifImagePlugin.py":["#\n# The Python Imaging Library.\n# $Id$\n#\n# GIF file handling\n#\n# History:\n# 1995-09-01 fl   Created\n# 1996-12-14 fl   Added interlace support\n# 1996-12-30 fl   Added animation support\n# 1997-01-05 fl   Added write support, fixed local colour map bug\n# 1997-02-23 fl   Make sure to load raster data in getdata()\n# 1997-07-05 fl   Support external decoder (0.4)\n# 1998-07-09 fl   Handle all modes when saving (0.5)\n# 1998-07-15 fl   Renamed offset attribute to avoid name clash\n# 2001-04-16 fl   Added rewind support (seek to frame 0) (0.6)\n# 2001-04-17 fl   Added palette optimization (0.7)\n# 2002-06-06 fl   Added transparency support for save (0.8)\n# 2004-02-24 fl   Disable interlacing for small images\n#\n# Copyright (c) 1997-2004 by Secret Labs AB\n# Copyright (c) 1995-2004 by Fredrik Lundh\n#\n# See the README file for information on usage and redistribution.\n#\nfrom __future__ import annotations\n\nimport itertools\nimport math\nimport os\nimport subprocess\nfrom enum import IntEnum\n\nfrom . import (\n    Image,\n    ImageChops,\n    ImageFile,\n    ImageMath,\n    ImageOps,\n    ImagePalette,\n    ImageSequence,\n)\nfrom ._binary import i16le as i16\nfrom ._binary import o8\nfrom ._binary import o16le as o16\n\n\nclass LoadingStrategy(IntEnum):\n    \"\"\".. versionadded:: 9.1.0\"\"\"\n\n    RGB_AFTER_FIRST = 0\n    RGB_AFTER_DIFFERENT_PALETTE_ONLY = 1\n    RGB_ALWAYS = 2\n\n\n#: .. versionadded:: 9.1.0\nLOADING_STRATEGY = LoadingStrategy.RGB_AFTER_FIRST\n\n# --------------------------------------------------------------------\n# Identify/read GIF files\n\n\ndef _accept(prefix):\n    return prefix[:6] in [b\"GIF87a\", b\"GIF89a\"]\n\n\n##\n# Image plugin for GIF images.  This plugin supports both GIF87 and\n# GIF89 images.\n\n\nclass GifImageFile(ImageFile.ImageFile):\n    format = \"GIF\"\n    format_description = \"Compuserve GIF\"\n    _close_exclusive_fp_after_loading = False\n\n    global_palette = None\n\n    def data(self):\n        s = self.fp.read(1)\n        if s and s[0]:\n            return self.fp.read(s[0])\n        return None\n\n    def _is_palette_needed(self, p):\n        for i in range(0, len(p), 3):\n            if not (i // 3 == p[i] == p[i + 1] == p[i + 2]):\n                return True\n        return False\n\n    def _open(self):\n        # Screen\n        s = self.fp.read(13)\n        if not _accept(s):\n            msg = \"not a GIF file\"\n            raise SyntaxError(msg)\n\n        self.info[\"version\"] = s[:6]\n        self._size = i16(s, 6), i16(s, 8)\n        self.tile = []\n        flags = s[10]\n        bits = (flags & 7) + 1\n\n        if flags & 128:\n            # get global palette\n            self.info[\"background\"] = s[11]\n            # check if palette contains colour indices\n            p = self.fp.read(3 << bits)\n            if self._is_palette_needed(p):\n                p = ImagePalette.raw(\"RGB\", p)\n                self.global_palette = self.palette = p\n\n        self._fp = self.fp  # FIXME: hack\n        self.__rewind = self.fp.tell()\n        self._n_frames = None\n        self._is_animated = None\n        self._seek(0)  # get ready to read first frame\n\n    @property\n    def n_frames(self):\n        if self._n_frames is None:\n            current = self.tell()\n            try:\n                while True:\n                    self._seek(self.tell() + 1, False)\n            except EOFError:\n                self._n_frames = self.tell() + 1\n            self.seek(current)\n        return self._n_frames\n\n    @property\n    def is_animated(self):\n        if self._is_animated is None:\n            if self._n_frames is not None:\n                self._is_animated = self._n_frames != 1\n            else:\n                current = self.tell()\n                if current:\n                    self._is_animated = True\n                else:\n                    try:\n                        self._seek(1, False)\n                        self._is_animated = True\n                    except EOFError:\n                        self._is_animated = False\n\n                    self.seek(current)\n        return self._is_animated\n\n    def seek(self, frame):\n        if not self._seek_check(frame):\n            return\n        if frame < self.__frame:\n            self.im = None\n            self._seek(0)\n\n        last_frame = self.__frame\n        for f in range(self.__frame + 1, frame + 1):\n            try:\n                self._seek(f)\n            except EOFError as e:\n                self.seek(last_frame)\n                msg = \"no more images in GIF file\"\n                raise EOFError(msg) from e\n\n    def _seek(self, frame, update_image=True):\n        if frame == 0:\n            # rewind\n            self.__offset = 0\n            self.dispose = None\n            self.__frame = -1\n            self._fp.seek(self.__rewind)\n            self.disposal_method = 0\n            if \"comment\" in self.info:\n                del self.info[\"comment\"]\n        else:\n            # ensure that the previous frame was loaded\n            if self.tile and update_image:\n                self.load()\n\n        if frame != self.__frame + 1:\n            msg = f\"cannot seek to frame {frame}\"\n            raise ValueError(msg)\n\n        self.fp = self._fp\n        if self.__offset:\n            # backup to last frame\n            self.fp.seek(self.__offset)\n            while self.data():\n                pass\n            self.__offset = 0\n\n        s = self.fp.read(1)\n        if not s or s == b\";\":\n            msg = \"no more images in GIF file\"\n            raise EOFError(msg)\n\n        palette = None\n\n        info = {}\n        frame_transparency = None\n        interlace = None\n        frame_dispose_extent = None\n        while True:\n            if not s:\n                s = self.fp.read(1)\n            if not s or s == b\";\":\n                break\n\n            elif s == b\"!\":\n                #\n                # extensions\n                #\n                s = self.fp.read(1)\n                block = self.data()\n                if s[0] == 249:\n                    #\n                    # graphic control extension\n                    #\n                    flags = block[0]\n                    if flags & 1:\n                        frame_transparency = block[3]\n                    info[\"duration\"] = i16(block, 1) * 10\n\n                    # disposal method - find the value of bits 4 - 6\n                    dispose_bits = 0b00011100 & flags\n                    dispose_bits = dispose_bits >> 2\n                    if dispose_bits:\n                        # only set the dispose if it is not\n                        # unspecified. I'm not sure if this is\n                        # correct, but it seems to prevent the last\n                        # frame from looking odd for some animations\n                        self.disposal_method = dispose_bits\n                elif s[0] == 254:\n                    #\n                    # comment extension\n                    #\n                    comment = b\"\"\n\n                    # Read this comment block\n                    while block:\n                        comment += block\n                        block = self.data()\n\n                    if \"comment\" in info:\n                        # If multiple comment blocks in frame, separate with \\n\n                        info[\"comment\"] += b\"\\n\" + comment\n                    else:\n                        info[\"comment\"] = comment\n                    s = None\n                    continue\n                elif s[0] == 255 and frame == 0:\n                    #\n                    # application extension\n                    #\n                    info[\"extension\"] = block, self.fp.tell()\n                    if block[:11] == b\"NETSCAPE2.0\":\n                        block = self.data()\n                        if len(block) >= 3 and block[0] == 1:\n                            self.info[\"loop\"] = i16(block, 1)\n                while self.data():\n                    pass\n\n            elif s == b\",\":\n                #\n                # local image\n                #\n                s = self.fp.read(9)\n\n                # extent\n                x0, y0 = i16(s, 0), i16(s, 2)\n                x1, y1 = x0 + i16(s, 4), y0 + i16(s, 6)\n                if (x1 > self.size[0] or y1 > self.size[1]) and update_image:\n                    self._size = max(x1, self.size[0]), max(y1, self.size[1])\n                    Image._decompression_bomb_check(self._size)\n                frame_dispose_extent = x0, y0, x1, y1\n                flags = s[8]\n\n                interlace = (flags & 64) != 0\n\n                if flags & 128:\n                    bits = (flags & 7) + 1\n                    p = self.fp.read(3 << bits)\n                    if self._is_palette_needed(p):\n                        palette = ImagePalette.raw(\"RGB\", p)\n                    else:\n                        palette = False\n\n                # image data\n                bits = self.fp.read(1)[0]\n                self.__offset = self.fp.tell()\n                break\n            s = None\n\n        if interlace is None:\n            msg = \"image not found in GIF frame\"\n            raise EOFError(msg)\n\n        self.__frame = frame\n        if not update_image:\n            return\n\n        self.tile = []\n\n        if self.dispose:\n            self.im.paste(self.dispose, self.dispose_extent)\n\n        self._frame_palette = palette if palette is not None else self.global_palette\n        self._frame_transparency = frame_transparency\n        if frame == 0:\n            if self._frame_palette:\n                if LOADING_STRATEGY == LoadingStrategy.RGB_ALWAYS:\n                    self._mode = \"RGBA\" if frame_transparency is not None else \"RGB\"\n                else:\n                    self._mode = \"P\"\n            else:\n                self._mode = \"L\"\n\n            if not palette and self.global_palette:\n                from copy import copy\n\n                palette = copy(self.global_palette)\n            self.palette = palette\n        else:\n            if self.mode == \"P\":\n                if (\n                    LOADING_STRATEGY != LoadingStrategy.RGB_AFTER_DIFFERENT_PALETTE_ONLY\n                    or palette\n                ):\n                    self.pyaccess = None\n                    if \"transparency\" in self.info:\n                        self.im.putpalettealpha(self.info[\"transparency\"], 0)\n                        self.im = self.im.convert(\"RGBA\", Image.Dither.FLOYDSTEINBERG)\n                        self._mode = \"RGBA\"\n                        del self.info[\"transparency\"]\n                    else:\n                        self._mode = \"RGB\"\n                        self.im = self.im.convert(\"RGB\", Image.Dither.FLOYDSTEINBERG)\n\n        def _rgb(color):\n            if self._frame_palette:\n                if color * 3 + 3 > len(self._frame_palette.palette):\n                    color = 0\n                color = tuple(self._frame_palette.palette[color * 3 : color * 3 + 3])\n            else:\n                color = (color, color, color)\n            return color\n\n        self.dispose_extent = frame_dispose_extent\n        try:\n            if self.disposal_method < 2:\n                # do not dispose or none specified\n                self.dispose = None\n            elif self.disposal_method == 2:\n                # replace with background colour\n\n                # only dispose the extent in this frame\n                x0, y0, x1, y1 = self.dispose_extent\n                dispose_size = (x1 - x0, y1 - y0)\n\n                Image._decompression_bomb_check(dispose_size)\n\n                # by convention, attempt to use transparency first\n                dispose_mode = \"P\"\n                color = self.info.get(\"transparency\", frame_transparency)\n                if color is not None:\n                    if self.mode in (\"RGB\", \"RGBA\"):\n                        dispose_mode = \"RGBA\"\n                        color = _rgb(color) + (0,)\n                else:\n                    color = self.info.get(\"background\", 0)\n                    if self.mode in (\"RGB\", \"RGBA\"):\n                        dispose_mode = \"RGB\"\n                        color = _rgb(color)\n                self.dispose = Image.core.fill(dispose_mode, dispose_size, color)\n            else:\n                # replace with previous contents\n                if self.im is not None:\n                    # only dispose the extent in this frame\n                    self.dispose = self._crop(self.im, self.dispose_extent)\n                elif frame_transparency is not None:\n                    x0, y0, x1, y1 = self.dispose_extent\n                    dispose_size = (x1 - x0, y1 - y0)\n\n                    Image._decompression_bomb_check(dispose_size)\n                    dispose_mode = \"P\"\n                    color = frame_transparency\n                    if self.mode in (\"RGB\", \"RGBA\"):\n                        dispose_mode = \"RGBA\"\n                        color = _rgb(frame_transparency) + (0,)\n                    self.dispose = Image.core.fill(dispose_mode, dispose_size, color)\n        except AttributeError:\n            pass\n\n        if interlace is not None:\n            transparency = -1\n            if frame_transparency is not None:\n                if frame == 0:\n                    if LOADING_STRATEGY != LoadingStrategy.RGB_ALWAYS:\n                        self.info[\"transparency\"] = frame_transparency\n                elif self.mode not in (\"RGB\", \"RGBA\"):\n                    transparency = frame_transparency\n            self.tile = [\n                (\n                    \"gif\",\n                    (x0, y0, x1, y1),\n                    self.__offset,\n                    (bits, interlace, transparency),\n                )\n            ]\n\n        if info.get(\"comment\"):\n            self.info[\"comment\"] = info[\"comment\"]\n        for k in [\"duration\", \"extension\"]:\n            if k in info:\n                self.info[k] = info[k]\n            elif k in self.info:\n                del self.info[k]\n\n    def load_prepare(self):\n        temp_mode = \"P\" if self._frame_palette else \"L\"\n        self._prev_im = None\n        if self.__frame == 0:\n            if self._frame_transparency is not None:\n                self.im = Image.core.fill(\n                    temp_mode, self.size, self._frame_transparency\n                )\n        elif self.mode in (\"RGB\", \"RGBA\"):\n            self._prev_im = self.im\n            if self._frame_palette:\n                self.im = Image.core.fill(\"P\", self.size, self._frame_transparency or 0)\n                self.im.putpalette(*self._frame_palette.getdata())\n            else:\n                self.im = None\n        self._mode = temp_mode\n        self._frame_palette = None\n\n        super().load_prepare()\n\n    def load_end(self):\n        if self.__frame == 0:\n            if self.mode == \"P\" and LOADING_STRATEGY == LoadingStrategy.RGB_ALWAYS:\n                if self._frame_transparency is not None:\n                    self.im.putpalettealpha(self._frame_transparency, 0)\n                    self._mode = \"RGBA\"\n                else:\n                    self._mode = \"RGB\"\n                self.im = self.im.convert(self.mode, Image.Dither.FLOYDSTEINBERG)\n            return\n        if not self._prev_im:\n            return\n        if self._frame_transparency is not None:\n            self.im.putpalettealpha(self._frame_transparency, 0)\n            frame_im = self.im.convert(\"RGBA\")\n        else:\n            frame_im = self.im.convert(\"RGB\")\n        frame_im = self._crop(frame_im, self.dispose_extent)\n\n        self.im = self._prev_im\n        self._mode = self.im.mode\n        if frame_im.mode == \"RGBA\":\n            self.im.paste(frame_im, self.dispose_extent, frame_im)\n        else:\n            self.im.paste(frame_im, self.dispose_extent)\n\n    def tell(self):\n        return self.__frame\n\n\n# --------------------------------------------------------------------\n# Write GIF files\n\n\nRAWMODE = {\"1\": \"L\", \"L\": \"L\", \"P\": \"P\"}\n\n\ndef _normalize_mode(im):\n    \"\"\"\n    Takes an image (or frame), returns an image in a mode that is appropriate\n    for saving in a Gif.\n\n    It may return the original image, or it may return an image converted to\n    palette or 'L' mode.\n\n    :param im: Image object\n    :returns: Image object\n    \"\"\"\n    if im.mode in RAWMODE:\n        im.load()\n        return im\n    if Image.getmodebase(im.mode) == \"RGB\":\n        im = im.convert(\"P\", palette=Image.Palette.ADAPTIVE)\n        if im.palette.mode == \"RGBA\":\n            for rgba in im.palette.colors:\n                if rgba[3] == 0:\n                    im.info[\"transparency\"] = im.palette.colors[rgba]\n                    break\n        return im\n    return im.convert(\"L\")\n\n\ndef _normalize_palette(im, palette, info):\n    \"\"\"\n    Normalizes the palette for image.\n      - Sets the palette to the incoming palette, if provided.\n      - Ensures that there's a palette for L mode images\n      - Optimizes the palette if necessary/desired.\n\n    :param im: Image object\n    :param palette: bytes object containing the source palette, or ....\n    :param info: encoderinfo\n    :returns: Image object\n    \"\"\"\n    source_palette = None\n    if palette:\n        # a bytes palette\n        if isinstance(palette, (bytes, bytearray, list)):\n            source_palette = bytearray(palette[:768])\n        if isinstance(palette, ImagePalette.ImagePalette):\n            source_palette = bytearray(palette.palette)\n\n    if im.mode == \"P\":\n        if not source_palette:\n            source_palette = im.im.getpalette(\"RGB\")[:768]\n    else:  # L-mode\n        if not source_palette:\n            source_palette = bytearray(i // 3 for i in range(768))\n        im.palette = ImagePalette.ImagePalette(\"RGB\", palette=source_palette)\n\n    if palette:\n        used_palette_colors = []\n        for i in range(0, len(source_palette), 3):\n            source_color = tuple(source_palette[i : i + 3])\n            index = im.palette.colors.get(source_color)\n            if index in used_palette_colors:\n                index = None\n            used_palette_colors.append(index)\n        for i, index in enumerate(used_palette_colors):\n            if index is None:\n                for j in range(len(used_palette_colors)):\n                    if j not in used_palette_colors:\n                        used_palette_colors[i] = j\n                        break\n        im = im.remap_palette(used_palette_colors)\n    else:\n        used_palette_colors = _get_optimize(im, info)\n        if used_palette_colors is not None:\n            im = im.remap_palette(used_palette_colors, source_palette)\n            if \"transparency\" in info:\n                try:\n                    info[\"transparency\"] = used_palette_colors.index(\n                        info[\"transparency\"]\n                    )\n                except ValueError:\n                    del info[\"transparency\"]\n            return im\n\n    im.palette.palette = source_palette\n    return im\n\n\ndef _write_single_frame(im, fp, palette):\n    im_out = _normalize_mode(im)\n    for k, v in im_out.info.items():\n        im.encoderinfo.setdefault(k, v)\n    im_out = _normalize_palette(im_out, palette, im.encoderinfo)\n\n    for s in _get_global_header(im_out, im.encoderinfo):\n        fp.write(s)\n\n    # local image header\n    flags = 0\n    if get_interlace(im):\n        flags = flags | 64\n    _write_local_header(fp, im, (0, 0), flags)\n\n    im_out.encoderconfig = (8, get_interlace(im))\n    ImageFile._save(im_out, fp, [(\"gif\", (0, 0) + im.size, 0, RAWMODE[im_out.mode])])\n\n    fp.write(b\"\\0\")  # end of image data\n\n\ndef _getbbox(base_im, im_frame):\n    if _get_palette_bytes(im_frame) != _get_palette_bytes(base_im):\n        im_frame = im_frame.convert(\"RGBA\")\n        base_im = base_im.convert(\"RGBA\")\n    delta = ImageChops.subtract_modulo(im_frame, base_im)\n    return delta, delta.getbbox(alpha_only=False)\n\n\ndef _write_multiple_frames(im, fp, palette):\n    duration = im.encoderinfo.get(\"duration\")\n    disposal = im.encoderinfo.get(\"disposal\", im.info.get(\"disposal\"))\n\n    im_frames = []\n    previous_im = None\n    frame_count = 0\n    background_im = None\n    for imSequence in itertools.chain([im], im.encoderinfo.get(\"append_images\", [])):\n        for im_frame in ImageSequence.Iterator(imSequence):\n            # a copy is required here since seek can still mutate the image\n            im_frame = _normalize_mode(im_frame.copy())\n            if frame_count == 0:\n                for k, v in im_frame.info.items():\n                    if k == \"transparency\":\n                        continue\n                    im.encoderinfo.setdefault(k, v)\n\n            encoderinfo = im.encoderinfo.copy()\n            if \"transparency\" in im_frame.info:\n                encoderinfo.setdefault(\"transparency\", im_frame.info[\"transparency\"])\n            im_frame = _normalize_palette(im_frame, palette, encoderinfo)\n            if isinstance(duration, (list, tuple)):\n                encoderinfo[\"duration\"] = duration[frame_count]\n            elif duration is None and \"duration\" in im_frame.info:\n                encoderinfo[\"duration\"] = im_frame.info[\"duration\"]\n            if isinstance(disposal, (list, tuple)):\n                encoderinfo[\"disposal\"] = disposal[frame_count]\n            frame_count += 1\n\n            diff_frame = None\n            if im_frames:\n                # delta frame\n                delta, bbox = _getbbox(previous_im, im_frame)\n                if not bbox:\n                    # This frame is identical to the previous frame\n                    if encoderinfo.get(\"duration\"):\n                        im_frames[-1][\"encoderinfo\"][\"duration\"] += encoderinfo[\n                            \"duration\"\n                        ]\n                    continue\n                if encoderinfo.get(\"disposal\") == 2:\n                    if background_im is None:\n                        color = im.encoderinfo.get(\n                            \"transparency\", im.info.get(\"transparency\", (0, 0, 0))\n                        )\n                        background = _get_background(im_frame, color)\n                        background_im = Image.new(\"P\", im_frame.size, background)\n                        background_im.putpalette(im_frames[0][\"im\"].palette)\n                    delta, bbox = _getbbox(background_im, im_frame)\n                if encoderinfo.get(\"optimize\") and im_frame.mode != \"1\":\n                    if \"transparency\" not in encoderinfo:\n                        try:\n                            encoderinfo[\n                                \"transparency\"\n                            ] = im_frame.palette._new_color_index(im_frame)\n                        except ValueError:\n                            pass\n                    if \"transparency\" in encoderinfo:\n                        # When the delta is zero, fill the image with transparency\n                        diff_frame = im_frame.copy()\n                        fill = Image.new(\n                            \"P\", diff_frame.size, encoderinfo[\"transparency\"]\n                        )\n                        if delta.mode == \"RGBA\":\n                            r, g, b, a = delta.split()\n                            mask = ImageMath.eval(\n                                \"convert(max(max(max(r, g), b), a) * 255, '1')\",\n                                r=r,\n                                g=g,\n                                b=b,\n                                a=a,\n                            )\n                        else:\n                            if delta.mode == \"P\":\n                                # Convert to L without considering palette\n                                delta_l = Image.new(\"L\", delta.size)\n                                delta_l.putdata(delta.getdata())\n                                delta = delta_l\n                            mask = ImageMath.eval(\"convert(im * 255, '1')\", im=delta)\n                        diff_frame.paste(fill, mask=ImageOps.invert(mask))\n            else:\n                bbox = None\n            previous_im = im_frame\n            im_frames.append(\n                {\"im\": diff_frame or im_frame, \"bbox\": bbox, \"encoderinfo\": encoderinfo}\n            )\n\n    if len(im_frames) == 1:\n        if \"duration\" in im.encoderinfo:\n            # Since multiple frames will not be written, use the combined duration\n            im.encoderinfo[\"duration\"] = im_frames[0][\"encoderinfo\"][\"duration\"]\n        return\n\n    for frame_data in im_frames:\n        im_frame = frame_data[\"im\"]\n        if not frame_data[\"bbox\"]:\n            # global header\n            for s in _get_global_header(im_frame, frame_data[\"encoderinfo\"]):\n                fp.write(s)\n            offset = (0, 0)\n        else:\n            # compress difference\n            if not palette:\n                frame_data[\"encoderinfo\"][\"include_color_table\"] = True\n\n            im_frame = im_frame.crop(frame_data[\"bbox\"])\n            offset = frame_data[\"bbox\"][:2]\n        _write_frame_data(fp, im_frame, offset, frame_data[\"encoderinfo\"])\n    return True\n\n\ndef _save_all(im, fp, filename):\n    _save(im, fp, filename, save_all=True)\n\n\ndef _save(im, fp, filename, save_all=False):\n    # header\n    if \"palette\" in im.encoderinfo or \"palette\" in im.info:\n        palette = im.encoderinfo.get(\"palette\", im.info.get(\"palette\"))\n    else:\n        palette = None\n        im.encoderinfo.setdefault(\"optimize\", True)\n\n    if not save_all or not _write_multiple_frames(im, fp, palette):\n        _write_single_frame(im, fp, palette)\n\n    fp.write(b\";\")  # end of file\n\n    if hasattr(fp, \"flush\"):\n        fp.flush()\n\n\ndef get_interlace(im):\n    interlace = im.encoderinfo.get(\"interlace\", 1)\n\n    # workaround for @PIL153\n    if min(im.size) < 16:\n        interlace = 0\n\n    return interlace\n\n\ndef _write_local_header(fp, im, offset, flags):\n    try:\n        transparency = im.encoderinfo[\"transparency\"]\n    except KeyError:\n        transparency = None\n\n    if \"duration\" in im.encoderinfo:\n        duration = int(im.encoderinfo[\"duration\"] / 10)\n    else:\n        duration = 0\n\n    disposal = int(im.encoderinfo.get(\"disposal\", 0))\n\n    if transparency is not None or duration != 0 or disposal:\n        packed_flag = 1 if transparency is not None else 0\n        packed_flag |= disposal << 2\n\n        fp.write(\n            b\"!\"\n            + o8(249)  # extension intro\n            + o8(4)  # length\n            + o8(packed_flag)  # packed fields\n            + o16(duration)  # duration\n            + o8(transparency or 0)  # transparency index\n            + o8(0)\n        )\n\n    include_color_table = im.encoderinfo.get(\"include_color_table\")\n    if include_color_table:\n        palette_bytes = _get_palette_bytes(im)\n        color_table_size = _get_color_table_size(palette_bytes)\n        if color_table_size:\n            flags = flags | 128  # local color table flag\n            flags = flags | color_table_size\n\n    fp.write(\n        b\",\"\n        + o16(offset[0])  # offset\n        + o16(offset[1])\n        + o16(im.size[0])  # size\n        + o16(im.size[1])\n        + o8(flags)  # flags\n    )\n    if include_color_table and color_table_size:\n        fp.write(_get_header_palette(palette_bytes))\n    fp.write(o8(8))  # bits\n\n\ndef _save_netpbm(im, fp, filename):\n    # Unused by default.\n    # To use, uncomment the register_save call at the end of the file.\n    #\n    # If you need real GIF compression and/or RGB quantization, you\n    # can use the external NETPBM/PBMPLUS utilities.  See comments\n    # below for information on how to enable this.\n    tempfile = im._dump()\n\n    try:\n        with open(filename, \"wb\") as f:\n            if im.mode != \"RGB\":\n                subprocess.check_call(\n                    [\"ppmtogif\", tempfile], stdout=f, stderr=subprocess.DEVNULL\n                )\n            else:\n                # Pipe ppmquant output into ppmtogif\n                # \"ppmquant 256 %s | ppmtogif > %s\" % (tempfile, filename)\n                quant_cmd = [\"ppmquant\", \"256\", tempfile]\n                togif_cmd = [\"ppmtogif\"]\n                quant_proc = subprocess.Popen(\n                    quant_cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL\n                )\n                togif_proc = subprocess.Popen(\n                    togif_cmd,\n                    stdin=quant_proc.stdout,\n                    stdout=f,\n                    stderr=subprocess.DEVNULL,\n                )\n\n                # Allow ppmquant to receive SIGPIPE if ppmtogif exits\n                quant_proc.stdout.close()\n\n                retcode = quant_proc.wait()\n                if retcode:\n                    raise subprocess.CalledProcessError(retcode, quant_cmd)\n\n                retcode = togif_proc.wait()\n                if retcode:\n                    raise subprocess.CalledProcessError(retcode, togif_cmd)\n    finally:\n        try:\n            os.unlink(tempfile)\n        except OSError:\n            pass\n\n\n# Force optimization so that we can test performance against\n# cases where it took lots of memory and time previously.\n_FORCE_OPTIMIZE = False\n\n\ndef _get_optimize(im, info):\n    \"\"\"\n    Palette optimization is a potentially expensive operation.\n\n    This function determines if the palette should be optimized using\n    some heuristics, then returns the list of palette entries in use.\n\n    :param im: Image object\n    :param info: encoderinfo\n    :returns: list of indexes of palette entries in use, or None\n    \"\"\"\n    if im.mode in (\"P\", \"L\") and info and info.get(\"optimize\"):\n        # Potentially expensive operation.\n\n        # The palette saves 3 bytes per color not used, but palette\n        # lengths are restricted to 3*(2**N) bytes. Max saving would\n        # be 768 -> 6 bytes if we went all the way down to 2 colors.\n        # * If we're over 128 colors, we can't save any space.\n        # * If there aren't any holes, it's not worth collapsing.\n        # * If we have a 'large' image, the palette is in the noise.\n\n        # create the new palette if not every color is used\n        optimise = _FORCE_OPTIMIZE or im.mode == \"L\"\n        if optimise or im.width * im.height < 512 * 512:\n            # check which colors are used\n            used_palette_colors = []\n            for i, count in enumerate(im.histogram()):\n                if count:\n                    used_palette_colors.append(i)\n\n            if optimise or max(used_palette_colors) >= len(used_palette_colors):\n                return used_palette_colors\n\n            num_palette_colors = len(im.palette.palette) // Image.getmodebands(\n                im.palette.mode\n            )\n            current_palette_size = 1 << (num_palette_colors - 1).bit_length()\n            if (\n                # check that the palette would become smaller when saved\n                len(used_palette_colors) <= current_palette_size // 2\n                # check that the palette is not already the smallest possible size\n                and current_palette_size > 2\n            ):\n                return used_palette_colors\n\n\ndef _get_color_table_size(palette_bytes):\n    # calculate the palette size for the header\n    if not palette_bytes:\n        return 0\n    elif len(palette_bytes) < 9:\n        return 1\n    else:\n        return math.ceil(math.log(len(palette_bytes) // 3, 2)) - 1\n\n\ndef _get_header_palette(palette_bytes):\n    \"\"\"\n    Returns the palette, null padded to the next power of 2 (*3) bytes\n    suitable for direct inclusion in the GIF header\n\n    :param palette_bytes: Unpadded palette bytes, in RGBRGB form\n    :returns: Null padded palette\n    \"\"\"\n    color_table_size = _get_color_table_size(palette_bytes)\n\n    # add the missing amount of bytes\n    # the palette has to be 2<<n in size\n    actual_target_size_diff = (2 << color_table_size) - len(palette_bytes) // 3\n    if actual_target_size_diff > 0:\n        palette_bytes += o8(0) * 3 * actual_target_size_diff\n    return palette_bytes\n\n\ndef _get_palette_bytes(im):\n    \"\"\"\n    Gets the palette for inclusion in the gif header\n\n    :param im: Image object\n    :returns: Bytes, len<=768 suitable for inclusion in gif header\n    \"\"\"\n    return im.palette.palette if im.palette else b\"\"\n\n\ndef _get_background(im, info_background):\n    background = 0\n    if info_background:\n        if isinstance(info_background, tuple):\n            # WebPImagePlugin stores an RGBA value in info[\"background\"]\n            # So it must be converted to the same format as GifImagePlugin's\n            # info[\"background\"] - a global color table index\n            try:\n                background = im.palette.getcolor(info_background, im)\n            except ValueError as e:\n                if str(e) not in (\n                    # If all 256 colors are in use,\n                    # then there is no need for the background color\n                    \"cannot allocate more than 256 colors\",\n                    # Ignore non-opaque WebP background\n                    \"cannot add non-opaque RGBA color to RGB palette\",\n                ):\n                    raise\n        else:\n            background = info_background\n    return background\n\n\ndef _get_global_header(im, info):\n    \"\"\"Return a list of strings representing a GIF header\"\"\"\n\n    # Header Block\n    # https://www.matthewflickinger.com/lab/whatsinagif/bits_and_bytes.asp\n\n    version = b\"87a\"\n    if im.info.get(\"version\") == b\"89a\" or (\n        info\n        and (\n            \"transparency\" in info\n            or info.get(\"loop\") is not None\n            or info.get(\"duration\")\n            or info.get(\"comment\")\n        )\n    ):\n        version = b\"89a\"\n\n    background = _get_background(im, info.get(\"background\"))\n\n    palette_bytes = _get_palette_bytes(im)\n    color_table_size = _get_color_table_size(palette_bytes)\n\n    header = [\n        b\"GIF\"  # signature\n        + version  # version\n        + o16(im.size[0])  # canvas width\n        + o16(im.size[1]),  # canvas height\n        # Logical Screen Descriptor\n        # size of global color table + global color table flag\n        o8(color_table_size + 128),  # packed fields\n        # background + reserved/aspect\n        o8(background) + o8(0),\n        # Global Color Table\n        _get_header_palette(palette_bytes),\n    ]\n    if info.get(\"loop\") is not None:\n        header.append(\n            b\"!\"\n            + o8(255)  # extension intro\n            + o8(11)\n            + b\"NETSCAPE2.0\"\n            + o8(3)\n            + o8(1)\n            + o16(info[\"loop\"])  # number of loops\n            + o8(0)\n        )\n    if info.get(\"comment\"):\n        comment_block = b\"!\" + o8(254)  # extension intro\n\n        comment = info[\"comment\"]\n        if isinstance(comment, str):\n            comment = comment.encode()\n        for i in range(0, len(comment), 255):\n            subblock = comment[i : i + 255]\n            comment_block += o8(len(subblock)) + subblock\n\n        comment_block += o8(0)\n        header.append(comment_block)\n    return header\n\n\ndef _write_frame_data(fp, im_frame, offset, params):\n    try:\n        im_frame.encoderinfo = params\n\n        # local image header\n        _write_local_header(fp, im_frame, offset, 0)\n\n        ImageFile._save(\n            im_frame, fp, [(\"gif\", (0, 0) + im_frame.size, 0, RAWMODE[im_frame.mode])]\n        )\n\n        fp.write(b\"\\0\")  # end of image data\n    finally:\n        del im_frame.encoderinfo\n\n\n# --------------------------------------------------------------------\n# Legacy GIF utilities\n\n\ndef getheader(im, palette=None, info=None):\n    \"\"\"\n    Legacy Method to get Gif data from image.\n\n    Warning:: May modify image data.\n\n    :param im: Image object\n    :param palette: bytes object containing the source palette, or ....\n    :param info: encoderinfo\n    :returns: tuple of(list of header items, optimized palette)\n\n    \"\"\"\n    used_palette_colors = _get_optimize(im, info)\n\n    if info is None:\n        info = {}\n\n    if \"background\" not in info and \"background\" in im.info:\n        info[\"background\"] = im.info[\"background\"]\n\n    im_mod = _normalize_palette(im, palette, info)\n    im.palette = im_mod.palette\n    im.im = im_mod.im\n    header = _get_global_header(im, info)\n\n    return header, used_palette_colors\n\n\ndef getdata(im, offset=(0, 0), **params):\n    \"\"\"\n    Legacy Method\n\n    Return a list of strings representing this image.\n    The first string is a local image header, the rest contains\n    encoded image data.\n\n    To specify duration, add the time in milliseconds,\n    e.g. ``getdata(im_frame, duration=1000)``\n\n    :param im: Image object\n    :param offset: Tuple of (x, y) pixels. Defaults to (0, 0)\n    :param \\\\**params: e.g. duration or other encoder info parameters\n    :returns: List of bytes containing GIF encoded frame data\n\n    \"\"\"\n\n    class Collector:\n        data = []\n\n        def write(self, data):\n            self.data.append(data)\n\n    im.load()  # make sure raster data is available\n\n    fp = Collector()\n\n    _write_frame_data(fp, im, offset, params)\n\n    return fp.data\n\n\n# --------------------------------------------------------------------\n# Registry\n\nImage.register_open(GifImageFile.format, GifImageFile, _accept)\nImage.register_save(GifImageFile.format, _save)\nImage.register_save_all(GifImageFile.format, _save_all)\nImage.register_extension(GifImageFile.format, \".gif\")\nImage.register_mime(GifImageFile.format, \"image/gif\")\n\n#\n# Uncomment the following line if you wish to use NETPBM/PBMPLUS\n# instead of the built-in \"uncompressed\" GIF encoder\n\n# Image.register_save(GifImageFile.format, _save_netpbm)\n",1097],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\BmpImagePlugin.py":["#\n# The Python Imaging Library.\n# $Id$\n#\n# BMP file handler\n#\n# Windows (and OS/2) native bitmap storage format.\n#\n# history:\n# 1995-09-01 fl   Created\n# 1996-04-30 fl   Added save\n# 1997-08-27 fl   Fixed save of 1-bit images\n# 1998-03-06 fl   Load P images as L where possible\n# 1998-07-03 fl   Load P images as 1 where possible\n# 1998-12-29 fl   Handle small palettes\n# 2002-12-30 fl   Fixed load of 1-bit palette images\n# 2003-04-21 fl   Fixed load of 1-bit monochrome images\n# 2003-04-23 fl   Added limited support for BI_BITFIELDS compression\n#\n# Copyright (c) 1997-2003 by Secret Labs AB\n# Copyright (c) 1995-2003 by Fredrik Lundh\n#\n# See the README file for information on usage and redistribution.\n#\nfrom __future__ import annotations\n\nimport os\n\nfrom . import Image, ImageFile, ImagePalette\nfrom ._binary import i16le as i16\nfrom ._binary import i32le as i32\nfrom ._binary import o8\nfrom ._binary import o16le as o16\nfrom ._binary import o32le as o32\n\n#\n# --------------------------------------------------------------------\n# Read BMP file\n\nBIT2MODE = {\n    # bits => mode, rawmode\n    1: (\"P\", \"P;1\"),\n    4: (\"P\", \"P;4\"),\n    8: (\"P\", \"P\"),\n    16: (\"RGB\", \"BGR;15\"),\n    24: (\"RGB\", \"BGR\"),\n    32: (\"RGB\", \"BGRX\"),\n}\n\n\ndef _accept(prefix):\n    return prefix[:2] == b\"BM\"\n\n\ndef _dib_accept(prefix):\n    return i32(prefix) in [12, 40, 64, 108, 124]\n\n\n# =============================================================================\n# Image plugin for the Windows BMP format.\n# =============================================================================\nclass BmpImageFile(ImageFile.ImageFile):\n    \"\"\"Image plugin for the Windows Bitmap format (BMP)\"\"\"\n\n    # ------------------------------------------------------------- Description\n    format_description = \"Windows Bitmap\"\n    format = \"BMP\"\n\n    # -------------------------------------------------- BMP Compression values\n    COMPRESSIONS = {\"RAW\": 0, \"RLE8\": 1, \"RLE4\": 2, \"BITFIELDS\": 3, \"JPEG\": 4, \"PNG\": 5}\n    for k, v in COMPRESSIONS.items():\n        vars()[k] = v\n\n    def _bitmap(self, header=0, offset=0):\n        \"\"\"Read relevant info about the BMP\"\"\"\n        read, seek = self.fp.read, self.fp.seek\n        if header:\n            seek(header)\n        # read bmp header size @offset 14 (this is part of the header size)\n        file_info = {\"header_size\": i32(read(4)), \"direction\": -1}\n\n        # -------------------- If requested, read header at a specific position\n        # read the rest of the bmp header, without its size\n        header_data = ImageFile._safe_read(self.fp, file_info[\"header_size\"] - 4)\n\n        # -------------------------------------------------- IBM OS/2 Bitmap v1\n        # ----- This format has different offsets because of width/height types\n        if file_info[\"header_size\"] == 12:\n            file_info[\"width\"] = i16(header_data, 0)\n            file_info[\"height\"] = i16(header_data, 2)\n            file_info[\"planes\"] = i16(header_data, 4)\n            file_info[\"bits\"] = i16(header_data, 6)\n            file_info[\"compression\"] = self.RAW\n            file_info[\"palette_padding\"] = 3\n\n        # --------------------------------------------- Windows Bitmap v2 to v5\n        # v3, OS/2 v2, v4, v5\n        elif file_info[\"header_size\"] in (40, 64, 108, 124):\n            file_info[\"y_flip\"] = header_data[7] == 0xFF\n            file_info[\"direction\"] = 1 if file_info[\"y_flip\"] else -1\n            file_info[\"width\"] = i32(header_data, 0)\n            file_info[\"height\"] = (\n                i32(header_data, 4)\n                if not file_info[\"y_flip\"]\n                else 2**32 - i32(header_data, 4)\n            )\n            file_info[\"planes\"] = i16(header_data, 8)\n            file_info[\"bits\"] = i16(header_data, 10)\n            file_info[\"compression\"] = i32(header_data, 12)\n            # byte size of pixel data\n            file_info[\"data_size\"] = i32(header_data, 16)\n            file_info[\"pixels_per_meter\"] = (\n                i32(header_data, 20),\n                i32(header_data, 24),\n            )\n            file_info[\"colors\"] = i32(header_data, 28)\n            file_info[\"palette_padding\"] = 4\n            self.info[\"dpi\"] = tuple(x / 39.3701 for x in file_info[\"pixels_per_meter\"])\n            if file_info[\"compression\"] == self.BITFIELDS:\n                if len(header_data) >= 52:\n                    for idx, mask in enumerate(\n                        [\"r_mask\", \"g_mask\", \"b_mask\", \"a_mask\"]\n                    ):\n                        file_info[mask] = i32(header_data, 36 + idx * 4)\n                else:\n                    # 40 byte headers only have the three components in the\n                    # bitfields masks, ref:\n                    # https://msdn.microsoft.com/en-us/library/windows/desktop/dd183376(v=vs.85).aspx\n                    # See also\n                    # https://github.com/python-pillow/Pillow/issues/1293\n                    # There is a 4th component in the RGBQuad, in the alpha\n                    # location, but it is listed as a reserved component,\n                    # and it is not generally an alpha channel\n                    file_info[\"a_mask\"] = 0x0\n                    for mask in [\"r_mask\", \"g_mask\", \"b_mask\"]:\n                        file_info[mask] = i32(read(4))\n                file_info[\"rgb_mask\"] = (\n                    file_info[\"r_mask\"],\n                    file_info[\"g_mask\"],\n                    file_info[\"b_mask\"],\n                )\n                file_info[\"rgba_mask\"] = (\n                    file_info[\"r_mask\"],\n                    file_info[\"g_mask\"],\n                    file_info[\"b_mask\"],\n                    file_info[\"a_mask\"],\n                )\n        else:\n            msg = f\"Unsupported BMP header type ({file_info['header_size']})\"\n            raise OSError(msg)\n\n        # ------------------ Special case : header is reported 40, which\n        # ---------------------- is shorter than real size for bpp >= 16\n        self._size = file_info[\"width\"], file_info[\"height\"]\n\n        # ------- If color count was not found in the header, compute from bits\n        file_info[\"colors\"] = (\n            file_info[\"colors\"]\n            if file_info.get(\"colors\", 0)\n            else (1 << file_info[\"bits\"])\n        )\n        if offset == 14 + file_info[\"header_size\"] and file_info[\"bits\"] <= 8:\n            offset += 4 * file_info[\"colors\"]\n\n        # ---------------------- Check bit depth for unusual unsupported values\n        self._mode, raw_mode = BIT2MODE.get(file_info[\"bits\"], (None, None))\n        if self.mode is None:\n            msg = f\"Unsupported BMP pixel depth ({file_info['bits']})\"\n            raise OSError(msg)\n\n        # ---------------- Process BMP with Bitfields compression (not palette)\n        decoder_name = \"raw\"\n        if file_info[\"compression\"] == self.BITFIELDS:\n            SUPPORTED = {\n                32: [\n                    (0xFF0000, 0xFF00, 0xFF, 0x0),\n                    (0xFF000000, 0xFF0000, 0xFF00, 0x0),\n                    (0xFF000000, 0xFF0000, 0xFF00, 0xFF),\n                    (0xFF, 0xFF00, 0xFF0000, 0xFF000000),\n                    (0xFF0000, 0xFF00, 0xFF, 0xFF000000),\n                    (0x0, 0x0, 0x0, 0x0),\n                ],\n                24: [(0xFF0000, 0xFF00, 0xFF)],\n                16: [(0xF800, 0x7E0, 0x1F), (0x7C00, 0x3E0, 0x1F)],\n            }\n            MASK_MODES = {\n                (32, (0xFF0000, 0xFF00, 0xFF, 0x0)): \"BGRX\",\n                (32, (0xFF000000, 0xFF0000, 0xFF00, 0x0)): \"XBGR\",\n                (32, (0xFF000000, 0xFF0000, 0xFF00, 0xFF)): \"ABGR\",\n                (32, (0xFF, 0xFF00, 0xFF0000, 0xFF000000)): \"RGBA\",\n                (32, (0xFF0000, 0xFF00, 0xFF, 0xFF000000)): \"BGRA\",\n                (32, (0x0, 0x0, 0x0, 0x0)): \"BGRA\",\n                (24, (0xFF0000, 0xFF00, 0xFF)): \"BGR\",\n                (16, (0xF800, 0x7E0, 0x1F)): \"BGR;16\",\n                (16, (0x7C00, 0x3E0, 0x1F)): \"BGR;15\",\n            }\n            if file_info[\"bits\"] in SUPPORTED:\n                if (\n                    file_info[\"bits\"] == 32\n                    and file_info[\"rgba_mask\"] in SUPPORTED[file_info[\"bits\"]]\n                ):\n                    raw_mode = MASK_MODES[(file_info[\"bits\"], file_info[\"rgba_mask\"])]\n                    self._mode = \"RGBA\" if \"A\" in raw_mode else self.mode\n                elif (\n                    file_info[\"bits\"] in (24, 16)\n                    and file_info[\"rgb_mask\"] in SUPPORTED[file_info[\"bits\"]]\n                ):\n                    raw_mode = MASK_MODES[(file_info[\"bits\"], file_info[\"rgb_mask\"])]\n                else:\n                    msg = \"Unsupported BMP bitfields layout\"\n                    raise OSError(msg)\n            else:\n                msg = \"Unsupported BMP bitfields layout\"\n                raise OSError(msg)\n        elif file_info[\"compression\"] == self.RAW:\n            if file_info[\"bits\"] == 32 and header == 22:  # 32-bit .cur offset\n                raw_mode, self._mode = \"BGRA\", \"RGBA\"\n        elif file_info[\"compression\"] in (self.RLE8, self.RLE4):\n            decoder_name = \"bmp_rle\"\n        else:\n            msg = f\"Unsupported BMP compression ({file_info['compression']})\"\n            raise OSError(msg)\n\n        # --------------- Once the header is processed, process the palette/LUT\n        if self.mode == \"P\":  # Paletted for 1, 4 and 8 bit images\n            # ---------------------------------------------------- 1-bit images\n            if not (0 < file_info[\"colors\"] <= 65536):\n                msg = f\"Unsupported BMP Palette size ({file_info['colors']})\"\n                raise OSError(msg)\n            else:\n                padding = file_info[\"palette_padding\"]\n                palette = read(padding * file_info[\"colors\"])\n                grayscale = True\n                indices = (\n                    (0, 255)\n                    if file_info[\"colors\"] == 2\n                    else list(range(file_info[\"colors\"]))\n                )\n\n                # ----------------- Check if grayscale and ignore palette if so\n                for ind, val in enumerate(indices):\n                    rgb = palette[ind * padding : ind * padding + 3]\n                    if rgb != o8(val) * 3:\n                        grayscale = False\n\n                # ------- If all colors are gray, white or black, ditch palette\n                if grayscale:\n                    self._mode = \"1\" if file_info[\"colors\"] == 2 else \"L\"\n                    raw_mode = self.mode\n                else:\n                    self._mode = \"P\"\n                    self.palette = ImagePalette.raw(\n                        \"BGRX\" if padding == 4 else \"BGR\", palette\n                    )\n\n        # ---------------------------- Finally set the tile data for the plugin\n        self.info[\"compression\"] = file_info[\"compression\"]\n        args = [raw_mode]\n        if decoder_name == \"bmp_rle\":\n            args.append(file_info[\"compression\"] == self.RLE4)\n        else:\n            args.append(((file_info[\"width\"] * file_info[\"bits\"] + 31) >> 3) & (~3))\n        args.append(file_info[\"direction\"])\n        self.tile = [\n            (\n                decoder_name,\n                (0, 0, file_info[\"width\"], file_info[\"height\"]),\n                offset or self.fp.tell(),\n                tuple(args),\n            )\n        ]\n\n    def _open(self):\n        \"\"\"Open file, check magic number and read header\"\"\"\n        # read 14 bytes: magic number, filesize, reserved, header final offset\n        head_data = self.fp.read(14)\n        # choke if the file does not have the required magic bytes\n        if not _accept(head_data):\n            msg = \"Not a BMP file\"\n            raise SyntaxError(msg)\n        # read the start position of the BMP image data (u32)\n        offset = i32(head_data, 10)\n        # load bitmap information (offset=raster info)\n        self._bitmap(offset=offset)\n\n\nclass BmpRleDecoder(ImageFile.PyDecoder):\n    _pulls_fd = True\n\n    def decode(self, buffer):\n        rle4 = self.args[1]\n        data = bytearray()\n        x = 0\n        while len(data) < self.state.xsize * self.state.ysize:\n            pixels = self.fd.read(1)\n            byte = self.fd.read(1)\n            if not pixels or not byte:\n                break\n            num_pixels = pixels[0]\n            if num_pixels:\n                # encoded mode\n                if x + num_pixels > self.state.xsize:\n                    # Too much data for row\n                    num_pixels = max(0, self.state.xsize - x)\n                if rle4:\n                    first_pixel = o8(byte[0] >> 4)\n                    second_pixel = o8(byte[0] & 0x0F)\n                    for index in range(num_pixels):\n                        if index % 2 == 0:\n                            data += first_pixel\n                        else:\n                            data += second_pixel\n                else:\n                    data += byte * num_pixels\n                x += num_pixels\n            else:\n                if byte[0] == 0:\n                    # end of line\n                    while len(data) % self.state.xsize != 0:\n                        data += b\"\\x00\"\n                    x = 0\n                elif byte[0] == 1:\n                    # end of bitmap\n                    break\n                elif byte[0] == 2:\n                    # delta\n                    bytes_read = self.fd.read(2)\n                    if len(bytes_read) < 2:\n                        break\n                    right, up = self.fd.read(2)\n                    data += b\"\\x00\" * (right + up * self.state.xsize)\n                    x = len(data) % self.state.xsize\n                else:\n                    # absolute mode\n                    if rle4:\n                        # 2 pixels per byte\n                        byte_count = byte[0] // 2\n                        bytes_read = self.fd.read(byte_count)\n                        for byte_read in bytes_read:\n                            data += o8(byte_read >> 4)\n                            data += o8(byte_read & 0x0F)\n                    else:\n                        byte_count = byte[0]\n                        bytes_read = self.fd.read(byte_count)\n                        data += bytes_read\n                    if len(bytes_read) < byte_count:\n                        break\n                    x += byte[0]\n\n                    # align to 16-bit word boundary\n                    if self.fd.tell() % 2 != 0:\n                        self.fd.seek(1, os.SEEK_CUR)\n        rawmode = \"L\" if self.mode == \"L\" else \"P\"\n        self.set_as_raw(bytes(data), (rawmode, 0, self.args[-1]))\n        return -1, 0\n\n\n# =============================================================================\n# Image plugin for the DIB format (BMP alias)\n# =============================================================================\nclass DibImageFile(BmpImageFile):\n    format = \"DIB\"\n    format_description = \"Windows Bitmap\"\n\n    def _open(self):\n        self._bitmap()\n\n\n#\n# --------------------------------------------------------------------\n# Write BMP file\n\n\nSAVE = {\n    \"1\": (\"1\", 1, 2),\n    \"L\": (\"L\", 8, 256),\n    \"P\": (\"P\", 8, 256),\n    \"RGB\": (\"BGR\", 24, 0),\n    \"RGBA\": (\"BGRA\", 32, 0),\n}\n\n\ndef _dib_save(im, fp, filename):\n    _save(im, fp, filename, False)\n\n\ndef _save(im, fp, filename, bitmap_header=True):\n    try:\n        rawmode, bits, colors = SAVE[im.mode]\n    except KeyError as e:\n        msg = f\"cannot write mode {im.mode} as BMP\"\n        raise OSError(msg) from e\n\n    info = im.encoderinfo\n\n    dpi = info.get(\"dpi\", (96, 96))\n\n    # 1 meter == 39.3701 inches\n    ppm = tuple(int(x * 39.3701 + 0.5) for x in dpi)\n\n    stride = ((im.size[0] * bits + 7) // 8 + 3) & (~3)\n    header = 40  # or 64 for OS/2 version 2\n    image = stride * im.size[1]\n\n    if im.mode == \"1\":\n        palette = b\"\".join(o8(i) * 4 for i in (0, 255))\n    elif im.mode == \"L\":\n        palette = b\"\".join(o8(i) * 4 for i in range(256))\n    elif im.mode == \"P\":\n        palette = im.im.getpalette(\"RGB\", \"BGRX\")\n        colors = len(palette) // 4\n    else:\n        palette = None\n\n    # bitmap header\n    if bitmap_header:\n        offset = 14 + header + colors * 4\n        file_size = offset + image\n        if file_size > 2**32 - 1:\n            msg = \"File size is too large for the BMP format\"\n            raise ValueError(msg)\n        fp.write(\n            b\"BM\"  # file type (magic)\n            + o32(file_size)  # file size\n            + o32(0)  # reserved\n            + o32(offset)  # image data offset\n        )\n\n    # bitmap info header\n    fp.write(\n        o32(header)  # info header size\n        + o32(im.size[0])  # width\n        + o32(im.size[1])  # height\n        + o16(1)  # planes\n        + o16(bits)  # depth\n        + o32(0)  # compression (0=uncompressed)\n        + o32(image)  # size of bitmap\n        + o32(ppm[0])  # resolution\n        + o32(ppm[1])  # resolution\n        + o32(colors)  # colors used\n        + o32(colors)  # colors important\n    )\n\n    fp.write(b\"\\0\" * (header - 40))  # padding (for OS/2 format)\n\n    if palette:\n        fp.write(palette)\n\n    ImageFile._save(im, fp, [(\"raw\", (0, 0) + im.size, 0, (rawmode, stride, -1))])\n\n\n#\n# --------------------------------------------------------------------\n# Registry\n\n\nImage.register_open(BmpImageFile.format, BmpImageFile, _accept)\nImage.register_save(BmpImageFile.format, _save)\n\nImage.register_extension(BmpImageFile.format, \".bmp\")\n\nImage.register_mime(BmpImageFile.format, \"image/bmp\")\n\nImage.register_decoder(\"bmp_rle\", BmpRleDecoder)\n\nImage.register_open(DibImageFile.format, DibImageFile, _dib_accept)\nImage.register_save(DibImageFile.format, _dib_save)\n\nImage.register_extension(DibImageFile.format, \".dib\")\n\nImage.register_mime(DibImageFile.format, \"image/bmp\")\n",471],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py":["#\n# The Python Imaging Library.\n# $Id$\n#\n# Binary input/output support routines.\n#\n# Copyright (c) 1997-2003 by Secret Labs AB\n# Copyright (c) 1995-2003 by Fredrik Lundh\n# Copyright (c) 2012 by Brian Crowell\n#\n# See the README file for information on usage and redistribution.\n#\n\n\n\"\"\"Binary input/output support routines.\"\"\"\nfrom __future__ import annotations\n\nfrom struct import pack, unpack_from\n\n\ndef i8(c: bytes) -> int:\n    return c[0]\n\n\ndef o8(i: int) -> bytes:\n    return bytes((i & 255,))\n\n\n# Input, le = little endian, be = big endian\ndef i16le(c: bytes, o: int = 0) -> int:\n    \"\"\"\n    Converts a 2-bytes (16 bits) string to an unsigned integer.\n\n    :param c: string containing bytes to convert\n    :param o: offset of bytes to convert in string\n    \"\"\"\n    return unpack_from(\"<H\", c, o)[0]\n\n\ndef si16le(c: bytes, o: int = 0) -> int:\n    \"\"\"\n    Converts a 2-bytes (16 bits) string to a signed integer.\n\n    :param c: string containing bytes to convert\n    :param o: offset of bytes to convert in string\n    \"\"\"\n    return unpack_from(\"<h\", c, o)[0]\n\n\ndef si16be(c: bytes, o: int = 0) -> int:\n    \"\"\"\n    Converts a 2-bytes (16 bits) string to a signed integer, big endian.\n\n    :param c: string containing bytes to convert\n    :param o: offset of bytes to convert in string\n    \"\"\"\n    return unpack_from(\">h\", c, o)[0]\n\n\ndef i32le(c: bytes, o: int = 0) -> int:\n    \"\"\"\n    Converts a 4-bytes (32 bits) string to an unsigned integer.\n\n    :param c: string containing bytes to convert\n    :param o: offset of bytes to convert in string\n    \"\"\"\n    return unpack_from(\"<I\", c, o)[0]\n\n\ndef si32le(c: bytes, o: int = 0) -> int:\n    \"\"\"\n    Converts a 4-bytes (32 bits) string to a signed integer.\n\n    :param c: string containing bytes to convert\n    :param o: offset of bytes to convert in string\n    \"\"\"\n    return unpack_from(\"<i\", c, o)[0]\n\n\ndef i16be(c: bytes, o: int = 0) -> int:\n    return unpack_from(\">H\", c, o)[0]\n\n\ndef i32be(c: bytes, o: int = 0) -> int:\n    return unpack_from(\">I\", c, o)[0]\n\n\n# Output, le = little endian, be = big endian\ndef o16le(i: int) -> bytes:\n    return pack(\"<H\", i)\n\n\ndef o32le(i: int) -> bytes:\n    return pack(\"<I\", i)\n\n\ndef o16be(i: int) -> bytes:\n    return pack(\">H\", i)\n\n\ndef o32be(i: int) -> bytes:\n    return pack(\">I\", i)\n",102],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\JpegImagePlugin.py":["#\n# The Python Imaging Library.\n# $Id$\n#\n# JPEG (JFIF) file handling\n#\n# See \"Digital Compression and Coding of Continuous-Tone Still Images,\n# Part 1, Requirements and Guidelines\" (CCITT T.81 / ISO 10918-1)\n#\n# History:\n# 1995-09-09 fl   Created\n# 1995-09-13 fl   Added full parser\n# 1996-03-25 fl   Added hack to use the IJG command line utilities\n# 1996-05-05 fl   Workaround Photoshop 2.5 CMYK polarity bug\n# 1996-05-28 fl   Added draft support, JFIF version (0.1)\n# 1996-12-30 fl   Added encoder options, added progression property (0.2)\n# 1997-08-27 fl   Save mode 1 images as BW (0.3)\n# 1998-07-12 fl   Added YCbCr to draft and save methods (0.4)\n# 1998-10-19 fl   Don't hang on files using 16-bit DQT's (0.4.1)\n# 2001-04-16 fl   Extract DPI settings from JFIF files (0.4.2)\n# 2002-07-01 fl   Skip pad bytes before markers; identify Exif files (0.4.3)\n# 2003-04-25 fl   Added experimental EXIF decoder (0.5)\n# 2003-06-06 fl   Added experimental EXIF GPSinfo decoder\n# 2003-09-13 fl   Extract COM markers\n# 2009-09-06 fl   Added icc_profile support (from Florian Hoech)\n# 2009-03-06 fl   Changed CMYK handling; always use Adobe polarity (0.6)\n# 2009-03-08 fl   Added subsampling support (from Justin Huff).\n#\n# Copyright (c) 1997-2003 by Secret Labs AB.\n# Copyright (c) 1995-1996 by Fredrik Lundh.\n#\n# See the README file for information on usage and redistribution.\n#\nfrom __future__ import annotations\n\nimport array\nimport io\nimport math\nimport os\nimport struct\nimport subprocess\nimport sys\nimport tempfile\nimport warnings\n\nfrom . import Image, ImageFile\nfrom ._binary import i16be as i16\nfrom ._binary import i32be as i32\nfrom ._binary import o8\nfrom ._binary import o16be as o16\nfrom .JpegPresets import presets\n\n#\n# Parser\n\n\ndef Skip(self, marker):\n    n = i16(self.fp.read(2)) - 2\n    ImageFile._safe_read(self.fp, n)\n\n\ndef APP(self, marker):\n    #\n    # Application marker.  Store these in the APP dictionary.\n    # Also look for well-known application markers.\n\n    n = i16(self.fp.read(2)) - 2\n    s = ImageFile._safe_read(self.fp, n)\n\n    app = \"APP%d\" % (marker & 15)\n\n    self.app[app] = s  # compatibility\n    self.applist.append((app, s))\n\n    if marker == 0xFFE0 and s[:4] == b\"JFIF\":\n        # extract JFIF information\n        self.info[\"jfif\"] = version = i16(s, 5)  # version\n        self.info[\"jfif_version\"] = divmod(version, 256)\n        # extract JFIF properties\n        try:\n            jfif_unit = s[7]\n            jfif_density = i16(s, 8), i16(s, 10)\n        except Exception:\n            pass\n        else:\n            if jfif_unit == 1:\n                self.info[\"dpi\"] = jfif_density\n            self.info[\"jfif_unit\"] = jfif_unit\n            self.info[\"jfif_density\"] = jfif_density\n    elif marker == 0xFFE1 and s[:6] == b\"Exif\\0\\0\":\n        # extract EXIF information\n        if \"exif\" in self.info:\n            self.info[\"exif\"] += s[6:]\n        else:\n            self.info[\"exif\"] = s\n            self._exif_offset = self.fp.tell() - n + 6\n    elif marker == 0xFFE2 and s[:5] == b\"FPXR\\0\":\n        # extract FlashPix information (incomplete)\n        self.info[\"flashpix\"] = s  # FIXME: value will change\n    elif marker == 0xFFE2 and s[:12] == b\"ICC_PROFILE\\0\":\n        # Since an ICC profile can be larger than the maximum size of\n        # a JPEG marker (64K), we need provisions to split it into\n        # multiple markers. The format defined by the ICC specifies\n        # one or more APP2 markers containing the following data:\n        #   Identifying string      ASCII \"ICC_PROFILE\\0\"  (12 bytes)\n        #   Marker sequence number  1, 2, etc (1 byte)\n        #   Number of markers       Total of APP2's used (1 byte)\n        #   Profile data            (remainder of APP2 data)\n        # Decoders should use the marker sequence numbers to\n        # reassemble the profile, rather than assuming that the APP2\n        # markers appear in the correct sequence.\n        self.icclist.append(s)\n    elif marker == 0xFFED and s[:14] == b\"Photoshop 3.0\\x00\":\n        # parse the image resource block\n        offset = 14\n        photoshop = self.info.setdefault(\"photoshop\", {})\n        while s[offset : offset + 4] == b\"8BIM\":\n            try:\n                offset += 4\n                # resource code\n                code = i16(s, offset)\n                offset += 2\n                # resource name (usually empty)\n                name_len = s[offset]\n                # name = s[offset+1:offset+1+name_len]\n                offset += 1 + name_len\n                offset += offset & 1  # align\n                # resource data block\n                size = i32(s, offset)\n                offset += 4\n                data = s[offset : offset + size]\n                if code == 0x03ED:  # ResolutionInfo\n                    data = {\n                        \"XResolution\": i32(data, 0) / 65536,\n                        \"DisplayedUnitsX\": i16(data, 4),\n                        \"YResolution\": i32(data, 8) / 65536,\n                        \"DisplayedUnitsY\": i16(data, 12),\n                    }\n                photoshop[code] = data\n                offset += size\n                offset += offset & 1  # align\n            except struct.error:\n                break  # insufficient data\n\n    elif marker == 0xFFEE and s[:5] == b\"Adobe\":\n        self.info[\"adobe\"] = i16(s, 5)\n        # extract Adobe custom properties\n        try:\n            adobe_transform = s[11]\n        except IndexError:\n            pass\n        else:\n            self.info[\"adobe_transform\"] = adobe_transform\n    elif marker == 0xFFE2 and s[:4] == b\"MPF\\0\":\n        # extract MPO information\n        self.info[\"mp\"] = s[4:]\n        # offset is current location minus buffer size\n        # plus constant header size\n        self.info[\"mpoffset\"] = self.fp.tell() - n + 4\n\n    # If DPI isn't in JPEG header, fetch from EXIF\n    if \"dpi\" not in self.info and \"exif\" in self.info:\n        try:\n            exif = self.getexif()\n            resolution_unit = exif[0x0128]\n            x_resolution = exif[0x011A]\n            try:\n                dpi = float(x_resolution[0]) / x_resolution[1]\n            except TypeError:\n                dpi = x_resolution\n            if math.isnan(dpi):\n                msg = \"DPI is not a number\"\n                raise ValueError(msg)\n            if resolution_unit == 3:  # cm\n                # 1 dpcm = 2.54 dpi\n                dpi *= 2.54\n            self.info[\"dpi\"] = dpi, dpi\n        except (\n            struct.error,\n            KeyError,\n            SyntaxError,\n            TypeError,\n            ValueError,\n            ZeroDivisionError,\n        ):\n            # struct.error for truncated EXIF\n            # KeyError for dpi not included\n            # SyntaxError for invalid/unreadable EXIF\n            # ValueError or TypeError for dpi being an invalid float\n            # ZeroDivisionError for invalid dpi rational value\n            self.info[\"dpi\"] = 72, 72\n\n\ndef COM(self, marker):\n    #\n    # Comment marker.  Store these in the APP dictionary.\n    n = i16(self.fp.read(2)) - 2\n    s = ImageFile._safe_read(self.fp, n)\n\n    self.info[\"comment\"] = s\n    self.app[\"COM\"] = s  # compatibility\n    self.applist.append((\"COM\", s))\n\n\ndef SOF(self, marker):\n    #\n    # Start of frame marker.  Defines the size and mode of the\n    # image.  JPEG is colour blind, so we use some simple\n    # heuristics to map the number of layers to an appropriate\n    # mode.  Note that this could be made a bit brighter, by\n    # looking for JFIF and Adobe APP markers.\n\n    n = i16(self.fp.read(2)) - 2\n    s = ImageFile._safe_read(self.fp, n)\n    self._size = i16(s, 3), i16(s, 1)\n\n    self.bits = s[0]\n    if self.bits != 8:\n        msg = f\"cannot handle {self.bits}-bit layers\"\n        raise SyntaxError(msg)\n\n    self.layers = s[5]\n    if self.layers == 1:\n        self._mode = \"L\"\n    elif self.layers == 3:\n        self._mode = \"RGB\"\n    elif self.layers == 4:\n        self._mode = \"CMYK\"\n    else:\n        msg = f\"cannot handle {self.layers}-layer images\"\n        raise SyntaxError(msg)\n\n    if marker in [0xFFC2, 0xFFC6, 0xFFCA, 0xFFCE]:\n        self.info[\"progressive\"] = self.info[\"progression\"] = 1\n\n    if self.icclist:\n        # fixup icc profile\n        self.icclist.sort()  # sort by sequence number\n        if self.icclist[0][13] == len(self.icclist):\n            profile = [p[14:] for p in self.icclist]\n            icc_profile = b\"\".join(profile)\n        else:\n            icc_profile = None  # wrong number of fragments\n        self.info[\"icc_profile\"] = icc_profile\n        self.icclist = []\n\n    for i in range(6, len(s), 3):\n        t = s[i : i + 3]\n        # 4-tuples: id, vsamp, hsamp, qtable\n        self.layer.append((t[0], t[1] // 16, t[1] & 15, t[2]))\n\n\ndef DQT(self, marker):\n    #\n    # Define quantization table.  Note that there might be more\n    # than one table in each marker.\n\n    # FIXME: The quantization tables can be used to estimate the\n    # compression quality.\n\n    n = i16(self.fp.read(2)) - 2\n    s = ImageFile._safe_read(self.fp, n)\n    while len(s):\n        v = s[0]\n        precision = 1 if (v // 16 == 0) else 2  # in bytes\n        qt_length = 1 + precision * 64\n        if len(s) < qt_length:\n            msg = \"bad quantization table marker\"\n            raise SyntaxError(msg)\n        data = array.array(\"B\" if precision == 1 else \"H\", s[1:qt_length])\n        if sys.byteorder == \"little\" and precision > 1:\n            data.byteswap()  # the values are always big-endian\n        self.quantization[v & 15] = [data[i] for i in zigzag_index]\n        s = s[qt_length:]\n\n\n#\n# JPEG marker table\n\nMARKER = {\n    0xFFC0: (\"SOF0\", \"Baseline DCT\", SOF),\n    0xFFC1: (\"SOF1\", \"Extended Sequential DCT\", SOF),\n    0xFFC2: (\"SOF2\", \"Progressive DCT\", SOF),\n    0xFFC3: (\"SOF3\", \"Spatial lossless\", SOF),\n    0xFFC4: (\"DHT\", \"Define Huffman table\", Skip),\n    0xFFC5: (\"SOF5\", \"Differential sequential DCT\", SOF),\n    0xFFC6: (\"SOF6\", \"Differential progressive DCT\", SOF),\n    0xFFC7: (\"SOF7\", \"Differential spatial\", SOF),\n    0xFFC8: (\"JPG\", \"Extension\", None),\n    0xFFC9: (\"SOF9\", \"Extended sequential DCT (AC)\", SOF),\n    0xFFCA: (\"SOF10\", \"Progressive DCT (AC)\", SOF),\n    0xFFCB: (\"SOF11\", \"Spatial lossless DCT (AC)\", SOF),\n    0xFFCC: (\"DAC\", \"Define arithmetic coding conditioning\", Skip),\n    0xFFCD: (\"SOF13\", \"Differential sequential DCT (AC)\", SOF),\n    0xFFCE: (\"SOF14\", \"Differential progressive DCT (AC)\", SOF),\n    0xFFCF: (\"SOF15\", \"Differential spatial (AC)\", SOF),\n    0xFFD0: (\"RST0\", \"Restart 0\", None),\n    0xFFD1: (\"RST1\", \"Restart 1\", None),\n    0xFFD2: (\"RST2\", \"Restart 2\", None),\n    0xFFD3: (\"RST3\", \"Restart 3\", None),\n    0xFFD4: (\"RST4\", \"Restart 4\", None),\n    0xFFD5: (\"RST5\", \"Restart 5\", None),\n    0xFFD6: (\"RST6\", \"Restart 6\", None),\n    0xFFD7: (\"RST7\", \"Restart 7\", None),\n    0xFFD8: (\"SOI\", \"Start of image\", None),\n    0xFFD9: (\"EOI\", \"End of image\", None),\n    0xFFDA: (\"SOS\", \"Start of scan\", Skip),\n    0xFFDB: (\"DQT\", \"Define quantization table\", DQT),\n    0xFFDC: (\"DNL\", \"Define number of lines\", Skip),\n    0xFFDD: (\"DRI\", \"Define restart interval\", Skip),\n    0xFFDE: (\"DHP\", \"Define hierarchical progression\", SOF),\n    0xFFDF: (\"EXP\", \"Expand reference component\", Skip),\n    0xFFE0: (\"APP0\", \"Application segment 0\", APP),\n    0xFFE1: (\"APP1\", \"Application segment 1\", APP),\n    0xFFE2: (\"APP2\", \"Application segment 2\", APP),\n    0xFFE3: (\"APP3\", \"Application segment 3\", APP),\n    0xFFE4: (\"APP4\", \"Application segment 4\", APP),\n    0xFFE5: (\"APP5\", \"Application segment 5\", APP),\n    0xFFE6: (\"APP6\", \"Application segment 6\", APP),\n    0xFFE7: (\"APP7\", \"Application segment 7\", APP),\n    0xFFE8: (\"APP8\", \"Application segment 8\", APP),\n    0xFFE9: (\"APP9\", \"Application segment 9\", APP),\n    0xFFEA: (\"APP10\", \"Application segment 10\", APP),\n    0xFFEB: (\"APP11\", \"Application segment 11\", APP),\n    0xFFEC: (\"APP12\", \"Application segment 12\", APP),\n    0xFFED: (\"APP13\", \"Application segment 13\", APP),\n    0xFFEE: (\"APP14\", \"Application segment 14\", APP),\n    0xFFEF: (\"APP15\", \"Application segment 15\", APP),\n    0xFFF0: (\"JPG0\", \"Extension 0\", None),\n    0xFFF1: (\"JPG1\", \"Extension 1\", None),\n    0xFFF2: (\"JPG2\", \"Extension 2\", None),\n    0xFFF3: (\"JPG3\", \"Extension 3\", None),\n    0xFFF4: (\"JPG4\", \"Extension 4\", None),\n    0xFFF5: (\"JPG5\", \"Extension 5\", None),\n    0xFFF6: (\"JPG6\", \"Extension 6\", None),\n    0xFFF7: (\"JPG7\", \"Extension 7\", None),\n    0xFFF8: (\"JPG8\", \"Extension 8\", None),\n    0xFFF9: (\"JPG9\", \"Extension 9\", None),\n    0xFFFA: (\"JPG10\", \"Extension 10\", None),\n    0xFFFB: (\"JPG11\", \"Extension 11\", None),\n    0xFFFC: (\"JPG12\", \"Extension 12\", None),\n    0xFFFD: (\"JPG13\", \"Extension 13\", None),\n    0xFFFE: (\"COM\", \"Comment\", COM),\n}\n\n\ndef _accept(prefix):\n    # Magic number was taken from https://en.wikipedia.org/wiki/JPEG\n    return prefix[:3] == b\"\\xFF\\xD8\\xFF\"\n\n\n##\n# Image plugin for JPEG and JFIF images.\n\n\nclass JpegImageFile(ImageFile.ImageFile):\n    format = \"JPEG\"\n    format_description = \"JPEG (ISO 10918)\"\n\n    def _open(self):\n        s = self.fp.read(3)\n\n        if not _accept(s):\n            msg = \"not a JPEG file\"\n            raise SyntaxError(msg)\n        s = b\"\\xFF\"\n\n        # Create attributes\n        self.bits = self.layers = 0\n\n        # JPEG specifics (internal)\n        self.layer = []\n        self.huffman_dc = {}\n        self.huffman_ac = {}\n        self.quantization = {}\n        self.app = {}  # compatibility\n        self.applist = []\n        self.icclist = []\n\n        while True:\n            i = s[0]\n            if i == 0xFF:\n                s = s + self.fp.read(1)\n                i = i16(s)\n            else:\n                # Skip non-0xFF junk\n                s = self.fp.read(1)\n                continue\n\n            if i in MARKER:\n                name, description, handler = MARKER[i]\n                if handler is not None:\n                    handler(self, i)\n                if i == 0xFFDA:  # start of scan\n                    rawmode = self.mode\n                    if self.mode == \"CMYK\":\n                        rawmode = \"CMYK;I\"  # assume adobe conventions\n                    self.tile = [(\"jpeg\", (0, 0) + self.size, 0, (rawmode, \"\"))]\n                    # self.__offset = self.fp.tell()\n                    break\n                s = self.fp.read(1)\n            elif i in {0, 0xFFFF}:\n                # padded marker or junk; move on\n                s = b\"\\xff\"\n            elif i == 0xFF00:  # Skip extraneous data (escaped 0xFF)\n                s = self.fp.read(1)\n            else:\n                msg = \"no marker found\"\n                raise SyntaxError(msg)\n\n    def load_read(self, read_bytes):\n        \"\"\"\n        internal: read more image data\n        For premature EOF and LOAD_TRUNCATED_IMAGES adds EOI marker\n        so libjpeg can finish decoding\n        \"\"\"\n        s = self.fp.read(read_bytes)\n\n        if not s and ImageFile.LOAD_TRUNCATED_IMAGES and not hasattr(self, \"_ended\"):\n            # Premature EOF.\n            # Pretend file is finished adding EOI marker\n            self._ended = True\n            return b\"\\xFF\\xD9\"\n\n        return s\n\n    def draft(self, mode, size):\n        if len(self.tile) != 1:\n            return\n\n        # Protect from second call\n        if self.decoderconfig:\n            return\n\n        d, e, o, a = self.tile[0]\n        scale = 1\n        original_size = self.size\n\n        if a[0] == \"RGB\" and mode in [\"L\", \"YCbCr\"]:\n            self._mode = mode\n            a = mode, \"\"\n\n        if size:\n            scale = min(self.size[0] // size[0], self.size[1] // size[1])\n            for s in [8, 4, 2, 1]:\n                if scale >= s:\n                    break\n            e = (\n                e[0],\n                e[1],\n                (e[2] - e[0] + s - 1) // s + e[0],\n                (e[3] - e[1] + s - 1) // s + e[1],\n            )\n            self._size = ((self.size[0] + s - 1) // s, (self.size[1] + s - 1) // s)\n            scale = s\n\n        self.tile = [(d, e, o, a)]\n        self.decoderconfig = (scale, 0)\n\n        box = (0, 0, original_size[0] / scale, original_size[1] / scale)\n        return self.mode, box\n\n    def load_djpeg(self):\n        # ALTERNATIVE: handle JPEGs via the IJG command line utilities\n\n        f, path = tempfile.mkstemp()\n        os.close(f)\n        if os.path.exists(self.filename):\n            subprocess.check_call([\"djpeg\", \"-outfile\", path, self.filename])\n        else:\n            try:\n                os.unlink(path)\n            except OSError:\n                pass\n\n            msg = \"Invalid Filename\"\n            raise ValueError(msg)\n\n        try:\n            with Image.open(path) as _im:\n                _im.load()\n                self.im = _im.im\n        finally:\n            try:\n                os.unlink(path)\n            except OSError:\n                pass\n\n        self._mode = self.im.mode\n        self._size = self.im.size\n\n        self.tile = []\n\n    def _getexif(self):\n        return _getexif(self)\n\n    def _getmp(self):\n        return _getmp(self)\n\n    def getxmp(self):\n        \"\"\"\n        Returns a dictionary containing the XMP tags.\n        Requires defusedxml to be installed.\n\n        :returns: XMP tags in a dictionary.\n        \"\"\"\n\n        for segment, content in self.applist:\n            if segment == \"APP1\":\n                marker, xmp_tags = content.split(b\"\\x00\")[:2]\n                if marker == b\"http://ns.adobe.com/xap/1.0/\":\n                    return self._getxmp(xmp_tags)\n        return {}\n\n\ndef _getexif(self):\n    if \"exif\" not in self.info:\n        return None\n    return self.getexif()._get_merged_dict()\n\n\ndef _getmp(self):\n    # Extract MP information.  This method was inspired by the \"highly\n    # experimental\" _getexif version that's been in use for years now,\n    # itself based on the ImageFileDirectory class in the TIFF plugin.\n\n    # The MP record essentially consists of a TIFF file embedded in a JPEG\n    # application marker.\n    try:\n        data = self.info[\"mp\"]\n    except KeyError:\n        return None\n    file_contents = io.BytesIO(data)\n    head = file_contents.read(8)\n    endianness = \">\" if head[:4] == b\"\\x4d\\x4d\\x00\\x2a\" else \"<\"\n    # process dictionary\n    from . import TiffImagePlugin\n\n    try:\n        info = TiffImagePlugin.ImageFileDirectory_v2(head)\n        file_contents.seek(info.next)\n        info.load(file_contents)\n        mp = dict(info)\n    except Exception as e:\n        msg = \"malformed MP Index (unreadable directory)\"\n        raise SyntaxError(msg) from e\n    # it's an error not to have a number of images\n    try:\n        quant = mp[0xB001]\n    except KeyError as e:\n        msg = \"malformed MP Index (no number of images)\"\n        raise SyntaxError(msg) from e\n    # get MP entries\n    mpentries = []\n    try:\n        rawmpentries = mp[0xB002]\n        for entrynum in range(0, quant):\n            unpackedentry = struct.unpack_from(\n                f\"{endianness}LLLHH\", rawmpentries, entrynum * 16\n            )\n            labels = (\"Attribute\", \"Size\", \"DataOffset\", \"EntryNo1\", \"EntryNo2\")\n            mpentry = dict(zip(labels, unpackedentry))\n            mpentryattr = {\n                \"DependentParentImageFlag\": bool(mpentry[\"Attribute\"] & (1 << 31)),\n                \"DependentChildImageFlag\": bool(mpentry[\"Attribute\"] & (1 << 30)),\n                \"RepresentativeImageFlag\": bool(mpentry[\"Attribute\"] & (1 << 29)),\n                \"Reserved\": (mpentry[\"Attribute\"] & (3 << 27)) >> 27,\n                \"ImageDataFormat\": (mpentry[\"Attribute\"] & (7 << 24)) >> 24,\n                \"MPType\": mpentry[\"Attribute\"] & 0x00FFFFFF,\n            }\n            if mpentryattr[\"ImageDataFormat\"] == 0:\n                mpentryattr[\"ImageDataFormat\"] = \"JPEG\"\n            else:\n                msg = \"unsupported picture format in MPO\"\n                raise SyntaxError(msg)\n            mptypemap = {\n                0x000000: \"Undefined\",\n                0x010001: \"Large Thumbnail (VGA Equivalent)\",\n                0x010002: \"Large Thumbnail (Full HD Equivalent)\",\n                0x020001: \"Multi-Frame Image (Panorama)\",\n                0x020002: \"Multi-Frame Image: (Disparity)\",\n                0x020003: \"Multi-Frame Image: (Multi-Angle)\",\n                0x030000: \"Baseline MP Primary Image\",\n            }\n            mpentryattr[\"MPType\"] = mptypemap.get(mpentryattr[\"MPType\"], \"Unknown\")\n            mpentry[\"Attribute\"] = mpentryattr\n            mpentries.append(mpentry)\n        mp[0xB002] = mpentries\n    except KeyError as e:\n        msg = \"malformed MP Index (bad MP Entry)\"\n        raise SyntaxError(msg) from e\n    # Next we should try and parse the individual image unique ID list;\n    # we don't because I've never seen this actually used in a real MPO\n    # file and so can't test it.\n    return mp\n\n\n# --------------------------------------------------------------------\n# stuff to save JPEG files\n\nRAWMODE = {\n    \"1\": \"L\",\n    \"L\": \"L\",\n    \"RGB\": \"RGB\",\n    \"RGBX\": \"RGB\",\n    \"CMYK\": \"CMYK;I\",  # assume adobe conventions\n    \"YCbCr\": \"YCbCr\",\n}\n\n# fmt: off\nzigzag_index = (\n    0,  1,  5,  6, 14, 15, 27, 28,\n    2,  4,  7, 13, 16, 26, 29, 42,\n    3,  8, 12, 17, 25, 30, 41, 43,\n    9, 11, 18, 24, 31, 40, 44, 53,\n    10, 19, 23, 32, 39, 45, 52, 54,\n    20, 22, 33, 38, 46, 51, 55, 60,\n    21, 34, 37, 47, 50, 56, 59, 61,\n    35, 36, 48, 49, 57, 58, 62, 63,\n)\n\nsamplings = {\n    (1, 1, 1, 1, 1, 1): 0,\n    (2, 1, 1, 1, 1, 1): 1,\n    (2, 2, 1, 1, 1, 1): 2,\n}\n# fmt: on\n\n\ndef get_sampling(im):\n    # There's no subsampling when images have only 1 layer\n    # (grayscale images) or when they are CMYK (4 layers),\n    # so set subsampling to the default value.\n    #\n    # NOTE: currently Pillow can't encode JPEG to YCCK format.\n    # If YCCK support is added in the future, subsampling code will have\n    # to be updated (here and in JpegEncode.c) to deal with 4 layers.\n    if not hasattr(im, \"layers\") or im.layers in (1, 4):\n        return -1\n    sampling = im.layer[0][1:3] + im.layer[1][1:3] + im.layer[2][1:3]\n    return samplings.get(sampling, -1)\n\n\ndef _save(im, fp, filename):\n    if im.width == 0 or im.height == 0:\n        msg = \"cannot write empty image as JPEG\"\n        raise ValueError(msg)\n\n    try:\n        rawmode = RAWMODE[im.mode]\n    except KeyError as e:\n        msg = f\"cannot write mode {im.mode} as JPEG\"\n        raise OSError(msg) from e\n\n    info = im.encoderinfo\n\n    dpi = [round(x) for x in info.get(\"dpi\", (0, 0))]\n\n    quality = info.get(\"quality\", -1)\n    subsampling = info.get(\"subsampling\", -1)\n    qtables = info.get(\"qtables\")\n\n    if quality == \"keep\":\n        quality = -1\n        subsampling = \"keep\"\n        qtables = \"keep\"\n    elif quality in presets:\n        preset = presets[quality]\n        quality = -1\n        subsampling = preset.get(\"subsampling\", -1)\n        qtables = preset.get(\"quantization\")\n    elif not isinstance(quality, int):\n        msg = \"Invalid quality setting\"\n        raise ValueError(msg)\n    else:\n        if subsampling in presets:\n            subsampling = presets[subsampling].get(\"subsampling\", -1)\n        if isinstance(qtables, str) and qtables in presets:\n            qtables = presets[qtables].get(\"quantization\")\n\n    if subsampling == \"4:4:4\":\n        subsampling = 0\n    elif subsampling == \"4:2:2\":\n        subsampling = 1\n    elif subsampling == \"4:2:0\":\n        subsampling = 2\n    elif subsampling == \"4:1:1\":\n        # For compatibility. Before Pillow 4.3, 4:1:1 actually meant 4:2:0.\n        # Set 4:2:0 if someone is still using that value.\n        subsampling = 2\n    elif subsampling == \"keep\":\n        if im.format != \"JPEG\":\n            msg = \"Cannot use 'keep' when original image is not a JPEG\"\n            raise ValueError(msg)\n        subsampling = get_sampling(im)\n\n    def validate_qtables(qtables):\n        if qtables is None:\n            return qtables\n        if isinstance(qtables, str):\n            try:\n                lines = [\n                    int(num)\n                    for line in qtables.splitlines()\n                    for num in line.split(\"#\", 1)[0].split()\n                ]\n            except ValueError as e:\n                msg = \"Invalid quantization table\"\n                raise ValueError(msg) from e\n            else:\n                qtables = [lines[s : s + 64] for s in range(0, len(lines), 64)]\n        if isinstance(qtables, (tuple, list, dict)):\n            if isinstance(qtables, dict):\n                qtables = [\n                    qtables[key] for key in range(len(qtables)) if key in qtables\n                ]\n            elif isinstance(qtables, tuple):\n                qtables = list(qtables)\n            if not (0 < len(qtables) < 5):\n                msg = \"None or too many quantization tables\"\n                raise ValueError(msg)\n            for idx, table in enumerate(qtables):\n                try:\n                    if len(table) != 64:\n                        msg = \"Invalid quantization table\"\n                        raise TypeError(msg)\n                    table = array.array(\"H\", table)\n                except TypeError as e:\n                    msg = \"Invalid quantization table\"\n                    raise ValueError(msg) from e\n                else:\n                    qtables[idx] = list(table)\n            return qtables\n\n    if qtables == \"keep\":\n        if im.format != \"JPEG\":\n            msg = \"Cannot use 'keep' when original image is not a JPEG\"\n            raise ValueError(msg)\n        qtables = getattr(im, \"quantization\", None)\n    qtables = validate_qtables(qtables)\n\n    extra = info.get(\"extra\", b\"\")\n\n    MAX_BYTES_IN_MARKER = 65533\n    icc_profile = info.get(\"icc_profile\")\n    if icc_profile:\n        ICC_OVERHEAD_LEN = 14\n        MAX_DATA_BYTES_IN_MARKER = MAX_BYTES_IN_MARKER - ICC_OVERHEAD_LEN\n        markers = []\n        while icc_profile:\n            markers.append(icc_profile[:MAX_DATA_BYTES_IN_MARKER])\n            icc_profile = icc_profile[MAX_DATA_BYTES_IN_MARKER:]\n        i = 1\n        for marker in markers:\n            size = o16(2 + ICC_OVERHEAD_LEN + len(marker))\n            extra += (\n                b\"\\xFF\\xE2\"\n                + size\n                + b\"ICC_PROFILE\\0\"\n                + o8(i)\n                + o8(len(markers))\n                + marker\n            )\n            i += 1\n\n    comment = info.get(\"comment\", im.info.get(\"comment\"))\n\n    # \"progressive\" is the official name, but older documentation\n    # says \"progression\"\n    # FIXME: issue a warning if the wrong form is used (post-1.1.7)\n    progressive = info.get(\"progressive\", False) or info.get(\"progression\", False)\n\n    optimize = info.get(\"optimize\", False)\n\n    exif = info.get(\"exif\", b\"\")\n    if isinstance(exif, Image.Exif):\n        exif = exif.tobytes()\n    if len(exif) > MAX_BYTES_IN_MARKER:\n        msg = \"EXIF data is too long\"\n        raise ValueError(msg)\n\n    # get keyword arguments\n    im.encoderconfig = (\n        quality,\n        progressive,\n        info.get(\"smooth\", 0),\n        optimize,\n        info.get(\"keep_rgb\", False),\n        info.get(\"streamtype\", 0),\n        dpi[0],\n        dpi[1],\n        subsampling,\n        info.get(\"restart_marker_blocks\", 0),\n        info.get(\"restart_marker_rows\", 0),\n        qtables,\n        comment,\n        extra,\n        exif,\n    )\n\n    # if we optimize, libjpeg needs a buffer big enough to hold the whole image\n    # in a shot. Guessing on the size, at im.size bytes. (raw pixel size is\n    # channels*size, this is a value that's been used in a django patch.\n    # https://github.com/matthewwithanm/django-imagekit/issues/50\n    bufsize = 0\n    if optimize or progressive:\n        # CMYK can be bigger\n        if im.mode == \"CMYK\":\n            bufsize = 4 * im.size[0] * im.size[1]\n        # keep sets quality to -1, but the actual value may be high.\n        elif quality >= 95 or quality == -1:\n            bufsize = 2 * im.size[0] * im.size[1]\n        else:\n            bufsize = im.size[0] * im.size[1]\n        if exif:\n            bufsize += len(exif) + 5\n        if extra:\n            bufsize += len(extra) + 1\n    else:\n        # The EXIF info needs to be written as one block, + APP1, + one spare byte.\n        # Ensure that our buffer is big enough. Same with the icc_profile block.\n        bufsize = max(bufsize, len(exif) + 5, len(extra) + 1)\n\n    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)\n\n\ndef _save_cjpeg(im, fp, filename):\n    # ALTERNATIVE: handle JPEGs via the IJG command line utilities.\n    tempfile = im._dump()\n    subprocess.check_call([\"cjpeg\", \"-outfile\", filename, tempfile])\n    try:\n        os.unlink(tempfile)\n    except OSError:\n        pass\n\n\n##\n# Factory for making JPEG and MPO instances\ndef jpeg_factory(fp=None, filename=None):\n    im = JpegImageFile(fp, filename)\n    try:\n        mpheader = im._getmp()\n        if mpheader[45057] > 1:\n            # It's actually an MPO\n            from .MpoImagePlugin import MpoImageFile\n\n            # Don't reload everything, just convert it.\n            im = MpoImageFile.adopt(im, mpheader)\n    except (TypeError, IndexError):\n        # It is really a JPEG\n        pass\n    except SyntaxError:\n        warnings.warn(\n            \"Image appears to be a malformed MPO file, it will be \"\n            \"interpreted as a base JPEG file\"\n        )\n    return im\n\n\n# ---------------------------------------------------------------------\n# Registry stuff\n\nImage.register_open(JpegImageFile.format, jpeg_factory, _accept)\nImage.register_save(JpegImageFile.format, _save)\n\nImage.register_extensions(JpegImageFile.format, [\".jfif\", \".jpe\", \".jpg\", \".jpeg\"])\n\nImage.register_mime(JpegImageFile.format, \"image/jpeg\")\n",868],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PpmImagePlugin.py":["#\n# The Python Imaging Library.\n# $Id$\n#\n# PPM support for PIL\n#\n# History:\n#       96-03-24 fl     Created\n#       98-03-06 fl     Write RGBA images (as RGB, that is)\n#\n# Copyright (c) Secret Labs AB 1997-98.\n# Copyright (c) Fredrik Lundh 1996.\n#\n# See the README file for information on usage and redistribution.\n#\nfrom __future__ import annotations\n\nfrom . import Image, ImageFile\nfrom ._binary import i16be as i16\nfrom ._binary import o8\nfrom ._binary import o32le as o32\n\n#\n# --------------------------------------------------------------------\n\nb_whitespace = b\"\\x20\\x09\\x0a\\x0b\\x0c\\x0d\"\n\nMODES = {\n    # standard\n    b\"P1\": \"1\",\n    b\"P2\": \"L\",\n    b\"P3\": \"RGB\",\n    b\"P4\": \"1\",\n    b\"P5\": \"L\",\n    b\"P6\": \"RGB\",\n    # extensions\n    b\"P0CMYK\": \"CMYK\",\n    # PIL extensions (for test purposes only)\n    b\"PyP\": \"P\",\n    b\"PyRGBA\": \"RGBA\",\n    b\"PyCMYK\": \"CMYK\",\n}\n\n\ndef _accept(prefix):\n    return prefix[0:1] == b\"P\" and prefix[1] in b\"0123456y\"\n\n\n##\n# Image plugin for PBM, PGM, and PPM images.\n\n\nclass PpmImageFile(ImageFile.ImageFile):\n    format = \"PPM\"\n    format_description = \"Pbmplus image\"\n\n    def _read_magic(self):\n        magic = b\"\"\n        # read until whitespace or longest available magic number\n        for _ in range(6):\n            c = self.fp.read(1)\n            if not c or c in b_whitespace:\n                break\n            magic += c\n        return magic\n\n    def _read_token(self):\n        token = b\"\"\n        while len(token) <= 10:  # read until next whitespace or limit of 10 characters\n            c = self.fp.read(1)\n            if not c:\n                break\n            elif c in b_whitespace:  # token ended\n                if not token:\n                    # skip whitespace at start\n                    continue\n                break\n            elif c == b\"#\":\n                # ignores rest of the line; stops at CR, LF or EOF\n                while self.fp.read(1) not in b\"\\r\\n\":\n                    pass\n                continue\n            token += c\n        if not token:\n            # Token was not even 1 byte\n            msg = \"Reached EOF while reading header\"\n            raise ValueError(msg)\n        elif len(token) > 10:\n            msg = f\"Token too long in file header: {token.decode()}\"\n            raise ValueError(msg)\n        return token\n\n    def _open(self):\n        magic_number = self._read_magic()\n        try:\n            mode = MODES[magic_number]\n        except KeyError:\n            msg = \"not a PPM file\"\n            raise SyntaxError(msg)\n\n        if magic_number in (b\"P1\", b\"P4\"):\n            self.custom_mimetype = \"image/x-portable-bitmap\"\n        elif magic_number in (b\"P2\", b\"P5\"):\n            self.custom_mimetype = \"image/x-portable-graymap\"\n        elif magic_number in (b\"P3\", b\"P6\"):\n            self.custom_mimetype = \"image/x-portable-pixmap\"\n\n        maxval = None\n        decoder_name = \"raw\"\n        if magic_number in (b\"P1\", b\"P2\", b\"P3\"):\n            decoder_name = \"ppm_plain\"\n        for ix in range(3):\n            token = int(self._read_token())\n            if ix == 0:  # token is the x size\n                xsize = token\n            elif ix == 1:  # token is the y size\n                ysize = token\n                if mode == \"1\":\n                    self._mode = \"1\"\n                    rawmode = \"1;I\"\n                    break\n                else:\n                    self._mode = rawmode = mode\n            elif ix == 2:  # token is maxval\n                maxval = token\n                if not 0 < maxval < 65536:\n                    msg = \"maxval must be greater than 0 and less than 65536\"\n                    raise ValueError(msg)\n                if maxval > 255 and mode == \"L\":\n                    self._mode = \"I\"\n\n                if decoder_name != \"ppm_plain\":\n                    # If maxval matches a bit depth, use the raw decoder directly\n                    if maxval == 65535 and mode == \"L\":\n                        rawmode = \"I;16B\"\n                    elif maxval != 255:\n                        decoder_name = \"ppm\"\n\n        args = (rawmode, 0, 1) if decoder_name == \"raw\" else (rawmode, maxval)\n        self._size = xsize, ysize\n        self.tile = [(decoder_name, (0, 0, xsize, ysize), self.fp.tell(), args)]\n\n\n#\n# --------------------------------------------------------------------\n\n\nclass PpmPlainDecoder(ImageFile.PyDecoder):\n    _pulls_fd = True\n\n    def _read_block(self):\n        return self.fd.read(ImageFile.SAFEBLOCK)\n\n    def _find_comment_end(self, block, start=0):\n        a = block.find(b\"\\n\", start)\n        b = block.find(b\"\\r\", start)\n        return min(a, b) if a * b > 0 else max(a, b)  # lowest nonnegative index (or -1)\n\n    def _ignore_comments(self, block):\n        if self._comment_spans:\n            # Finish current comment\n            while block:\n                comment_end = self._find_comment_end(block)\n                if comment_end != -1:\n                    # Comment ends in this block\n                    # Delete tail of comment\n                    block = block[comment_end + 1 :]\n                    break\n                else:\n                    # Comment spans whole block\n                    # So read the next block, looking for the end\n                    block = self._read_block()\n\n        # Search for any further comments\n        self._comment_spans = False\n        while True:\n            comment_start = block.find(b\"#\")\n            if comment_start == -1:\n                # No comment found\n                break\n            comment_end = self._find_comment_end(block, comment_start)\n            if comment_end != -1:\n                # Comment ends in this block\n                # Delete comment\n                block = block[:comment_start] + block[comment_end + 1 :]\n            else:\n                # Comment continues to next block(s)\n                block = block[:comment_start]\n                self._comment_spans = True\n                break\n        return block\n\n    def _decode_bitonal(self):\n        \"\"\"\n        This is a separate method because in the plain PBM format, all data tokens are\n        exactly one byte, so the inter-token whitespace is optional.\n        \"\"\"\n        data = bytearray()\n        total_bytes = self.state.xsize * self.state.ysize\n\n        while len(data) != total_bytes:\n            block = self._read_block()  # read next block\n            if not block:\n                # eof\n                break\n\n            block = self._ignore_comments(block)\n\n            tokens = b\"\".join(block.split())\n            for token in tokens:\n                if token not in (48, 49):\n                    msg = b\"Invalid token for this mode: %s\" % bytes([token])\n                    raise ValueError(msg)\n            data = (data + tokens)[:total_bytes]\n        invert = bytes.maketrans(b\"01\", b\"\\xFF\\x00\")\n        return data.translate(invert)\n\n    def _decode_blocks(self, maxval):\n        data = bytearray()\n        max_len = 10\n        out_byte_count = 4 if self.mode == \"I\" else 1\n        out_max = 65535 if self.mode == \"I\" else 255\n        bands = Image.getmodebands(self.mode)\n        total_bytes = self.state.xsize * self.state.ysize * bands * out_byte_count\n\n        half_token = False\n        while len(data) != total_bytes:\n            block = self._read_block()  # read next block\n            if not block:\n                if half_token:\n                    block = bytearray(b\" \")  # flush half_token\n                else:\n                    # eof\n                    break\n\n            block = self._ignore_comments(block)\n\n            if half_token:\n                block = half_token + block  # stitch half_token to new block\n                half_token = False\n\n            tokens = block.split()\n\n            if block and not block[-1:].isspace():  # block might split token\n                half_token = tokens.pop()  # save half token for later\n                if len(half_token) > max_len:  # prevent buildup of half_token\n                    msg = (\n                        b\"Token too long found in data: %s\" % half_token[: max_len + 1]\n                    )\n                    raise ValueError(msg)\n\n            for token in tokens:\n                if len(token) > max_len:\n                    msg = b\"Token too long found in data: %s\" % token[: max_len + 1]\n                    raise ValueError(msg)\n                value = int(token)\n                if value > maxval:\n                    msg = f\"Channel value too large for this mode: {value}\"\n                    raise ValueError(msg)\n                value = round(value / maxval * out_max)\n                data += o32(value) if self.mode == \"I\" else o8(value)\n                if len(data) == total_bytes:  # finished!\n                    break\n        return data\n\n    def decode(self, buffer):\n        self._comment_spans = False\n        if self.mode == \"1\":\n            data = self._decode_bitonal()\n            rawmode = \"1;8\"\n        else:\n            maxval = self.args[-1]\n            data = self._decode_blocks(maxval)\n            rawmode = \"I;32\" if self.mode == \"I\" else self.mode\n        self.set_as_raw(bytes(data), rawmode)\n        return -1, 0\n\n\nclass PpmDecoder(ImageFile.PyDecoder):\n    _pulls_fd = True\n\n    def decode(self, buffer):\n        data = bytearray()\n        maxval = self.args[-1]\n        in_byte_count = 1 if maxval < 256 else 2\n        out_byte_count = 4 if self.mode == \"I\" else 1\n        out_max = 65535 if self.mode == \"I\" else 255\n        bands = Image.getmodebands(self.mode)\n        while len(data) < self.state.xsize * self.state.ysize * bands * out_byte_count:\n            pixels = self.fd.read(in_byte_count * bands)\n            if len(pixels) < in_byte_count * bands:\n                # eof\n                break\n            for b in range(bands):\n                value = (\n                    pixels[b] if in_byte_count == 1 else i16(pixels, b * in_byte_count)\n                )\n                value = min(out_max, round(value / maxval * out_max))\n                data += o32(value) if self.mode == \"I\" else o8(value)\n        rawmode = \"I;32\" if self.mode == \"I\" else self.mode\n        self.set_as_raw(bytes(data), rawmode)\n        return -1, 0\n\n\n#\n# --------------------------------------------------------------------\n\n\ndef _save(im, fp, filename):\n    if im.mode == \"1\":\n        rawmode, head = \"1;I\", b\"P4\"\n    elif im.mode == \"L\":\n        rawmode, head = \"L\", b\"P5\"\n    elif im.mode == \"I\":\n        rawmode, head = \"I;16B\", b\"P5\"\n    elif im.mode in (\"RGB\", \"RGBA\"):\n        rawmode, head = \"RGB\", b\"P6\"\n    else:\n        msg = f\"cannot write mode {im.mode} as PPM\"\n        raise OSError(msg)\n    fp.write(head + b\"\\n%d %d\\n\" % im.size)\n    if head == b\"P6\":\n        fp.write(b\"255\\n\")\n    elif head == b\"P5\":\n        if rawmode == \"L\":\n            fp.write(b\"255\\n\")\n        else:\n            fp.write(b\"65535\\n\")\n    ImageFile._save(im, fp, [(\"raw\", (0, 0) + im.size, 0, (rawmode, 0, 1))])\n\n\n#\n# --------------------------------------------------------------------\n\n\nImage.register_open(PpmImageFile.format, PpmImageFile, _accept)\nImage.register_save(PpmImageFile.format, _save)\n\nImage.register_decoder(\"ppm\", PpmDecoder)\nImage.register_decoder(\"ppm_plain\", PpmPlainDecoder)\n\nImage.register_extensions(PpmImageFile.format, [\".pbm\", \".pgm\", \".ppm\", \".pnm\"])\n\nImage.register_mime(PpmImageFile.format, \"image/x-portable-anymap\")\n",344],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py":["#\n# The Python Imaging Library.\n# $Id$\n#\n# PNG support code\n#\n# See \"PNG (Portable Network Graphics) Specification, version 1.0;\n# W3C Recommendation\", 1996-10-01, Thomas Boutell (ed.).\n#\n# history:\n# 1996-05-06 fl   Created (couldn't resist it)\n# 1996-12-14 fl   Upgraded, added read and verify support (0.2)\n# 1996-12-15 fl   Separate PNG stream parser\n# 1996-12-29 fl   Added write support, added getchunks\n# 1996-12-30 fl   Eliminated circular references in decoder (0.3)\n# 1998-07-12 fl   Read/write 16-bit images as mode I (0.4)\n# 2001-02-08 fl   Added transparency support (from Zircon) (0.5)\n# 2001-04-16 fl   Don't close data source in \"open\" method (0.6)\n# 2004-02-24 fl   Don't even pretend to support interlaced files (0.7)\n# 2004-08-31 fl   Do basic sanity check on chunk identifiers (0.8)\n# 2004-09-20 fl   Added PngInfo chunk container\n# 2004-12-18 fl   Added DPI read support (based on code by Niki Spahiev)\n# 2008-08-13 fl   Added tRNS support for RGB images\n# 2009-03-06 fl   Support for preserving ICC profiles (by Florian Hoech)\n# 2009-03-08 fl   Added zTXT support (from Lowell Alleman)\n# 2009-03-29 fl   Read interlaced PNG files (from Conrado Porto Lopes Gouvua)\n#\n# Copyright (c) 1997-2009 by Secret Labs AB\n# Copyright (c) 1996 by Fredrik Lundh\n#\n# See the README file for information on usage and redistribution.\n#\nfrom __future__ import annotations\n\nimport itertools\nimport logging\nimport re\nimport struct\nimport warnings\nimport zlib\nfrom enum import IntEnum\n\nfrom . import Image, ImageChops, ImageFile, ImagePalette, ImageSequence\nfrom ._binary import i16be as i16\nfrom ._binary import i32be as i32\nfrom ._binary import o8\nfrom ._binary import o16be as o16\nfrom ._binary import o32be as o32\n\nlogger = logging.getLogger(__name__)\n\nis_cid = re.compile(rb\"\\w\\w\\w\\w\").match\n\n\n_MAGIC = b\"\\211PNG\\r\\n\\032\\n\"\n\n\n_MODES = {\n    # supported bits/color combinations, and corresponding modes/rawmodes\n    # Grayscale\n    (1, 0): (\"1\", \"1\"),\n    (2, 0): (\"L\", \"L;2\"),\n    (4, 0): (\"L\", \"L;4\"),\n    (8, 0): (\"L\", \"L\"),\n    (16, 0): (\"I\", \"I;16B\"),\n    # Truecolour\n    (8, 2): (\"RGB\", \"RGB\"),\n    (16, 2): (\"RGB\", \"RGB;16B\"),\n    # Indexed-colour\n    (1, 3): (\"P\", \"P;1\"),\n    (2, 3): (\"P\", \"P;2\"),\n    (4, 3): (\"P\", \"P;4\"),\n    (8, 3): (\"P\", \"P\"),\n    # Grayscale with alpha\n    (8, 4): (\"LA\", \"LA\"),\n    (16, 4): (\"RGBA\", \"LA;16B\"),  # LA;16B->LA not yet available\n    # Truecolour with alpha\n    (8, 6): (\"RGBA\", \"RGBA\"),\n    (16, 6): (\"RGBA\", \"RGBA;16B\"),\n}\n\n\n_simple_palette = re.compile(b\"^\\xff*\\x00\\xff*$\")\n\nMAX_TEXT_CHUNK = ImageFile.SAFEBLOCK\n\"\"\"\nMaximum decompressed size for a iTXt or zTXt chunk.\nEliminates decompression bombs where compressed chunks can expand 1000x.\nSee :ref:`Text in PNG File Format<png-text>`.\n\"\"\"\nMAX_TEXT_MEMORY = 64 * MAX_TEXT_CHUNK\n\"\"\"\nSet the maximum total text chunk size.\nSee :ref:`Text in PNG File Format<png-text>`.\n\"\"\"\n\n\n# APNG frame disposal modes\nclass Disposal(IntEnum):\n    OP_NONE = 0\n    \"\"\"\n    No disposal is done on this frame before rendering the next frame.\n    See :ref:`Saving APNG sequences<apng-saving>`.\n    \"\"\"\n    OP_BACKGROUND = 1\n    \"\"\"\n    This frames modified region is cleared to fully transparent black before rendering\n    the next frame.\n    See :ref:`Saving APNG sequences<apng-saving>`.\n    \"\"\"\n    OP_PREVIOUS = 2\n    \"\"\"\n    This frames modified region is reverted to the previous frames contents before\n    rendering the next frame.\n    See :ref:`Saving APNG sequences<apng-saving>`.\n    \"\"\"\n\n\n# APNG frame blend modes\nclass Blend(IntEnum):\n    OP_SOURCE = 0\n    \"\"\"\n    All color components of this frame, including alpha, overwrite the previous output\n    image contents.\n    See :ref:`Saving APNG sequences<apng-saving>`.\n    \"\"\"\n    OP_OVER = 1\n    \"\"\"\n    This frame should be alpha composited with the previous output image contents.\n    See :ref:`Saving APNG sequences<apng-saving>`.\n    \"\"\"\n\n\ndef _safe_zlib_decompress(s):\n    dobj = zlib.decompressobj()\n    plaintext = dobj.decompress(s, MAX_TEXT_CHUNK)\n    if dobj.unconsumed_tail:\n        msg = \"Decompressed Data Too Large\"\n        raise ValueError(msg)\n    return plaintext\n\n\ndef _crc32(data, seed=0):\n    return zlib.crc32(data, seed) & 0xFFFFFFFF\n\n\n# --------------------------------------------------------------------\n# Support classes.  Suitable for PNG and related formats like MNG etc.\n\n\nclass ChunkStream:\n    def __init__(self, fp):\n        self.fp = fp\n        self.queue = []\n\n    def read(self):\n        \"\"\"Fetch a new chunk. Returns header information.\"\"\"\n        cid = None\n\n        if self.queue:\n            cid, pos, length = self.queue.pop()\n            self.fp.seek(pos)\n        else:\n            s = self.fp.read(8)\n            cid = s[4:]\n            pos = self.fp.tell()\n            length = i32(s)\n\n        if not is_cid(cid):\n            if not ImageFile.LOAD_TRUNCATED_IMAGES:\n                msg = f\"broken PNG file (chunk {repr(cid)})\"\n                raise SyntaxError(msg)\n\n        return cid, pos, length\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def close(self):\n        self.queue = self.fp = None\n\n    def push(self, cid, pos, length):\n        self.queue.append((cid, pos, length))\n\n    def call(self, cid, pos, length):\n        \"\"\"Call the appropriate chunk handler\"\"\"\n\n        logger.debug(\"STREAM %r %s %s\", cid, pos, length)\n        return getattr(self, \"chunk_\" + cid.decode(\"ascii\"))(pos, length)\n\n    def crc(self, cid, data):\n        \"\"\"Read and verify checksum\"\"\"\n\n        # Skip CRC checks for ancillary chunks if allowed to load truncated\n        # images\n        # 5th byte of first char is 1 [specs, section 5.4]\n        if ImageFile.LOAD_TRUNCATED_IMAGES and (cid[0] >> 5 & 1):\n            self.crc_skip(cid, data)\n            return\n\n        try:\n            crc1 = _crc32(data, _crc32(cid))\n            crc2 = i32(self.fp.read(4))\n            if crc1 != crc2:\n                msg = f\"broken PNG file (bad header checksum in {repr(cid)})\"\n                raise SyntaxError(msg)\n        except struct.error as e:\n            msg = f\"broken PNG file (incomplete checksum in {repr(cid)})\"\n            raise SyntaxError(msg) from e\n\n    def crc_skip(self, cid, data):\n        \"\"\"Read checksum\"\"\"\n\n        self.fp.read(4)\n\n    def verify(self, endchunk=b\"IEND\"):\n        # Simple approach; just calculate checksum for all remaining\n        # blocks.  Must be called directly after open.\n\n        cids = []\n\n        while True:\n            try:\n                cid, pos, length = self.read()\n            except struct.error as e:\n                msg = \"truncated PNG file\"\n                raise OSError(msg) from e\n\n            if cid == endchunk:\n                break\n            self.crc(cid, ImageFile._safe_read(self.fp, length))\n            cids.append(cid)\n\n        return cids\n\n\nclass iTXt(str):\n    \"\"\"\n    Subclass of string to allow iTXt chunks to look like strings while\n    keeping their extra information\n\n    \"\"\"\n\n    @staticmethod\n    def __new__(cls, text, lang=None, tkey=None):\n        \"\"\"\n        :param cls: the class to use when creating the instance\n        :param text: value for this key\n        :param lang: language code\n        :param tkey: UTF-8 version of the key name\n        \"\"\"\n\n        self = str.__new__(cls, text)\n        self.lang = lang\n        self.tkey = tkey\n        return self\n\n\nclass PngInfo:\n    \"\"\"\n    PNG chunk container (for use with save(pnginfo=))\n\n    \"\"\"\n\n    def __init__(self):\n        self.chunks = []\n\n    def add(self, cid, data, after_idat=False):\n        \"\"\"Appends an arbitrary chunk. Use with caution.\n\n        :param cid: a byte string, 4 bytes long.\n        :param data: a byte string of the encoded data\n        :param after_idat: for use with private chunks. Whether the chunk\n                           should be written after IDAT\n\n        \"\"\"\n\n        chunk = [cid, data]\n        if after_idat:\n            chunk.append(True)\n        self.chunks.append(tuple(chunk))\n\n    def add_itxt(self, key, value, lang=\"\", tkey=\"\", zip=False):\n        \"\"\"Appends an iTXt chunk.\n\n        :param key: latin-1 encodable text key name\n        :param value: value for this key\n        :param lang: language code\n        :param tkey: UTF-8 version of the key name\n        :param zip: compression flag\n\n        \"\"\"\n\n        if not isinstance(key, bytes):\n            key = key.encode(\"latin-1\", \"strict\")\n        if not isinstance(value, bytes):\n            value = value.encode(\"utf-8\", \"strict\")\n        if not isinstance(lang, bytes):\n            lang = lang.encode(\"utf-8\", \"strict\")\n        if not isinstance(tkey, bytes):\n            tkey = tkey.encode(\"utf-8\", \"strict\")\n\n        if zip:\n            self.add(\n                b\"iTXt\",\n                key + b\"\\0\\x01\\0\" + lang + b\"\\0\" + tkey + b\"\\0\" + zlib.compress(value),\n            )\n        else:\n            self.add(b\"iTXt\", key + b\"\\0\\0\\0\" + lang + b\"\\0\" + tkey + b\"\\0\" + value)\n\n    def add_text(self, key, value, zip=False):\n        \"\"\"Appends a text chunk.\n\n        :param key: latin-1 encodable text key name\n        :param value: value for this key, text or an\n           :py:class:`PIL.PngImagePlugin.iTXt` instance\n        :param zip: compression flag\n\n        \"\"\"\n        if isinstance(value, iTXt):\n            return self.add_itxt(key, value, value.lang, value.tkey, zip=zip)\n\n        # The tEXt chunk stores latin-1 text\n        if not isinstance(value, bytes):\n            try:\n                value = value.encode(\"latin-1\", \"strict\")\n            except UnicodeError:\n                return self.add_itxt(key, value, zip=zip)\n\n        if not isinstance(key, bytes):\n            key = key.encode(\"latin-1\", \"strict\")\n\n        if zip:\n            self.add(b\"zTXt\", key + b\"\\0\\0\" + zlib.compress(value))\n        else:\n            self.add(b\"tEXt\", key + b\"\\0\" + value)\n\n\n# --------------------------------------------------------------------\n# PNG image stream (IHDR/IEND)\n\n\nclass PngStream(ChunkStream):\n    def __init__(self, fp):\n        super().__init__(fp)\n\n        # local copies of Image attributes\n        self.im_info = {}\n        self.im_text = {}\n        self.im_size = (0, 0)\n        self.im_mode = None\n        self.im_tile = None\n        self.im_palette = None\n        self.im_custom_mimetype = None\n        self.im_n_frames = None\n        self._seq_num = None\n        self.rewind_state = None\n\n        self.text_memory = 0\n\n    def check_text_memory(self, chunklen):\n        self.text_memory += chunklen\n        if self.text_memory > MAX_TEXT_MEMORY:\n            msg = (\n                \"Too much memory used in text chunks: \"\n                f\"{self.text_memory}>MAX_TEXT_MEMORY\"\n            )\n            raise ValueError(msg)\n\n    def save_rewind(self):\n        self.rewind_state = {\n            \"info\": self.im_info.copy(),\n            \"tile\": self.im_tile,\n            \"seq_num\": self._seq_num,\n        }\n\n    def rewind(self):\n        self.im_info = self.rewind_state[\"info\"]\n        self.im_tile = self.rewind_state[\"tile\"]\n        self._seq_num = self.rewind_state[\"seq_num\"]\n\n    def chunk_iCCP(self, pos, length):\n        # ICC profile\n        s = ImageFile._safe_read(self.fp, length)\n        # according to PNG spec, the iCCP chunk contains:\n        # Profile name  1-79 bytes (character string)\n        # Null separator        1 byte (null character)\n        # Compression method    1 byte (0)\n        # Compressed profile    n bytes (zlib with deflate compression)\n        i = s.find(b\"\\0\")\n        logger.debug(\"iCCP profile name %r\", s[:i])\n        logger.debug(\"Compression method %s\", s[i])\n        comp_method = s[i]\n        if comp_method != 0:\n            msg = f\"Unknown compression method {comp_method} in iCCP chunk\"\n            raise SyntaxError(msg)\n        try:\n            icc_profile = _safe_zlib_decompress(s[i + 2 :])\n        except ValueError:\n            if ImageFile.LOAD_TRUNCATED_IMAGES:\n                icc_profile = None\n            else:\n                raise\n        except zlib.error:\n            icc_profile = None  # FIXME\n        self.im_info[\"icc_profile\"] = icc_profile\n        return s\n\n    def chunk_IHDR(self, pos, length):\n        # image header\n        s = ImageFile._safe_read(self.fp, length)\n        if length < 13:\n            if ImageFile.LOAD_TRUNCATED_IMAGES:\n                return s\n            msg = \"Truncated IHDR chunk\"\n            raise ValueError(msg)\n        self.im_size = i32(s, 0), i32(s, 4)\n        try:\n            self.im_mode, self.im_rawmode = _MODES[(s[8], s[9])]\n        except Exception:\n            pass\n        if s[12]:\n            self.im_info[\"interlace\"] = 1\n        if s[11]:\n            msg = \"unknown filter category\"\n            raise SyntaxError(msg)\n        return s\n\n    def chunk_IDAT(self, pos, length):\n        # image data\n        if \"bbox\" in self.im_info:\n            tile = [(\"zip\", self.im_info[\"bbox\"], pos, self.im_rawmode)]\n        else:\n            if self.im_n_frames is not None:\n                self.im_info[\"default_image\"] = True\n            tile = [(\"zip\", (0, 0) + self.im_size, pos, self.im_rawmode)]\n        self.im_tile = tile\n        self.im_idat = length\n        msg = \"image data found\"\n        raise EOFError(msg)\n\n    def chunk_IEND(self, pos, length):\n        msg = \"end of PNG image\"\n        raise EOFError(msg)\n\n    def chunk_PLTE(self, pos, length):\n        # palette\n        s = ImageFile._safe_read(self.fp, length)\n        if self.im_mode == \"P\":\n            self.im_palette = \"RGB\", s\n        return s\n\n    def chunk_tRNS(self, pos, length):\n        # transparency\n        s = ImageFile._safe_read(self.fp, length)\n        if self.im_mode == \"P\":\n            if _simple_palette.match(s):\n                # tRNS contains only one full-transparent entry,\n                # other entries are full opaque\n                i = s.find(b\"\\0\")\n                if i >= 0:\n                    self.im_info[\"transparency\"] = i\n            else:\n                # otherwise, we have a byte string with one alpha value\n                # for each palette entry\n                self.im_info[\"transparency\"] = s\n        elif self.im_mode in (\"1\", \"L\", \"I\"):\n            self.im_info[\"transparency\"] = i16(s)\n        elif self.im_mode == \"RGB\":\n            self.im_info[\"transparency\"] = i16(s), i16(s, 2), i16(s, 4)\n        return s\n\n    def chunk_gAMA(self, pos, length):\n        # gamma setting\n        s = ImageFile._safe_read(self.fp, length)\n        self.im_info[\"gamma\"] = i32(s) / 100000.0\n        return s\n\n    def chunk_cHRM(self, pos, length):\n        # chromaticity, 8 unsigned ints, actual value is scaled by 100,000\n        # WP x,y, Red x,y, Green x,y Blue x,y\n\n        s = ImageFile._safe_read(self.fp, length)\n        raw_vals = struct.unpack(\">%dI\" % (len(s) // 4), s)\n        self.im_info[\"chromaticity\"] = tuple(elt / 100000.0 for elt in raw_vals)\n        return s\n\n    def chunk_sRGB(self, pos, length):\n        # srgb rendering intent, 1 byte\n        # 0 perceptual\n        # 1 relative colorimetric\n        # 2 saturation\n        # 3 absolute colorimetric\n\n        s = ImageFile._safe_read(self.fp, length)\n        if length < 1:\n            if ImageFile.LOAD_TRUNCATED_IMAGES:\n                return s\n            msg = \"Truncated sRGB chunk\"\n            raise ValueError(msg)\n        self.im_info[\"srgb\"] = s[0]\n        return s\n\n    def chunk_pHYs(self, pos, length):\n        # pixels per unit\n        s = ImageFile._safe_read(self.fp, length)\n        if length < 9:\n            if ImageFile.LOAD_TRUNCATED_IMAGES:\n                return s\n            msg = \"Truncated pHYs chunk\"\n            raise ValueError(msg)\n        px, py = i32(s, 0), i32(s, 4)\n        unit = s[8]\n        if unit == 1:  # meter\n            dpi = px * 0.0254, py * 0.0254\n            self.im_info[\"dpi\"] = dpi\n        elif unit == 0:\n            self.im_info[\"aspect\"] = px, py\n        return s\n\n    def chunk_tEXt(self, pos, length):\n        # text\n        s = ImageFile._safe_read(self.fp, length)\n        try:\n            k, v = s.split(b\"\\0\", 1)\n        except ValueError:\n            # fallback for broken tEXt tags\n            k = s\n            v = b\"\"\n        if k:\n            k = k.decode(\"latin-1\", \"strict\")\n            v_str = v.decode(\"latin-1\", \"replace\")\n\n            self.im_info[k] = v if k == \"exif\" else v_str\n            self.im_text[k] = v_str\n            self.check_text_memory(len(v_str))\n\n        return s\n\n    def chunk_zTXt(self, pos, length):\n        # compressed text\n        s = ImageFile._safe_read(self.fp, length)\n        try:\n            k, v = s.split(b\"\\0\", 1)\n        except ValueError:\n            k = s\n            v = b\"\"\n        if v:\n            comp_method = v[0]\n        else:\n            comp_method = 0\n        if comp_method != 0:\n            msg = f\"Unknown compression method {comp_method} in zTXt chunk\"\n            raise SyntaxError(msg)\n        try:\n            v = _safe_zlib_decompress(v[1:])\n        except ValueError:\n            if ImageFile.LOAD_TRUNCATED_IMAGES:\n                v = b\"\"\n            else:\n                raise\n        except zlib.error:\n            v = b\"\"\n\n        if k:\n            k = k.decode(\"latin-1\", \"strict\")\n            v = v.decode(\"latin-1\", \"replace\")\n\n            self.im_info[k] = self.im_text[k] = v\n            self.check_text_memory(len(v))\n\n        return s\n\n    def chunk_iTXt(self, pos, length):\n        # international text\n        r = s = ImageFile._safe_read(self.fp, length)\n        try:\n            k, r = r.split(b\"\\0\", 1)\n        except ValueError:\n            return s\n        if len(r) < 2:\n            return s\n        cf, cm, r = r[0], r[1], r[2:]\n        try:\n            lang, tk, v = r.split(b\"\\0\", 2)\n        except ValueError:\n            return s\n        if cf != 0:\n            if cm == 0:\n                try:\n                    v = _safe_zlib_decompress(v)\n                except ValueError:\n                    if ImageFile.LOAD_TRUNCATED_IMAGES:\n                        return s\n                    else:\n                        raise\n                except zlib.error:\n                    return s\n            else:\n                return s\n        try:\n            k = k.decode(\"latin-1\", \"strict\")\n            lang = lang.decode(\"utf-8\", \"strict\")\n            tk = tk.decode(\"utf-8\", \"strict\")\n            v = v.decode(\"utf-8\", \"strict\")\n        except UnicodeError:\n            return s\n\n        self.im_info[k] = self.im_text[k] = iTXt(v, lang, tk)\n        self.check_text_memory(len(v))\n\n        return s\n\n    def chunk_eXIf(self, pos, length):\n        s = ImageFile._safe_read(self.fp, length)\n        self.im_info[\"exif\"] = b\"Exif\\x00\\x00\" + s\n        return s\n\n    # APNG chunks\n    def chunk_acTL(self, pos, length):\n        s = ImageFile._safe_read(self.fp, length)\n        if length < 8:\n            if ImageFile.LOAD_TRUNCATED_IMAGES:\n                return s\n            msg = \"APNG contains truncated acTL chunk\"\n            raise ValueError(msg)\n        if self.im_n_frames is not None:\n            self.im_n_frames = None\n            warnings.warn(\"Invalid APNG, will use default PNG image if possible\")\n            return s\n        n_frames = i32(s)\n        if n_frames == 0 or n_frames > 0x80000000:\n            warnings.warn(\"Invalid APNG, will use default PNG image if possible\")\n            return s\n        self.im_n_frames = n_frames\n        self.im_info[\"loop\"] = i32(s, 4)\n        self.im_custom_mimetype = \"image/apng\"\n        return s\n\n    def chunk_fcTL(self, pos, length):\n        s = ImageFile._safe_read(self.fp, length)\n        if length < 26:\n            if ImageFile.LOAD_TRUNCATED_IMAGES:\n                return s\n            msg = \"APNG contains truncated fcTL chunk\"\n            raise ValueError(msg)\n        seq = i32(s)\n        if (self._seq_num is None and seq != 0) or (\n            self._seq_num is not None and self._seq_num != seq - 1\n        ):\n            msg = \"APNG contains frame sequence errors\"\n            raise SyntaxError(msg)\n        self._seq_num = seq\n        width, height = i32(s, 4), i32(s, 8)\n        px, py = i32(s, 12), i32(s, 16)\n        im_w, im_h = self.im_size\n        if px + width > im_w or py + height > im_h:\n            msg = \"APNG contains invalid frames\"\n            raise SyntaxError(msg)\n        self.im_info[\"bbox\"] = (px, py, px + width, py + height)\n        delay_num, delay_den = i16(s, 20), i16(s, 22)\n        if delay_den == 0:\n            delay_den = 100\n        self.im_info[\"duration\"] = float(delay_num) / float(delay_den) * 1000\n        self.im_info[\"disposal\"] = s[24]\n        self.im_info[\"blend\"] = s[25]\n        return s\n\n    def chunk_fdAT(self, pos, length):\n        if length < 4:\n            if ImageFile.LOAD_TRUNCATED_IMAGES:\n                s = ImageFile._safe_read(self.fp, length)\n                return s\n            msg = \"APNG contains truncated fDAT chunk\"\n            raise ValueError(msg)\n        s = ImageFile._safe_read(self.fp, 4)\n        seq = i32(s)\n        if self._seq_num != seq - 1:\n            msg = \"APNG contains frame sequence errors\"\n            raise SyntaxError(msg)\n        self._seq_num = seq\n        return self.chunk_IDAT(pos + 4, length - 4)\n\n\n# --------------------------------------------------------------------\n# PNG reader\n\n\ndef _accept(prefix):\n    return prefix[:8] == _MAGIC\n\n\n##\n# Image plugin for PNG images.\n\n\nclass PngImageFile(ImageFile.ImageFile):\n    format = \"PNG\"\n    format_description = \"Portable network graphics\"\n\n    def _open(self):\n        if not _accept(self.fp.read(8)):\n            msg = \"not a PNG file\"\n            raise SyntaxError(msg)\n        self._fp = self.fp\n        self.__frame = 0\n\n        #\n        # Parse headers up to the first IDAT or fDAT chunk\n\n        self.private_chunks = []\n        self.png = PngStream(self.fp)\n\n        while True:\n            #\n            # get next chunk\n\n            cid, pos, length = self.png.read()\n\n            try:\n                s = self.png.call(cid, pos, length)\n            except EOFError:\n                break\n            except AttributeError:\n                logger.debug(\"%r %s %s (unknown)\", cid, pos, length)\n                s = ImageFile._safe_read(self.fp, length)\n                if cid[1:2].islower():\n                    self.private_chunks.append((cid, s))\n\n            self.png.crc(cid, s)\n\n        #\n        # Copy relevant attributes from the PngStream.  An alternative\n        # would be to let the PngStream class modify these attributes\n        # directly, but that introduces circular references which are\n        # difficult to break if things go wrong in the decoder...\n        # (believe me, I've tried ;-)\n\n        self._mode = self.png.im_mode\n        self._size = self.png.im_size\n        self.info = self.png.im_info\n        self._text = None\n        self.tile = self.png.im_tile\n        self.custom_mimetype = self.png.im_custom_mimetype\n        self.n_frames = self.png.im_n_frames or 1\n        self.default_image = self.info.get(\"default_image\", False)\n\n        if self.png.im_palette:\n            rawmode, data = self.png.im_palette\n            self.palette = ImagePalette.raw(rawmode, data)\n\n        if cid == b\"fdAT\":\n            self.__prepare_idat = length - 4\n        else:\n            self.__prepare_idat = length  # used by load_prepare()\n\n        if self.png.im_n_frames is not None:\n            self._close_exclusive_fp_after_loading = False\n            self.png.save_rewind()\n            self.__rewind_idat = self.__prepare_idat\n            self.__rewind = self._fp.tell()\n            if self.default_image:\n                # IDAT chunk contains default image and not first animation frame\n                self.n_frames += 1\n            self._seek(0)\n        self.is_animated = self.n_frames > 1\n\n    @property\n    def text(self):\n        # experimental\n        if self._text is None:\n            # iTxt, tEXt and zTXt chunks may appear at the end of the file\n            # So load the file to ensure that they are read\n            if self.is_animated:\n                frame = self.__frame\n                # for APNG, seek to the final frame before loading\n                self.seek(self.n_frames - 1)\n            self.load()\n            if self.is_animated:\n                self.seek(frame)\n        return self._text\n\n    def verify(self):\n        \"\"\"Verify PNG file\"\"\"\n\n        if self.fp is None:\n            msg = \"verify must be called directly after open\"\n            raise RuntimeError(msg)\n\n        # back up to beginning of IDAT block\n        self.fp.seek(self.tile[0][2] - 8)\n\n        self.png.verify()\n        self.png.close()\n\n        if self._exclusive_fp:\n            self.fp.close()\n        self.fp = None\n\n    def seek(self, frame):\n        if not self._seek_check(frame):\n            return\n        if frame < self.__frame:\n            self._seek(0, True)\n\n        last_frame = self.__frame\n        for f in range(self.__frame + 1, frame + 1):\n            try:\n                self._seek(f)\n            except EOFError as e:\n                self.seek(last_frame)\n                msg = \"no more images in APNG file\"\n                raise EOFError(msg) from e\n\n    def _seek(self, frame, rewind=False):\n        if frame == 0:\n            if rewind:\n                self._fp.seek(self.__rewind)\n                self.png.rewind()\n                self.__prepare_idat = self.__rewind_idat\n                self.im = None\n                if self.pyaccess:\n                    self.pyaccess = None\n                self.info = self.png.im_info\n                self.tile = self.png.im_tile\n                self.fp = self._fp\n            self._prev_im = None\n            self.dispose = None\n            self.default_image = self.info.get(\"default_image\", False)\n            self.dispose_op = self.info.get(\"disposal\")\n            self.blend_op = self.info.get(\"blend\")\n            self.dispose_extent = self.info.get(\"bbox\")\n            self.__frame = 0\n        else:\n            if frame != self.__frame + 1:\n                msg = f\"cannot seek to frame {frame}\"\n                raise ValueError(msg)\n\n            # ensure previous frame was loaded\n            self.load()\n\n            if self.dispose:\n                self.im.paste(self.dispose, self.dispose_extent)\n            self._prev_im = self.im.copy()\n\n            self.fp = self._fp\n\n            # advance to the next frame\n            if self.__prepare_idat:\n                ImageFile._safe_read(self.fp, self.__prepare_idat)\n                self.__prepare_idat = 0\n            frame_start = False\n            while True:\n                self.fp.read(4)  # CRC\n\n                try:\n                    cid, pos, length = self.png.read()\n                except (struct.error, SyntaxError):\n                    break\n\n                if cid == b\"IEND\":\n                    msg = \"No more images in APNG file\"\n                    raise EOFError(msg)\n                if cid == b\"fcTL\":\n                    if frame_start:\n                        # there must be at least one fdAT chunk between fcTL chunks\n                        msg = \"APNG missing frame data\"\n                        raise SyntaxError(msg)\n                    frame_start = True\n\n                try:\n                    self.png.call(cid, pos, length)\n                except UnicodeDecodeError:\n                    break\n                except EOFError:\n                    if cid == b\"fdAT\":\n                        length -= 4\n                        if frame_start:\n                            self.__prepare_idat = length\n                            break\n                    ImageFile._safe_read(self.fp, length)\n                except AttributeError:\n                    logger.debug(\"%r %s %s (unknown)\", cid, pos, length)\n                    ImageFile._safe_read(self.fp, length)\n\n            self.__frame = frame\n            self.tile = self.png.im_tile\n            self.dispose_op = self.info.get(\"disposal\")\n            self.blend_op = self.info.get(\"blend\")\n            self.dispose_extent = self.info.get(\"bbox\")\n\n            if not self.tile:\n                msg = \"image not found in APNG frame\"\n                raise EOFError(msg)\n\n        # setup frame disposal (actual disposal done when needed in the next _seek())\n        if self._prev_im is None and self.dispose_op == Disposal.OP_PREVIOUS:\n            self.dispose_op = Disposal.OP_BACKGROUND\n\n        if self.dispose_op == Disposal.OP_PREVIOUS:\n            self.dispose = self._prev_im.copy()\n            self.dispose = self._crop(self.dispose, self.dispose_extent)\n        elif self.dispose_op == Disposal.OP_BACKGROUND:\n            self.dispose = Image.core.fill(self.mode, self.size)\n            self.dispose = self._crop(self.dispose, self.dispose_extent)\n        else:\n            self.dispose = None\n\n    def tell(self):\n        return self.__frame\n\n    def load_prepare(self):\n        \"\"\"internal: prepare to read PNG file\"\"\"\n\n        if self.info.get(\"interlace\"):\n            self.decoderconfig = self.decoderconfig + (1,)\n\n        self.__idat = self.__prepare_idat  # used by load_read()\n        ImageFile.ImageFile.load_prepare(self)\n\n    def load_read(self, read_bytes):\n        \"\"\"internal: read more image data\"\"\"\n\n        while self.__idat == 0:\n            # end of chunk, skip forward to next one\n\n            self.fp.read(4)  # CRC\n\n            cid, pos, length = self.png.read()\n\n            if cid not in [b\"IDAT\", b\"DDAT\", b\"fdAT\"]:\n                self.png.push(cid, pos, length)\n                return b\"\"\n\n            if cid == b\"fdAT\":\n                try:\n                    self.png.call(cid, pos, length)\n                except EOFError:\n                    pass\n                self.__idat = length - 4  # sequence_num has already been read\n            else:\n                self.__idat = length  # empty chunks are allowed\n\n        # read more data from this chunk\n        if read_bytes <= 0:\n            read_bytes = self.__idat\n        else:\n            read_bytes = min(read_bytes, self.__idat)\n\n        self.__idat = self.__idat - read_bytes\n\n        return self.fp.read(read_bytes)\n\n    def load_end(self):\n        \"\"\"internal: finished reading image data\"\"\"\n        if self.__idat != 0:\n            self.fp.read(self.__idat)\n        while True:\n            self.fp.read(4)  # CRC\n\n            try:\n                cid, pos, length = self.png.read()\n            except (struct.error, SyntaxError):\n                break\n\n            if cid == b\"IEND\":\n                break\n            elif cid == b\"fcTL\" and self.is_animated:\n                # start of the next frame, stop reading\n                self.__prepare_idat = 0\n                self.png.push(cid, pos, length)\n                break\n\n            try:\n                self.png.call(cid, pos, length)\n            except UnicodeDecodeError:\n                break\n            except EOFError:\n                if cid == b\"fdAT\":\n                    length -= 4\n                ImageFile._safe_read(self.fp, length)\n            except AttributeError:\n                logger.debug(\"%r %s %s (unknown)\", cid, pos, length)\n                s = ImageFile._safe_read(self.fp, length)\n                if cid[1:2].islower():\n                    self.private_chunks.append((cid, s, True))\n        self._text = self.png.im_text\n        if not self.is_animated:\n            self.png.close()\n            self.png = None\n        else:\n            if self._prev_im and self.blend_op == Blend.OP_OVER:\n                updated = self._crop(self.im, self.dispose_extent)\n                if self.im.mode == \"RGB\" and \"transparency\" in self.info:\n                    mask = updated.convert_transparent(\n                        \"RGBA\", self.info[\"transparency\"]\n                    )\n                else:\n                    mask = updated.convert(\"RGBA\")\n                self._prev_im.paste(updated, self.dispose_extent, mask)\n                self.im = self._prev_im\n                if self.pyaccess:\n                    self.pyaccess = None\n\n    def _getexif(self):\n        if \"exif\" not in self.info:\n            self.load()\n        if \"exif\" not in self.info and \"Raw profile type exif\" not in self.info:\n            return None\n        return self.getexif()._get_merged_dict()\n\n    def getexif(self):\n        if \"exif\" not in self.info:\n            self.load()\n\n        return super().getexif()\n\n    def getxmp(self):\n        \"\"\"\n        Returns a dictionary containing the XMP tags.\n        Requires defusedxml to be installed.\n\n        :returns: XMP tags in a dictionary.\n        \"\"\"\n        return (\n            self._getxmp(self.info[\"XML:com.adobe.xmp\"])\n            if \"XML:com.adobe.xmp\" in self.info\n            else {}\n        )\n\n\n# --------------------------------------------------------------------\n# PNG writer\n\n_OUTMODES = {\n    # supported PIL modes, and corresponding rawmodes/bits/color combinations\n    \"1\": (\"1\", b\"\\x01\\x00\"),\n    \"L;1\": (\"L;1\", b\"\\x01\\x00\"),\n    \"L;2\": (\"L;2\", b\"\\x02\\x00\"),\n    \"L;4\": (\"L;4\", b\"\\x04\\x00\"),\n    \"L\": (\"L\", b\"\\x08\\x00\"),\n    \"LA\": (\"LA\", b\"\\x08\\x04\"),\n    \"I\": (\"I;16B\", b\"\\x10\\x00\"),\n    \"I;16\": (\"I;16B\", b\"\\x10\\x00\"),\n    \"I;16B\": (\"I;16B\", b\"\\x10\\x00\"),\n    \"P;1\": (\"P;1\", b\"\\x01\\x03\"),\n    \"P;2\": (\"P;2\", b\"\\x02\\x03\"),\n    \"P;4\": (\"P;4\", b\"\\x04\\x03\"),\n    \"P\": (\"P\", b\"\\x08\\x03\"),\n    \"RGB\": (\"RGB\", b\"\\x08\\x02\"),\n    \"RGBA\": (\"RGBA\", b\"\\x08\\x06\"),\n}\n\n\ndef putchunk(fp, cid, *data):\n    \"\"\"Write a PNG chunk (including CRC field)\"\"\"\n\n    data = b\"\".join(data)\n\n    fp.write(o32(len(data)) + cid)\n    fp.write(data)\n    crc = _crc32(data, _crc32(cid))\n    fp.write(o32(crc))\n\n\nclass _idat:\n    # wrap output from the encoder in IDAT chunks\n\n    def __init__(self, fp, chunk):\n        self.fp = fp\n        self.chunk = chunk\n\n    def write(self, data):\n        self.chunk(self.fp, b\"IDAT\", data)\n\n\nclass _fdat:\n    # wrap encoder output in fdAT chunks\n\n    def __init__(self, fp, chunk, seq_num):\n        self.fp = fp\n        self.chunk = chunk\n        self.seq_num = seq_num\n\n    def write(self, data):\n        self.chunk(self.fp, b\"fdAT\", o32(self.seq_num), data)\n        self.seq_num += 1\n\n\ndef _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images):\n    duration = im.encoderinfo.get(\"duration\", im.info.get(\"duration\", 0))\n    loop = im.encoderinfo.get(\"loop\", im.info.get(\"loop\", 0))\n    disposal = im.encoderinfo.get(\"disposal\", im.info.get(\"disposal\", Disposal.OP_NONE))\n    blend = im.encoderinfo.get(\"blend\", im.info.get(\"blend\", Blend.OP_SOURCE))\n\n    if default_image:\n        chain = itertools.chain(append_images)\n    else:\n        chain = itertools.chain([im], append_images)\n\n    im_frames = []\n    frame_count = 0\n    for im_seq in chain:\n        for im_frame in ImageSequence.Iterator(im_seq):\n            if im_frame.mode == rawmode:\n                im_frame = im_frame.copy()\n            else:\n                im_frame = im_frame.convert(rawmode)\n            encoderinfo = im.encoderinfo.copy()\n            if isinstance(duration, (list, tuple)):\n                encoderinfo[\"duration\"] = duration[frame_count]\n            if isinstance(disposal, (list, tuple)):\n                encoderinfo[\"disposal\"] = disposal[frame_count]\n            if isinstance(blend, (list, tuple)):\n                encoderinfo[\"blend\"] = blend[frame_count]\n            frame_count += 1\n\n            if im_frames:\n                previous = im_frames[-1]\n                prev_disposal = previous[\"encoderinfo\"].get(\"disposal\")\n                prev_blend = previous[\"encoderinfo\"].get(\"blend\")\n                if prev_disposal == Disposal.OP_PREVIOUS and len(im_frames) < 2:\n                    prev_disposal = Disposal.OP_BACKGROUND\n\n                if prev_disposal == Disposal.OP_BACKGROUND:\n                    base_im = previous[\"im\"].copy()\n                    dispose = Image.core.fill(\"RGBA\", im.size, (0, 0, 0, 0))\n                    bbox = previous[\"bbox\"]\n                    if bbox:\n                        dispose = dispose.crop(bbox)\n                    else:\n                        bbox = (0, 0) + im.size\n                    base_im.paste(dispose, bbox)\n                elif prev_disposal == Disposal.OP_PREVIOUS:\n                    base_im = im_frames[-2][\"im\"]\n                else:\n                    base_im = previous[\"im\"]\n                delta = ImageChops.subtract_modulo(\n                    im_frame.convert(\"RGBA\"), base_im.convert(\"RGBA\")\n                )\n                bbox = delta.getbbox(alpha_only=False)\n                if (\n                    not bbox\n                    and prev_disposal == encoderinfo.get(\"disposal\")\n                    and prev_blend == encoderinfo.get(\"blend\")\n                ):\n                    previous[\"encoderinfo\"][\"duration\"] += encoderinfo.get(\n                        \"duration\", duration\n                    )\n                    continue\n            else:\n                bbox = None\n            if \"duration\" not in encoderinfo:\n                encoderinfo[\"duration\"] = duration\n            im_frames.append({\"im\": im_frame, \"bbox\": bbox, \"encoderinfo\": encoderinfo})\n\n    if len(im_frames) == 1 and not default_image:\n        return im_frames[0][\"im\"]\n\n    # animation control\n    chunk(\n        fp,\n        b\"acTL\",\n        o32(len(im_frames)),  # 0: num_frames\n        o32(loop),  # 4: num_plays\n    )\n\n    # default image IDAT (if it exists)\n    if default_image:\n        if im.mode != rawmode:\n            im = im.convert(rawmode)\n        ImageFile._save(im, _idat(fp, chunk), [(\"zip\", (0, 0) + im.size, 0, rawmode)])\n\n    seq_num = 0\n    for frame, frame_data in enumerate(im_frames):\n        im_frame = frame_data[\"im\"]\n        if not frame_data[\"bbox\"]:\n            bbox = (0, 0) + im_frame.size\n        else:\n            bbox = frame_data[\"bbox\"]\n            im_frame = im_frame.crop(bbox)\n        size = im_frame.size\n        encoderinfo = frame_data[\"encoderinfo\"]\n        frame_duration = int(round(encoderinfo[\"duration\"]))\n        frame_disposal = encoderinfo.get(\"disposal\", disposal)\n        frame_blend = encoderinfo.get(\"blend\", blend)\n        # frame control\n        chunk(\n            fp,\n            b\"fcTL\",\n            o32(seq_num),  # sequence_number\n            o32(size[0]),  # width\n            o32(size[1]),  # height\n            o32(bbox[0]),  # x_offset\n            o32(bbox[1]),  # y_offset\n            o16(frame_duration),  # delay_numerator\n            o16(1000),  # delay_denominator\n            o8(frame_disposal),  # dispose_op\n            o8(frame_blend),  # blend_op\n        )\n        seq_num += 1\n        # frame data\n        if frame == 0 and not default_image:\n            # first frame must be in IDAT chunks for backwards compatibility\n            ImageFile._save(\n                im_frame,\n                _idat(fp, chunk),\n                [(\"zip\", (0, 0) + im_frame.size, 0, rawmode)],\n            )\n        else:\n            fdat_chunks = _fdat(fp, chunk, seq_num)\n            ImageFile._save(\n                im_frame,\n                fdat_chunks,\n                [(\"zip\", (0, 0) + im_frame.size, 0, rawmode)],\n            )\n            seq_num = fdat_chunks.seq_num\n\n\ndef _save_all(im, fp, filename):\n    _save(im, fp, filename, save_all=True)\n\n\ndef _save(im, fp, filename, chunk=putchunk, save_all=False):\n    # save an image to disk (called by the save method)\n\n    if save_all:\n        default_image = im.encoderinfo.get(\n            \"default_image\", im.info.get(\"default_image\")\n        )\n        modes = set()\n        append_images = im.encoderinfo.get(\"append_images\", [])\n        for im_seq in itertools.chain([im], append_images):\n            for im_frame in ImageSequence.Iterator(im_seq):\n                modes.add(im_frame.mode)\n        for mode in (\"RGBA\", \"RGB\", \"P\"):\n            if mode in modes:\n                break\n        else:\n            mode = modes.pop()\n    else:\n        mode = im.mode\n\n    if mode == \"P\":\n        #\n        # attempt to minimize storage requirements for palette images\n        if \"bits\" in im.encoderinfo:\n            # number of bits specified by user\n            colors = min(1 << im.encoderinfo[\"bits\"], 256)\n        else:\n            # check palette contents\n            if im.palette:\n                colors = max(min(len(im.palette.getdata()[1]) // 3, 256), 1)\n            else:\n                colors = 256\n\n        if colors <= 16:\n            if colors <= 2:\n                bits = 1\n            elif colors <= 4:\n                bits = 2\n            else:\n                bits = 4\n            mode = f\"{mode};{bits}\"\n\n    # encoder options\n    im.encoderconfig = (\n        im.encoderinfo.get(\"optimize\", False),\n        im.encoderinfo.get(\"compress_level\", -1),\n        im.encoderinfo.get(\"compress_type\", -1),\n        im.encoderinfo.get(\"dictionary\", b\"\"),\n    )\n\n    # get the corresponding PNG mode\n    try:\n        rawmode, mode = _OUTMODES[mode]\n    except KeyError as e:\n        msg = f\"cannot write mode {mode} as PNG\"\n        raise OSError(msg) from e\n\n    #\n    # write minimal PNG file\n\n    fp.write(_MAGIC)\n\n    chunk(\n        fp,\n        b\"IHDR\",\n        o32(im.size[0]),  # 0: size\n        o32(im.size[1]),\n        mode,  # 8: depth/type\n        b\"\\0\",  # 10: compression\n        b\"\\0\",  # 11: filter category\n        b\"\\0\",  # 12: interlace flag\n    )\n\n    chunks = [b\"cHRM\", b\"gAMA\", b\"sBIT\", b\"sRGB\", b\"tIME\"]\n\n    icc = im.encoderinfo.get(\"icc_profile\", im.info.get(\"icc_profile\"))\n    if icc:\n        # ICC profile\n        # according to PNG spec, the iCCP chunk contains:\n        # Profile name  1-79 bytes (character string)\n        # Null separator        1 byte (null character)\n        # Compression method    1 byte (0)\n        # Compressed profile    n bytes (zlib with deflate compression)\n        name = b\"ICC Profile\"\n        data = name + b\"\\0\\0\" + zlib.compress(icc)\n        chunk(fp, b\"iCCP\", data)\n\n        # You must either have sRGB or iCCP.\n        # Disallow sRGB chunks when an iCCP-chunk has been emitted.\n        chunks.remove(b\"sRGB\")\n\n    info = im.encoderinfo.get(\"pnginfo\")\n    if info:\n        chunks_multiple_allowed = [b\"sPLT\", b\"iTXt\", b\"tEXt\", b\"zTXt\"]\n        for info_chunk in info.chunks:\n            cid, data = info_chunk[:2]\n            if cid in chunks:\n                chunks.remove(cid)\n                chunk(fp, cid, data)\n            elif cid in chunks_multiple_allowed:\n                chunk(fp, cid, data)\n            elif cid[1:2].islower():\n                # Private chunk\n                after_idat = info_chunk[2:3]\n                if not after_idat:\n                    chunk(fp, cid, data)\n\n    if im.mode == \"P\":\n        palette_byte_number = colors * 3\n        palette_bytes = im.im.getpalette(\"RGB\")[:palette_byte_number]\n        while len(palette_bytes) < palette_byte_number:\n            palette_bytes += b\"\\0\"\n        chunk(fp, b\"PLTE\", palette_bytes)\n\n    transparency = im.encoderinfo.get(\"transparency\", im.info.get(\"transparency\", None))\n\n    if transparency or transparency == 0:\n        if im.mode == \"P\":\n            # limit to actual palette size\n            alpha_bytes = colors\n            if isinstance(transparency, bytes):\n                chunk(fp, b\"tRNS\", transparency[:alpha_bytes])\n            else:\n                transparency = max(0, min(255, transparency))\n                alpha = b\"\\xFF\" * transparency + b\"\\0\"\n                chunk(fp, b\"tRNS\", alpha[:alpha_bytes])\n        elif im.mode in (\"1\", \"L\", \"I\"):\n            transparency = max(0, min(65535, transparency))\n            chunk(fp, b\"tRNS\", o16(transparency))\n        elif im.mode == \"RGB\":\n            red, green, blue = transparency\n            chunk(fp, b\"tRNS\", o16(red) + o16(green) + o16(blue))\n        else:\n            if \"transparency\" in im.encoderinfo:\n                # don't bother with transparency if it's an RGBA\n                # and it's in the info dict. It's probably just stale.\n                msg = \"cannot use transparency for this mode\"\n                raise OSError(msg)\n    else:\n        if im.mode == \"P\" and im.im.getpalettemode() == \"RGBA\":\n            alpha = im.im.getpalette(\"RGBA\", \"A\")\n            alpha_bytes = colors\n            chunk(fp, b\"tRNS\", alpha[:alpha_bytes])\n\n    dpi = im.encoderinfo.get(\"dpi\")\n    if dpi:\n        chunk(\n            fp,\n            b\"pHYs\",\n            o32(int(dpi[0] / 0.0254 + 0.5)),\n            o32(int(dpi[1] / 0.0254 + 0.5)),\n            b\"\\x01\",\n        )\n\n    if info:\n        chunks = [b\"bKGD\", b\"hIST\"]\n        for info_chunk in info.chunks:\n            cid, data = info_chunk[:2]\n            if cid in chunks:\n                chunks.remove(cid)\n                chunk(fp, cid, data)\n\n    exif = im.encoderinfo.get(\"exif\")\n    if exif:\n        if isinstance(exif, Image.Exif):\n            exif = exif.tobytes(8)\n        if exif.startswith(b\"Exif\\x00\\x00\"):\n            exif = exif[6:]\n        chunk(fp, b\"eXIf\", exif)\n\n    if save_all:\n        im = _write_multiple_frames(\n            im, fp, chunk, rawmode, default_image, append_images\n        )\n    if im:\n        ImageFile._save(im, _idat(fp, chunk), [(\"zip\", (0, 0) + im.size, 0, rawmode)])\n\n    if info:\n        for info_chunk in info.chunks:\n            cid, data = info_chunk[:2]\n            if cid[1:2].islower():\n                # Private chunk\n                after_idat = info_chunk[2:3]\n                if after_idat:\n                    chunk(fp, cid, data)\n\n    chunk(fp, b\"IEND\", b\"\")\n\n    if hasattr(fp, \"flush\"):\n        fp.flush()\n\n\n# --------------------------------------------------------------------\n# PNG chunk converter\n\n\ndef getchunks(im, **params):\n    \"\"\"Return a list of PNG chunks representing this image.\"\"\"\n\n    class collector:\n        data = []\n\n        def write(self, data):\n            pass\n\n        def append(self, chunk):\n            self.data.append(chunk)\n\n    def append(fp, cid, *data):\n        data = b\"\".join(data)\n        crc = o32(_crc32(data, _crc32(cid)))\n        fp.append((cid, data, crc))\n\n    fp = collector()\n\n    try:\n        im.encoderinfo = params\n        _save(im, fp, None, append)\n    finally:\n        del im.encoderinfo\n\n    return fp.data\n\n\n# --------------------------------------------------------------------\n# Registry\n\nImage.register_open(PngImageFile.format, PngImageFile, _accept)\nImage.register_save(PngImageFile.format, _save)\nImage.register_save_all(PngImageFile.format, _save_all)\n\nImage.register_extensions(PngImageFile.format, [\".png\", \".apng\"])\n\nImage.register_mime(PngImageFile.format, \"image/png\")\n",1460],"C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py":["# Copyright 2001-2019 by Vinay Sajip. All Rights Reserved.\n#\n# Permission to use, copy, modify, and distribute this software and its\n# documentation for any purpose and without fee is hereby granted,\n# provided that the above copyright notice appear in all copies and that\n# both that copyright notice and this permission notice appear in\n# supporting documentation, and that the name of Vinay Sajip\n# not be used in advertising or publicity pertaining to distribution\n# of the software without specific, written prior permission.\n# VINAY SAJIP DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING\n# ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL\n# VINAY SAJIP BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR\n# ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER\n# IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT\n# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n\n\"\"\"\nLogging package for Python. Based on PEP 282 and comments thereto in\ncomp.lang.python.\n\nCopyright (C) 2001-2019 Vinay Sajip. All Rights Reserved.\n\nTo use, simply 'import logging' and log away!\n\"\"\"\n\nimport sys, os, time, io, re, traceback, warnings, weakref, collections.abc\n\nfrom types import GenericAlias\nfrom string import Template\nfrom string import Formatter as StrFormatter\n\n\n__all__ = ['BASIC_FORMAT', 'BufferingFormatter', 'CRITICAL', 'DEBUG', 'ERROR',\n           'FATAL', 'FileHandler', 'Filter', 'Formatter', 'Handler', 'INFO',\n           'LogRecord', 'Logger', 'LoggerAdapter', 'NOTSET', 'NullHandler',\n           'StreamHandler', 'WARN', 'WARNING', 'addLevelName', 'basicConfig',\n           'captureWarnings', 'critical', 'debug', 'disable', 'error',\n           'exception', 'fatal', 'getLevelName', 'getLogger', 'getLoggerClass',\n           'info', 'log', 'makeLogRecord', 'setLoggerClass', 'shutdown',\n           'warn', 'warning', 'getLogRecordFactory', 'setLogRecordFactory',\n           'lastResort', 'raiseExceptions', 'getLevelNamesMapping']\n\nimport threading\n\n__author__  = \"Vinay Sajip <vinay_sajip@red-dove.com>\"\n__status__  = \"production\"\n# The following module attributes are no longer updated.\n__version__ = \"0.5.1.2\"\n__date__    = \"07 February 2010\"\n\n#---------------------------------------------------------------------------\n#   Miscellaneous module data\n#---------------------------------------------------------------------------\n\n#\n#_startTime is used as the base when calculating the relative time of events\n#\n_startTime = time.time()\n\n#\n#raiseExceptions is used to see if exceptions during handling should be\n#propagated\n#\nraiseExceptions = True\n\n#\n# If you don't want threading information in the log, set this to zero\n#\nlogThreads = True\n\n#\n# If you don't want multiprocessing information in the log, set this to zero\n#\nlogMultiprocessing = True\n\n#\n# If you don't want process information in the log, set this to zero\n#\nlogProcesses = True\n\n#---------------------------------------------------------------------------\n#   Level related stuff\n#---------------------------------------------------------------------------\n#\n# Default levels and level names, these can be replaced with any positive set\n# of values having corresponding names. There is a pseudo-level, NOTSET, which\n# is only really there as a lower limit for user-defined levels. Handlers and\n# loggers are initialized with NOTSET so that they will log all messages, even\n# at user-defined levels.\n#\n\nCRITICAL = 50\nFATAL = CRITICAL\nERROR = 40\nWARNING = 30\nWARN = WARNING\nINFO = 20\nDEBUG = 10\nNOTSET = 0\n\n_levelToName = {\n    CRITICAL: 'CRITICAL',\n    ERROR: 'ERROR',\n    WARNING: 'WARNING',\n    INFO: 'INFO',\n    DEBUG: 'DEBUG',\n    NOTSET: 'NOTSET',\n}\n_nameToLevel = {\n    'CRITICAL': CRITICAL,\n    'FATAL': FATAL,\n    'ERROR': ERROR,\n    'WARN': WARNING,\n    'WARNING': WARNING,\n    'INFO': INFO,\n    'DEBUG': DEBUG,\n    'NOTSET': NOTSET,\n}\n\ndef getLevelNamesMapping():\n    return _nameToLevel.copy()\n\ndef getLevelName(level):\n    \"\"\"\n    Return the textual or numeric representation of logging level 'level'.\n\n    If the level is one of the predefined levels (CRITICAL, ERROR, WARNING,\n    INFO, DEBUG) then you get the corresponding string. If you have\n    associated levels with names using addLevelName then the name you have\n    associated with 'level' is returned.\n\n    If a numeric value corresponding to one of the defined levels is passed\n    in, the corresponding string representation is returned.\n\n    If a string representation of the level is passed in, the corresponding\n    numeric value is returned.\n\n    If no matching numeric or string value is passed in, the string\n    'Level %s' % level is returned.\n    \"\"\"\n    # See Issues #22386, #27937 and #29220 for why it's this way\n    result = _levelToName.get(level)\n    if result is not None:\n        return result\n    result = _nameToLevel.get(level)\n    if result is not None:\n        return result\n    return \"Level %s\" % level\n\ndef addLevelName(level, levelName):\n    \"\"\"\n    Associate 'levelName' with 'level'.\n\n    This is used when converting levels to text during message formatting.\n    \"\"\"\n    _acquireLock()\n    try:    #unlikely to cause an exception, but you never know...\n        _levelToName[level] = levelName\n        _nameToLevel[levelName] = level\n    finally:\n        _releaseLock()\n\nif hasattr(sys, \"_getframe\"):\n    currentframe = lambda: sys._getframe(1)\nelse: #pragma: no cover\n    def currentframe():\n        \"\"\"Return the frame object for the caller's stack frame.\"\"\"\n        try:\n            raise Exception\n        except Exception:\n            return sys.exc_info()[2].tb_frame.f_back\n\n#\n# _srcfile is used when walking the stack to check when we've got the first\n# caller stack frame, by skipping frames whose filename is that of this\n# module's source. It therefore should contain the filename of this module's\n# source file.\n#\n# Ordinarily we would use __file__ for this, but frozen modules don't always\n# have __file__ set, for some reason (see Issue #21736). Thus, we get the\n# filename from a handy code object from a function defined in this module.\n# (There's no particular reason for picking addLevelName.)\n#\n\n_srcfile = os.path.normcase(addLevelName.__code__.co_filename)\n\n# _srcfile is only used in conjunction with sys._getframe().\n# Setting _srcfile to None will prevent findCaller() from being called. This\n# way, you can avoid the overhead of fetching caller information.\n\n# The following is based on warnings._is_internal_frame. It makes sure that\n# frames of the import mechanism are skipped when logging at module level and\n# using a stacklevel value greater than one.\ndef _is_internal_frame(frame):\n    \"\"\"Signal whether the frame is a CPython or logging module internal.\"\"\"\n    filename = os.path.normcase(frame.f_code.co_filename)\n    return filename == _srcfile or (\n        \"importlib\" in filename and \"_bootstrap\" in filename\n    )\n\n\ndef _checkLevel(level):\n    if isinstance(level, int):\n        rv = level\n    elif str(level) == level:\n        if level not in _nameToLevel:\n            raise ValueError(\"Unknown level: %r\" % level)\n        rv = _nameToLevel[level]\n    else:\n        raise TypeError(\"Level not an integer or a valid string: %r\"\n                        % (level,))\n    return rv\n\n#---------------------------------------------------------------------------\n#   Thread-related stuff\n#---------------------------------------------------------------------------\n\n#\n#_lock is used to serialize access to shared data structures in this module.\n#This needs to be an RLock because fileConfig() creates and configures\n#Handlers, and so might arbitrary user threads. Since Handler code updates the\n#shared dictionary _handlers, it needs to acquire the lock. But if configuring,\n#the lock would already have been acquired - so we need an RLock.\n#The same argument applies to Loggers and Manager.loggerDict.\n#\n_lock = threading.RLock()\n\ndef _acquireLock():\n    \"\"\"\n    Acquire the module-level lock for serializing access to shared data.\n\n    This should be released with _releaseLock().\n    \"\"\"\n    if _lock:\n        _lock.acquire()\n\ndef _releaseLock():\n    \"\"\"\n    Release the module-level lock acquired by calling _acquireLock().\n    \"\"\"\n    if _lock:\n        _lock.release()\n\n\n# Prevent a held logging lock from blocking a child from logging.\n\nif not hasattr(os, 'register_at_fork'):  # Windows and friends.\n    def _register_at_fork_reinit_lock(instance):\n        pass  # no-op when os.register_at_fork does not exist.\nelse:\n    # A collection of instances with a _at_fork_reinit method (logging.Handler)\n    # to be called in the child after forking.  The weakref avoids us keeping\n    # discarded Handler instances alive.\n    _at_fork_reinit_lock_weakset = weakref.WeakSet()\n\n    def _register_at_fork_reinit_lock(instance):\n        _acquireLock()\n        try:\n            _at_fork_reinit_lock_weakset.add(instance)\n        finally:\n            _releaseLock()\n\n    def _after_at_fork_child_reinit_locks():\n        for handler in _at_fork_reinit_lock_weakset:\n            handler._at_fork_reinit()\n\n        # _acquireLock() was called in the parent before forking.\n        # The lock is reinitialized to unlocked state.\n        _lock._at_fork_reinit()\n\n    os.register_at_fork(before=_acquireLock,\n                        after_in_child=_after_at_fork_child_reinit_locks,\n                        after_in_parent=_releaseLock)\n\n\n#---------------------------------------------------------------------------\n#   The logging record\n#---------------------------------------------------------------------------\n\nclass LogRecord(object):\n    \"\"\"\n    A LogRecord instance represents an event being logged.\n\n    LogRecord instances are created every time something is logged. They\n    contain all the information pertinent to the event being logged. The\n    main information passed in is in msg and args, which are combined\n    using str(msg) % args to create the message field of the record. The\n    record also includes information such as when the record was created,\n    the source line where the logging call was made, and any exception\n    information to be logged.\n    \"\"\"\n    def __init__(self, name, level, pathname, lineno,\n                 msg, args, exc_info, func=None, sinfo=None, **kwargs):\n        \"\"\"\n        Initialize a logging record with interesting information.\n        \"\"\"\n        ct = time.time()\n        self.name = name\n        self.msg = msg\n        #\n        # The following statement allows passing of a dictionary as a sole\n        # argument, so that you can do something like\n        #  logging.debug(\"a %(a)d b %(b)s\", {'a':1, 'b':2})\n        # Suggested by Stefan Behnel.\n        # Note that without the test for args[0], we get a problem because\n        # during formatting, we test to see if the arg is present using\n        # 'if self.args:'. If the event being logged is e.g. 'Value is %d'\n        # and if the passed arg fails 'if self.args:' then no formatting\n        # is done. For example, logger.warning('Value is %d', 0) would log\n        # 'Value is %d' instead of 'Value is 0'.\n        # For the use case of passing a dictionary, this should not be a\n        # problem.\n        # Issue #21172: a request was made to relax the isinstance check\n        # to hasattr(args[0], '__getitem__'). However, the docs on string\n        # formatting still seem to suggest a mapping object is required.\n        # Thus, while not removing the isinstance check, it does now look\n        # for collections.abc.Mapping rather than, as before, dict.\n        if (args and len(args) == 1 and isinstance(args[0], collections.abc.Mapping)\n            and args[0]):\n            args = args[0]\n        self.args = args\n        self.levelname = getLevelName(level)\n        self.levelno = level\n        self.pathname = pathname\n        try:\n            self.filename = os.path.basename(pathname)\n            self.module = os.path.splitext(self.filename)[0]\n        except (TypeError, ValueError, AttributeError):\n            self.filename = pathname\n            self.module = \"Unknown module\"\n        self.exc_info = exc_info\n        self.exc_text = None      # used to cache the traceback text\n        self.stack_info = sinfo\n        self.lineno = lineno\n        self.funcName = func\n        self.created = ct\n        self.msecs = int((ct - int(ct)) * 1000) + 0.0  # see gh-89047\n        self.relativeCreated = (self.created - _startTime) * 1000\n        if logThreads:\n            self.thread = threading.get_ident()\n            self.threadName = threading.current_thread().name\n        else: # pragma: no cover\n            self.thread = None\n            self.threadName = None\n        if not logMultiprocessing: # pragma: no cover\n            self.processName = None\n        else:\n            self.processName = 'MainProcess'\n            mp = sys.modules.get('multiprocessing')\n            if mp is not None:\n                # Errors may occur if multiprocessing has not finished loading\n                # yet - e.g. if a custom import hook causes third-party code\n                # to run when multiprocessing calls import. See issue 8200\n                # for an example\n                try:\n                    self.processName = mp.current_process().name\n                except Exception: #pragma: no cover\n                    pass\n        if logProcesses and hasattr(os, 'getpid'):\n            self.process = os.getpid()\n        else:\n            self.process = None\n\n    def __repr__(self):\n        return '<LogRecord: %s, %s, %s, %s, \"%s\">'%(self.name, self.levelno,\n            self.pathname, self.lineno, self.msg)\n\n    def getMessage(self):\n        \"\"\"\n        Return the message for this LogRecord.\n\n        Return the message for this LogRecord after merging any user-supplied\n        arguments with the message.\n        \"\"\"\n        msg = str(self.msg)\n        if self.args:\n            msg = msg % self.args\n        return msg\n\n#\n#   Determine which class to use when instantiating log records.\n#\n_logRecordFactory = LogRecord\n\ndef setLogRecordFactory(factory):\n    \"\"\"\n    Set the factory to be used when instantiating a log record.\n\n    :param factory: A callable which will be called to instantiate\n    a log record.\n    \"\"\"\n    global _logRecordFactory\n    _logRecordFactory = factory\n\ndef getLogRecordFactory():\n    \"\"\"\n    Return the factory to be used when instantiating a log record.\n    \"\"\"\n\n    return _logRecordFactory\n\ndef makeLogRecord(dict):\n    \"\"\"\n    Make a LogRecord whose attributes are defined by the specified dictionary,\n    This function is useful for converting a logging event received over\n    a socket connection (which is sent as a dictionary) into a LogRecord\n    instance.\n    \"\"\"\n    rv = _logRecordFactory(None, None, \"\", 0, \"\", (), None, None)\n    rv.__dict__.update(dict)\n    return rv\n\n\n#---------------------------------------------------------------------------\n#   Formatter classes and functions\n#---------------------------------------------------------------------------\n_str_formatter = StrFormatter()\ndel StrFormatter\n\n\nclass PercentStyle(object):\n\n    default_format = '%(message)s'\n    asctime_format = '%(asctime)s'\n    asctime_search = '%(asctime)'\n    validation_pattern = re.compile(r'%\\(\\w+\\)[#0+ -]*(\\*|\\d+)?(\\.(\\*|\\d+))?[diouxefgcrsa%]', re.I)\n\n    def __init__(self, fmt, *, defaults=None):\n        self._fmt = fmt or self.default_format\n        self._defaults = defaults\n\n    def usesTime(self):\n        return self._fmt.find(self.asctime_search) >= 0\n\n    def validate(self):\n        \"\"\"Validate the input format, ensure it matches the correct style\"\"\"\n        if not self.validation_pattern.search(self._fmt):\n            raise ValueError(\"Invalid format '%s' for '%s' style\" % (self._fmt, self.default_format[0]))\n\n    def _format(self, record):\n        if defaults := self._defaults:\n            values = defaults | record.__dict__\n        else:\n            values = record.__dict__\n        return self._fmt % values\n\n    def format(self, record):\n        try:\n            return self._format(record)\n        except KeyError as e:\n            raise ValueError('Formatting field not found in record: %s' % e)\n\n\nclass StrFormatStyle(PercentStyle):\n    default_format = '{message}'\n    asctime_format = '{asctime}'\n    asctime_search = '{asctime'\n\n    fmt_spec = re.compile(r'^(.?[<>=^])?[+ -]?#?0?(\\d+|{\\w+})?[,_]?(\\.(\\d+|{\\w+}))?[bcdefgnosx%]?$', re.I)\n    field_spec = re.compile(r'^(\\d+|\\w+)(\\.\\w+|\\[[^]]+\\])*$')\n\n    def _format(self, record):\n        if defaults := self._defaults:\n            values = defaults | record.__dict__\n        else:\n            values = record.__dict__\n        return self._fmt.format(**values)\n\n    def validate(self):\n        \"\"\"Validate the input format, ensure it is the correct string formatting style\"\"\"\n        fields = set()\n        try:\n            for _, fieldname, spec, conversion in _str_formatter.parse(self._fmt):\n                if fieldname:\n                    if not self.field_spec.match(fieldname):\n                        raise ValueError('invalid field name/expression: %r' % fieldname)\n                    fields.add(fieldname)\n                if conversion and conversion not in 'rsa':\n                    raise ValueError('invalid conversion: %r' % conversion)\n                if spec and not self.fmt_spec.match(spec):\n                    raise ValueError('bad specifier: %r' % spec)\n        except ValueError as e:\n            raise ValueError('invalid format: %s' % e)\n        if not fields:\n            raise ValueError('invalid format: no fields')\n\n\nclass StringTemplateStyle(PercentStyle):\n    default_format = '${message}'\n    asctime_format = '${asctime}'\n    asctime_search = '${asctime}'\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._tpl = Template(self._fmt)\n\n    def usesTime(self):\n        fmt = self._fmt\n        return fmt.find('$asctime') >= 0 or fmt.find(self.asctime_search) >= 0\n\n    def validate(self):\n        pattern = Template.pattern\n        fields = set()\n        for m in pattern.finditer(self._fmt):\n            d = m.groupdict()\n            if d['named']:\n                fields.add(d['named'])\n            elif d['braced']:\n                fields.add(d['braced'])\n            elif m.group(0) == '$':\n                raise ValueError('invalid format: bare \\'$\\' not allowed')\n        if not fields:\n            raise ValueError('invalid format: no fields')\n\n    def _format(self, record):\n        if defaults := self._defaults:\n            values = defaults | record.__dict__\n        else:\n            values = record.__dict__\n        return self._tpl.substitute(**values)\n\n\nBASIC_FORMAT = \"%(levelname)s:%(name)s:%(message)s\"\n\n_STYLES = {\n    '%': (PercentStyle, BASIC_FORMAT),\n    '{': (StrFormatStyle, '{levelname}:{name}:{message}'),\n    '$': (StringTemplateStyle, '${levelname}:${name}:${message}'),\n}\n\nclass Formatter(object):\n    \"\"\"\n    Formatter instances are used to convert a LogRecord to text.\n\n    Formatters need to know how a LogRecord is constructed. They are\n    responsible for converting a LogRecord to (usually) a string which can\n    be interpreted by either a human or an external system. The base Formatter\n    allows a formatting string to be specified. If none is supplied, the\n    style-dependent default value, \"%(message)s\", \"{message}\", or\n    \"${message}\", is used.\n\n    The Formatter can be initialized with a format string which makes use of\n    knowledge of the LogRecord attributes - e.g. the default value mentioned\n    above makes use of the fact that the user's message and arguments are pre-\n    formatted into a LogRecord's message attribute. Currently, the useful\n    attributes in a LogRecord are described by:\n\n    %(name)s            Name of the logger (logging channel)\n    %(levelno)s         Numeric logging level for the message (DEBUG, INFO,\n                        WARNING, ERROR, CRITICAL)\n    %(levelname)s       Text logging level for the message (\"DEBUG\", \"INFO\",\n                        \"WARNING\", \"ERROR\", \"CRITICAL\")\n    %(pathname)s        Full pathname of the source file where the logging\n                        call was issued (if available)\n    %(filename)s        Filename portion of pathname\n    %(module)s          Module (name portion of filename)\n    %(lineno)d          Source line number where the logging call was issued\n                        (if available)\n    %(funcName)s        Function name\n    %(created)f         Time when the LogRecord was created (time.time()\n                        return value)\n    %(asctime)s         Textual time when the LogRecord was created\n    %(msecs)d           Millisecond portion of the creation time\n    %(relativeCreated)d Time in milliseconds when the LogRecord was created,\n                        relative to the time the logging module was loaded\n                        (typically at application startup time)\n    %(thread)d          Thread ID (if available)\n    %(threadName)s      Thread name (if available)\n    %(process)d         Process ID (if available)\n    %(message)s         The result of record.getMessage(), computed just as\n                        the record is emitted\n    \"\"\"\n\n    converter = time.localtime\n\n    def __init__(self, fmt=None, datefmt=None, style='%', validate=True, *,\n                 defaults=None):\n        \"\"\"\n        Initialize the formatter with specified format strings.\n\n        Initialize the formatter either with the specified format string, or a\n        default as described above. Allow for specialized date formatting with\n        the optional datefmt argument. If datefmt is omitted, you get an\n        ISO8601-like (or RFC 3339-like) format.\n\n        Use a style parameter of '%', '{' or '$' to specify that you want to\n        use one of %-formatting, :meth:`str.format` (``{}``) formatting or\n        :class:`string.Template` formatting in your format string.\n\n        .. versionchanged:: 3.2\n           Added the ``style`` parameter.\n        \"\"\"\n        if style not in _STYLES:\n            raise ValueError('Style must be one of: %s' % ','.join(\n                             _STYLES.keys()))\n        self._style = _STYLES[style][0](fmt, defaults=defaults)\n        if validate:\n            self._style.validate()\n\n        self._fmt = self._style._fmt\n        self.datefmt = datefmt\n\n    default_time_format = '%Y-%m-%d %H:%M:%S'\n    default_msec_format = '%s,%03d'\n\n    def formatTime(self, record, datefmt=None):\n        \"\"\"\n        Return the creation time of the specified LogRecord as formatted text.\n\n        This method should be called from format() by a formatter which\n        wants to make use of a formatted time. This method can be overridden\n        in formatters to provide for any specific requirement, but the\n        basic behaviour is as follows: if datefmt (a string) is specified,\n        it is used with time.strftime() to format the creation time of the\n        record. Otherwise, an ISO8601-like (or RFC 3339-like) format is used.\n        The resulting string is returned. This function uses a user-configurable\n        function to convert the creation time to a tuple. By default,\n        time.localtime() is used; to change this for a particular formatter\n        instance, set the 'converter' attribute to a function with the same\n        signature as time.localtime() or time.gmtime(). To change it for all\n        formatters, for example if you want all logging times to be shown in GMT,\n        set the 'converter' attribute in the Formatter class.\n        \"\"\"\n        ct = self.converter(record.created)\n        if datefmt:\n            s = time.strftime(datefmt, ct)\n        else:\n            s = time.strftime(self.default_time_format, ct)\n            if self.default_msec_format:\n                s = self.default_msec_format % (s, record.msecs)\n        return s\n\n    def formatException(self, ei):\n        \"\"\"\n        Format and return the specified exception information as a string.\n\n        This default implementation just uses\n        traceback.print_exception()\n        \"\"\"\n        sio = io.StringIO()\n        tb = ei[2]\n        # See issues #9427, #1553375. Commented out for now.\n        #if getattr(self, 'fullstack', False):\n        #    traceback.print_stack(tb.tb_frame.f_back, file=sio)\n        traceback.print_exception(ei[0], ei[1], tb, None, sio)\n        s = sio.getvalue()\n        sio.close()\n        if s[-1:] == \"\\n\":\n            s = s[:-1]\n        return s\n\n    def usesTime(self):\n        \"\"\"\n        Check if the format uses the creation time of the record.\n        \"\"\"\n        return self._style.usesTime()\n\n    def formatMessage(self, record):\n        return self._style.format(record)\n\n    def formatStack(self, stack_info):\n        \"\"\"\n        This method is provided as an extension point for specialized\n        formatting of stack information.\n\n        The input data is a string as returned from a call to\n        :func:`traceback.print_stack`, but with the last trailing newline\n        removed.\n\n        The base implementation just returns the value passed in.\n        \"\"\"\n        return stack_info\n\n    def format(self, record):\n        \"\"\"\n        Format the specified record as text.\n\n        The record's attribute dictionary is used as the operand to a\n        string formatting operation which yields the returned string.\n        Before formatting the dictionary, a couple of preparatory steps\n        are carried out. The message attribute of the record is computed\n        using LogRecord.getMessage(). If the formatting string uses the\n        time (as determined by a call to usesTime(), formatTime() is\n        called to format the event time. If there is exception information,\n        it is formatted using formatException() and appended to the message.\n        \"\"\"\n        record.message = record.getMessage()\n        if self.usesTime():\n            record.asctime = self.formatTime(record, self.datefmt)\n        s = self.formatMessage(record)\n        if record.exc_info:\n            # Cache the traceback text to avoid converting it multiple times\n            # (it's constant anyway)\n            if not record.exc_text:\n                record.exc_text = self.formatException(record.exc_info)\n        if record.exc_text:\n            if s[-1:] != \"\\n\":\n                s = s + \"\\n\"\n            s = s + record.exc_text\n        if record.stack_info:\n            if s[-1:] != \"\\n\":\n                s = s + \"\\n\"\n            s = s + self.formatStack(record.stack_info)\n        return s\n\n#\n#   The default formatter to use when no other is specified\n#\n_defaultFormatter = Formatter()\n\nclass BufferingFormatter(object):\n    \"\"\"\n    A formatter suitable for formatting a number of records.\n    \"\"\"\n    def __init__(self, linefmt=None):\n        \"\"\"\n        Optionally specify a formatter which will be used to format each\n        individual record.\n        \"\"\"\n        if linefmt:\n            self.linefmt = linefmt\n        else:\n            self.linefmt = _defaultFormatter\n\n    def formatHeader(self, records):\n        \"\"\"\n        Return the header string for the specified records.\n        \"\"\"\n        return \"\"\n\n    def formatFooter(self, records):\n        \"\"\"\n        Return the footer string for the specified records.\n        \"\"\"\n        return \"\"\n\n    def format(self, records):\n        \"\"\"\n        Format the specified records and return the result as a string.\n        \"\"\"\n        rv = \"\"\n        if len(records) > 0:\n            rv = rv + self.formatHeader(records)\n            for record in records:\n                rv = rv + self.linefmt.format(record)\n            rv = rv + self.formatFooter(records)\n        return rv\n\n#---------------------------------------------------------------------------\n#   Filter classes and functions\n#---------------------------------------------------------------------------\n\nclass Filter(object):\n    \"\"\"\n    Filter instances are used to perform arbitrary filtering of LogRecords.\n\n    Loggers and Handlers can optionally use Filter instances to filter\n    records as desired. The base filter class only allows events which are\n    below a certain point in the logger hierarchy. For example, a filter\n    initialized with \"A.B\" will allow events logged by loggers \"A.B\",\n    \"A.B.C\", \"A.B.C.D\", \"A.B.D\" etc. but not \"A.BB\", \"B.A.B\" etc. If\n    initialized with the empty string, all events are passed.\n    \"\"\"\n    def __init__(self, name=''):\n        \"\"\"\n        Initialize a filter.\n\n        Initialize with the name of the logger which, together with its\n        children, will have its events allowed through the filter. If no\n        name is specified, allow every event.\n        \"\"\"\n        self.name = name\n        self.nlen = len(name)\n\n    def filter(self, record):\n        \"\"\"\n        Determine if the specified record is to be logged.\n\n        Returns True if the record should be logged, or False otherwise.\n        If deemed appropriate, the record may be modified in-place.\n        \"\"\"\n        if self.nlen == 0:\n            return True\n        elif self.name == record.name:\n            return True\n        elif record.name.find(self.name, 0, self.nlen) != 0:\n            return False\n        return (record.name[self.nlen] == \".\")\n\nclass Filterer(object):\n    \"\"\"\n    A base class for loggers and handlers which allows them to share\n    common code.\n    \"\"\"\n    def __init__(self):\n        \"\"\"\n        Initialize the list of filters to be an empty list.\n        \"\"\"\n        self.filters = []\n\n    def addFilter(self, filter):\n        \"\"\"\n        Add the specified filter to this handler.\n        \"\"\"\n        if not (filter in self.filters):\n            self.filters.append(filter)\n\n    def removeFilter(self, filter):\n        \"\"\"\n        Remove the specified filter from this handler.\n        \"\"\"\n        if filter in self.filters:\n            self.filters.remove(filter)\n\n    def filter(self, record):\n        \"\"\"\n        Determine if a record is loggable by consulting all the filters.\n\n        The default is to allow the record to be logged; any filter can veto\n        this and the record is then dropped. Returns a zero value if a record\n        is to be dropped, else non-zero.\n\n        .. versionchanged:: 3.2\n\n           Allow filters to be just callables.\n        \"\"\"\n        rv = True\n        for f in self.filters:\n            if hasattr(f, 'filter'):\n                result = f.filter(record)\n            else:\n                result = f(record) # assume callable - will raise if not\n            if not result:\n                rv = False\n                break\n        return rv\n\n#---------------------------------------------------------------------------\n#   Handler classes and functions\n#---------------------------------------------------------------------------\n\n_handlers = weakref.WeakValueDictionary()  #map of handler names to handlers\n_handlerList = [] # added to allow handlers to be removed in reverse of order initialized\n\ndef _removeHandlerRef(wr):\n    \"\"\"\n    Remove a handler reference from the internal cleanup list.\n    \"\"\"\n    # This function can be called during module teardown, when globals are\n    # set to None. It can also be called from another thread. So we need to\n    # pre-emptively grab the necessary globals and check if they're None,\n    # to prevent race conditions and failures during interpreter shutdown.\n    acquire, release, handlers = _acquireLock, _releaseLock, _handlerList\n    if acquire and release and handlers:\n        acquire()\n        try:\n            handlers.remove(wr)\n        except ValueError:\n            pass\n        finally:\n            release()\n\ndef _addHandlerRef(handler):\n    \"\"\"\n    Add a handler to the internal cleanup list using a weak reference.\n    \"\"\"\n    _acquireLock()\n    try:\n        _handlerList.append(weakref.ref(handler, _removeHandlerRef))\n    finally:\n        _releaseLock()\n\nclass Handler(Filterer):\n    \"\"\"\n    Handler instances dispatch logging events to specific destinations.\n\n    The base handler class. Acts as a placeholder which defines the Handler\n    interface. Handlers can optionally use Formatter instances to format\n    records as desired. By default, no formatter is specified; in this case,\n    the 'raw' message as determined by record.message is logged.\n    \"\"\"\n    def __init__(self, level=NOTSET):\n        \"\"\"\n        Initializes the instance - basically setting the formatter to None\n        and the filter list to empty.\n        \"\"\"\n        Filterer.__init__(self)\n        self._name = None\n        self.level = _checkLevel(level)\n        self.formatter = None\n        self._closed = False\n        # Add the handler to the global _handlerList (for cleanup on shutdown)\n        _addHandlerRef(self)\n        self.createLock()\n\n    def get_name(self):\n        return self._name\n\n    def set_name(self, name):\n        _acquireLock()\n        try:\n            if self._name in _handlers:\n                del _handlers[self._name]\n            self._name = name\n            if name:\n                _handlers[name] = self\n        finally:\n            _releaseLock()\n\n    name = property(get_name, set_name)\n\n    def createLock(self):\n        \"\"\"\n        Acquire a thread lock for serializing access to the underlying I/O.\n        \"\"\"\n        self.lock = threading.RLock()\n        _register_at_fork_reinit_lock(self)\n\n    def _at_fork_reinit(self):\n        self.lock._at_fork_reinit()\n\n    def acquire(self):\n        \"\"\"\n        Acquire the I/O thread lock.\n        \"\"\"\n        if self.lock:\n            self.lock.acquire()\n\n    def release(self):\n        \"\"\"\n        Release the I/O thread lock.\n        \"\"\"\n        if self.lock:\n            self.lock.release()\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the logging level of this handler.  level must be an int or a str.\n        \"\"\"\n        self.level = _checkLevel(level)\n\n    def format(self, record):\n        \"\"\"\n        Format the specified record.\n\n        If a formatter is set, use it. Otherwise, use the default formatter\n        for the module.\n        \"\"\"\n        if self.formatter:\n            fmt = self.formatter\n        else:\n            fmt = _defaultFormatter\n        return fmt.format(record)\n\n    def emit(self, record):\n        \"\"\"\n        Do whatever it takes to actually log the specified logging record.\n\n        This version is intended to be implemented by subclasses and so\n        raises a NotImplementedError.\n        \"\"\"\n        raise NotImplementedError('emit must be implemented '\n                                  'by Handler subclasses')\n\n    def handle(self, record):\n        \"\"\"\n        Conditionally emit the specified logging record.\n\n        Emission depends on filters which may have been added to the handler.\n        Wrap the actual emission of the record with acquisition/release of\n        the I/O thread lock. Returns whether the filter passed the record for\n        emission.\n        \"\"\"\n        rv = self.filter(record)\n        if rv:\n            self.acquire()\n            try:\n                self.emit(record)\n            finally:\n                self.release()\n        return rv\n\n    def setFormatter(self, fmt):\n        \"\"\"\n        Set the formatter for this handler.\n        \"\"\"\n        self.formatter = fmt\n\n    def flush(self):\n        \"\"\"\n        Ensure all logging output has been flushed.\n\n        This version does nothing and is intended to be implemented by\n        subclasses.\n        \"\"\"\n        pass\n\n    def close(self):\n        \"\"\"\n        Tidy up any resources used by the handler.\n\n        This version removes the handler from an internal map of handlers,\n        _handlers, which is used for handler lookup by name. Subclasses\n        should ensure that this gets called from overridden close()\n        methods.\n        \"\"\"\n        #get the module data lock, as we're updating a shared structure.\n        _acquireLock()\n        try:    #unlikely to raise an exception, but you never know...\n            self._closed = True\n            if self._name and self._name in _handlers:\n                del _handlers[self._name]\n        finally:\n            _releaseLock()\n\n    def handleError(self, record):\n        \"\"\"\n        Handle errors which occur during an emit() call.\n\n        This method should be called from handlers when an exception is\n        encountered during an emit() call. If raiseExceptions is false,\n        exceptions get silently ignored. This is what is mostly wanted\n        for a logging system - most users will not care about errors in\n        the logging system, they are more interested in application errors.\n        You could, however, replace this with a custom handler if you wish.\n        The record which was being processed is passed in to this method.\n        \"\"\"\n        if raiseExceptions and sys.stderr:  # see issue 13807\n            t, v, tb = sys.exc_info()\n            try:\n                sys.stderr.write('--- Logging error ---\\n')\n                traceback.print_exception(t, v, tb, None, sys.stderr)\n                sys.stderr.write('Call stack:\\n')\n                # Walk the stack frame up until we're out of logging,\n                # so as to print the calling context.\n                frame = tb.tb_frame\n                while (frame and os.path.dirname(frame.f_code.co_filename) ==\n                       __path__[0]):\n                    frame = frame.f_back\n                if frame:\n                    traceback.print_stack(frame, file=sys.stderr)\n                else:\n                    # couldn't find the right stack frame, for some reason\n                    sys.stderr.write('Logged from file %s, line %s\\n' % (\n                                     record.filename, record.lineno))\n                # Issue 18671: output logging message and arguments\n                try:\n                    sys.stderr.write('Message: %r\\n'\n                                     'Arguments: %s\\n' % (record.msg,\n                                                          record.args))\n                except RecursionError:  # See issue 36272\n                    raise\n                except Exception:\n                    sys.stderr.write('Unable to print the message and arguments'\n                                     ' - possible formatting error.\\nUse the'\n                                     ' traceback above to help find the error.\\n'\n                                    )\n            except OSError: #pragma: no cover\n                pass    # see issue 5971\n            finally:\n                del t, v, tb\n\n    def __repr__(self):\n        level = getLevelName(self.level)\n        return '<%s (%s)>' % (self.__class__.__name__, level)\n\nclass StreamHandler(Handler):\n    \"\"\"\n    A handler class which writes logging records, appropriately formatted,\n    to a stream. Note that this class does not close the stream, as\n    sys.stdout or sys.stderr may be used.\n    \"\"\"\n\n    terminator = '\\n'\n\n    def __init__(self, stream=None):\n        \"\"\"\n        Initialize the handler.\n\n        If stream is not specified, sys.stderr is used.\n        \"\"\"\n        Handler.__init__(self)\n        if stream is None:\n            stream = sys.stderr\n        self.stream = stream\n\n    def flush(self):\n        \"\"\"\n        Flushes the stream.\n        \"\"\"\n        self.acquire()\n        try:\n            if self.stream and hasattr(self.stream, \"flush\"):\n                self.stream.flush()\n        finally:\n            self.release()\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        If a formatter is specified, it is used to format the record.\n        The record is then written to the stream with a trailing newline.  If\n        exception information is present, it is formatted using\n        traceback.print_exception and appended to the stream.  If the stream\n        has an 'encoding' attribute, it is used to determine how to do the\n        output to the stream.\n        \"\"\"\n        try:\n            msg = self.format(record)\n            stream = self.stream\n            # issue 35046: merged two stream.writes into one.\n            stream.write(msg + self.terminator)\n            self.flush()\n        except RecursionError:  # See issue 36272\n            raise\n        except Exception:\n            self.handleError(record)\n\n    def setStream(self, stream):\n        \"\"\"\n        Sets the StreamHandler's stream to the specified value,\n        if it is different.\n\n        Returns the old stream, if the stream was changed, or None\n        if it wasn't.\n        \"\"\"\n        if stream is self.stream:\n            result = None\n        else:\n            result = self.stream\n            self.acquire()\n            try:\n                self.flush()\n                self.stream = stream\n            finally:\n                self.release()\n        return result\n\n    def __repr__(self):\n        level = getLevelName(self.level)\n        name = getattr(self.stream, 'name', '')\n        #  bpo-36015: name can be an int\n        name = str(name)\n        if name:\n            name += ' '\n        return '<%s %s(%s)>' % (self.__class__.__name__, name, level)\n\n    __class_getitem__ = classmethod(GenericAlias)\n\n\nclass FileHandler(StreamHandler):\n    \"\"\"\n    A handler class which writes formatted logging records to disk files.\n    \"\"\"\n    def __init__(self, filename, mode='a', encoding=None, delay=False, errors=None):\n        \"\"\"\n        Open the specified file and use it as the stream for logging.\n        \"\"\"\n        # Issue #27493: add support for Path objects to be passed in\n        filename = os.fspath(filename)\n        #keep the absolute path, otherwise derived classes which use this\n        #may come a cropper when the current directory changes\n        self.baseFilename = os.path.abspath(filename)\n        self.mode = mode\n        self.encoding = encoding\n        if \"b\" not in mode:\n            self.encoding = io.text_encoding(encoding)\n        self.errors = errors\n        self.delay = delay\n        # bpo-26789: FileHandler keeps a reference to the builtin open()\n        # function to be able to open or reopen the file during Python\n        # finalization.\n        self._builtin_open = open\n        if delay:\n            #We don't open the stream, but we still need to call the\n            #Handler constructor to set level, formatter, lock etc.\n            Handler.__init__(self)\n            self.stream = None\n        else:\n            StreamHandler.__init__(self, self._open())\n\n    def close(self):\n        \"\"\"\n        Closes the stream.\n        \"\"\"\n        self.acquire()\n        try:\n            try:\n                if self.stream:\n                    try:\n                        self.flush()\n                    finally:\n                        stream = self.stream\n                        self.stream = None\n                        if hasattr(stream, \"close\"):\n                            stream.close()\n            finally:\n                # Issue #19523: call unconditionally to\n                # prevent a handler leak when delay is set\n                # Also see Issue #42378: we also rely on\n                # self._closed being set to True there\n                StreamHandler.close(self)\n        finally:\n            self.release()\n\n    def _open(self):\n        \"\"\"\n        Open the current base file with the (original) mode and encoding.\n        Return the resulting stream.\n        \"\"\"\n        open_func = self._builtin_open\n        return open_func(self.baseFilename, self.mode,\n                         encoding=self.encoding, errors=self.errors)\n\n    def emit(self, record):\n        \"\"\"\n        Emit a record.\n\n        If the stream was not opened because 'delay' was specified in the\n        constructor, open it before calling the superclass's emit.\n\n        If stream is not open, current mode is 'w' and `_closed=True`, record\n        will not be emitted (see Issue #42378).\n        \"\"\"\n        if self.stream is None:\n            if self.mode != 'w' or not self._closed:\n                self.stream = self._open()\n        if self.stream:\n            StreamHandler.emit(self, record)\n\n    def __repr__(self):\n        level = getLevelName(self.level)\n        return '<%s %s (%s)>' % (self.__class__.__name__, self.baseFilename, level)\n\n\nclass _StderrHandler(StreamHandler):\n    \"\"\"\n    This class is like a StreamHandler using sys.stderr, but always uses\n    whatever sys.stderr is currently set to rather than the value of\n    sys.stderr at handler construction time.\n    \"\"\"\n    def __init__(self, level=NOTSET):\n        \"\"\"\n        Initialize the handler.\n        \"\"\"\n        Handler.__init__(self, level)\n\n    @property\n    def stream(self):\n        return sys.stderr\n\n\n_defaultLastResort = _StderrHandler(WARNING)\nlastResort = _defaultLastResort\n\n#---------------------------------------------------------------------------\n#   Manager classes and functions\n#---------------------------------------------------------------------------\n\nclass PlaceHolder(object):\n    \"\"\"\n    PlaceHolder instances are used in the Manager logger hierarchy to take\n    the place of nodes for which no loggers have been defined. This class is\n    intended for internal use only and not as part of the public API.\n    \"\"\"\n    def __init__(self, alogger):\n        \"\"\"\n        Initialize with the specified logger being a child of this placeholder.\n        \"\"\"\n        self.loggerMap = { alogger : None }\n\n    def append(self, alogger):\n        \"\"\"\n        Add the specified logger as a child of this placeholder.\n        \"\"\"\n        if alogger not in self.loggerMap:\n            self.loggerMap[alogger] = None\n\n#\n#   Determine which class to use when instantiating loggers.\n#\n\ndef setLoggerClass(klass):\n    \"\"\"\n    Set the class to be used when instantiating a logger. The class should\n    define __init__() such that only a name argument is required, and the\n    __init__() should call Logger.__init__()\n    \"\"\"\n    if klass != Logger:\n        if not issubclass(klass, Logger):\n            raise TypeError(\"logger not derived from logging.Logger: \"\n                            + klass.__name__)\n    global _loggerClass\n    _loggerClass = klass\n\ndef getLoggerClass():\n    \"\"\"\n    Return the class to be used when instantiating a logger.\n    \"\"\"\n    return _loggerClass\n\nclass Manager(object):\n    \"\"\"\n    There is [under normal circumstances] just one Manager instance, which\n    holds the hierarchy of loggers.\n    \"\"\"\n    def __init__(self, rootnode):\n        \"\"\"\n        Initialize the manager with the root node of the logger hierarchy.\n        \"\"\"\n        self.root = rootnode\n        self.disable = 0\n        self.emittedNoHandlerWarning = False\n        self.loggerDict = {}\n        self.loggerClass = None\n        self.logRecordFactory = None\n\n    @property\n    def disable(self):\n        return self._disable\n\n    @disable.setter\n    def disable(self, value):\n        self._disable = _checkLevel(value)\n\n    def getLogger(self, name):\n        \"\"\"\n        Get a logger with the specified name (channel name), creating it\n        if it doesn't yet exist. This name is a dot-separated hierarchical\n        name, such as \"a\", \"a.b\", \"a.b.c\" or similar.\n\n        If a PlaceHolder existed for the specified name [i.e. the logger\n        didn't exist but a child of it did], replace it with the created\n        logger and fix up the parent/child references which pointed to the\n        placeholder to now point to the logger.\n        \"\"\"\n        rv = None\n        if not isinstance(name, str):\n            raise TypeError('A logger name must be a string')\n        _acquireLock()\n        try:\n            if name in self.loggerDict:\n                rv = self.loggerDict[name]\n                if isinstance(rv, PlaceHolder):\n                    ph = rv\n                    rv = (self.loggerClass or _loggerClass)(name)\n                    rv.manager = self\n                    self.loggerDict[name] = rv\n                    self._fixupChildren(ph, rv)\n                    self._fixupParents(rv)\n            else:\n                rv = (self.loggerClass or _loggerClass)(name)\n                rv.manager = self\n                self.loggerDict[name] = rv\n                self._fixupParents(rv)\n        finally:\n            _releaseLock()\n        return rv\n\n    def setLoggerClass(self, klass):\n        \"\"\"\n        Set the class to be used when instantiating a logger with this Manager.\n        \"\"\"\n        if klass != Logger:\n            if not issubclass(klass, Logger):\n                raise TypeError(\"logger not derived from logging.Logger: \"\n                                + klass.__name__)\n        self.loggerClass = klass\n\n    def setLogRecordFactory(self, factory):\n        \"\"\"\n        Set the factory to be used when instantiating a log record with this\n        Manager.\n        \"\"\"\n        self.logRecordFactory = factory\n\n    def _fixupParents(self, alogger):\n        \"\"\"\n        Ensure that there are either loggers or placeholders all the way\n        from the specified logger to the root of the logger hierarchy.\n        \"\"\"\n        name = alogger.name\n        i = name.rfind(\".\")\n        rv = None\n        while (i > 0) and not rv:\n            substr = name[:i]\n            if substr not in self.loggerDict:\n                self.loggerDict[substr] = PlaceHolder(alogger)\n            else:\n                obj = self.loggerDict[substr]\n                if isinstance(obj, Logger):\n                    rv = obj\n                else:\n                    assert isinstance(obj, PlaceHolder)\n                    obj.append(alogger)\n            i = name.rfind(\".\", 0, i - 1)\n        if not rv:\n            rv = self.root\n        alogger.parent = rv\n\n    def _fixupChildren(self, ph, alogger):\n        \"\"\"\n        Ensure that children of the placeholder ph are connected to the\n        specified logger.\n        \"\"\"\n        name = alogger.name\n        namelen = len(name)\n        for c in ph.loggerMap.keys():\n            #The if means ... if not c.parent.name.startswith(nm)\n            if c.parent.name[:namelen] != name:\n                alogger.parent = c.parent\n                c.parent = alogger\n\n    def _clear_cache(self):\n        \"\"\"\n        Clear the cache for all loggers in loggerDict\n        Called when level changes are made\n        \"\"\"\n\n        _acquireLock()\n        for logger in self.loggerDict.values():\n            if isinstance(logger, Logger):\n                logger._cache.clear()\n        self.root._cache.clear()\n        _releaseLock()\n\n#---------------------------------------------------------------------------\n#   Logger classes and functions\n#---------------------------------------------------------------------------\n\nclass Logger(Filterer):\n    \"\"\"\n    Instances of the Logger class represent a single logging channel. A\n    \"logging channel\" indicates an area of an application. Exactly how an\n    \"area\" is defined is up to the application developer. Since an\n    application can have any number of areas, logging channels are identified\n    by a unique string. Application areas can be nested (e.g. an area\n    of \"input processing\" might include sub-areas \"read CSV files\", \"read\n    XLS files\" and \"read Gnumeric files\"). To cater for this natural nesting,\n    channel names are organized into a namespace hierarchy where levels are\n    separated by periods, much like the Java or Python package namespace. So\n    in the instance given above, channel names might be \"input\" for the upper\n    level, and \"input.csv\", \"input.xls\" and \"input.gnu\" for the sub-levels.\n    There is no arbitrary limit to the depth of nesting.\n    \"\"\"\n    def __init__(self, name, level=NOTSET):\n        \"\"\"\n        Initialize the logger with a name and an optional level.\n        \"\"\"\n        Filterer.__init__(self)\n        self.name = name\n        self.level = _checkLevel(level)\n        self.parent = None\n        self.propagate = True\n        self.handlers = []\n        self.disabled = False\n        self._cache = {}\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the logging level of this logger.  level must be an int or a str.\n        \"\"\"\n        self.level = _checkLevel(level)\n        self.manager._clear_cache()\n\n    def debug(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'DEBUG'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.debug(\"Houston, we have a %s\", \"thorny problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(DEBUG):\n            self._log(DEBUG, msg, args, **kwargs)\n\n    def info(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'INFO'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(INFO):\n            self._log(INFO, msg, args, **kwargs)\n\n    def warning(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'WARNING'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.warning(\"Houston, we have a %s\", \"bit of a problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(WARNING):\n            self._log(WARNING, msg, args, **kwargs)\n\n    def warn(self, msg, *args, **kwargs):\n        warnings.warn(\"The 'warn' method is deprecated, \"\n            \"use 'warning' instead\", DeprecationWarning, 2)\n        self.warning(msg, *args, **kwargs)\n\n    def error(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'ERROR'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.error(\"Houston, we have a %s\", \"major problem\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(ERROR):\n            self._log(ERROR, msg, args, **kwargs)\n\n    def exception(self, msg, *args, exc_info=True, **kwargs):\n        \"\"\"\n        Convenience method for logging an ERROR with exception information.\n        \"\"\"\n        self.error(msg, *args, exc_info=exc_info, **kwargs)\n\n    def critical(self, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with severity 'CRITICAL'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.critical(\"Houston, we have a %s\", \"major disaster\", exc_info=1)\n        \"\"\"\n        if self.isEnabledFor(CRITICAL):\n            self._log(CRITICAL, msg, args, **kwargs)\n\n    def fatal(self, msg, *args, **kwargs):\n        \"\"\"\n        Don't use this method, use critical() instead.\n        \"\"\"\n        self.critical(msg, *args, **kwargs)\n\n    def log(self, level, msg, *args, **kwargs):\n        \"\"\"\n        Log 'msg % args' with the integer severity 'level'.\n\n        To pass exception information, use the keyword argument exc_info with\n        a true value, e.g.\n\n        logger.log(level, \"We have a %s\", \"mysterious problem\", exc_info=1)\n        \"\"\"\n        if not isinstance(level, int):\n            if raiseExceptions:\n                raise TypeError(\"level must be an integer\")\n            else:\n                return\n        if self.isEnabledFor(level):\n            self._log(level, msg, args, **kwargs)\n\n    def findCaller(self, stack_info=False, stacklevel=1):\n        \"\"\"\n        Find the stack frame of the caller so that we can note the source\n        file name, line number and function name.\n        \"\"\"\n        f = currentframe()\n        #On some versions of IronPython, currentframe() returns None if\n        #IronPython isn't run with -X:Frames.\n        if f is None:\n            return \"(unknown file)\", 0, \"(unknown function)\", None\n        while stacklevel > 0:\n            next_f = f.f_back\n            if next_f is None:\n                ## We've got options here.\n                ## If we want to use the last (deepest) frame:\n                break\n                ## If we want to mimic the warnings module:\n                #return (\"sys\", 1, \"(unknown function)\", None)\n                ## If we want to be pedantic:\n                #raise ValueError(\"call stack is not deep enough\")\n            f = next_f\n            if not _is_internal_frame(f):\n                stacklevel -= 1\n        co = f.f_code\n        sinfo = None\n        if stack_info:\n            with io.StringIO() as sio:\n                sio.write(\"Stack (most recent call last):\\n\")\n                traceback.print_stack(f, file=sio)\n                sinfo = sio.getvalue()\n                if sinfo[-1] == '\\n':\n                    sinfo = sinfo[:-1]\n        return co.co_filename, f.f_lineno, co.co_name, sinfo\n\n    def makeRecord(self, name, level, fn, lno, msg, args, exc_info,\n                   func=None, extra=None, sinfo=None):\n        \"\"\"\n        A factory method which can be overridden in subclasses to create\n        specialized LogRecords.\n        \"\"\"\n        rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n                             sinfo)\n        if extra is not None:\n            for key in extra:\n                if (key in [\"message\", \"asctime\"]) or (key in rv.__dict__):\n                    raise KeyError(\"Attempt to overwrite %r in LogRecord\" % key)\n                rv.__dict__[key] = extra[key]\n        return rv\n\n    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False,\n             stacklevel=1):\n        \"\"\"\n        Low-level logging routine which creates a LogRecord and then calls\n        all the handlers of this logger to handle the record.\n        \"\"\"\n        sinfo = None\n        if _srcfile:\n            #IronPython doesn't track Python frames, so findCaller raises an\n            #exception on some versions of IronPython. We trap it here so that\n            #IronPython can use logging.\n            try:\n                fn, lno, func, sinfo = self.findCaller(stack_info, stacklevel)\n            except ValueError: # pragma: no cover\n                fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        else: # pragma: no cover\n            fn, lno, func = \"(unknown file)\", 0, \"(unknown function)\"\n        if exc_info:\n            if isinstance(exc_info, BaseException):\n                exc_info = (type(exc_info), exc_info, exc_info.__traceback__)\n            elif not isinstance(exc_info, tuple):\n                exc_info = sys.exc_info()\n        record = self.makeRecord(self.name, level, fn, lno, msg, args,\n                                 exc_info, func, extra, sinfo)\n        self.handle(record)\n\n    def handle(self, record):\n        \"\"\"\n        Call the handlers for the specified record.\n\n        This method is used for unpickled records received from a socket, as\n        well as those created locally. Logger-level filtering is applied.\n        \"\"\"\n        if (not self.disabled) and self.filter(record):\n            self.callHandlers(record)\n\n    def addHandler(self, hdlr):\n        \"\"\"\n        Add the specified handler to this logger.\n        \"\"\"\n        _acquireLock()\n        try:\n            if not (hdlr in self.handlers):\n                self.handlers.append(hdlr)\n        finally:\n            _releaseLock()\n\n    def removeHandler(self, hdlr):\n        \"\"\"\n        Remove the specified handler from this logger.\n        \"\"\"\n        _acquireLock()\n        try:\n            if hdlr in self.handlers:\n                self.handlers.remove(hdlr)\n        finally:\n            _releaseLock()\n\n    def hasHandlers(self):\n        \"\"\"\n        See if this logger has any handlers configured.\n\n        Loop through all handlers for this logger and its parents in the\n        logger hierarchy. Return True if a handler was found, else False.\n        Stop searching up the hierarchy whenever a logger with the \"propagate\"\n        attribute set to zero is found - that will be the last logger which\n        is checked for the existence of handlers.\n        \"\"\"\n        c = self\n        rv = False\n        while c:\n            if c.handlers:\n                rv = True\n                break\n            if not c.propagate:\n                break\n            else:\n                c = c.parent\n        return rv\n\n    def callHandlers(self, record):\n        \"\"\"\n        Pass a record to all relevant handlers.\n\n        Loop through all handlers for this logger and its parents in the\n        logger hierarchy. If no handler was found, output a one-off error\n        message to sys.stderr. Stop searching up the hierarchy whenever a\n        logger with the \"propagate\" attribute set to zero is found - that\n        will be the last logger whose handlers are called.\n        \"\"\"\n        c = self\n        found = 0\n        while c:\n            for hdlr in c.handlers:\n                found = found + 1\n                if record.levelno >= hdlr.level:\n                    hdlr.handle(record)\n            if not c.propagate:\n                c = None    #break out\n            else:\n                c = c.parent\n        if (found == 0):\n            if lastResort:\n                if record.levelno >= lastResort.level:\n                    lastResort.handle(record)\n            elif raiseExceptions and not self.manager.emittedNoHandlerWarning:\n                sys.stderr.write(\"No handlers could be found for logger\"\n                                 \" \\\"%s\\\"\\n\" % self.name)\n                self.manager.emittedNoHandlerWarning = True\n\n    def getEffectiveLevel(self):\n        \"\"\"\n        Get the effective level for this logger.\n\n        Loop through this logger and its parents in the logger hierarchy,\n        looking for a non-zero logging level. Return the first one found.\n        \"\"\"\n        logger = self\n        while logger:\n            if logger.level:\n                return logger.level\n            logger = logger.parent\n        return NOTSET\n\n    def isEnabledFor(self, level):\n        \"\"\"\n        Is this logger enabled for level 'level'?\n        \"\"\"\n        if self.disabled:\n            return False\n\n        try:\n            return self._cache[level]\n        except KeyError:\n            _acquireLock()\n            try:\n                if self.manager.disable >= level:\n                    is_enabled = self._cache[level] = False\n                else:\n                    is_enabled = self._cache[level] = (\n                        level >= self.getEffectiveLevel()\n                    )\n            finally:\n                _releaseLock()\n            return is_enabled\n\n    def getChild(self, suffix):\n        \"\"\"\n        Get a logger which is a descendant to this one.\n\n        This is a convenience method, such that\n\n        logging.getLogger('abc').getChild('def.ghi')\n\n        is the same as\n\n        logging.getLogger('abc.def.ghi')\n\n        It's useful, for example, when the parent logger is named using\n        __name__ rather than a literal string.\n        \"\"\"\n        if self.root is not self:\n            suffix = '.'.join((self.name, suffix))\n        return self.manager.getLogger(suffix)\n\n    def __repr__(self):\n        level = getLevelName(self.getEffectiveLevel())\n        return '<%s %s (%s)>' % (self.__class__.__name__, self.name, level)\n\n    def __reduce__(self):\n        if getLogger(self.name) is not self:\n            import pickle\n            raise pickle.PicklingError('logger cannot be pickled')\n        return getLogger, (self.name,)\n\n\nclass RootLogger(Logger):\n    \"\"\"\n    A root logger is not that different to any other logger, except that\n    it must have a logging level and there is only one instance of it in\n    the hierarchy.\n    \"\"\"\n    def __init__(self, level):\n        \"\"\"\n        Initialize the logger with the name \"root\".\n        \"\"\"\n        Logger.__init__(self, \"root\", level)\n\n    def __reduce__(self):\n        return getLogger, ()\n\n_loggerClass = Logger\n\nclass LoggerAdapter(object):\n    \"\"\"\n    An adapter for loggers which makes it easier to specify contextual\n    information in logging output.\n    \"\"\"\n\n    def __init__(self, logger, extra=None):\n        \"\"\"\n        Initialize the adapter with a logger and a dict-like object which\n        provides contextual information. This constructor signature allows\n        easy stacking of LoggerAdapters, if so desired.\n\n        You can effectively pass keyword arguments as shown in the\n        following example:\n\n        adapter = LoggerAdapter(someLogger, dict(p1=v1, p2=\"v2\"))\n        \"\"\"\n        self.logger = logger\n        self.extra = extra\n\n    def process(self, msg, kwargs):\n        \"\"\"\n        Process the logging message and keyword arguments passed in to\n        a logging call to insert contextual information. You can either\n        manipulate the message itself, the keyword args or both. Return\n        the message and kwargs modified (or not) to suit your needs.\n\n        Normally, you'll only need to override this one method in a\n        LoggerAdapter subclass for your specific needs.\n        \"\"\"\n        kwargs[\"extra\"] = self.extra\n        return msg, kwargs\n\n    #\n    # Boilerplate convenience methods\n    #\n    def debug(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a debug call to the underlying logger.\n        \"\"\"\n        self.log(DEBUG, msg, *args, **kwargs)\n\n    def info(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an info call to the underlying logger.\n        \"\"\"\n        self.log(INFO, msg, *args, **kwargs)\n\n    def warning(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a warning call to the underlying logger.\n        \"\"\"\n        self.log(WARNING, msg, *args, **kwargs)\n\n    def warn(self, msg, *args, **kwargs):\n        warnings.warn(\"The 'warn' method is deprecated, \"\n            \"use 'warning' instead\", DeprecationWarning, 2)\n        self.warning(msg, *args, **kwargs)\n\n    def error(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an error call to the underlying logger.\n        \"\"\"\n        self.log(ERROR, msg, *args, **kwargs)\n\n    def exception(self, msg, *args, exc_info=True, **kwargs):\n        \"\"\"\n        Delegate an exception call to the underlying logger.\n        \"\"\"\n        self.log(ERROR, msg, *args, exc_info=exc_info, **kwargs)\n\n    def critical(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a critical call to the underlying logger.\n        \"\"\"\n        self.log(CRITICAL, msg, *args, **kwargs)\n\n    def log(self, level, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a log call to the underlying logger, after adding\n        contextual information from this adapter instance.\n        \"\"\"\n        if self.isEnabledFor(level):\n            msg, kwargs = self.process(msg, kwargs)\n            self.logger.log(level, msg, *args, **kwargs)\n\n    def isEnabledFor(self, level):\n        \"\"\"\n        Is this logger enabled for level 'level'?\n        \"\"\"\n        return self.logger.isEnabledFor(level)\n\n    def setLevel(self, level):\n        \"\"\"\n        Set the specified level on the underlying logger.\n        \"\"\"\n        self.logger.setLevel(level)\n\n    def getEffectiveLevel(self):\n        \"\"\"\n        Get the effective level for the underlying logger.\n        \"\"\"\n        return self.logger.getEffectiveLevel()\n\n    def hasHandlers(self):\n        \"\"\"\n        See if the underlying logger has any handlers.\n        \"\"\"\n        return self.logger.hasHandlers()\n\n    def _log(self, level, msg, args, exc_info=None, extra=None, stack_info=False):\n        \"\"\"\n        Low-level log implementation, proxied to allow nested logger adapters.\n        \"\"\"\n        return self.logger._log(\n            level,\n            msg,\n            args,\n            exc_info=exc_info,\n            extra=extra,\n            stack_info=stack_info,\n        )\n\n    @property\n    def manager(self):\n        return self.logger.manager\n\n    @manager.setter\n    def manager(self, value):\n        self.logger.manager = value\n\n    @property\n    def name(self):\n        return self.logger.name\n\n    def __repr__(self):\n        logger = self.logger\n        level = getLevelName(logger.getEffectiveLevel())\n        return '<%s %s (%s)>' % (self.__class__.__name__, logger.name, level)\n\n    __class_getitem__ = classmethod(GenericAlias)\n\nroot = RootLogger(WARNING)\nLogger.root = root\nLogger.manager = Manager(Logger.root)\n\n#---------------------------------------------------------------------------\n# Configuration classes and functions\n#---------------------------------------------------------------------------\n\ndef basicConfig(**kwargs):\n    \"\"\"\n    Do basic configuration for the logging system.\n\n    This function does nothing if the root logger already has handlers\n    configured, unless the keyword argument *force* is set to ``True``.\n    It is a convenience method intended for use by simple scripts\n    to do one-shot configuration of the logging package.\n\n    The default behaviour is to create a StreamHandler which writes to\n    sys.stderr, set a formatter using the BASIC_FORMAT format string, and\n    add the handler to the root logger.\n\n    A number of optional keyword arguments may be specified, which can alter\n    the default behaviour.\n\n    filename  Specifies that a FileHandler be created, using the specified\n              filename, rather than a StreamHandler.\n    filemode  Specifies the mode to open the file, if filename is specified\n              (if filemode is unspecified, it defaults to 'a').\n    format    Use the specified format string for the handler.\n    datefmt   Use the specified date/time format.\n    style     If a format string is specified, use this to specify the\n              type of format string (possible values '%', '{', '$', for\n              %-formatting, :meth:`str.format` and :class:`string.Template`\n              - defaults to '%').\n    level     Set the root logger level to the specified level.\n    stream    Use the specified stream to initialize the StreamHandler. Note\n              that this argument is incompatible with 'filename' - if both\n              are present, 'stream' is ignored.\n    handlers  If specified, this should be an iterable of already created\n              handlers, which will be added to the root handler. Any handler\n              in the list which does not have a formatter assigned will be\n              assigned the formatter created in this function.\n    force     If this keyword  is specified as true, any existing handlers\n              attached to the root logger are removed and closed, before\n              carrying out the configuration as specified by the other\n              arguments.\n    encoding  If specified together with a filename, this encoding is passed to\n              the created FileHandler, causing it to be used when the file is\n              opened.\n    errors    If specified together with a filename, this value is passed to the\n              created FileHandler, causing it to be used when the file is\n              opened in text mode. If not specified, the default value is\n              `backslashreplace`.\n\n    Note that you could specify a stream created using open(filename, mode)\n    rather than passing the filename and mode in. However, it should be\n    remembered that StreamHandler does not close its stream (since it may be\n    using sys.stdout or sys.stderr), whereas FileHandler closes its stream\n    when the handler is closed.\n\n    .. versionchanged:: 3.2\n       Added the ``style`` parameter.\n\n    .. versionchanged:: 3.3\n       Added the ``handlers`` parameter. A ``ValueError`` is now thrown for\n       incompatible arguments (e.g. ``handlers`` specified together with\n       ``filename``/``filemode``, or ``filename``/``filemode`` specified\n       together with ``stream``, or ``handlers`` specified together with\n       ``stream``.\n\n    .. versionchanged:: 3.8\n       Added the ``force`` parameter.\n\n    .. versionchanged:: 3.9\n       Added the ``encoding`` and ``errors`` parameters.\n    \"\"\"\n    # Add thread safety in case someone mistakenly calls\n    # basicConfig() from multiple threads\n    _acquireLock()\n    try:\n        force = kwargs.pop('force', False)\n        encoding = kwargs.pop('encoding', None)\n        errors = kwargs.pop('errors', 'backslashreplace')\n        if force:\n            for h in root.handlers[:]:\n                root.removeHandler(h)\n                h.close()\n        if len(root.handlers) == 0:\n            handlers = kwargs.pop(\"handlers\", None)\n            if handlers is None:\n                if \"stream\" in kwargs and \"filename\" in kwargs:\n                    raise ValueError(\"'stream' and 'filename' should not be \"\n                                     \"specified together\")\n            else:\n                if \"stream\" in kwargs or \"filename\" in kwargs:\n                    raise ValueError(\"'stream' or 'filename' should not be \"\n                                     \"specified together with 'handlers'\")\n            if handlers is None:\n                filename = kwargs.pop(\"filename\", None)\n                mode = kwargs.pop(\"filemode\", 'a')\n                if filename:\n                    if 'b' in mode:\n                        errors = None\n                    else:\n                        encoding = io.text_encoding(encoding)\n                    h = FileHandler(filename, mode,\n                                    encoding=encoding, errors=errors)\n                else:\n                    stream = kwargs.pop(\"stream\", None)\n                    h = StreamHandler(stream)\n                handlers = [h]\n            dfs = kwargs.pop(\"datefmt\", None)\n            style = kwargs.pop(\"style\", '%')\n            if style not in _STYLES:\n                raise ValueError('Style must be one of: %s' % ','.join(\n                                 _STYLES.keys()))\n            fs = kwargs.pop(\"format\", _STYLES[style][1])\n            fmt = Formatter(fs, dfs, style)\n            for h in handlers:\n                if h.formatter is None:\n                    h.setFormatter(fmt)\n                root.addHandler(h)\n            level = kwargs.pop(\"level\", None)\n            if level is not None:\n                root.setLevel(level)\n            if kwargs:\n                keys = ', '.join(kwargs.keys())\n                raise ValueError('Unrecognised argument(s): %s' % keys)\n    finally:\n        _releaseLock()\n\n#---------------------------------------------------------------------------\n# Utility functions at module level.\n# Basically delegate everything to the root logger.\n#---------------------------------------------------------------------------\n\ndef getLogger(name=None):\n    \"\"\"\n    Return a logger with the specified name, creating it if necessary.\n\n    If no name is specified, return the root logger.\n    \"\"\"\n    if not name or isinstance(name, str) and name == root.name:\n        return root\n    return Logger.manager.getLogger(name)\n\ndef critical(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'CRITICAL' on the root logger. If the logger\n    has no handlers, call basicConfig() to add a console handler with a\n    pre-defined format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.critical(msg, *args, **kwargs)\n\ndef fatal(msg, *args, **kwargs):\n    \"\"\"\n    Don't use this function, use critical() instead.\n    \"\"\"\n    critical(msg, *args, **kwargs)\n\ndef error(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'ERROR' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.error(msg, *args, **kwargs)\n\ndef exception(msg, *args, exc_info=True, **kwargs):\n    \"\"\"\n    Log a message with severity 'ERROR' on the root logger, with exception\n    information. If the logger has no handlers, basicConfig() is called to add\n    a console handler with a pre-defined format.\n    \"\"\"\n    error(msg, *args, exc_info=exc_info, **kwargs)\n\ndef warning(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'WARNING' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.warning(msg, *args, **kwargs)\n\ndef warn(msg, *args, **kwargs):\n    warnings.warn(\"The 'warn' function is deprecated, \"\n        \"use 'warning' instead\", DeprecationWarning, 2)\n    warning(msg, *args, **kwargs)\n\ndef info(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'INFO' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.info(msg, *args, **kwargs)\n\ndef debug(msg, *args, **kwargs):\n    \"\"\"\n    Log a message with severity 'DEBUG' on the root logger. If the logger has\n    no handlers, call basicConfig() to add a console handler with a pre-defined\n    format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.debug(msg, *args, **kwargs)\n\ndef log(level, msg, *args, **kwargs):\n    \"\"\"\n    Log 'msg % args' with the integer severity 'level' on the root logger. If\n    the logger has no handlers, call basicConfig() to add a console handler\n    with a pre-defined format.\n    \"\"\"\n    if len(root.handlers) == 0:\n        basicConfig()\n    root.log(level, msg, *args, **kwargs)\n\ndef disable(level=CRITICAL):\n    \"\"\"\n    Disable all logging calls of severity 'level' and below.\n    \"\"\"\n    root.manager.disable = level\n    root.manager._clear_cache()\n\ndef shutdown(handlerList=_handlerList):\n    \"\"\"\n    Perform any cleanup actions in the logging system (e.g. flushing\n    buffers).\n\n    Should be called at application exit.\n    \"\"\"\n    for wr in reversed(handlerList[:]):\n        #errors might occur, for example, if files are locked\n        #we just ignore them if raiseExceptions is not set\n        try:\n            h = wr()\n            if h:\n                try:\n                    h.acquire()\n                    h.flush()\n                    h.close()\n                except (OSError, ValueError):\n                    # Ignore errors which might be caused\n                    # because handlers have been closed but\n                    # references to them are still around at\n                    # application exit.\n                    pass\n                finally:\n                    h.release()\n        except: # ignore everything, as we're shutting down\n            if raiseExceptions:\n                raise\n            #else, swallow\n\n#Let's try and shutdown automatically on application exit...\nimport atexit\natexit.register(shutdown)\n\n# Null handler\n\nclass NullHandler(Handler):\n    \"\"\"\n    This handler does nothing. It's intended to be used to avoid the\n    \"No handlers could be found for logger XXX\" one-off warning. This is\n    important for library code, which may contain code to log events. If a user\n    of the library does not configure logging, the one-off warning might be\n    produced; to avoid this, the library developer simply needs to instantiate\n    a NullHandler and add it to the top-level logger of the library module or\n    package.\n    \"\"\"\n    def handle(self, record):\n        \"\"\"Stub.\"\"\"\n\n    def emit(self, record):\n        \"\"\"Stub.\"\"\"\n\n    def createLock(self):\n        self.lock = None\n\n    def _at_fork_reinit(self):\n        pass\n\n# Warnings integration\n\n_warnings_showwarning = None\n\ndef _showwarning(message, category, filename, lineno, file=None, line=None):\n    \"\"\"\n    Implementation of showwarnings which redirects to logging, which will first\n    check to see if the file parameter is None. If a file is specified, it will\n    delegate to the original warnings implementation of showwarning. Otherwise,\n    it will call warnings.formatwarning and will log the resulting string to a\n    warnings logger named \"py.warnings\" with level logging.WARNING.\n    \"\"\"\n    if file is not None:\n        if _warnings_showwarning is not None:\n            _warnings_showwarning(message, category, filename, lineno, file, line)\n    else:\n        s = warnings.formatwarning(message, category, filename, lineno, line)\n        logger = getLogger(\"py.warnings\")\n        if not logger.handlers:\n            logger.addHandler(NullHandler())\n        # bpo-46557: Log str(s) as msg instead of logger.warning(\"%s\", s)\n        # since some log aggregation tools group logs by the msg arg\n        logger.warning(str(s))\n\ndef captureWarnings(capture):\n    \"\"\"\n    If capture is true, redirect all warnings to the logging package.\n    If capture is False, ensure that warnings are not redirected to logging\n    but to their original destinations.\n    \"\"\"\n    global _warnings_showwarning\n    if capture:\n        if _warnings_showwarning is None:\n            _warnings_showwarning = warnings.showwarning\n            warnings.showwarning = _showwarning\n    else:\n        if _warnings_showwarning is not None:\n            warnings.showwarning = _warnings_showwarning\n            _warnings_showwarning = None\n",2273],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py":["#\n# The Python Imaging Library.\n# $Id$\n#\n# base class for image file handlers\n#\n# history:\n# 1995-09-09 fl   Created\n# 1996-03-11 fl   Fixed load mechanism.\n# 1996-04-15 fl   Added pcx/xbm decoders.\n# 1996-04-30 fl   Added encoders.\n# 1996-12-14 fl   Added load helpers\n# 1997-01-11 fl   Use encode_to_file where possible\n# 1997-08-27 fl   Flush output in _save\n# 1998-03-05 fl   Use memory mapping for some modes\n# 1999-02-04 fl   Use memory mapping also for \"I;16\" and \"I;16B\"\n# 1999-05-31 fl   Added image parser\n# 2000-10-12 fl   Set readonly flag on memory-mapped images\n# 2002-03-20 fl   Use better messages for common decoder errors\n# 2003-04-21 fl   Fall back on mmap/map_buffer if map is not available\n# 2003-10-30 fl   Added StubImageFile class\n# 2004-02-25 fl   Made incremental parser more robust\n#\n# Copyright (c) 1997-2004 by Secret Labs AB\n# Copyright (c) 1995-2004 by Fredrik Lundh\n#\n# See the README file for information on usage and redistribution.\n#\nfrom __future__ import annotations\n\nimport io\nimport itertools\nimport struct\nimport sys\nfrom typing import Any, NamedTuple\n\nfrom . import Image\nfrom ._deprecate import deprecate\nfrom ._util import is_path\n\nMAXBLOCK = 65536\n\nSAFEBLOCK = 1024 * 1024\n\nLOAD_TRUNCATED_IMAGES = False\n\"\"\"Whether or not to load truncated image files. User code may change this.\"\"\"\n\nERRORS = {\n    -1: \"image buffer overrun error\",\n    -2: \"decoding error\",\n    -3: \"unknown error\",\n    -8: \"bad configuration\",\n    -9: \"out of memory error\",\n}\n\"\"\"\nDict of known error codes returned from :meth:`.PyDecoder.decode`,\n:meth:`.PyEncoder.encode` :meth:`.PyEncoder.encode_to_pyfd` and\n:meth:`.PyEncoder.encode_to_file`.\n\"\"\"\n\n\n#\n# --------------------------------------------------------------------\n# Helpers\n\n\ndef _get_oserror(error, *, encoder):\n    try:\n        msg = Image.core.getcodecstatus(error)\n    except AttributeError:\n        msg = ERRORS.get(error)\n    if not msg:\n        msg = f\"{'encoder' if encoder else 'decoder'} error {error}\"\n    msg += f\" when {'writing' if encoder else 'reading'} image file\"\n    return OSError(msg)\n\n\ndef raise_oserror(error):\n    deprecate(\n        \"raise_oserror\",\n        12,\n        action=\"It is only useful for translating error codes returned by a codec's \"\n        \"decode() method, which ImageFile already does automatically.\",\n    )\n    raise _get_oserror(error, encoder=False)\n\n\ndef _tilesort(t):\n    # sort on offset\n    return t[2]\n\n\nclass _Tile(NamedTuple):\n    encoder_name: str\n    extents: tuple[int, int, int, int]\n    offset: int\n    args: tuple[Any, ...] | str | None\n\n\n#\n# --------------------------------------------------------------------\n# ImageFile base class\n\n\nclass ImageFile(Image.Image):\n    \"\"\"Base class for image file format handlers.\"\"\"\n\n    def __init__(self, fp=None, filename=None):\n        super().__init__()\n\n        self._min_frame = 0\n\n        self.custom_mimetype = None\n\n        self.tile = None\n        \"\"\" A list of tile descriptors, or ``None`` \"\"\"\n\n        self.readonly = 1  # until we know better\n\n        self.decoderconfig = ()\n        self.decodermaxblock = MAXBLOCK\n\n        if is_path(fp):\n            # filename\n            self.fp = open(fp, \"rb\")\n            self.filename = fp\n            self._exclusive_fp = True\n        else:\n            # stream\n            self.fp = fp\n            self.filename = filename\n            # can be overridden\n            self._exclusive_fp = None\n\n        try:\n            try:\n                self._open()\n            except (\n                IndexError,  # end of data\n                TypeError,  # end of data (ord)\n                KeyError,  # unsupported mode\n                EOFError,  # got header but not the first frame\n                struct.error,\n            ) as v:\n                raise SyntaxError(v) from v\n\n            if not self.mode or self.size[0] <= 0 or self.size[1] <= 0:\n                msg = \"not identified by this driver\"\n                raise SyntaxError(msg)\n        except BaseException:\n            # close the file only if we have opened it this constructor\n            if self._exclusive_fp:\n                self.fp.close()\n            raise\n\n    def get_format_mimetype(self):\n        if self.custom_mimetype:\n            return self.custom_mimetype\n        if self.format is not None:\n            return Image.MIME.get(self.format.upper())\n\n    def __setstate__(self, state):\n        self.tile = []\n        super().__setstate__(state)\n\n    def verify(self):\n        \"\"\"Check file integrity\"\"\"\n\n        # raise exception if something's wrong.  must be called\n        # directly after open, and closes file when finished.\n        if self._exclusive_fp:\n            self.fp.close()\n        self.fp = None\n\n    def load(self):\n        \"\"\"Load image data based on tile list\"\"\"\n\n        if self.tile is None:\n            msg = \"cannot load this image\"\n            raise OSError(msg)\n\n        pixel = Image.Image.load(self)\n        if not self.tile:\n            return pixel\n\n        self.map = None\n        use_mmap = self.filename and len(self.tile) == 1\n        # As of pypy 2.1.0, memory mapping was failing here.\n        use_mmap = use_mmap and not hasattr(sys, \"pypy_version_info\")\n\n        readonly = 0\n\n        # look for read/seek overrides\n        try:\n            read = self.load_read\n            # don't use mmap if there are custom read/seek functions\n            use_mmap = False\n        except AttributeError:\n            read = self.fp.read\n\n        try:\n            seek = self.load_seek\n            use_mmap = False\n        except AttributeError:\n            seek = self.fp.seek\n\n        if use_mmap:\n            # try memory mapping\n            decoder_name, extents, offset, args = self.tile[0]\n            if isinstance(args, str):\n                args = (args, 0, 1)\n            if (\n                decoder_name == \"raw\"\n                and len(args) >= 3\n                and args[0] == self.mode\n                and args[0] in Image._MAPMODES\n            ):\n                try:\n                    # use mmap, if possible\n                    import mmap\n\n                    with open(self.filename) as fp:\n                        self.map = mmap.mmap(fp.fileno(), 0, access=mmap.ACCESS_READ)\n                    if offset + self.size[1] * args[1] > self.map.size():\n                        msg = \"buffer is not large enough\"\n                        raise OSError(msg)\n                    self.im = Image.core.map_buffer(\n                        self.map, self.size, decoder_name, offset, args\n                    )\n                    readonly = 1\n                    # After trashing self.im,\n                    # we might need to reload the palette data.\n                    if self.palette:\n                        self.palette.dirty = 1\n                except (AttributeError, OSError, ImportError):\n                    self.map = None\n\n        self.load_prepare()\n        err_code = -3  # initialize to unknown error\n        if not self.map:\n            # sort tiles in file order\n            self.tile.sort(key=_tilesort)\n\n            try:\n                # FIXME: This is a hack to handle TIFF's JpegTables tag.\n                prefix = self.tile_prefix\n            except AttributeError:\n                prefix = b\"\"\n\n            # Remove consecutive duplicates that only differ by their offset\n            self.tile = [\n                list(tiles)[-1]\n                for _, tiles in itertools.groupby(\n                    self.tile, lambda tile: (tile[0], tile[1], tile[3])\n                )\n            ]\n            for decoder_name, extents, offset, args in self.tile:\n                seek(offset)\n                decoder = Image._getdecoder(\n                    self.mode, decoder_name, args, self.decoderconfig\n                )\n                try:\n                    decoder.setimage(self.im, extents)\n                    if decoder.pulls_fd:\n                        decoder.setfd(self.fp)\n                        err_code = decoder.decode(b\"\")[1]\n                    else:\n                        b = prefix\n                        while True:\n                            try:\n                                s = read(self.decodermaxblock)\n                            except (IndexError, struct.error) as e:\n                                # truncated png/gif\n                                if LOAD_TRUNCATED_IMAGES:\n                                    break\n                                else:\n                                    msg = \"image file is truncated\"\n                                    raise OSError(msg) from e\n\n                            if not s:  # truncated jpeg\n                                if LOAD_TRUNCATED_IMAGES:\n                                    break\n                                else:\n                                    msg = (\n                                        \"image file is truncated \"\n                                        f\"({len(b)} bytes not processed)\"\n                                    )\n                                    raise OSError(msg)\n\n                            b = b + s\n                            n, err_code = decoder.decode(b)\n                            if n < 0:\n                                break\n                            b = b[n:]\n                finally:\n                    # Need to cleanup here to prevent leaks\n                    decoder.cleanup()\n\n        self.tile = []\n        self.readonly = readonly\n\n        self.load_end()\n\n        if self._exclusive_fp and self._close_exclusive_fp_after_loading:\n            self.fp.close()\n        self.fp = None\n\n        if not self.map and not LOAD_TRUNCATED_IMAGES and err_code < 0:\n            # still raised if decoder fails to return anything\n            raise _get_oserror(err_code, encoder=False)\n\n        return Image.Image.load(self)\n\n    def load_prepare(self):\n        # create image memory if necessary\n        if not self.im or self.im.mode != self.mode or self.im.size != self.size:\n            self.im = Image.core.new(self.mode, self.size)\n        # create palette (optional)\n        if self.mode == \"P\":\n            Image.Image.load(self)\n\n    def load_end(self):\n        # may be overridden\n        pass\n\n    # may be defined for contained formats\n    # def load_seek(self, pos):\n    #     pass\n\n    # may be defined for blocked formats (e.g. PNG)\n    # def load_read(self, bytes):\n    #     pass\n\n    def _seek_check(self, frame):\n        if (\n            frame < self._min_frame\n            # Only check upper limit on frames if additional seek operations\n            # are not required to do so\n            or (\n                not (hasattr(self, \"_n_frames\") and self._n_frames is None)\n                and frame >= self.n_frames + self._min_frame\n            )\n        ):\n            msg = \"attempt to seek outside sequence\"\n            raise EOFError(msg)\n\n        return self.tell() != frame\n\n\nclass StubImageFile(ImageFile):\n    \"\"\"\n    Base class for stub image loaders.\n\n    A stub loader is an image loader that can identify files of a\n    certain format, but relies on external code to load the file.\n    \"\"\"\n\n    def _open(self):\n        msg = \"StubImageFile subclass must implement _open\"\n        raise NotImplementedError(msg)\n\n    def load(self):\n        loader = self._load()\n        if loader is None:\n            msg = f\"cannot find loader for this {self.format} file\"\n            raise OSError(msg)\n        image = loader.load(self)\n        assert image is not None\n        # become the other object (!)\n        self.__class__ = image.__class__\n        self.__dict__ = image.__dict__\n        return image.load()\n\n    def _load(self):\n        \"\"\"(Hook) Find actual image loader.\"\"\"\n        msg = \"StubImageFile subclass must implement _load\"\n        raise NotImplementedError(msg)\n\n\nclass Parser:\n    \"\"\"\n    Incremental image parser.  This class implements the standard\n    feed/close consumer interface.\n    \"\"\"\n\n    incremental = None\n    image = None\n    data = None\n    decoder = None\n    offset = 0\n    finished = 0\n\n    def reset(self):\n        \"\"\"\n        (Consumer) Reset the parser.  Note that you can only call this\n        method immediately after you've created a parser; parser\n        instances cannot be reused.\n        \"\"\"\n        assert self.data is None, \"cannot reuse parsers\"\n\n    def feed(self, data):\n        \"\"\"\n        (Consumer) Feed data to the parser.\n\n        :param data: A string buffer.\n        :exception OSError: If the parser failed to parse the image file.\n        \"\"\"\n        # collect data\n\n        if self.finished:\n            return\n\n        if self.data is None:\n            self.data = data\n        else:\n            self.data = self.data + data\n\n        # parse what we have\n        if self.decoder:\n            if self.offset > 0:\n                # skip header\n                skip = min(len(self.data), self.offset)\n                self.data = self.data[skip:]\n                self.offset = self.offset - skip\n                if self.offset > 0 or not self.data:\n                    return\n\n            n, e = self.decoder.decode(self.data)\n\n            if n < 0:\n                # end of stream\n                self.data = None\n                self.finished = 1\n                if e < 0:\n                    # decoding error\n                    self.image = None\n                    raise _get_oserror(e, encoder=False)\n                else:\n                    # end of image\n                    return\n            self.data = self.data[n:]\n\n        elif self.image:\n            # if we end up here with no decoder, this file cannot\n            # be incrementally parsed.  wait until we've gotten all\n            # available data\n            pass\n\n        else:\n            # attempt to open this file\n            try:\n                with io.BytesIO(self.data) as fp:\n                    im = Image.open(fp)\n            except OSError:\n                pass  # not enough data\n            else:\n                flag = hasattr(im, \"load_seek\") or hasattr(im, \"load_read\")\n                if flag or len(im.tile) != 1:\n                    # custom load code, or multiple tiles\n                    self.decode = None\n                else:\n                    # initialize decoder\n                    im.load_prepare()\n                    d, e, o, a = im.tile[0]\n                    im.tile = []\n                    self.decoder = Image._getdecoder(im.mode, d, a, im.decoderconfig)\n                    self.decoder.setimage(im.im, e)\n\n                    # calculate decoder offset\n                    self.offset = o\n                    if self.offset <= len(self.data):\n                        self.data = self.data[self.offset :]\n                        self.offset = 0\n\n                self.image = im\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def close(self):\n        \"\"\"\n        (Consumer) Close the stream.\n\n        :returns: An image object.\n        :exception OSError: If the parser failed to parse the image file either\n                            because it cannot be identified or cannot be\n                            decoded.\n        \"\"\"\n        # finish decoding\n        if self.decoder:\n            # get rid of what's left in the buffers\n            self.feed(b\"\")\n            self.data = self.decoder = None\n            if not self.finished:\n                msg = \"image was incomplete\"\n                raise OSError(msg)\n        if not self.image:\n            msg = \"cannot parse this image\"\n            raise OSError(msg)\n        if self.data:\n            # incremental parsing not possible; reopen the file\n            # not that we have all data\n            with io.BytesIO(self.data) as fp:\n                try:\n                    self.image = Image.open(fp)\n                finally:\n                    self.image.load()\n        return self.image\n\n\n# --------------------------------------------------------------------\n\n\ndef _save(im, fp, tile, bufsize=0):\n    \"\"\"Helper to save image based on tile list\n\n    :param im: Image object.\n    :param fp: File object.\n    :param tile: Tile list.\n    :param bufsize: Optional buffer size\n    \"\"\"\n\n    im.load()\n    if not hasattr(im, \"encoderconfig\"):\n        im.encoderconfig = ()\n    tile.sort(key=_tilesort)\n    # FIXME: make MAXBLOCK a configuration parameter\n    # It would be great if we could have the encoder specify what it needs\n    # But, it would need at least the image size in most cases. RawEncode is\n    # a tricky case.\n    bufsize = max(MAXBLOCK, bufsize, im.size[0] * 4)  # see RawEncode.c\n    try:\n        fh = fp.fileno()\n        fp.flush()\n        _encode_tile(im, fp, tile, bufsize, fh)\n    except (AttributeError, io.UnsupportedOperation) as exc:\n        _encode_tile(im, fp, tile, bufsize, None, exc)\n    if hasattr(fp, \"flush\"):\n        fp.flush()\n\n\ndef _encode_tile(im, fp, tile: list[_Tile], bufsize, fh, exc=None):\n    for encoder_name, extents, offset, args in tile:\n        if offset > 0:\n            fp.seek(offset)\n        encoder = Image._getencoder(im.mode, encoder_name, args, im.encoderconfig)\n        try:\n            encoder.setimage(im.im, extents)\n            if encoder.pushes_fd:\n                encoder.setfd(fp)\n                errcode = encoder.encode_to_pyfd()[1]\n            else:\n                if exc:\n                    # compress to Python file-compatible object\n                    while True:\n                        errcode, data = encoder.encode(bufsize)[1:]\n                        fp.write(data)\n                        if errcode:\n                            break\n                else:\n                    # slight speedup: compress to real file object\n                    errcode = encoder.encode_to_file(fh, bufsize)\n            if errcode < 0:\n                raise _get_oserror(errcode, encoder=True) from exc\n        finally:\n            encoder.cleanup()\n\n\ndef _safe_read(fp, size):\n    \"\"\"\n    Reads large blocks in a safe way.  Unlike fp.read(n), this function\n    doesn't trust the user.  If the requested size is larger than\n    SAFEBLOCK, the file is read block by block.\n\n    :param fp: File handle.  Must implement a <b>read</b> method.\n    :param size: Number of bytes to read.\n    :returns: A string containing <i>size</i> bytes of data.\n\n    Raises an OSError if the file is truncated and the read cannot be completed\n\n    \"\"\"\n    if size <= 0:\n        return b\"\"\n    if size <= SAFEBLOCK:\n        data = fp.read(size)\n        if len(data) < size:\n            msg = \"Truncated File Read\"\n            raise OSError(msg)\n        return data\n    data = []\n    remaining_size = size\n    while remaining_size > 0:\n        block = fp.read(min(remaining_size, SAFEBLOCK))\n        if not block:\n            break\n        data.append(block)\n        remaining_size -= len(block)\n    if sum(len(d) for d in data) < size:\n        msg = \"Truncated File Read\"\n        raise OSError(msg)\n    return b\"\".join(data)\n\n\nclass PyCodecState:\n    def __init__(self):\n        self.xsize = 0\n        self.ysize = 0\n        self.xoff = 0\n        self.yoff = 0\n\n    def extents(self):\n        return self.xoff, self.yoff, self.xoff + self.xsize, self.yoff + self.ysize\n\n\nclass PyCodec:\n    def __init__(self, mode, *args):\n        self.im = None\n        self.state = PyCodecState()\n        self.fd = None\n        self.mode = mode\n        self.init(args)\n\n    def init(self, args):\n        \"\"\"\n        Override to perform codec specific initialization\n\n        :param args: Array of args items from the tile entry\n        :returns: None\n        \"\"\"\n        self.args = args\n\n    def cleanup(self):\n        \"\"\"\n        Override to perform codec specific cleanup\n\n        :returns: None\n        \"\"\"\n        pass\n\n    def setfd(self, fd):\n        \"\"\"\n        Called from ImageFile to set the Python file-like object\n\n        :param fd: A Python file-like object\n        :returns: None\n        \"\"\"\n        self.fd = fd\n\n    def setimage(self, im, extents=None):\n        \"\"\"\n        Called from ImageFile to set the core output image for the codec\n\n        :param im: A core image object\n        :param extents: a 4 tuple of (x0, y0, x1, y1) defining the rectangle\n            for this tile\n        :returns: None\n        \"\"\"\n\n        # following c code\n        self.im = im\n\n        if extents:\n            (x0, y0, x1, y1) = extents\n        else:\n            (x0, y0, x1, y1) = (0, 0, 0, 0)\n\n        if x0 == 0 and x1 == 0:\n            self.state.xsize, self.state.ysize = self.im.size\n        else:\n            self.state.xoff = x0\n            self.state.yoff = y0\n            self.state.xsize = x1 - x0\n            self.state.ysize = y1 - y0\n\n        if self.state.xsize <= 0 or self.state.ysize <= 0:\n            msg = \"Size cannot be negative\"\n            raise ValueError(msg)\n\n        if (\n            self.state.xsize + self.state.xoff > self.im.size[0]\n            or self.state.ysize + self.state.yoff > self.im.size[1]\n        ):\n            msg = \"Tile cannot extend outside image\"\n            raise ValueError(msg)\n\n\nclass PyDecoder(PyCodec):\n    \"\"\"\n    Python implementation of a format decoder. Override this class and\n    add the decoding logic in the :meth:`decode` method.\n\n    See :ref:`Writing Your Own File Codec in Python<file-codecs-py>`\n    \"\"\"\n\n    _pulls_fd = False\n\n    @property\n    def pulls_fd(self):\n        return self._pulls_fd\n\n    def decode(self, buffer):\n        \"\"\"\n        Override to perform the decoding process.\n\n        :param buffer: A bytes object with the data to be decoded.\n        :returns: A tuple of ``(bytes consumed, errcode)``.\n            If finished with decoding return -1 for the bytes consumed.\n            Err codes are from :data:`.ImageFile.ERRORS`.\n        \"\"\"\n        msg = \"unavailable in base decoder\"\n        raise NotImplementedError(msg)\n\n    def set_as_raw(self, data, rawmode=None):\n        \"\"\"\n        Convenience method to set the internal image from a stream of raw data\n\n        :param data: Bytes to be set\n        :param rawmode: The rawmode to be used for the decoder.\n            If not specified, it will default to the mode of the image\n        :returns: None\n        \"\"\"\n\n        if not rawmode:\n            rawmode = self.mode\n        d = Image._getdecoder(self.mode, \"raw\", rawmode)\n        d.setimage(self.im, self.state.extents())\n        s = d.decode(data)\n\n        if s[0] >= 0:\n            msg = \"not enough image data\"\n            raise ValueError(msg)\n        if s[1] != 0:\n            msg = \"cannot decode image data\"\n            raise ValueError(msg)\n\n\nclass PyEncoder(PyCodec):\n    \"\"\"\n    Python implementation of a format encoder. Override this class and\n    add the decoding logic in the :meth:`encode` method.\n\n    See :ref:`Writing Your Own File Codec in Python<file-codecs-py>`\n    \"\"\"\n\n    _pushes_fd = False\n\n    @property\n    def pushes_fd(self):\n        return self._pushes_fd\n\n    def encode(self, bufsize):\n        \"\"\"\n        Override to perform the encoding process.\n\n        :param bufsize: Buffer size.\n        :returns: A tuple of ``(bytes encoded, errcode, bytes)``.\n            If finished with encoding return 1 for the error code.\n            Err codes are from :data:`.ImageFile.ERRORS`.\n        \"\"\"\n        msg = \"unavailable in base encoder\"\n        raise NotImplementedError(msg)\n\n    def encode_to_pyfd(self):\n        \"\"\"\n        If ``pushes_fd`` is ``True``, then this method will be used,\n        and ``encode()`` will only be called once.\n\n        :returns: A tuple of ``(bytes consumed, errcode)``.\n            Err codes are from :data:`.ImageFile.ERRORS`.\n        \"\"\"\n        if not self.pushes_fd:\n            return 0, -8  # bad configuration\n        bytes_consumed, errcode, data = self.encode(0)\n        if data:\n            self.fd.write(data)\n        return bytes_consumed, errcode\n\n    def encode_to_file(self, fh, bufsize):\n        \"\"\"\n        :param fh: File handle.\n        :param bufsize: Buffer size.\n\n        :returns: If finished successfully, return 0.\n            Otherwise, return an error code. Err codes are from\n            :data:`.ImageFile.ERRORS`.\n        \"\"\"\n        errcode = 0\n        while errcode == 0:\n            status, errcode, buf = self.encode(bufsize)\n            if status > 0:\n                fh.write(buf[status:])\n        return errcode\n",795],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py":["# -*- coding: utf-8 -*-\n# imageio is distributed under the terms of the (new) BSD License.\n\n\"\"\" Read/Write images using Pillow/PIL.\n\nBackend Library: `Pillow <https://pillow.readthedocs.io/en/stable/>`_\n\nPlugin that wraps the the Pillow library. Pillow is a friendly fork of PIL\n(Python Image Library) and supports reading and writing of common formats (jpg,\npng, gif, tiff, ...). For, the complete list of features and supported formats\nplease refer to pillows official docs (see the Backend Library link).\n\nParameters\n----------\nrequest : Request\n    A request object representing the resource to be operated on.\n\nMethods\n-------\n\n.. autosummary::\n    :toctree: _plugins/pillow\n\n    PillowPlugin.read\n    PillowPlugin.write\n    PillowPlugin.iter\n    PillowPlugin.get_meta\n\n\"\"\"\n\nimport sys\nimport warnings\nfrom io import BytesIO\nfrom typing import Any, Callable, Dict, Iterator, List, Optional, Tuple, Union, cast\n\nimport numpy as np\nfrom PIL import ExifTags, GifImagePlugin, Image, ImageSequence, UnidentifiedImageError\nfrom PIL import __version__ as pil_version  # type: ignore\n\nfrom ..core.request import URI_BYTES, InitializationError, IOMode, Request\nfrom ..core.v3_plugin_api import ImageProperties, PluginV3\nfrom ..typing import ArrayLike\n\n\ndef pillow_version() -> Tuple[int]:\n    return tuple(int(x) for x in pil_version.split(\".\"))\n\n\ndef _exif_orientation_transform(orientation: int, mode: str) -> Callable:\n    # get transformation that transforms an image from a\n    # given EXIF orientation into the standard orientation\n\n    # -1 if the mode has color channel, 0 otherwise\n    axis = -2 if Image.getmodebands(mode) > 1 else -1\n\n    EXIF_ORIENTATION = {\n        1: lambda x: x,\n        2: lambda x: np.flip(x, axis=axis),\n        3: lambda x: np.rot90(x, k=2),\n        4: lambda x: np.flip(x, axis=axis - 1),\n        5: lambda x: np.flip(np.rot90(x, k=3), axis=axis),\n        6: lambda x: np.rot90(x, k=3),\n        7: lambda x: np.flip(np.rot90(x, k=1), axis=axis),\n        8: lambda x: np.rot90(x, k=1),\n    }\n\n    return EXIF_ORIENTATION[orientation]\n\n\nclass PillowPlugin(PluginV3):\n    def __init__(self, request: Request) -> None:\n        \"\"\"Instantiate a new Pillow Plugin Object\n\n        Parameters\n        ----------\n        request : {Request}\n            A request object representing the resource to be operated on.\n\n        \"\"\"\n\n        super().__init__(request)\n\n        # Register HEIF opener for Pillow\n        try:\n            from pillow_heif import register_heif_opener\n        except ImportError:\n            pass\n        else:\n            register_heif_opener()\n\n        # Register AVIF opener for Pillow\n        try:\n            from pillow_heif import register_avif_opener\n        except ImportError:\n            pass\n        else:\n            register_avif_opener()\n\n        self._image: Image = None\n        self.images_to_write = []\n\n        if request.mode.io_mode == IOMode.read:\n            try:\n                with Image.open(request.get_file()):\n                    # Check if it is generally possible to read the image.\n                    # This will not read any data and merely try to find a\n                    # compatible pillow plugin (ref: the pillow docs).\n                    pass\n            except UnidentifiedImageError:\n                if request._uri_type == URI_BYTES:\n                    raise InitializationError(\n                        \"Pillow can not read the provided bytes.\"\n                    ) from None\n                else:\n                    raise InitializationError(\n                        f\"Pillow can not read {request.raw_uri}.\"\n                    ) from None\n\n            self._image = Image.open(self._request.get_file())\n        else:\n            self.save_args = {}\n\n            extension = self.request.extension or self.request.format_hint\n            if extension is None:\n                warnings.warn(\n                    \"Can't determine file format to write as. You _must_\"\n                    \" set `format` during write or the call will fail. Use \"\n                    \"`extension` to supress this warning. \",\n                    UserWarning,\n                )\n                return\n\n            tirage = [Image.preinit, Image.init]\n            for format_loader in tirage:\n                format_loader()\n                if extension in Image.registered_extensions().keys():\n                    return\n\n            raise InitializationError(\n                f\"Pillow can not write `{extension}` files.\"\n            ) from None\n\n    def close(self) -> None:\n        self._flush_writer()\n\n        if self._image:\n            self._image.close()\n\n        self._request.finish()\n\n    def read(\n        self,\n        *,\n        index: int = None,\n        mode: str = None,\n        rotate: bool = False,\n        apply_gamma: bool = False,\n        writeable_output: bool = True,\n        pilmode: str = None,\n        exifrotate: bool = None,\n        as_gray: bool = None,\n    ) -> np.ndarray:\n        \"\"\"\n        Parses the given URI and creates a ndarray from it.\n\n        Parameters\n        ----------\n        index : int\n            If the ImageResource contains multiple ndimages, and index is an\n            integer, select the index-th ndimage from among them and return it.\n            If index is an ellipsis (...), read all ndimages in the file and\n            stack them along a new batch dimension and return them. If index is\n            None, this plugin reads the first image of the file (index=0) unless\n            the image is a GIF or APNG, in which case all images are read\n            (index=...).\n        mode : str\n            Convert the image to the given mode before returning it. If None,\n            the mode will be left unchanged. Possible modes can be found at:\n            https://pillow.readthedocs.io/en/stable/handbook/concepts.html#modes\n        rotate : bool\n            If True and the image contains an EXIF orientation tag,\n            apply the orientation before returning the ndimage.\n        apply_gamma : bool\n            If True and the image contains metadata about gamma, apply gamma\n            correction to the image.\n        writable_output : bool\n            If True, ensure that the image is writable before returning it to\n            the user. This incurs a full copy of the pixel data if the data\n            served by pillow is read-only. Consequentially, setting this flag to\n            False improves performance for some images.\n        pilmode : str\n            Deprecated, use `mode` instead.\n        exifrotate : bool\n            Deprecated, use `rotate` instead.\n        as_gray : bool\n            Deprecated. Exists to raise a constructive error message.\n\n        Returns\n        -------\n        ndimage : ndarray\n            A numpy array containing the loaded image data\n\n        Notes\n        -----\n        If you read a paletted image (e.g. GIF) then the plugin will apply the\n        palette by default. Should you wish to read the palette indices of each\n        pixel use ``mode=\"P\"``. The coresponding color pallete can be found in\n        the image's metadata using the ``palette`` key when metadata is\n        extracted using the ``exclude_applied=False`` kwarg. The latter is\n        needed, as palettes are applied by default and hence excluded by default\n        to keep metadata and pixel data consistent.\n\n        \"\"\"\n\n        if pilmode is not None:\n            warnings.warn(\n                \"`pilmode` is deprecated. Use `mode` instead.\", DeprecationWarning\n            )\n            mode = pilmode\n\n        if exifrotate is not None:\n            warnings.warn(\n                \"`exifrotate` is deprecated. Use `rotate` instead.\", DeprecationWarning\n            )\n            rotate = exifrotate\n\n        if as_gray is not None:\n            raise TypeError(\n                \"The keyword `as_gray` is no longer supported.\"\n                \"Use `mode='F'` for a backward-compatible result, or \"\n                \" `mode='L'` for an integer-valued result.\"\n            )\n\n        if self._image.format == \"GIF\":\n            # Converting GIF P frames to RGB\n            # https://github.com/python-pillow/Pillow/pull/6150\n            GifImagePlugin.LOADING_STRATEGY = (\n                GifImagePlugin.LoadingStrategy.RGB_AFTER_DIFFERENT_PALETTE_ONLY\n            )\n\n        if index is None:\n            if self._image.format == \"GIF\":\n                index = Ellipsis\n            elif self._image.custom_mimetype == \"image/apng\":\n                index = Ellipsis\n            else:\n                index = 0\n\n        if isinstance(index, int):\n            # will raise IO error if index >= number of frames in image\n            self._image.seek(index)\n            image = self._apply_transforms(\n                self._image, mode, rotate, apply_gamma, writeable_output\n            )\n        else:\n            iterator = self.iter(\n                mode=mode,\n                rotate=rotate,\n                apply_gamma=apply_gamma,\n                writeable_output=writeable_output,\n            )\n            image = np.stack([im for im in iterator], axis=0)\n\n        return image\n\n    def iter(\n        self,\n        *,\n        mode: str = None,\n        rotate: bool = False,\n        apply_gamma: bool = False,\n        writeable_output: bool = True,\n    ) -> Iterator[np.ndarray]:\n        \"\"\"\n        Iterate over all ndimages/frames in the URI\n\n        Parameters\n        ----------\n        mode : {str, None}\n            Convert the image to the given mode before returning it. If None,\n            the mode will be left unchanged. Possible modes can be found at:\n            https://pillow.readthedocs.io/en/stable/handbook/concepts.html#modes\n        rotate : {bool}\n            If set to ``True`` and the image contains an EXIF orientation tag,\n            apply the orientation before returning the ndimage.\n        apply_gamma : {bool}\n            If ``True`` and the image contains metadata about gamma, apply gamma\n            correction to the image.\n        writable_output : bool\n            If True, ensure that the image is writable before returning it to\n            the user. This incurs a full copy of the pixel data if the data\n            served by pillow is read-only. Consequentially, setting this flag to\n            False improves performance for some images.\n        \"\"\"\n\n        for im in ImageSequence.Iterator(self._image):\n            yield self._apply_transforms(\n                im, mode, rotate, apply_gamma, writeable_output\n            )\n\n    def _apply_transforms(\n        self, image, mode, rotate, apply_gamma, writeable_output\n    ) -> np.ndarray:\n        if mode is not None:\n            image = image.convert(mode)\n        elif image.mode == \"P\":\n            # adjust for pillow9 changes\n            # see: https://github.com/python-pillow/Pillow/issues/5929\n            image = image.convert(image.palette.mode)\n        elif image.format == \"PNG\" and image.mode == \"I\":\n            major, minor, patch = pillow_version()\n\n            if sys.byteorder == \"little\":\n                desired_mode = \"I;16\"\n            else:  # pragma: no cover\n                # can't test big-endian in GH-Actions\n                desired_mode = \"I;16B\"\n\n            if major < 10:  # pragma: no cover\n                warnings.warn(\n                    \"Loading 16-bit (uint16) PNG as int32 due to limitations \"\n                    \"in pillow's PNG decoder. This will be fixed in a future \"\n                    \"version of pillow which will make this warning dissapear.\",\n                    UserWarning,\n                )\n            elif minor < 1:  # pragma: no cover\n                # pillow<10.1.0 can directly decode into 16-bit grayscale\n                image.mode = desired_mode\n            else:\n                # pillow >= 10.1.0\n                image = image.convert(desired_mode)\n\n        image = np.asarray(image)\n\n        meta = self.metadata(index=self._image.tell(), exclude_applied=False)\n        if rotate and \"Orientation\" in meta:\n            transformation = _exif_orientation_transform(\n                meta[\"Orientation\"], self._image.mode\n            )\n            image = transformation(image)\n\n        if apply_gamma and \"gamma\" in meta:\n            gamma = float(meta[\"gamma\"])\n            scale = float(65536 if image.dtype == np.uint16 else 255)\n            gain = 1.0\n            image = ((image / scale) ** gamma) * scale * gain + 0.4999\n            image = np.round(image).astype(np.uint8)\n\n        if writeable_output and not image.flags[\"WRITEABLE\"]:\n            image = np.array(image)\n\n        return image\n\n    def write(\n        self,\n        ndimage: Union[ArrayLike, List[ArrayLike]],\n        *,\n        mode: str = None,\n        format: str = None,\n        is_batch: bool = None,\n        **kwargs,\n    ) -> Optional[bytes]:\n        \"\"\"\n        Write an ndimage to the URI specified in path.\n\n        If the URI points to a file on the current host and the file does not\n        yet exist it will be created. If the file exists already, it will be\n        appended if possible; otherwise, it will be replaced.\n\n        If necessary, the image is broken down along the leading dimension to\n        fit into individual frames of the chosen format. If the format doesn't\n        support multiple frames, and IOError is raised.\n\n        Parameters\n        ----------\n        image : ndarray or list\n            The ndimage to write. If a list is given each element is expected to\n            be an ndimage.\n        mode : str\n            Specify the image's color format. If None (default), the mode is\n            inferred from the array's shape and dtype. Possible modes can be\n            found at:\n            https://pillow.readthedocs.io/en/stable/handbook/concepts.html#modes\n        format : str\n            Optional format override. If omitted, the format to use is\n            determined from the filename extension. If a file object was used\n            instead of a filename, this parameter must always be used.\n        is_batch : bool\n            Explicitly tell the writer that ``image`` is a batch of images\n            (True) or not (False). If None, the writer will guess this from the\n            provided ``mode`` or ``image.shape``. While the latter often works,\n            it may cause problems for small images due to aliasing of spatial\n            and color-channel axes.\n        kwargs : ...\n            Extra arguments to pass to pillow. If a writer doesn't recognise an\n            option, it is silently ignored. The available options are described\n            in pillow's `image format documentation\n            <https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html>`_\n            for each writer.\n\n        Notes\n        -----\n        When writing batches of very narrow (2-4 pixels wide) gray images set\n        the ``mode`` explicitly to avoid the batch being identified as a colored\n        image.\n\n        \"\"\"\n        if \"fps\" in kwargs:\n            warnings.warn(\n                \"The keyword `fps` is no longer supported. Use `duration`\"\n                \"(in ms) instead, e.g. `fps=50` == `duration=20` (1000 * 1/50).\",\n                DeprecationWarning,\n            )\n            kwargs[\"duration\"] = 1000 * 1 / kwargs.get(\"fps\")\n\n        if isinstance(ndimage, list):\n            ndimage = np.stack(ndimage, axis=0)\n            is_batch = True\n        else:\n            ndimage = np.asarray(ndimage)\n\n        # check if ndimage is a batch of frames/pages (e.g. for writing GIF)\n        # if mode is given, use it; otherwise fall back to image.ndim only\n        if is_batch is not None:\n            pass\n        elif mode is not None:\n            is_batch = (\n                ndimage.ndim > 3 if Image.getmodebands(mode) > 1 else ndimage.ndim > 2\n            )\n        elif ndimage.ndim == 2:\n            is_batch = False\n        elif ndimage.ndim == 3 and ndimage.shape[-1] == 1:\n            raise ValueError(\"Can't write images with one color channel.\")\n        elif ndimage.ndim == 3 and ndimage.shape[-1] in [2, 3, 4]:\n            # Note: this makes a channel-last assumption\n            is_batch = False\n        else:\n            is_batch = True\n\n        if not is_batch:\n            ndimage = ndimage[None, ...]\n\n        for frame in ndimage:\n            pil_frame = Image.fromarray(frame, mode=mode)\n            if \"bits\" in kwargs:\n                pil_frame = pil_frame.quantize(colors=2 ** kwargs[\"bits\"])\n            self.images_to_write.append(pil_frame)\n\n        if (\n            format is not None\n            and \"format\" in self.save_args\n            and self.save_args[\"format\"] != format\n        ):\n            old_format = self.save_args[\"format\"]\n            warnings.warn(\n                \"Changing the output format during incremental\"\n                \" writes is strongly discouraged.\"\n                f\" Was `{old_format}`, is now `{format}`.\",\n                UserWarning,\n            )\n\n        extension = self.request.extension or self.request.format_hint\n        self.save_args[\"format\"] = format or Image.registered_extensions()[extension]\n        self.save_args.update(kwargs)\n\n        # when writing to `bytes` we flush instantly\n        result = None\n        if self._request._uri_type == URI_BYTES:\n            self._flush_writer()\n            file = cast(BytesIO, self._request.get_file())\n            result = file.getvalue()\n\n        return result\n\n    def _flush_writer(self):\n        if len(self.images_to_write) == 0:\n            return\n\n        primary_image = self.images_to_write.pop(0)\n\n        if len(self.images_to_write) > 0:\n            self.save_args[\"save_all\"] = True\n            self.save_args[\"append_images\"] = self.images_to_write\n\n        primary_image.save(self._request.get_file(), **self.save_args)\n        self.images_to_write.clear()\n        self.save_args.clear()\n\n    def get_meta(self, *, index=0) -> Dict[str, Any]:\n        return self.metadata(index=index, exclude_applied=False)\n\n    def metadata(\n        self, index: int = None, exclude_applied: bool = True\n    ) -> Dict[str, Any]:\n        \"\"\"Read ndimage metadata.\n\n        Parameters\n        ----------\n        index : {integer, None}\n            If the ImageResource contains multiple ndimages, and index is an\n            integer, select the index-th ndimage from among them and return its\n            metadata. If index is an ellipsis (...), read and return global\n            metadata. If index is None, this plugin reads metadata from the\n            first image of the file (index=0) unless the image is a GIF or APNG,\n            in which case global metadata is read (index=...).\n        exclude_applied : bool\n            If True, exclude metadata fields that are applied to the image while\n            reading. For example, if the binary data contains a rotation flag,\n            the image is rotated by default and the rotation flag is excluded\n            from the metadata to avoid confusion.\n\n        Returns\n        -------\n        metadata : dict\n            A dictionary of format-specific metadata.\n\n        \"\"\"\n\n        if index is None:\n            if self._image.format == \"GIF\":\n                index = Ellipsis\n            elif self._image.custom_mimetype == \"image/apng\":\n                index = Ellipsis\n            else:\n                index = 0\n\n        if isinstance(index, int) and self._image.tell() != index:\n            self._image.seek(index)\n\n        metadata = self._image.info.copy()\n        metadata[\"mode\"] = self._image.mode\n        metadata[\"shape\"] = self._image.size\n\n        if self._image.mode == \"P\" and not exclude_applied:\n            metadata[\"palette\"] = np.asarray(tuple(self._image.palette.colors.keys()))\n\n        if self._image.getexif():\n            exif_data = {\n                ExifTags.TAGS.get(key, \"unknown\"): value\n                for key, value in dict(self._image.getexif()).items()\n            }\n            exif_data.pop(\"unknown\", None)\n            metadata.update(exif_data)\n\n        if exclude_applied:\n            metadata.pop(\"Orientation\", None)\n\n        return metadata\n\n    def properties(self, index: int = None) -> ImageProperties:\n        \"\"\"Standardized ndimage metadata\n        Parameters\n        ----------\n        index : int\n            If the ImageResource contains multiple ndimages, and index is an\n            integer, select the index-th ndimage from among them and return its\n            properties. If index is an ellipsis (...), read and return the\n            properties of all ndimages in the file stacked along a new batch\n            dimension. If index is None, this plugin reads and returns the\n            properties of the first image (index=0) unless the image is a GIF or\n            APNG, in which case it reads and returns the properties all images\n            (index=...).\n\n        Returns\n        -------\n        properties : ImageProperties\n            A dataclass filled with standardized image metadata.\n\n        Notes\n        -----\n        This does not decode pixel data and is fast for large images.\n\n        \"\"\"\n\n        if index is None:\n            if self._image.format == \"GIF\":\n                index = Ellipsis\n            elif self._image.custom_mimetype == \"image/apng\":\n                index = Ellipsis\n            else:\n                index = 0\n\n        if index is Ellipsis:\n            self._image.seek(0)\n        else:\n            self._image.seek(index)\n\n        if self._image.mode == \"P\":\n            # mode of palette images is determined by their palette\n            mode = self._image.palette.mode\n        else:\n            mode = self._image.mode\n\n        width: int = self._image.width\n        height: int = self._image.height\n        shape: Tuple[int, ...] = (height, width)\n\n        n_frames: Optional[int] = None\n        if index is ...:\n            n_frames = getattr(self._image, \"n_frames\", 1)\n            shape = (n_frames, *shape)\n\n        dummy = np.asarray(Image.new(mode, (1, 1)))\n        pil_shape: Tuple[int, ...] = dummy.shape\n        if len(pil_shape) > 2:\n            shape = (*shape, *pil_shape[2:])\n\n        return ImageProperties(\n            shape=shape,\n            dtype=dummy.dtype,\n            n_images=n_frames,\n            is_batch=index is Ellipsis,\n        )\n",613],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\imopen.py":["from pathlib import Path\nimport warnings\n\nfrom ..config import known_plugins\nfrom ..config.extensions import known_extensions\nfrom .request import (\n    SPECIAL_READ_URIS,\n    URI_FILENAME,\n    InitializationError,\n    IOMode,\n    Request,\n)\n\n\ndef imopen(\n    uri,\n    io_mode,\n    *,\n    plugin=None,\n    extension=None,\n    format_hint=None,\n    legacy_mode=False,\n    **kwargs,\n):\n    \"\"\"Open an ImageResource.\n\n    .. warning::\n        This warning is for pypy users. If you are not using a context manager,\n        remember to deconstruct the returned plugin to avoid leaking the file\n        handle to an unclosed file.\n\n    Parameters\n    ----------\n    uri : str or pathlib.Path or bytes or file or Request\n        The :doc:`ImageResource <../../user_guide/requests>` to load the\n        image from.\n    io_mode : str\n        The mode in which the file is opened. Possible values are::\n\n            ``r`` - open the file for reading\n            ``w`` - open the file for writing\n\n        Depreciated since v2.9:\n        A second character can be added to give the reader a hint on what\n        the user expects. This will be ignored by new plugins and will\n        only have an effect on legacy plugins. Possible values are::\n\n            ``i`` for a single image,\n            ``I`` for multiple images,\n            ``v`` for a single volume,\n            ``V`` for multiple volumes,\n            ``?`` for don't care\n\n    plugin : str, Plugin, or None\n        The plugin to use. If set to None imopen will perform a\n        search for a matching plugin. If not None, this takes priority over\n        the provided format hint.\n    extension : str\n        If not None, treat the provided ImageResource as if it had the given\n        extension. This affects the order in which backends are considered, and\n        when writing this may also influence the format used when encoding.\n    format_hint : str\n        Deprecated. Use `extension` instead.\n    legacy_mode : bool\n        If true use the v2 behavior when searching for a suitable\n        plugin. This will ignore v3 plugins and will check ``plugin``\n        against known extensions if no plugin with the given name can be found.\n    **kwargs : Any\n        Additional keyword arguments will be passed to the plugin upon\n        construction.\n\n    Notes\n    -----\n    Registered plugins are controlled via the ``known_plugins`` dict in\n    ``imageio.config``.\n\n    Passing a ``Request`` as the uri is only supported if ``legacy_mode``\n    is ``True``. In this case ``io_mode`` is ignored.\n\n    Using the kwarg ``format_hint`` does not enforce the given format. It merely\n    provides a `hint` to the selection process and plugin. The selection\n    processes uses this hint for optimization; however, a plugin's decision how\n    to read a ImageResource will - typically - still be based on the content of\n    the resource.\n\n\n    Examples\n    --------\n\n    >>> import imageio.v3 as iio\n    >>> with iio.imopen(\"/path/to/image.png\", \"r\") as file:\n    >>>     im = file.read()\n\n    >>> with iio.imopen(\"/path/to/output.jpg\", \"w\") as file:\n    >>>     file.write(im)\n\n    \"\"\"\n\n    if isinstance(uri, Request) and legacy_mode:\n        warnings.warn(\n            \"`iio.core.Request` is a low-level object and using it\"\n            \" directly as input to `imopen` is discouraged. This will raise\"\n            \" an exception in ImageIO v3.\",\n            DeprecationWarning,\n            stacklevel=2,\n        )\n\n        request = uri\n        uri = request.raw_uri\n        io_mode = request.mode.io_mode\n        request.format_hint = format_hint\n    else:\n        request = Request(uri, io_mode, format_hint=format_hint, extension=extension)\n\n    source = \"<bytes>\" if isinstance(uri, bytes) else uri\n\n    # fast-path based on plugin\n    # (except in legacy mode)\n    if plugin is not None:\n        if isinstance(plugin, str):\n            try:\n                config = known_plugins[plugin]\n            except KeyError:\n                request.finish()\n                raise ValueError(\n                    f\"`{plugin}` is not a registered plugin name.\"\n                ) from None\n\n            def loader(request, **kwargs):\n                return config.plugin_class(request, **kwargs)\n\n        else:\n\n            def loader(request, **kwargs):\n                return plugin(request, **kwargs)\n\n        try:\n            return loader(request, **kwargs)\n        except InitializationError as class_specific:\n            err_from = class_specific\n            err_type = RuntimeError if legacy_mode else IOError\n            err_msg = f\"`{plugin}` can not handle the given uri.\"\n        except ImportError:\n            err_from = None\n            err_type = ImportError\n            err_msg = (\n                f\"The `{config.name}` plugin is not installed. \"\n                f\"Use `pip install imageio[{config.install_name}]` to install it.\"\n            )\n        except Exception as generic_error:\n            err_from = generic_error\n            err_type = IOError\n            err_msg = f\"An unknown error occurred while initializing plugin `{plugin}`.\"\n\n        request.finish()\n        raise err_type(err_msg) from err_from\n\n    # fast-path based on format_hint\n    if request.format_hint is not None:\n        for candidate_format in known_extensions[format_hint]:\n            for plugin_name in candidate_format.priority:\n                config = known_plugins[plugin_name]\n\n                try:\n                    candidate_plugin = config.plugin_class\n                except ImportError:\n                    # not installed\n                    continue\n\n                try:\n                    plugin_instance = candidate_plugin(request, **kwargs)\n                except InitializationError:\n                    # file extension doesn't match file type\n                    continue\n\n                return plugin_instance\n        else:\n            resource = (\n                \"<bytes>\" if isinstance(request.raw_uri, bytes) else request.raw_uri\n            )\n            warnings.warn(f\"`{resource}` can not be opened as a `{format_hint}` file.\")\n\n    # fast-path based on file extension\n    if request.extension in known_extensions:\n        for candidate_format in known_extensions[request.extension]:\n            for plugin_name in candidate_format.priority:\n                config = known_plugins[plugin_name]\n\n                try:\n                    candidate_plugin = config.plugin_class\n                except ImportError:\n                    # not installed\n                    continue\n\n                try:\n                    plugin_instance = candidate_plugin(request, **kwargs)\n                except InitializationError:\n                    # file extension doesn't match file type\n                    continue\n\n                return plugin_instance\n\n    # error out for read-only special targets\n    # this is hacky; can we come up with a better solution for this?\n    if request.mode.io_mode == IOMode.write:\n        if isinstance(uri, str) and uri.startswith(SPECIAL_READ_URIS):\n            request.finish()\n            err_type = ValueError if legacy_mode else IOError\n            err_msg = f\"`{source}` is read-only.\"\n            raise err_type(err_msg)\n\n    # error out for directories\n    # this is a bit hacky and should be cleaned once we decide\n    # how to gracefully handle DICOM\n    if request._uri_type == URI_FILENAME and Path(request.raw_uri).is_dir():\n        request.finish()\n        err_type = ValueError if legacy_mode else IOError\n        err_msg = (\n            \"ImageIO does not generally support reading folders. \"\n            \"Limited support may be available via specific plugins. \"\n            \"Specify the plugin explicitly using the `plugin` kwarg, e.g. `plugin='DICOM'`\"\n        )\n        raise err_type(err_msg)\n\n    # close the current request here and use fresh/new ones while trying each\n    # plugin This is slow (means potentially reopening a resource several\n    # times), but should only happen rarely because this is the fallback if all\n    # else fails.\n    request.finish()\n\n    # fallback option: try all plugins\n    for config in known_plugins.values():\n        # each plugin gets its own request\n        request = Request(uri, io_mode, format_hint=format_hint)\n\n        try:\n            plugin_instance = config.plugin_class(request, **kwargs)\n        except InitializationError:\n            continue\n        except ImportError:\n            continue\n        else:\n            return plugin_instance\n\n    err_type = ValueError if legacy_mode else IOError\n    err_msg = f\"Could not find a backend to open `{source}`` with iomode `{io_mode}`.\"\n\n    # check if a missing plugin could help\n    if request.extension in known_extensions:\n        missing_plugins = list()\n\n        formats = known_extensions[request.extension]\n        plugin_names = [\n            plugin for file_format in formats for plugin in file_format.priority\n        ]\n        for name in plugin_names:\n            config = known_plugins[name]\n\n            try:\n                config.plugin_class\n                continue\n            except ImportError:\n                missing_plugins.append(config)\n\n        if len(missing_plugins) > 0:\n            install_candidates = \"\\n\".join(\n                [\n                    (\n                        f\"  {config.name}:  \"\n                        f\"pip install imageio[{config.install_name}]\"\n                    )\n                    for config in missing_plugins\n                ]\n            )\n            err_msg += (\n                \"\\nBased on the extension, the following plugins might add capable backends:\\n\"\n                f\"{install_candidates}\"\n            )\n\n    request.finish()\n    raise err_type(err_msg)\n",281],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\v3.py":["import numpy as np\n\nfrom .core.imopen import imopen\n\n\ndef imread(uri, *, index=None, plugin=None, extension=None, format_hint=None, **kwargs):\n    \"\"\"Read an ndimage from a URI.\n\n    Opens the given URI and reads an ndimage from it. The exact behavior\n    depends on both the file type and plugin used to open the file. To learn\n    about the exact behavior, check the documentation of the relevant plugin.\n    Typically, imread attempts to read all data stored in the URI.\n\n    Parameters\n    ----------\n    uri : {str, pathlib.Path, bytes, file}\n        The resource to load the image from, e.g. a filename, pathlib.Path,\n        http address or file object, see the docs for more info.\n    index : {int, Ellipsis, None}\n        If the ImageResource contains multiple ndimages, and index is an\n        integer, select the index-th ndimage from among them and return it. If\n        index is an ellipsis (...), read all ndimages in the file and stack them\n        along a new batch dimension. If index is None, let the plugin decide.\n    plugin : {str, None}\n        The plugin to use. If set to None (default) imread will perform a\n        search for a matching plugin. If not None, this takes priority over\n        the provided format hint  (if present).\n    extension : str\n        If not None, treat the provided ImageResource as if it had the given\n        extension. This affects the order in which backends are considered.\n    format_hint : str\n        Deprecated. Use `extension` instead.\n    **kwargs :\n        Additional keyword arguments will be passed to the plugin's read call.\n\n    Returns\n    -------\n    image : ndimage\n        The ndimage located at the given URI.\n    \"\"\"\n\n    plugin_kwargs = {\n        \"legacy_mode\": False,\n        \"plugin\": plugin,\n        \"format_hint\": format_hint,\n        \"extension\": extension,\n    }\n\n    call_kwargs = kwargs\n    if index is not None:\n        call_kwargs[\"index\"] = index\n\n    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n        return np.asarray(img_file.read(**call_kwargs))\n\n\ndef imiter(uri, *, plugin=None, extension=None, format_hint=None, **kwargs):\n    \"\"\"Read a sequence of ndimages from a URI.\n\n    Returns an iterable that yields ndimages from the given URI. The exact\n    behavior depends on both, the file type and plugin used to open the file.\n    To learn about the exact behavior, check the documentation of the relevant\n    plugin.\n\n    Parameters\n    ----------\n    uri : {str, pathlib.Path, bytes, file}\n        The resource to load the image from, e.g. a filename, pathlib.Path,\n        http address or file object, see the docs for more info.\n    plugin : {str, None}\n        The plugin to use. If set to None (default) imiter will perform a\n        search for a matching plugin. If not None, this takes priority over\n        the provided format hint (if present).\n    extension : str\n        If not None, treat the provided ImageResource as if it had the given\n        extension. This affects the order in which backends are considered.\n    format_hint : str\n        Deprecated. Use `extension` instead.\n    **kwargs :\n        Additional keyword arguments will be passed to the plugin's ``iter``\n        call.\n\n    Yields\n    ------\n    image : ndimage\n        The next ndimage located at the given URI.\n\n    \"\"\"\n\n    with imopen(\n        uri,\n        \"r\",\n        legacy_mode=False,\n        plugin=plugin,\n        format_hint=format_hint,\n        extension=extension,\n    ) as img_file:\n        for image in img_file.iter(**kwargs):\n            # Note: casting to ndarray here to ensure compatibility\n            # with the v2.9 API\n            yield np.asarray(image)\n\n\ndef imwrite(uri, image, *, plugin=None, extension=None, format_hint=None, **kwargs):\n    \"\"\"Write an ndimage to the given URI.\n\n    The exact behavior depends on the file type and plugin used. To learn about\n    the exact behavior, check the documentation of the relevant plugin.\n\n    Parameters\n    ----------\n    uri : {str, pathlib.Path, bytes, file}\n        The resource to save the image to, e.g. a filename, pathlib.Path,\n        http address or file object, check the docs for more info.\n    image : np.ndarray\n        The image to write to disk.\n    plugin : {str, None}\n        The plugin to use. If set to None (default) imwrite will perform a\n        search for a matching plugin. If not None, this takes priority over\n        the provided format hint (if present).\n    extension : str\n        If not None, treat the provided ImageResource as if it had the given\n        extension. This affects the order in which backends are considered, and\n        may also influence the format used when encoding.\n    format_hint : str\n        Deprecated. Use `extension` instead.\n    **kwargs :\n        Additional keyword arguments will be passed to the plugin's ``write``\n        call.\n\n    Returns\n    -------\n    encoded_image : None or Bytes\n        Returns ``None`` in all cases, except when ``uri`` is set to ``<bytes>``.\n        In this case it returns the encoded ndimage as a bytes string.\n\n    \"\"\"\n\n    with imopen(\n        uri,\n        \"w\",\n        legacy_mode=False,\n        plugin=plugin,\n        format_hint=format_hint,\n        extension=extension,\n    ) as img_file:\n        encoded = img_file.write(image, **kwargs)\n\n    return encoded\n\n\ndef improps(uri, *, index=None, plugin=None, extension=None, **kwargs):\n    \"\"\"Read standardized metadata.\n\n    Opens the given URI and reads the properties of an ndimage from it. The\n    properties represent standardized metadata. This means that they will have\n    the same name regardless of the format being read or plugin/backend being\n    used. Further, any field will be, where possible, populated with a sensible\n    default (may be `None`) if the ImageResource does not declare a value in its\n    metadata.\n\n    Parameters\n    ----------\n    index : int\n        If the ImageResource contains multiple ndimages, and index is an\n        integer, select the index-th ndimage from among them and return its\n        properties. If index is an ellipsis (...), read all ndimages in the file\n        and stack them along a new batch dimension and return their properties.\n        If index is None, let the plugin decide.\n    plugin : {str, None}\n        The plugin to be used. If None, performs a search for a matching\n        plugin.\n    extension : str\n        If not None, treat the provided ImageResource as if it had the given\n        extension. This affects the order in which backends are considered.\n    **kwargs :\n        Additional keyword arguments will be passed to the plugin's ``properties``\n        call.\n\n    Returns\n    -------\n    properties : ImageProperties\n        A dataclass filled with standardized image metadata.\n\n    Notes\n    -----\n    Where possible, this will avoid loading pixel data.\n\n    See Also\n    --------\n    imageio.core.v3_plugin_api.ImageProperties\n\n    \"\"\"\n\n    plugin_kwargs = {\"legacy_mode\": False, \"plugin\": plugin, \"extension\": extension}\n\n    call_kwargs = kwargs\n    if index is not None:\n        call_kwargs[\"index\"] = index\n\n    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n        properties = img_file.properties(**call_kwargs)\n\n    return properties\n\n\ndef immeta(\n    uri, *, index=None, plugin=None, extension=None, exclude_applied=True, **kwargs\n):\n    \"\"\"Read format-specific metadata.\n\n    Opens the given URI and reads metadata for an ndimage from it. The contents\n    of the returned metadata dictionary is specific to both the image format and\n    plugin used to open the ImageResource. To learn about the exact behavior,\n    check the documentation of the relevant plugin. Typically, immeta returns a\n    dictionary specific to the image format, where keys match metadata field\n    names and values are a field's contents.\n\n    Parameters\n    ----------\n    uri : {str, pathlib.Path, bytes, file}\n        The resource to load the image from, e.g. a filename, pathlib.Path, http\n        address or file object, see the docs for more info.\n    index : {int, None}\n        If the ImageResource contains multiple ndimages, and index is an\n        integer, select the index-th ndimage from among them and return its\n        metadata. If index is an ellipsis (...), return global metadata. If\n        index is None, let the plugin decide the default.\n    plugin : {str, None}\n        The plugin to be used. If None (default), performs a search for a\n        matching plugin.\n    extension : str\n        If not None, treat the provided ImageResource as if it had the given\n        extension. This affects the order in which backends are considered.\n    **kwargs :\n        Additional keyword arguments will be passed to the plugin's metadata\n        method.\n\n    Returns\n    -------\n    image : ndimage\n        The ndimage located at the given URI.\n\n    \"\"\"\n\n    plugin_kwargs = {\"legacy_mode\": False, \"plugin\": plugin, \"extension\": extension}\n\n    call_kwargs = kwargs\n    call_kwargs[\"exclude_applied\"] = exclude_applied\n    if index is not None:\n        call_kwargs[\"index\"] = index\n\n    with imopen(uri, \"r\", **plugin_kwargs) as img_file:\n        metadata = img_file.metadata(**call_kwargs)\n\n    return metadata\n\n\n__all__ = [\"imopen\", \"imread\", \"imwrite\", \"imiter\", \"improps\", \"immeta\"]\n",259],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py":["__all__ = ['imread', 'imsave']\n\nfrom functools import wraps\nimport numpy as np\n\nfrom imageio.v3 import imread as imageio_imread, imwrite as imsave\n\n\n@wraps(imageio_imread)\ndef imread(*args, **kwargs):\n    out = np.asarray(imageio_imread(*args, **kwargs))\n    if not out.flags['WRITEABLE']:\n        out = out.copy()\n    return out\n",14],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\manage_plugins.py":["\"\"\"Handle image reading, writing and plotting plugins.\n\nTo improve performance, plugins are only loaded as needed. As a result, there\ncan be multiple states for a given plugin:\n\n    available: Defined in an *ini file located in `skimage.io._plugins`.\n        See also `skimage.io.available_plugins`.\n    partial definition: Specified in an *ini file, but not defined in the\n        corresponding plugin module. This will raise an error when loaded.\n    available but not on this system: Defined in `skimage.io._plugins`, but\n        a dependent library (e.g. Qt, PIL) is not available on your system.\n        This will raise an error when loaded.\n    loaded: The real availability is determined when it's explicitly loaded,\n        either because it's one of the default plugins, or because it's\n        loaded explicitly by the user.\n\n\"\"\"\nimport os.path\nimport warnings\nfrom configparser import ConfigParser\nfrom glob import glob\n\nfrom .collection import imread_collection_wrapper\n\n__all__ = ['use_plugin', 'call_plugin', 'plugin_info', 'plugin_order',\n           'reset_plugins', 'find_available_plugins', 'available_plugins']\n\n# The plugin store will save a list of *loaded* io functions for each io type\n# (e.g. 'imread', 'imsave', etc.). Plugins are loaded as requested.\nplugin_store = None\n# Dictionary mapping plugin names to a list of functions they provide.\nplugin_provides = {}\n# The module names for the plugins in `skimage.io._plugins`.\nplugin_module_name = {}\n# Meta-data about plugins provided by *.ini files.\nplugin_meta_data = {}\n# For each plugin type, default to the first available plugin as defined by\n# the following preferences.\npreferred_plugins = {\n    # Default plugins for all types (overridden by specific types below).\n    'all': ['imageio', 'pil', 'matplotlib'],\n    'imshow': ['matplotlib'],\n    'imshow_collection': ['matplotlib']\n}\n\n\ndef _clear_plugins():\n    \"\"\"Clear the plugin state to the default, i.e., where no plugins are loaded\n    \"\"\"\n    global plugin_store\n    plugin_store = {'imread': [],\n                    'imsave': [],\n                    'imshow': [],\n                    'imread_collection': [],\n                    'imshow_collection': [],\n                    '_app_show': []}\n\n\n_clear_plugins()\n\n\ndef _load_preferred_plugins():\n    # Load preferred plugin for each io function.\n    io_types = ['imsave', 'imshow', 'imread_collection', 'imshow_collection',\n                'imread']\n    for p_type in io_types:\n        _set_plugin(p_type, preferred_plugins['all'])\n\n    plugin_types = (p for p in preferred_plugins.keys() if p != 'all')\n    for p_type in plugin_types:\n        _set_plugin(p_type, preferred_plugins[p_type])\n\n\ndef _set_plugin(plugin_type, plugin_list):\n    for plugin in plugin_list:\n        if plugin not in available_plugins:\n            continue\n        try:\n            use_plugin(plugin, kind=plugin_type)\n            break\n        except (ImportError, RuntimeError, OSError):\n            pass\n\n\ndef reset_plugins():\n    _clear_plugins()\n    _load_preferred_plugins()\n\n\ndef _parse_config_file(filename):\n    \"\"\"Return plugin name and meta-data dict from plugin config file.\"\"\"\n    parser = ConfigParser()\n    parser.read(filename)\n    name = parser.sections()[0]\n\n    meta_data = {}\n    for opt in parser.options(name):\n        meta_data[opt] = parser.get(name, opt)\n\n    return name, meta_data\n\n\ndef _scan_plugins():\n    \"\"\"Scan the plugins directory for .ini files and parse them\n    to gather plugin meta-data.\n    \"\"\"\n    pd = os.path.dirname(__file__)\n    config_files = glob(os.path.join(pd, '_plugins', '*.ini'))\n\n    for filename in config_files:\n        name, meta_data = _parse_config_file(filename)\n        if 'provides' not in meta_data:\n            warnings.warn(f'file {filename} not recognized as a scikit-image io plugin, skipping.')\n            continue\n        plugin_meta_data[name] = meta_data\n        provides = [s.strip() for s in meta_data['provides'].split(',')]\n        valid_provides = [p for p in provides if p in plugin_store]\n\n        for p in provides:\n            if p not in plugin_store:\n                print(f\"Plugin `{name}` wants to provide non-existent `{p}`. Ignoring.\")\n\n        # Add plugins that provide 'imread' as provider of 'imread_collection'.\n        need_to_add_collection = ('imread_collection' not in valid_provides and\n                                  'imread' in valid_provides)\n        if need_to_add_collection:\n            valid_provides.append('imread_collection')\n\n        plugin_provides[name] = valid_provides\n\n        plugin_module_name[name] = os.path.basename(filename)[:-4]\n\n\n_scan_plugins()\n\n\ndef find_available_plugins(loaded=False):\n    \"\"\"List available plugins.\n\n    Parameters\n    ----------\n    loaded : bool\n        If True, show only those plugins currently loaded.  By default,\n        all plugins are shown.\n\n    Returns\n    -------\n    p : dict\n        Dictionary with plugin names as keys and exposed functions as\n        values.\n\n    \"\"\"\n    active_plugins = set()\n    for plugin_func in plugin_store.values():\n        for plugin, func in plugin_func:\n            active_plugins.add(plugin)\n\n    d = {}\n    for plugin in plugin_provides:\n        if not loaded or plugin in active_plugins:\n            d[plugin] = [f for f in plugin_provides[plugin]\n                         if not f.startswith('_')]\n\n    return d\n\n\navailable_plugins = find_available_plugins()\n\n\ndef call_plugin(kind, *args, **kwargs):\n    \"\"\"Find the appropriate plugin of 'kind' and execute it.\n\n    Parameters\n    ----------\n    kind : {'imshow', 'imsave', 'imread', 'imread_collection'}\n        Function to look up.\n    plugin : str, optional\n        Plugin to load.  Defaults to None, in which case the first\n        matching plugin is used.\n    *args, **kwargs : arguments and keyword arguments\n        Passed to the plugin function.\n\n    \"\"\"\n    if kind not in plugin_store:\n        raise ValueError(f'Invalid function ({kind}) requested.')\n\n    plugin_funcs = plugin_store[kind]\n    if len(plugin_funcs) == 0:\n        msg = (f\"No suitable plugin registered for {kind}.\\n\\n\"\n               \"You may load I/O plugins with the `skimage.io.use_plugin` \"\n               \"command.  A list of all available plugins are shown in the \"\n               \"`skimage.io` docstring.\")\n        raise RuntimeError(msg)\n\n    plugin = kwargs.pop('plugin', None)\n    if plugin is None:\n        _, func = plugin_funcs[0]\n    else:\n        _load(plugin)\n        try:\n            func = [f for (p, f) in plugin_funcs if p == plugin][0]\n        except IndexError:\n            raise RuntimeError(f'Could not find the plugin \"{plugin}\" for {kind}.')\n\n    return func(*args, **kwargs)\n\n\ndef use_plugin(name, kind=None):\n    \"\"\"Set the default plugin for a specified operation.  The plugin\n    will be loaded if it hasn't been already.\n\n    Parameters\n    ----------\n    name : str\n        Name of plugin.\n    kind : {'imsave', 'imread', 'imshow', 'imread_collection', 'imshow_collection'}, optional\n        Set the plugin for this function.  By default,\n        the plugin is set for all functions.\n\n    See Also\n    --------\n    available_plugins : List of available plugins\n\n    Examples\n    --------\n    To use Matplotlib as the default image reader, you would write:\n\n    >>> from skimage import io\n    >>> io.use_plugin('matplotlib', 'imread')\n\n    To see a list of available plugins run ``io.available_plugins``. Note that\n    this lists plugins that are defined, but the full list may not be usable\n    if your system does not have the required libraries installed.\n\n    \"\"\"\n    if kind is None:\n        kind = plugin_store.keys()\n    else:\n        if kind not in plugin_provides[name]:\n            raise RuntimeError(f\"Plugin {name} does not support `{kind}`.\")\n\n        if kind == 'imshow':\n            kind = [kind, '_app_show']\n        else:\n            kind = [kind]\n\n    _load(name)\n\n    for k in kind:\n        if k not in plugin_store:\n            raise RuntimeError(f\"'{k}' is not a known plugin function.\")\n\n        funcs = plugin_store[k]\n\n        # Shuffle the plugins so that the requested plugin stands first\n        # in line\n        funcs = [(n, f) for (n, f) in funcs if n == name] + \\\n                [(n, f) for (n, f) in funcs if n != name]\n\n        plugin_store[k] = funcs\n\n\ndef _inject_imread_collection_if_needed(module):\n    \"\"\"Add `imread_collection` to module if not already present.\"\"\"\n    if not hasattr(module, 'imread_collection') and hasattr(module, 'imread'):\n        imread = getattr(module, 'imread')\n        func = imread_collection_wrapper(imread)\n        setattr(module, 'imread_collection', func)\n\n\ndef _load(plugin):\n    \"\"\"Load the given plugin.\n\n    Parameters\n    ----------\n    plugin : str\n        Name of plugin to load.\n\n    See Also\n    --------\n    plugins : List of available plugins\n\n    \"\"\"\n    if plugin in find_available_plugins(loaded=True):\n        return\n    if plugin not in plugin_module_name:\n        raise ValueError(f\"Plugin {plugin} not found.\")\n    else:\n        modname = plugin_module_name[plugin]\n        plugin_module = __import__('skimage.io._plugins.' + modname,\n                                   fromlist=[modname])\n\n    provides = plugin_provides[plugin]\n    for p in provides:\n        if p == 'imread_collection':\n            _inject_imread_collection_if_needed(plugin_module)\n        elif not hasattr(plugin_module, p):\n            print(f\"Plugin {plugin} does not provide {p} as advertised.  Ignoring.\")\n            continue\n\n        store = plugin_store[p]\n        func = getattr(plugin_module, p)\n        if (plugin, func) not in store:\n            store.append((plugin, func))\n\n\ndef plugin_info(plugin):\n    \"\"\"Return plugin meta-data.\n\n    Parameters\n    ----------\n    plugin : str\n        Name of plugin.\n\n    Returns\n    -------\n    m : dict\n        Meta data as specified in plugin ``.ini``.\n\n    \"\"\"\n    try:\n        return plugin_meta_data[plugin]\n    except KeyError:\n        raise ValueError(f'No information on plugin \"{plugin}\"')\n\n\ndef plugin_order():\n    \"\"\"Return the currently preferred plugin order.\n\n    Returns\n    -------\n    p : dict\n        Dictionary of preferred plugin order, with function name as key and\n        plugins (in order of preference) as value.\n\n    \"\"\"\n    p = {}\n    for func in plugin_store:\n        p[func] = [plugin_name for (plugin_name, f) in plugin_store[func]]\n    return p\n",340],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\_io.py":["import pathlib\n\nimport numpy as np\n\nfrom .._shared.utils import warn\nfrom ..exposure import is_low_contrast\nfrom ..color.colorconv import rgb2gray, rgba2rgb\nfrom ..io.manage_plugins import call_plugin\nfrom .util import file_or_url_context\n\n\n__all__ = ['imread', 'imsave', 'imshow', 'show',\n           'imread_collection', 'imshow_collection']\n\n\ndef imread(fname, as_gray=False, plugin=None, **plugin_args):\n    \"\"\"Load an image from file.\n\n    Parameters\n    ----------\n    fname : str or pathlib.Path\n        Image file name, e.g. ``test.jpg`` or URL.\n    as_gray : bool, optional\n        If True, convert color images to gray-scale (64-bit floats).\n        Images that are already in gray-scale format are not converted.\n    plugin : str, optional\n        Name of plugin to use.  By default, the different plugins are\n        tried (starting with imageio) until a suitable\n        candidate is found.  If not given and fname is a tiff file, the\n        tifffile plugin will be used.\n\n    Other Parameters\n    ----------------\n    plugin_args : keywords\n        Passed to the given plugin.\n\n    Returns\n    -------\n    img_array : ndarray\n        The different color bands/channels are stored in the\n        third dimension, such that a gray-image is MxN, an\n        RGB-image MxNx3 and an RGBA-image MxNx4.\n\n    \"\"\"\n    if isinstance(fname, pathlib.Path):\n        fname = str(fname.resolve())\n\n    if plugin is None and hasattr(fname, 'lower'):\n        if fname.lower().endswith(('.tiff', '.tif')):\n            plugin = 'tifffile'\n\n    with file_or_url_context(fname) as fname:\n        img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n\n    if not hasattr(img, 'ndim'):\n        return img\n\n    if img.ndim > 2:\n        if img.shape[-1] not in (3, 4) and img.shape[-3] in (3, 4):\n            img = np.swapaxes(img, -1, -3)\n            img = np.swapaxes(img, -2, -3)\n\n        if as_gray:\n            if img.shape[2] == 4:\n                img = rgba2rgb(img)\n            img = rgb2gray(img)\n\n    return img\n\n\ndef imread_collection(load_pattern, conserve_memory=True,\n                      plugin=None, **plugin_args):\n    \"\"\"\n    Load a collection of images.\n\n    Parameters\n    ----------\n    load_pattern : str or list\n        List of objects to load. These are usually filenames, but may\n        vary depending on the currently active plugin.  See the docstring\n        for ``ImageCollection`` for the default behaviour of this parameter.\n    conserve_memory : bool, optional\n        If True, never keep more than one in memory at a specific\n        time.  Otherwise, images will be cached once they are loaded.\n\n    Returns\n    -------\n    ic : ImageCollection\n        Collection of images.\n\n    Other Parameters\n    ----------------\n    plugin_args : keywords\n        Passed to the given plugin.\n\n    \"\"\"\n    return call_plugin('imread_collection', load_pattern, conserve_memory,\n                       plugin=plugin, **plugin_args)\n\n\ndef imsave(fname, arr, plugin=None, check_contrast=True, **plugin_args):\n    \"\"\"Save an image to file.\n\n    Parameters\n    ----------\n    fname : str or pathlib.Path\n        Target filename.\n    arr : ndarray of shape (M,N) or (M,N,3) or (M,N,4)\n        Image data.\n    plugin : str, optional\n        Name of plugin to use.  By default, the different plugins are\n        tried (starting with imageio) until a suitable\n        candidate is found.  If not given and fname is a tiff file, the\n        tifffile plugin will be used.\n    check_contrast : bool, optional\n        Check for low contrast and print warning (default: True).\n\n    Other Parameters\n    ----------------\n    plugin_args : keywords\n        Passed to the given plugin.\n\n    Notes\n    -----\n    When saving a JPEG, the compression ratio may be controlled using the\n    ``quality`` keyword argument which is an integer with values in [1, 100]\n    where 1 is worst quality and smallest file size, and 100 is best quality\n    and largest file size (default 75).  This is only available when using\n    the PIL and imageio plugins.\n    \"\"\"\n    if isinstance(fname, pathlib.Path):\n        fname = str(fname.resolve())\n    if plugin is None and hasattr(fname, 'lower'):\n        if fname.lower().endswith(('.tiff', '.tif')):\n            plugin = 'tifffile'\n    if arr.dtype == bool:\n        warn(f'{fname} is a boolean image: setting True to 255 and False to 0. '\n             'To silence this warning, please convert the image using '\n             'img_as_ubyte.', stacklevel=2)\n        arr = arr.astype('uint8') * 255\n    if check_contrast and is_low_contrast(arr):\n        warn(f'{fname} is a low contrast image')\n    return call_plugin('imsave', fname, arr, plugin=plugin, **plugin_args)\n\n\ndef imshow(arr, plugin=None, **plugin_args):\n    \"\"\"Display an image.\n\n    Parameters\n    ----------\n    arr : ndarray or str\n        Image data or name of image file.\n    plugin : str\n        Name of plugin to use.  By default, the different plugins are\n        tried (starting with imageio) until a suitable\n        candidate is found.\n\n    Other Parameters\n    ----------------\n    plugin_args : keywords\n        Passed to the given plugin.\n\n    \"\"\"\n    if isinstance(arr, str):\n        arr = call_plugin('imread', arr, plugin=plugin)\n    return call_plugin('imshow', arr, plugin=plugin, **plugin_args)\n\n\ndef imshow_collection(ic, plugin=None, **plugin_args):\n    \"\"\"Display a collection of images.\n\n    Parameters\n    ----------\n    ic : ImageCollection\n        Collection to display.\n    plugin : str\n        Name of plugin to use.  By default, the different plugins are\n        tried until a suitable candidate is found.\n\n    Other Parameters\n    ----------------\n    plugin_args : keywords\n        Passed to the given plugin.\n\n    \"\"\"\n    return call_plugin('imshow_collection', ic, plugin=plugin, **plugin_args)\n\n\ndef show():\n    '''Display pending images.\n\n    Launch the event loop of the current gui plugin, and display all\n    pending images, queued via `imshow`. This is required when using\n    `imshow` from non-interactive scripts.\n\n    A call to `show` will block execution of code until all windows\n    have been closed.\n\n    Examples\n    --------\n    >>> import skimage.io as io\n\n    >>> rng = np.random.default_rng()\n    >>> for i in range(4):\n    ...     ax_im = io.imshow(rng.random((50, 50)))\n    >>> io.show() # doctest: +SKIP\n\n    '''\n    return call_plugin('_app_show')\n",209],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py":["import collections.abc\nimport functools\nimport re\nimport sys\nimport warnings\n\nfrom .._utils import set_module\nimport numpy as np\nimport numpy.core.numeric as _nx\nfrom numpy.core import transpose\nfrom numpy.core.numeric import (\n    ones, zeros_like, arange, concatenate, array, asarray, asanyarray, empty,\n    ndarray, take, dot, where, intp, integer, isscalar, absolute\n    )\nfrom numpy.core.umath import (\n    pi, add, arctan2, frompyfunc, cos, less_equal, sqrt, sin,\n    mod, exp, not_equal, subtract\n    )\nfrom numpy.core.fromnumeric import (\n    ravel, nonzero, partition, mean, any, sum\n    )\nfrom numpy.core.numerictypes import typecodes\nfrom numpy.core import overrides\nfrom numpy.core.function_base import add_newdoc\nfrom numpy.lib.twodim_base import diag\nfrom numpy.core.multiarray import (\n    _place, add_docstring, bincount, normalize_axis_index, _monotonicity,\n    interp as compiled_interp, interp_complex as compiled_interp_complex\n    )\nfrom numpy.core.umath import _add_newdoc_ufunc as add_newdoc_ufunc\n\nimport builtins\n\n# needed in this module for compatibility\nfrom numpy.lib.histograms import histogram, histogramdd  # noqa: F401\n\n\narray_function_dispatch = functools.partial(\n    overrides.array_function_dispatch, module='numpy')\n\n\n__all__ = [\n    'select', 'piecewise', 'trim_zeros', 'copy', 'iterable', 'percentile',\n    'diff', 'gradient', 'angle', 'unwrap', 'sort_complex', 'disp', 'flip',\n    'rot90', 'extract', 'place', 'vectorize', 'asarray_chkfinite', 'average',\n    'bincount', 'digitize', 'cov', 'corrcoef',\n    'msort', 'median', 'sinc', 'hamming', 'hanning', 'bartlett',\n    'blackman', 'kaiser', 'trapz', 'i0', 'add_newdoc', 'add_docstring',\n    'meshgrid', 'delete', 'insert', 'append', 'interp', 'add_newdoc_ufunc',\n    'quantile'\n    ]\n\n# _QuantileMethods is a dictionary listing all the supported methods to\n# compute quantile/percentile.\n#\n# Below virtual_index refer to the index of the element where the percentile\n# would be found in the sorted sample.\n# When the sample contains exactly the percentile wanted, the virtual_index is\n# an integer to the index of this element.\n# When the percentile wanted is in between two elements, the virtual_index\n# is made of a integer part (a.k.a 'i' or 'left') and a fractional part\n# (a.k.a 'g' or 'gamma')\n#\n# Each method in _QuantileMethods has two properties\n# get_virtual_index : Callable\n#   The function used to compute the virtual_index.\n# fix_gamma : Callable\n#   A function used for discret methods to force the index to a specific value.\n_QuantileMethods = dict(\n    # --- HYNDMAN and FAN METHODS\n    # Discrete methods\n    inverted_cdf=dict(\n        get_virtual_index=lambda n, quantiles: _inverted_cdf(n, quantiles),\n        fix_gamma=lambda gamma, _: gamma,  # should never be called\n    ),\n    averaged_inverted_cdf=dict(\n        get_virtual_index=lambda n, quantiles: (n * quantiles) - 1,\n        fix_gamma=lambda gamma, _: _get_gamma_mask(\n            shape=gamma.shape,\n            default_value=1.,\n            conditioned_value=0.5,\n            where=gamma == 0),\n    ),\n    closest_observation=dict(\n        get_virtual_index=lambda n, quantiles: _closest_observation(n,\n                                                                    quantiles),\n        fix_gamma=lambda gamma, _: gamma,  # should never be called\n    ),\n    # Continuous methods\n    interpolated_inverted_cdf=dict(\n        get_virtual_index=lambda n, quantiles:\n        _compute_virtual_index(n, quantiles, 0, 1),\n        fix_gamma=lambda gamma, _: gamma,\n    ),\n    hazen=dict(\n        get_virtual_index=lambda n, quantiles:\n        _compute_virtual_index(n, quantiles, 0.5, 0.5),\n        fix_gamma=lambda gamma, _: gamma,\n    ),\n    weibull=dict(\n        get_virtual_index=lambda n, quantiles:\n        _compute_virtual_index(n, quantiles, 0, 0),\n        fix_gamma=lambda gamma, _: gamma,\n    ),\n    # Default method.\n    # To avoid some rounding issues, `(n-1) * quantiles` is preferred to\n    # `_compute_virtual_index(n, quantiles, 1, 1)`.\n    # They are mathematically equivalent.\n    linear=dict(\n        get_virtual_index=lambda n, quantiles: (n - 1) * quantiles,\n        fix_gamma=lambda gamma, _: gamma,\n    ),\n    median_unbiased=dict(\n        get_virtual_index=lambda n, quantiles:\n        _compute_virtual_index(n, quantiles, 1 / 3.0, 1 / 3.0),\n        fix_gamma=lambda gamma, _: gamma,\n    ),\n    normal_unbiased=dict(\n        get_virtual_index=lambda n, quantiles:\n        _compute_virtual_index(n, quantiles, 3 / 8.0, 3 / 8.0),\n        fix_gamma=lambda gamma, _: gamma,\n    ),\n    # --- OTHER METHODS\n    lower=dict(\n        get_virtual_index=lambda n, quantiles: np.floor(\n            (n - 1) * quantiles).astype(np.intp),\n        fix_gamma=lambda gamma, _: gamma,\n        # should never be called, index dtype is int\n    ),\n    higher=dict(\n        get_virtual_index=lambda n, quantiles: np.ceil(\n            (n - 1) * quantiles).astype(np.intp),\n        fix_gamma=lambda gamma, _: gamma,\n        # should never be called, index dtype is int\n    ),\n    midpoint=dict(\n        get_virtual_index=lambda n, quantiles: 0.5 * (\n                np.floor((n - 1) * quantiles)\n                + np.ceil((n - 1) * quantiles)),\n        fix_gamma=lambda gamma, index: _get_gamma_mask(\n            shape=gamma.shape,\n            default_value=0.5,\n            conditioned_value=0.,\n            where=index % 1 == 0),\n    ),\n    nearest=dict(\n        get_virtual_index=lambda n, quantiles: np.around(\n            (n - 1) * quantiles).astype(np.intp),\n        fix_gamma=lambda gamma, _: gamma,\n        # should never be called, index dtype is int\n    ))\n\n\ndef _rot90_dispatcher(m, k=None, axes=None):\n    return (m,)\n\n\n@array_function_dispatch(_rot90_dispatcher)\ndef rot90(m, k=1, axes=(0, 1)):\n    \"\"\"\n    Rotate an array by 90 degrees in the plane specified by axes.\n\n    Rotation direction is from the first towards the second axis.\n    This means for a 2D array with the default `k` and `axes`, the\n    rotation will be counterclockwise.\n\n    Parameters\n    ----------\n    m : array_like\n        Array of two or more dimensions.\n    k : integer\n        Number of times the array is rotated by 90 degrees.\n    axes : (2,) array_like\n        The array is rotated in the plane defined by the axes.\n        Axes must be different.\n\n        .. versionadded:: 1.12.0\n\n    Returns\n    -------\n    y : ndarray\n        A rotated view of `m`.\n\n    See Also\n    --------\n    flip : Reverse the order of elements in an array along the given axis.\n    fliplr : Flip an array horizontally.\n    flipud : Flip an array vertically.\n\n    Notes\n    -----\n    ``rot90(m, k=1, axes=(1,0))``  is the reverse of\n    ``rot90(m, k=1, axes=(0,1))``\n\n    ``rot90(m, k=1, axes=(1,0))`` is equivalent to\n    ``rot90(m, k=-1, axes=(0,1))``\n\n    Examples\n    --------\n    >>> m = np.array([[1,2],[3,4]], int)\n    >>> m\n    array([[1, 2],\n           [3, 4]])\n    >>> np.rot90(m)\n    array([[2, 4],\n           [1, 3]])\n    >>> np.rot90(m, 2)\n    array([[4, 3],\n           [2, 1]])\n    >>> m = np.arange(8).reshape((2,2,2))\n    >>> np.rot90(m, 1, (1,2))\n    array([[[1, 3],\n            [0, 2]],\n           [[5, 7],\n            [4, 6]]])\n\n    \"\"\"\n    axes = tuple(axes)\n    if len(axes) != 2:\n        raise ValueError(\"len(axes) must be 2.\")\n\n    m = asanyarray(m)\n\n    if axes[0] == axes[1] or absolute(axes[0] - axes[1]) == m.ndim:\n        raise ValueError(\"Axes must be different.\")\n\n    if (axes[0] >= m.ndim or axes[0] < -m.ndim\n        or axes[1] >= m.ndim or axes[1] < -m.ndim):\n        raise ValueError(\"Axes={} out of range for array of ndim={}.\"\n            .format(axes, m.ndim))\n\n    k %= 4\n\n    if k == 0:\n        return m[:]\n    if k == 2:\n        return flip(flip(m, axes[0]), axes[1])\n\n    axes_list = arange(0, m.ndim)\n    (axes_list[axes[0]], axes_list[axes[1]]) = (axes_list[axes[1]],\n                                                axes_list[axes[0]])\n\n    if k == 1:\n        return transpose(flip(m, axes[1]), axes_list)\n    else:\n        # k == 3\n        return flip(transpose(m, axes_list), axes[1])\n\n\ndef _flip_dispatcher(m, axis=None):\n    return (m,)\n\n\n@array_function_dispatch(_flip_dispatcher)\ndef flip(m, axis=None):\n    \"\"\"\n    Reverse the order of elements in an array along the given axis.\n\n    The shape of the array is preserved, but the elements are reordered.\n\n    .. versionadded:: 1.12.0\n\n    Parameters\n    ----------\n    m : array_like\n        Input array.\n    axis : None or int or tuple of ints, optional\n         Axis or axes along which to flip over. The default,\n         axis=None, will flip over all of the axes of the input array.\n         If axis is negative it counts from the last to the first axis.\n\n         If axis is a tuple of ints, flipping is performed on all of the axes\n         specified in the tuple.\n\n         .. versionchanged:: 1.15.0\n            None and tuples of axes are supported\n\n    Returns\n    -------\n    out : array_like\n        A view of `m` with the entries of axis reversed.  Since a view is\n        returned, this operation is done in constant time.\n\n    See Also\n    --------\n    flipud : Flip an array vertically (axis=0).\n    fliplr : Flip an array horizontally (axis=1).\n\n    Notes\n    -----\n    flip(m, 0) is equivalent to flipud(m).\n\n    flip(m, 1) is equivalent to fliplr(m).\n\n    flip(m, n) corresponds to ``m[...,::-1,...]`` with ``::-1`` at position n.\n\n    flip(m) corresponds to ``m[::-1,::-1,...,::-1]`` with ``::-1`` at all\n    positions.\n\n    flip(m, (0, 1)) corresponds to ``m[::-1,::-1,...]`` with ``::-1`` at\n    position 0 and position 1.\n\n    Examples\n    --------\n    >>> A = np.arange(8).reshape((2,2,2))\n    >>> A\n    array([[[0, 1],\n            [2, 3]],\n           [[4, 5],\n            [6, 7]]])\n    >>> np.flip(A, 0)\n    array([[[4, 5],\n            [6, 7]],\n           [[0, 1],\n            [2, 3]]])\n    >>> np.flip(A, 1)\n    array([[[2, 3],\n            [0, 1]],\n           [[6, 7],\n            [4, 5]]])\n    >>> np.flip(A)\n    array([[[7, 6],\n            [5, 4]],\n           [[3, 2],\n            [1, 0]]])\n    >>> np.flip(A, (0, 2))\n    array([[[5, 4],\n            [7, 6]],\n           [[1, 0],\n            [3, 2]]])\n    >>> A = np.random.randn(3,4,5)\n    >>> np.all(np.flip(A,2) == A[:,:,::-1,...])\n    True\n    \"\"\"\n    if not hasattr(m, 'ndim'):\n        m = asarray(m)\n    if axis is None:\n        indexer = (np.s_[::-1],) * m.ndim\n    else:\n        axis = _nx.normalize_axis_tuple(axis, m.ndim)\n        indexer = [np.s_[:]] * m.ndim\n        for ax in axis:\n            indexer[ax] = np.s_[::-1]\n        indexer = tuple(indexer)\n    return m[indexer]\n\n\n@set_module('numpy')\ndef iterable(y):\n    \"\"\"\n    Check whether or not an object can be iterated over.\n\n    Parameters\n    ----------\n    y : object\n      Input object.\n\n    Returns\n    -------\n    b : bool\n      Return ``True`` if the object has an iterator method or is a\n      sequence and ``False`` otherwise.\n\n\n    Examples\n    --------\n    >>> np.iterable([1, 2, 3])\n    True\n    >>> np.iterable(2)\n    False\n\n    Notes\n    -----\n    In most cases, the results of ``np.iterable(obj)`` are consistent with\n    ``isinstance(obj, collections.abc.Iterable)``. One notable exception is\n    the treatment of 0-dimensional arrays::\n\n        >>> from collections.abc import Iterable\n        >>> a = np.array(1.0)  # 0-dimensional numpy array\n        >>> isinstance(a, Iterable)\n        True\n        >>> np.iterable(a)\n        False\n\n    \"\"\"\n    try:\n        iter(y)\n    except TypeError:\n        return False\n    return True\n\n\ndef _average_dispatcher(a, axis=None, weights=None, returned=None, *,\n                        keepdims=None):\n    return (a, weights)\n\n\n@array_function_dispatch(_average_dispatcher)\ndef average(a, axis=None, weights=None, returned=False, *,\n            keepdims=np._NoValue):\n    \"\"\"\n    Compute the weighted average along the specified axis.\n\n    Parameters\n    ----------\n    a : array_like\n        Array containing data to be averaged. If `a` is not an array, a\n        conversion is attempted.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which to average `a`.  The default,\n        axis=None, will average over all of the elements of the input array.\n        If axis is negative it counts from the last to the first axis.\n\n        .. versionadded:: 1.7.0\n\n        If axis is a tuple of ints, averaging is performed on all of the axes\n        specified in the tuple instead of a single axis or all the axes as\n        before.\n    weights : array_like, optional\n        An array of weights associated with the values in `a`. Each value in\n        `a` contributes to the average according to its associated weight.\n        The weights array can either be 1-D (in which case its length must be\n        the size of `a` along the given axis) or of the same shape as `a`.\n        If `weights=None`, then all data in `a` are assumed to have a\n        weight equal to one.  The 1-D calculation is::\n\n            avg = sum(a * weights) / sum(weights)\n\n        The only constraint on `weights` is that `sum(weights)` must not be 0.\n    returned : bool, optional\n        Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)\n        is returned, otherwise only the average is returned.\n        If `weights=None`, `sum_of_weights` is equivalent to the number of\n        elements over which the average is taken.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the original `a`.\n        *Note:* `keepdims` will not work with instances of `numpy.matrix`\n        or other classes whose methods do not support `keepdims`.\n\n        .. versionadded:: 1.23.0\n\n    Returns\n    -------\n    retval, [sum_of_weights] : array_type or double\n        Return the average along the specified axis. When `returned` is `True`,\n        return a tuple with the average as the first element and the sum\n        of the weights as the second element. `sum_of_weights` is of the\n        same type as `retval`. The result dtype follows a genereal pattern.\n        If `weights` is None, the result dtype will be that of `a` , or ``float64``\n        if `a` is integral. Otherwise, if `weights` is not None and `a` is non-\n        integral, the result type will be the type of lowest precision capable of\n        representing values of both `a` and `weights`. If `a` happens to be\n        integral, the previous rules still applies but the result dtype will\n        at least be ``float64``.\n\n    Raises\n    ------\n    ZeroDivisionError\n        When all weights along axis are zero. See `numpy.ma.average` for a\n        version robust to this type of error.\n    TypeError\n        When the length of 1D `weights` is not the same as the shape of `a`\n        along axis.\n\n    See Also\n    --------\n    mean\n\n    ma.average : average for masked arrays -- useful if your data contains\n                 \"missing\" values\n    numpy.result_type : Returns the type that results from applying the\n                        numpy type promotion rules to the arguments.\n\n    Examples\n    --------\n    >>> data = np.arange(1, 5)\n    >>> data\n    array([1, 2, 3, 4])\n    >>> np.average(data)\n    2.5\n    >>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))\n    4.0\n\n    >>> data = np.arange(6).reshape((3, 2))\n    >>> data\n    array([[0, 1],\n           [2, 3],\n           [4, 5]])\n    >>> np.average(data, axis=1, weights=[1./4, 3./4])\n    array([0.75, 2.75, 4.75])\n    >>> np.average(data, weights=[1./4, 3./4])\n    Traceback (most recent call last):\n        ...\n    TypeError: Axis must be specified when shapes of a and weights differ.\n\n    >>> a = np.ones(5, dtype=np.float128)\n    >>> w = np.ones(5, dtype=np.complex64)\n    >>> avg = np.average(a, weights=w)\n    >>> print(avg.dtype)\n    complex256\n\n    With ``keepdims=True``, the following result has shape (3, 1).\n\n    >>> np.average(data, axis=1, keepdims=True)\n    array([[0.5],\n           [2.5],\n           [4.5]])\n    \"\"\"\n    a = np.asanyarray(a)\n\n    if keepdims is np._NoValue:\n        # Don't pass on the keepdims argument if one wasn't given.\n        keepdims_kw = {}\n    else:\n        keepdims_kw = {'keepdims': keepdims}\n\n    if weights is None:\n        avg = a.mean(axis, **keepdims_kw)\n        avg_as_array = np.asanyarray(avg)\n        scl = avg_as_array.dtype.type(a.size/avg_as_array.size)\n    else:\n        wgt = np.asanyarray(weights)\n\n        if issubclass(a.dtype.type, (np.integer, np.bool_)):\n            result_dtype = np.result_type(a.dtype, wgt.dtype, 'f8')\n        else:\n            result_dtype = np.result_type(a.dtype, wgt.dtype)\n\n        # Sanity checks\n        if a.shape != wgt.shape:\n            if axis is None:\n                raise TypeError(\n                    \"Axis must be specified when shapes of a and weights \"\n                    \"differ.\")\n            if wgt.ndim != 1:\n                raise TypeError(\n                    \"1D weights expected when shapes of a and weights differ.\")\n            if wgt.shape[0] != a.shape[axis]:\n                raise ValueError(\n                    \"Length of weights not compatible with specified axis.\")\n\n            # setup wgt to broadcast along axis\n            wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)\n            wgt = wgt.swapaxes(-1, axis)\n\n        scl = wgt.sum(axis=axis, dtype=result_dtype, **keepdims_kw)\n        if np.any(scl == 0.0):\n            raise ZeroDivisionError(\n                \"Weights sum to zero, can't be normalized\")\n\n        avg = avg_as_array = np.multiply(a, wgt,\n                          dtype=result_dtype).sum(axis, **keepdims_kw) / scl\n\n    if returned:\n        if scl.shape != avg_as_array.shape:\n            scl = np.broadcast_to(scl, avg_as_array.shape).copy()\n        return avg, scl\n    else:\n        return avg\n\n\n@set_module('numpy')\ndef asarray_chkfinite(a, dtype=None, order=None):\n    \"\"\"Convert the input to an array, checking for NaNs or Infs.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data, in any form that can be converted to an array.  This\n        includes lists, lists of tuples, tuples, tuples of tuples, tuples\n        of lists and ndarrays.  Success requires no NaNs or Infs.\n    dtype : data-type, optional\n        By default, the data-type is inferred from the input data.\n    order : {'C', 'F', 'A', 'K'}, optional\n        Memory layout.  'A' and 'K' depend on the order of input array a.\n        'C' row-major (C-style),\n        'F' column-major (Fortran-style) memory representation.\n        'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise\n        'K' (keep) preserve input order\n        Defaults to 'C'.\n\n    Returns\n    -------\n    out : ndarray\n        Array interpretation of `a`.  No copy is performed if the input\n        is already an ndarray.  If `a` is a subclass of ndarray, a base\n        class ndarray is returned.\n\n    Raises\n    ------\n    ValueError\n        Raises ValueError if `a` contains NaN (Not a Number) or Inf (Infinity).\n\n    See Also\n    --------\n    asarray : Create and array.\n    asanyarray : Similar function which passes through subclasses.\n    ascontiguousarray : Convert input to a contiguous array.\n    asfarray : Convert input to a floating point ndarray.\n    asfortranarray : Convert input to an ndarray with column-major\n                     memory order.\n    fromiter : Create an array from an iterator.\n    fromfunction : Construct an array by executing a function on grid\n                   positions.\n\n    Examples\n    --------\n    Convert a list into an array.  If all elements are finite\n    ``asarray_chkfinite`` is identical to ``asarray``.\n\n    >>> a = [1, 2]\n    >>> np.asarray_chkfinite(a, dtype=float)\n    array([1., 2.])\n\n    Raises ValueError if array_like contains Nans or Infs.\n\n    >>> a = [1, 2, np.inf]\n    >>> try:\n    ...     np.asarray_chkfinite(a)\n    ... except ValueError:\n    ...     print('ValueError')\n    ...\n    ValueError\n\n    \"\"\"\n    a = asarray(a, dtype=dtype, order=order)\n    if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():\n        raise ValueError(\n            \"array must not contain infs or NaNs\")\n    return a\n\n\ndef _piecewise_dispatcher(x, condlist, funclist, *args, **kw):\n    yield x\n    # support the undocumented behavior of allowing scalars\n    if np.iterable(condlist):\n        yield from condlist\n\n\n@array_function_dispatch(_piecewise_dispatcher)\ndef piecewise(x, condlist, funclist, *args, **kw):\n    \"\"\"\n    Evaluate a piecewise-defined function.\n\n    Given a set of conditions and corresponding functions, evaluate each\n    function on the input data wherever its condition is true.\n\n    Parameters\n    ----------\n    x : ndarray or scalar\n        The input domain.\n    condlist : list of bool arrays or bool scalars\n        Each boolean array corresponds to a function in `funclist`.  Wherever\n        `condlist[i]` is True, `funclist[i](x)` is used as the output value.\n\n        Each boolean array in `condlist` selects a piece of `x`,\n        and should therefore be of the same shape as `x`.\n\n        The length of `condlist` must correspond to that of `funclist`.\n        If one extra function is given, i.e. if\n        ``len(funclist) == len(condlist) + 1``, then that extra function\n        is the default value, used wherever all conditions are false.\n    funclist : list of callables, f(x,*args,**kw), or scalars\n        Each function is evaluated over `x` wherever its corresponding\n        condition is True.  It should take a 1d array as input and give an 1d\n        array or a scalar value as output.  If, instead of a callable,\n        a scalar is provided then a constant function (``lambda x: scalar``) is\n        assumed.\n    args : tuple, optional\n        Any further arguments given to `piecewise` are passed to the functions\n        upon execution, i.e., if called ``piecewise(..., ..., 1, 'a')``, then\n        each function is called as ``f(x, 1, 'a')``.\n    kw : dict, optional\n        Keyword arguments used in calling `piecewise` are passed to the\n        functions upon execution, i.e., if called\n        ``piecewise(..., ..., alpha=1)``, then each function is called as\n        ``f(x, alpha=1)``.\n\n    Returns\n    -------\n    out : ndarray\n        The output is the same shape and type as x and is found by\n        calling the functions in `funclist` on the appropriate portions of `x`,\n        as defined by the boolean arrays in `condlist`.  Portions not covered\n        by any condition have a default value of 0.\n\n\n    See Also\n    --------\n    choose, select, where\n\n    Notes\n    -----\n    This is similar to choose or select, except that functions are\n    evaluated on elements of `x` that satisfy the corresponding condition from\n    `condlist`.\n\n    The result is::\n\n            |--\n            |funclist[0](x[condlist[0]])\n      out = |funclist[1](x[condlist[1]])\n            |...\n            |funclist[n2](x[condlist[n2]])\n            |--\n\n    Examples\n    --------\n    Define the sigma function, which is -1 for ``x < 0`` and +1 for ``x >= 0``.\n\n    >>> x = np.linspace(-2.5, 2.5, 6)\n    >>> np.piecewise(x, [x < 0, x >= 0], [-1, 1])\n    array([-1., -1., -1.,  1.,  1.,  1.])\n\n    Define the absolute value, which is ``-x`` for ``x <0`` and ``x`` for\n    ``x >= 0``.\n\n    >>> np.piecewise(x, [x < 0, x >= 0], [lambda x: -x, lambda x: x])\n    array([2.5,  1.5,  0.5,  0.5,  1.5,  2.5])\n\n    Apply the same function to a scalar value.\n\n    >>> y = -2\n    >>> np.piecewise(y, [y < 0, y >= 0], [lambda x: -x, lambda x: x])\n    array(2)\n\n    \"\"\"\n    x = asanyarray(x)\n    n2 = len(funclist)\n\n    # undocumented: single condition is promoted to a list of one condition\n    if isscalar(condlist) or (\n            not isinstance(condlist[0], (list, ndarray)) and x.ndim != 0):\n        condlist = [condlist]\n\n    condlist = asarray(condlist, dtype=bool)\n    n = len(condlist)\n\n    if n == n2 - 1:  # compute the \"otherwise\" condition.\n        condelse = ~np.any(condlist, axis=0, keepdims=True)\n        condlist = np.concatenate([condlist, condelse], axis=0)\n        n += 1\n    elif n != n2:\n        raise ValueError(\n            \"with {} condition(s), either {} or {} functions are expected\"\n            .format(n, n, n+1)\n        )\n\n    y = zeros_like(x)\n    for cond, func in zip(condlist, funclist):\n        if not isinstance(func, collections.abc.Callable):\n            y[cond] = func\n        else:\n            vals = x[cond]\n            if vals.size > 0:\n                y[cond] = func(vals, *args, **kw)\n\n    return y\n\n\ndef _select_dispatcher(condlist, choicelist, default=None):\n    yield from condlist\n    yield from choicelist\n\n\n@array_function_dispatch(_select_dispatcher)\ndef select(condlist, choicelist, default=0):\n    \"\"\"\n    Return an array drawn from elements in choicelist, depending on conditions.\n\n    Parameters\n    ----------\n    condlist : list of bool ndarrays\n        The list of conditions which determine from which array in `choicelist`\n        the output elements are taken. When multiple conditions are satisfied,\n        the first one encountered in `condlist` is used.\n    choicelist : list of ndarrays\n        The list of arrays from which the output elements are taken. It has\n        to be of the same length as `condlist`.\n    default : scalar, optional\n        The element inserted in `output` when all conditions evaluate to False.\n\n    Returns\n    -------\n    output : ndarray\n        The output at position m is the m-th element of the array in\n        `choicelist` where the m-th element of the corresponding array in\n        `condlist` is True.\n\n    See Also\n    --------\n    where : Return elements from one of two arrays depending on condition.\n    take, choose, compress, diag, diagonal\n\n    Examples\n    --------\n    >>> x = np.arange(6)\n    >>> condlist = [x<3, x>3]\n    >>> choicelist = [x, x**2]\n    >>> np.select(condlist, choicelist, 42)\n    array([ 0,  1,  2, 42, 16, 25])\n\n    >>> condlist = [x<=4, x>3]\n    >>> choicelist = [x, x**2]\n    >>> np.select(condlist, choicelist, 55)\n    array([ 0,  1,  2,  3,  4, 25])\n\n    \"\"\"\n    # Check the size of condlist and choicelist are the same, or abort.\n    if len(condlist) != len(choicelist):\n        raise ValueError(\n            'list of cases must be same length as list of conditions')\n\n    # Now that the dtype is known, handle the deprecated select([], []) case\n    if len(condlist) == 0:\n        raise ValueError(\"select with an empty condition list is not possible\")\n\n    choicelist = [np.asarray(choice) for choice in choicelist]\n\n    try:\n        intermediate_dtype = np.result_type(*choicelist)\n    except TypeError as e:\n        msg = f'Choicelist elements do not have a common dtype: {e}'\n        raise TypeError(msg) from None\n    default_array = np.asarray(default)\n    choicelist.append(default_array)\n\n    # need to get the result type before broadcasting for correct scalar\n    # behaviour\n    try:\n        dtype = np.result_type(intermediate_dtype, default_array)\n    except TypeError as e:\n        msg = f'Choicelists and default value do not have a common dtype: {e}'\n        raise TypeError(msg) from None\n\n    # Convert conditions to arrays and broadcast conditions and choices\n    # as the shape is needed for the result. Doing it separately optimizes\n    # for example when all choices are scalars.\n    condlist = np.broadcast_arrays(*condlist)\n    choicelist = np.broadcast_arrays(*choicelist)\n\n    # If cond array is not an ndarray in boolean format or scalar bool, abort.\n    for i, cond in enumerate(condlist):\n        if cond.dtype.type is not np.bool_:\n            raise TypeError(\n                'invalid entry {} in condlist: should be boolean ndarray'.format(i))\n\n    if choicelist[0].ndim == 0:\n        # This may be common, so avoid the call.\n        result_shape = condlist[0].shape\n    else:\n        result_shape = np.broadcast_arrays(condlist[0], choicelist[0])[0].shape\n\n    result = np.full(result_shape, choicelist[-1], dtype)\n\n    # Use np.copyto to burn each choicelist array onto result, using the\n    # corresponding condlist as a boolean mask. This is done in reverse\n    # order since the first choice should take precedence.\n    choicelist = choicelist[-2::-1]\n    condlist = condlist[::-1]\n    for choice, cond in zip(choicelist, condlist):\n        np.copyto(result, choice, where=cond)\n\n    return result\n\n\ndef _copy_dispatcher(a, order=None, subok=None):\n    return (a,)\n\n\n@array_function_dispatch(_copy_dispatcher)\ndef copy(a, order='K', subok=False):\n    \"\"\"\n    Return an array copy of the given object.\n\n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    order : {'C', 'F', 'A', 'K'}, optional\n        Controls the memory layout of the copy. 'C' means C-order,\n        'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n        'C' otherwise. 'K' means match the layout of `a` as closely\n        as possible. (Note that this function and :meth:`ndarray.copy` are very\n        similar, but have different default values for their order=\n        arguments.)\n    subok : bool, optional\n        If True, then sub-classes will be passed-through, otherwise the\n        returned array will be forced to be a base-class array (defaults to False).\n\n        .. versionadded:: 1.19.0\n\n    Returns\n    -------\n    arr : ndarray\n        Array interpretation of `a`.\n\n    See Also\n    --------\n    ndarray.copy : Preferred method for creating an array copy\n\n    Notes\n    -----\n    This is equivalent to:\n\n    >>> np.array(a, copy=True)  #doctest: +SKIP\n\n    Examples\n    --------\n    Create an array x, with a reference y and a copy z:\n\n    >>> x = np.array([1, 2, 3])\n    >>> y = x\n    >>> z = np.copy(x)\n\n    Note that, when we modify x, y changes, but not z:\n\n    >>> x[0] = 10\n    >>> x[0] == y[0]\n    True\n    >>> x[0] == z[0]\n    False\n\n    Note that, np.copy clears previously set WRITEABLE=False flag.\n\n    >>> a = np.array([1, 2, 3])\n    >>> a.flags[\"WRITEABLE\"] = False\n    >>> b = np.copy(a)\n    >>> b.flags[\"WRITEABLE\"]\n    True\n    >>> b[0] = 3\n    >>> b\n    array([3, 2, 3])\n\n    Note that np.copy is a shallow copy and will not copy object\n    elements within arrays. This is mainly important for arrays\n    containing Python objects. The new array will contain the\n    same object which may lead to surprises if that object can\n    be modified (is mutable):\n\n    >>> a = np.array([1, 'm', [2, 3, 4]], dtype=object)\n    >>> b = np.copy(a)\n    >>> b[2][0] = 10\n    >>> a\n    array([1, 'm', list([10, 3, 4])], dtype=object)\n\n    To ensure all elements within an ``object`` array are copied,\n    use `copy.deepcopy`:\n\n    >>> import copy\n    >>> a = np.array([1, 'm', [2, 3, 4]], dtype=object)\n    >>> c = copy.deepcopy(a)\n    >>> c[2][0] = 10\n    >>> c\n    array([1, 'm', list([10, 3, 4])], dtype=object)\n    >>> a\n    array([1, 'm', list([2, 3, 4])], dtype=object)\n\n    \"\"\"\n    return array(a, order=order, subok=subok, copy=True)\n\n# Basic operations\n\n\ndef _gradient_dispatcher(f, *varargs, axis=None, edge_order=None):\n    yield f\n    yield from varargs\n\n\n@array_function_dispatch(_gradient_dispatcher)\ndef gradient(f, *varargs, axis=None, edge_order=1):\n    \"\"\"\n    Return the gradient of an N-dimensional array.\n\n    The gradient is computed using second order accurate central differences\n    in the interior points and either first or second order accurate one-sides\n    (forward or backwards) differences at the boundaries.\n    The returned gradient hence has the same shape as the input array.\n\n    Parameters\n    ----------\n    f : array_like\n        An N-dimensional array containing samples of a scalar function.\n    varargs : list of scalar or array, optional\n        Spacing between f values. Default unitary spacing for all dimensions.\n        Spacing can be specified using:\n\n        1. single scalar to specify a sample distance for all dimensions.\n        2. N scalars to specify a constant sample distance for each dimension.\n           i.e. `dx`, `dy`, `dz`, ...\n        3. N arrays to specify the coordinates of the values along each\n           dimension of F. The length of the array must match the size of\n           the corresponding dimension\n        4. Any combination of N scalars/arrays with the meaning of 2. and 3.\n\n        If `axis` is given, the number of varargs must equal the number of axes.\n        Default: 1.\n\n    edge_order : {1, 2}, optional\n        Gradient is calculated using N-th order accurate differences\n        at the boundaries. Default: 1.\n\n        .. versionadded:: 1.9.1\n\n    axis : None or int or tuple of ints, optional\n        Gradient is calculated only along the given axis or axes\n        The default (axis = None) is to calculate the gradient for all the axes\n        of the input array. axis may be negative, in which case it counts from\n        the last to the first axis.\n\n        .. versionadded:: 1.11.0\n\n    Returns\n    -------\n    gradient : ndarray or list of ndarray\n        A list of ndarrays (or a single ndarray if there is only one dimension)\n        corresponding to the derivatives of f with respect to each dimension.\n        Each derivative has the same shape as f.\n\n    Examples\n    --------\n    >>> f = np.array([1, 2, 4, 7, 11, 16], dtype=float)\n    >>> np.gradient(f)\n    array([1. , 1.5, 2.5, 3.5, 4.5, 5. ])\n    >>> np.gradient(f, 2)\n    array([0.5 ,  0.75,  1.25,  1.75,  2.25,  2.5 ])\n\n    Spacing can be also specified with an array that represents the coordinates\n    of the values F along the dimensions.\n    For instance a uniform spacing:\n\n    >>> x = np.arange(f.size)\n    >>> np.gradient(f, x)\n    array([1. ,  1.5,  2.5,  3.5,  4.5,  5. ])\n\n    Or a non uniform one:\n\n    >>> x = np.array([0., 1., 1.5, 3.5, 4., 6.], dtype=float)\n    >>> np.gradient(f, x)\n    array([1. ,  3. ,  3.5,  6.7,  6.9,  2.5])\n\n    For two dimensional arrays, the return will be two arrays ordered by\n    axis. In this example the first array stands for the gradient in\n    rows and the second one in columns direction:\n\n    >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float))\n    [array([[ 2.,  2., -1.],\n           [ 2.,  2., -1.]]), array([[1. , 2.5, 4. ],\n           [1. , 1. , 1. ]])]\n\n    In this example the spacing is also specified:\n    uniform for axis=0 and non uniform for axis=1\n\n    >>> dx = 2.\n    >>> y = [1., 1.5, 3.5]\n    >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), dx, y)\n    [array([[ 1. ,  1. , -0.5],\n           [ 1. ,  1. , -0.5]]), array([[2. , 2. , 2. ],\n           [2. , 1.7, 0.5]])]\n\n    It is possible to specify how boundaries are treated using `edge_order`\n\n    >>> x = np.array([0, 1, 2, 3, 4])\n    >>> f = x**2\n    >>> np.gradient(f, edge_order=1)\n    array([1.,  2.,  4.,  6.,  7.])\n    >>> np.gradient(f, edge_order=2)\n    array([0., 2., 4., 6., 8.])\n\n    The `axis` keyword can be used to specify a subset of axes of which the\n    gradient is calculated\n\n    >>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), axis=0)\n    array([[ 2.,  2., -1.],\n           [ 2.,  2., -1.]])\n\n    Notes\n    -----\n    Assuming that :math:`f\\\\in C^{3}` (i.e., :math:`f` has at least 3 continuous\n    derivatives) and let :math:`h_{*}` be a non-homogeneous stepsize, we\n    minimize the \"consistency error\" :math:`\\\\eta_{i}` between the true gradient\n    and its estimate from a linear combination of the neighboring grid-points:\n\n    .. math::\n\n        \\\\eta_{i} = f_{i}^{\\\\left(1\\\\right)} -\n                    \\\\left[ \\\\alpha f\\\\left(x_{i}\\\\right) +\n                            \\\\beta f\\\\left(x_{i} + h_{d}\\\\right) +\n                            \\\\gamma f\\\\left(x_{i}-h_{s}\\\\right)\n                    \\\\right]\n\n    By substituting :math:`f(x_{i} + h_{d})` and :math:`f(x_{i} - h_{s})`\n    with their Taylor series expansion, this translates into solving\n    the following the linear system:\n\n    .. math::\n\n        \\\\left\\\\{\n            \\\\begin{array}{r}\n                \\\\alpha+\\\\beta+\\\\gamma=0 \\\\\\\\\n                \\\\beta h_{d}-\\\\gamma h_{s}=1 \\\\\\\\\n                \\\\beta h_{d}^{2}+\\\\gamma h_{s}^{2}=0\n            \\\\end{array}\n        \\\\right.\n\n    The resulting approximation of :math:`f_{i}^{(1)}` is the following:\n\n    .. math::\n\n        \\\\hat f_{i}^{(1)} =\n            \\\\frac{\n                h_{s}^{2}f\\\\left(x_{i} + h_{d}\\\\right)\n                + \\\\left(h_{d}^{2} - h_{s}^{2}\\\\right)f\\\\left(x_{i}\\\\right)\n                - h_{d}^{2}f\\\\left(x_{i}-h_{s}\\\\right)}\n                { h_{s}h_{d}\\\\left(h_{d} + h_{s}\\\\right)}\n            + \\\\mathcal{O}\\\\left(\\\\frac{h_{d}h_{s}^{2}\n                                + h_{s}h_{d}^{2}}{h_{d}\n                                + h_{s}}\\\\right)\n\n    It is worth noting that if :math:`h_{s}=h_{d}`\n    (i.e., data are evenly spaced)\n    we find the standard second order approximation:\n\n    .. math::\n\n        \\\\hat f_{i}^{(1)}=\n            \\\\frac{f\\\\left(x_{i+1}\\\\right) - f\\\\left(x_{i-1}\\\\right)}{2h}\n            + \\\\mathcal{O}\\\\left(h^{2}\\\\right)\n\n    With a similar procedure the forward/backward approximations used for\n    boundaries can be derived.\n\n    References\n    ----------\n    .. [1]  Quarteroni A., Sacco R., Saleri F. (2007) Numerical Mathematics\n            (Texts in Applied Mathematics). New York: Springer.\n    .. [2]  Durran D. R. (1999) Numerical Methods for Wave Equations\n            in Geophysical Fluid Dynamics. New York: Springer.\n    .. [3]  Fornberg B. (1988) Generation of Finite Difference Formulas on\n            Arbitrarily Spaced Grids,\n            Mathematics of Computation 51, no. 184 : 699-706.\n            `PDF <http://www.ams.org/journals/mcom/1988-51-184/\n            S0025-5718-1988-0935077-0/S0025-5718-1988-0935077-0.pdf>`_.\n    \"\"\"\n    f = np.asanyarray(f)\n    N = f.ndim  # number of dimensions\n\n    if axis is None:\n        axes = tuple(range(N))\n    else:\n        axes = _nx.normalize_axis_tuple(axis, N)\n\n    len_axes = len(axes)\n    n = len(varargs)\n    if n == 0:\n        # no spacing argument - use 1 in all axes\n        dx = [1.0] * len_axes\n    elif n == 1 and np.ndim(varargs[0]) == 0:\n        # single scalar for all axes\n        dx = varargs * len_axes\n    elif n == len_axes:\n        # scalar or 1d array for each axis\n        dx = list(varargs)\n        for i, distances in enumerate(dx):\n            distances = np.asanyarray(distances)\n            if distances.ndim == 0:\n                continue\n            elif distances.ndim != 1:\n                raise ValueError(\"distances must be either scalars or 1d\")\n            if len(distances) != f.shape[axes[i]]:\n                raise ValueError(\"when 1d, distances must match \"\n                                 \"the length of the corresponding dimension\")\n            if np.issubdtype(distances.dtype, np.integer):\n                # Convert numpy integer types to float64 to avoid modular\n                # arithmetic in np.diff(distances).\n                distances = distances.astype(np.float64)\n            diffx = np.diff(distances)\n            # if distances are constant reduce to the scalar case\n            # since it brings a consistent speedup\n            if (diffx == diffx[0]).all():\n                diffx = diffx[0]\n            dx[i] = diffx\n    else:\n        raise TypeError(\"invalid number of arguments\")\n\n    if edge_order > 2:\n        raise ValueError(\"'edge_order' greater than 2 not supported\")\n\n    # use central differences on interior and one-sided differences on the\n    # endpoints. This preserves second order-accuracy over the full domain.\n\n    outvals = []\n\n    # create slice objects --- initially all are [:, :, ..., :]\n    slice1 = [slice(None)]*N\n    slice2 = [slice(None)]*N\n    slice3 = [slice(None)]*N\n    slice4 = [slice(None)]*N\n\n    otype = f.dtype\n    if otype.type is np.datetime64:\n        # the timedelta dtype with the same unit information\n        otype = np.dtype(otype.name.replace('datetime', 'timedelta'))\n        # view as timedelta to allow addition\n        f = f.view(otype)\n    elif otype.type is np.timedelta64:\n        pass\n    elif np.issubdtype(otype, np.inexact):\n        pass\n    else:\n        # All other types convert to floating point.\n        # First check if f is a numpy integer type; if so, convert f to float64\n        # to avoid modular arithmetic when computing the changes in f.\n        if np.issubdtype(otype, np.integer):\n            f = f.astype(np.float64)\n        otype = np.float64\n\n    for axis, ax_dx in zip(axes, dx):\n        if f.shape[axis] < edge_order + 1:\n            raise ValueError(\n                \"Shape of array too small to calculate a numerical gradient, \"\n                \"at least (edge_order + 1) elements are required.\")\n        # result allocation\n        out = np.empty_like(f, dtype=otype)\n\n        # spacing for the current axis\n        uniform_spacing = np.ndim(ax_dx) == 0\n\n        # Numerical differentiation: 2nd order interior\n        slice1[axis] = slice(1, -1)\n        slice2[axis] = slice(None, -2)\n        slice3[axis] = slice(1, -1)\n        slice4[axis] = slice(2, None)\n\n        if uniform_spacing:\n            out[tuple(slice1)] = (f[tuple(slice4)] - f[tuple(slice2)]) / (2. * ax_dx)\n        else:\n            dx1 = ax_dx[0:-1]\n            dx2 = ax_dx[1:]\n            a = -(dx2)/(dx1 * (dx1 + dx2))\n            b = (dx2 - dx1) / (dx1 * dx2)\n            c = dx1 / (dx2 * (dx1 + dx2))\n            # fix the shape for broadcasting\n            shape = np.ones(N, dtype=int)\n            shape[axis] = -1\n            a.shape = b.shape = c.shape = shape\n            # 1D equivalent -- out[1:-1] = a * f[:-2] + b * f[1:-1] + c * f[2:]\n            out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n\n        # Numerical differentiation: 1st order edges\n        if edge_order == 1:\n            slice1[axis] = 0\n            slice2[axis] = 1\n            slice3[axis] = 0\n            dx_0 = ax_dx if uniform_spacing else ax_dx[0]\n            # 1D equivalent -- out[0] = (f[1] - f[0]) / (x[1] - x[0])\n            out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_0\n\n            slice1[axis] = -1\n            slice2[axis] = -1\n            slice3[axis] = -2\n            dx_n = ax_dx if uniform_spacing else ax_dx[-1]\n            # 1D equivalent -- out[-1] = (f[-1] - f[-2]) / (x[-1] - x[-2])\n            out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n\n        # Numerical differentiation: 2nd order edges\n        else:\n            slice1[axis] = 0\n            slice2[axis] = 0\n            slice3[axis] = 1\n            slice4[axis] = 2\n            if uniform_spacing:\n                a = -1.5 / ax_dx\n                b = 2. / ax_dx\n                c = -0.5 / ax_dx\n            else:\n                dx1 = ax_dx[0]\n                dx2 = ax_dx[1]\n                a = -(2. * dx1 + dx2)/(dx1 * (dx1 + dx2))\n                b = (dx1 + dx2) / (dx1 * dx2)\n                c = - dx1 / (dx2 * (dx1 + dx2))\n            # 1D equivalent -- out[0] = a * f[0] + b * f[1] + c * f[2]\n            out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n\n            slice1[axis] = -1\n            slice2[axis] = -3\n            slice3[axis] = -2\n            slice4[axis] = -1\n            if uniform_spacing:\n                a = 0.5 / ax_dx\n                b = -2. / ax_dx\n                c = 1.5 / ax_dx\n            else:\n                dx1 = ax_dx[-2]\n                dx2 = ax_dx[-1]\n                a = (dx2) / (dx1 * (dx1 + dx2))\n                b = - (dx2 + dx1) / (dx1 * dx2)\n                c = (2. * dx2 + dx1) / (dx2 * (dx1 + dx2))\n            # 1D equivalent -- out[-1] = a * f[-3] + b * f[-2] + c * f[-1]\n            out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n\n        outvals.append(out)\n\n        # reset the slice object in this dimension to \":\"\n        slice1[axis] = slice(None)\n        slice2[axis] = slice(None)\n        slice3[axis] = slice(None)\n        slice4[axis] = slice(None)\n\n    if len_axes == 1:\n        return outvals[0]\n    elif np._using_numpy2_behavior():\n        return tuple(outvals)\n    else:\n        return outvals\n\n\ndef _diff_dispatcher(a, n=None, axis=None, prepend=None, append=None):\n    return (a, prepend, append)\n\n\n@array_function_dispatch(_diff_dispatcher)\ndef diff(a, n=1, axis=-1, prepend=np._NoValue, append=np._NoValue):\n    \"\"\"\n    Calculate the n-th discrete difference along the given axis.\n\n    The first difference is given by ``out[i] = a[i+1] - a[i]`` along\n    the given axis, higher differences are calculated by using `diff`\n    recursively.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array\n    n : int, optional\n        The number of times values are differenced. If zero, the input\n        is returned as-is.\n    axis : int, optional\n        The axis along which the difference is taken, default is the\n        last axis.\n    prepend, append : array_like, optional\n        Values to prepend or append to `a` along axis prior to\n        performing the difference.  Scalar values are expanded to\n        arrays with length 1 in the direction of axis and the shape\n        of the input array in along all other axes.  Otherwise the\n        dimension and shape must match `a` except along axis.\n\n        .. versionadded:: 1.16.0\n\n    Returns\n    -------\n    diff : ndarray\n        The n-th differences. The shape of the output is the same as `a`\n        except along `axis` where the dimension is smaller by `n`. The\n        type of the output is the same as the type of the difference\n        between any two elements of `a`. This is the same as the type of\n        `a` in most cases. A notable exception is `datetime64`, which\n        results in a `timedelta64` output array.\n\n    See Also\n    --------\n    gradient, ediff1d, cumsum\n\n    Notes\n    -----\n    Type is preserved for boolean arrays, so the result will contain\n    `False` when consecutive elements are the same and `True` when they\n    differ.\n\n    For unsigned integer arrays, the results will also be unsigned. This\n    should not be surprising, as the result is consistent with\n    calculating the difference directly:\n\n    >>> u8_arr = np.array([1, 0], dtype=np.uint8)\n    >>> np.diff(u8_arr)\n    array([255], dtype=uint8)\n    >>> u8_arr[1,...] - u8_arr[0,...]\n    255\n\n    If this is not desirable, then the array should be cast to a larger\n    integer type first:\n\n    >>> i16_arr = u8_arr.astype(np.int16)\n    >>> np.diff(i16_arr)\n    array([-1], dtype=int16)\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 4, 7, 0])\n    >>> np.diff(x)\n    array([ 1,  2,  3, -7])\n    >>> np.diff(x, n=2)\n    array([  1,   1, -10])\n\n    >>> x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]])\n    >>> np.diff(x)\n    array([[2, 3, 4],\n           [5, 1, 2]])\n    >>> np.diff(x, axis=0)\n    array([[-1,  2,  0, -2]])\n\n    >>> x = np.arange('1066-10-13', '1066-10-16', dtype=np.datetime64)\n    >>> np.diff(x)\n    array([1, 1], dtype='timedelta64[D]')\n\n    \"\"\"\n    if n == 0:\n        return a\n    if n < 0:\n        raise ValueError(\n            \"order must be non-negative but got \" + repr(n))\n\n    a = asanyarray(a)\n    nd = a.ndim\n    if nd == 0:\n        raise ValueError(\"diff requires input that is at least one dimensional\")\n    axis = normalize_axis_index(axis, nd)\n\n    combined = []\n    if prepend is not np._NoValue:\n        prepend = np.asanyarray(prepend)\n        if prepend.ndim == 0:\n            shape = list(a.shape)\n            shape[axis] = 1\n            prepend = np.broadcast_to(prepend, tuple(shape))\n        combined.append(prepend)\n\n    combined.append(a)\n\n    if append is not np._NoValue:\n        append = np.asanyarray(append)\n        if append.ndim == 0:\n            shape = list(a.shape)\n            shape[axis] = 1\n            append = np.broadcast_to(append, tuple(shape))\n        combined.append(append)\n\n    if len(combined) > 1:\n        a = np.concatenate(combined, axis)\n\n    slice1 = [slice(None)] * nd\n    slice2 = [slice(None)] * nd\n    slice1[axis] = slice(1, None)\n    slice2[axis] = slice(None, -1)\n    slice1 = tuple(slice1)\n    slice2 = tuple(slice2)\n\n    op = not_equal if a.dtype == np.bool_ else subtract\n    for _ in range(n):\n        a = op(a[slice1], a[slice2])\n\n    return a\n\n\ndef _interp_dispatcher(x, xp, fp, left=None, right=None, period=None):\n    return (x, xp, fp)\n\n\n@array_function_dispatch(_interp_dispatcher)\ndef interp(x, xp, fp, left=None, right=None, period=None):\n    \"\"\"\n    One-dimensional linear interpolation for monotonically increasing sample points.\n\n    Returns the one-dimensional piecewise linear interpolant to a function\n    with given discrete data points (`xp`, `fp`), evaluated at `x`.\n\n    Parameters\n    ----------\n    x : array_like\n        The x-coordinates at which to evaluate the interpolated values.\n\n    xp : 1-D sequence of floats\n        The x-coordinates of the data points, must be increasing if argument\n        `period` is not specified. Otherwise, `xp` is internally sorted after\n        normalizing the periodic boundaries with ``xp = xp % period``.\n\n    fp : 1-D sequence of float or complex\n        The y-coordinates of the data points, same length as `xp`.\n\n    left : optional float or complex corresponding to fp\n        Value to return for `x < xp[0]`, default is `fp[0]`.\n\n    right : optional float or complex corresponding to fp\n        Value to return for `x > xp[-1]`, default is `fp[-1]`.\n\n    period : None or float, optional\n        A period for the x-coordinates. This parameter allows the proper\n        interpolation of angular x-coordinates. Parameters `left` and `right`\n        are ignored if `period` is specified.\n\n        .. versionadded:: 1.10.0\n\n    Returns\n    -------\n    y : float or complex (corresponding to fp) or ndarray\n        The interpolated values, same shape as `x`.\n\n    Raises\n    ------\n    ValueError\n        If `xp` and `fp` have different length\n        If `xp` or `fp` are not 1-D sequences\n        If `period == 0`\n\n    See Also\n    --------\n    scipy.interpolate\n\n    Warnings\n    --------\n    The x-coordinate sequence is expected to be increasing, but this is not\n    explicitly enforced.  However, if the sequence `xp` is non-increasing,\n    interpolation results are meaningless.\n\n    Note that, since NaN is unsortable, `xp` also cannot contain NaNs.\n\n    A simple check for `xp` being strictly increasing is::\n\n        np.all(np.diff(xp) > 0)\n\n    Examples\n    --------\n    >>> xp = [1, 2, 3]\n    >>> fp = [3, 2, 0]\n    >>> np.interp(2.5, xp, fp)\n    1.0\n    >>> np.interp([0, 1, 1.5, 2.72, 3.14], xp, fp)\n    array([3.  , 3.  , 2.5 , 0.56, 0.  ])\n    >>> UNDEF = -99.0\n    >>> np.interp(3.14, xp, fp, right=UNDEF)\n    -99.0\n\n    Plot an interpolant to the sine function:\n\n    >>> x = np.linspace(0, 2*np.pi, 10)\n    >>> y = np.sin(x)\n    >>> xvals = np.linspace(0, 2*np.pi, 50)\n    >>> yinterp = np.interp(xvals, x, y)\n    >>> import matplotlib.pyplot as plt\n    >>> plt.plot(x, y, 'o')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.plot(xvals, yinterp, '-x')\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.show()\n\n    Interpolation with periodic x-coordinates:\n\n    >>> x = [-180, -170, -185, 185, -10, -5, 0, 365]\n    >>> xp = [190, -190, 350, -350]\n    >>> fp = [5, 10, 3, 4]\n    >>> np.interp(x, xp, fp, period=360)\n    array([7.5 , 5.  , 8.75, 6.25, 3.  , 3.25, 3.5 , 3.75])\n\n    Complex interpolation:\n\n    >>> x = [1.5, 4.0]\n    >>> xp = [2,3,5]\n    >>> fp = [1.0j, 0, 2+3j]\n    >>> np.interp(x, xp, fp)\n    array([0.+1.j , 1.+1.5j])\n\n    \"\"\"\n\n    fp = np.asarray(fp)\n\n    if np.iscomplexobj(fp):\n        interp_func = compiled_interp_complex\n        input_dtype = np.complex128\n    else:\n        interp_func = compiled_interp\n        input_dtype = np.float64\n\n    if period is not None:\n        if period == 0:\n            raise ValueError(\"period must be a non-zero value\")\n        period = abs(period)\n        left = None\n        right = None\n\n        x = np.asarray(x, dtype=np.float64)\n        xp = np.asarray(xp, dtype=np.float64)\n        fp = np.asarray(fp, dtype=input_dtype)\n\n        if xp.ndim != 1 or fp.ndim != 1:\n            raise ValueError(\"Data points must be 1-D sequences\")\n        if xp.shape[0] != fp.shape[0]:\n            raise ValueError(\"fp and xp are not of the same length\")\n        # normalizing periodic boundaries\n        x = x % period\n        xp = xp % period\n        asort_xp = np.argsort(xp)\n        xp = xp[asort_xp]\n        fp = fp[asort_xp]\n        xp = np.concatenate((xp[-1:]-period, xp, xp[0:1]+period))\n        fp = np.concatenate((fp[-1:], fp, fp[0:1]))\n\n    return interp_func(x, xp, fp, left, right)\n\n\ndef _angle_dispatcher(z, deg=None):\n    return (z,)\n\n\n@array_function_dispatch(_angle_dispatcher)\ndef angle(z, deg=False):\n    \"\"\"\n    Return the angle of the complex argument.\n\n    Parameters\n    ----------\n    z : array_like\n        A complex number or sequence of complex numbers.\n    deg : bool, optional\n        Return angle in degrees if True, radians if False (default).\n\n    Returns\n    -------\n    angle : ndarray or scalar\n        The counterclockwise angle from the positive real axis on the complex\n        plane in the range ``(-pi, pi]``, with dtype as numpy.float64.\n\n        .. versionchanged:: 1.16.0\n            This function works on subclasses of ndarray like `ma.array`.\n\n    See Also\n    --------\n    arctan2\n    absolute\n\n    Notes\n    -----\n    Although the angle of the complex number 0 is undefined, ``numpy.angle(0)``\n    returns the value 0.\n\n    Examples\n    --------\n    >>> np.angle([1.0, 1.0j, 1+1j])               # in radians\n    array([ 0.        ,  1.57079633,  0.78539816]) # may vary\n    >>> np.angle(1+1j, deg=True)                  # in degrees\n    45.0\n\n    \"\"\"\n    z = asanyarray(z)\n    if issubclass(z.dtype.type, _nx.complexfloating):\n        zimag = z.imag\n        zreal = z.real\n    else:\n        zimag = 0\n        zreal = z\n\n    a = arctan2(zimag, zreal)\n    if deg:\n        a *= 180/pi\n    return a\n\n\ndef _unwrap_dispatcher(p, discont=None, axis=None, *, period=None):\n    return (p,)\n\n\n@array_function_dispatch(_unwrap_dispatcher)\ndef unwrap(p, discont=None, axis=-1, *, period=2*pi):\n    r\"\"\"\n    Unwrap by taking the complement of large deltas with respect to the period.\n\n    This unwraps a signal `p` by changing elements which have an absolute\n    difference from their predecessor of more than ``max(discont, period/2)``\n    to their `period`-complementary values.\n\n    For the default case where `period` is :math:`2\\pi` and `discont` is\n    :math:`\\pi`, this unwraps a radian phase `p` such that adjacent differences\n    are never greater than :math:`\\pi` by adding :math:`2k\\pi` for some\n    integer :math:`k`.\n\n    Parameters\n    ----------\n    p : array_like\n        Input array.\n    discont : float, optional\n        Maximum discontinuity between values, default is ``period/2``.\n        Values below ``period/2`` are treated as if they were ``period/2``.\n        To have an effect different from the default, `discont` should be\n        larger than ``period/2``.\n    axis : int, optional\n        Axis along which unwrap will operate, default is the last axis.\n    period : float, optional\n        Size of the range over which the input wraps. By default, it is\n        ``2 pi``.\n\n        .. versionadded:: 1.21.0\n\n    Returns\n    -------\n    out : ndarray\n        Output array.\n\n    See Also\n    --------\n    rad2deg, deg2rad\n\n    Notes\n    -----\n    If the discontinuity in `p` is smaller than ``period/2``,\n    but larger than `discont`, no unwrapping is done because taking\n    the complement would only make the discontinuity larger.\n\n    Examples\n    --------\n    >>> phase = np.linspace(0, np.pi, num=5)\n    >>> phase[3:] += np.pi\n    >>> phase\n    array([ 0.        ,  0.78539816,  1.57079633,  5.49778714,  6.28318531]) # may vary\n    >>> np.unwrap(phase)\n    array([ 0.        ,  0.78539816,  1.57079633, -0.78539816,  0.        ]) # may vary\n    >>> np.unwrap([0, 1, 2, -1, 0], period=4)\n    array([0, 1, 2, 3, 4])\n    >>> np.unwrap([ 1, 2, 3, 4, 5, 6, 1, 2, 3], period=6)\n    array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n    >>> np.unwrap([2, 3, 4, 5, 2, 3, 4, 5], period=4)\n    array([2, 3, 4, 5, 6, 7, 8, 9])\n    >>> phase_deg = np.mod(np.linspace(0 ,720, 19), 360) - 180\n    >>> np.unwrap(phase_deg, period=360)\n    array([-180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,\n            180.,  220.,  260.,  300.,  340.,  380.,  420.,  460.,  500.,\n            540.])\n    \"\"\"\n    p = asarray(p)\n    nd = p.ndim\n    dd = diff(p, axis=axis)\n    if discont is None:\n        discont = period/2\n    slice1 = [slice(None, None)]*nd     # full slices\n    slice1[axis] = slice(1, None)\n    slice1 = tuple(slice1)\n    dtype = np.result_type(dd, period)\n    if _nx.issubdtype(dtype, _nx.integer):\n        interval_high, rem = divmod(period, 2)\n        boundary_ambiguous = rem == 0\n    else:\n        interval_high = period / 2\n        boundary_ambiguous = True\n    interval_low = -interval_high\n    ddmod = mod(dd - interval_low, period) + interval_low\n    if boundary_ambiguous:\n        # for `mask = (abs(dd) == period/2)`, the above line made\n        # `ddmod[mask] == -period/2`. correct these such that\n        # `ddmod[mask] == sign(dd[mask])*period/2`.\n        _nx.copyto(ddmod, interval_high,\n                   where=(ddmod == interval_low) & (dd > 0))\n    ph_correct = ddmod - dd\n    _nx.copyto(ph_correct, 0, where=abs(dd) < discont)\n    up = array(p, copy=True, dtype=dtype)\n    up[slice1] = p[slice1] + ph_correct.cumsum(axis)\n    return up\n\n\ndef _sort_complex(a):\n    return (a,)\n\n\n@array_function_dispatch(_sort_complex)\ndef sort_complex(a):\n    \"\"\"\n    Sort a complex array using the real part first, then the imaginary part.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array\n\n    Returns\n    -------\n    out : complex ndarray\n        Always returns a sorted complex array.\n\n    Examples\n    --------\n    >>> np.sort_complex([5, 3, 6, 2, 1])\n    array([1.+0.j, 2.+0.j, 3.+0.j, 5.+0.j, 6.+0.j])\n\n    >>> np.sort_complex([1 + 2j, 2 - 1j, 3 - 2j, 3 - 3j, 3 + 5j])\n    array([1.+2.j,  2.-1.j,  3.-3.j,  3.-2.j,  3.+5.j])\n\n    \"\"\"\n    b = array(a, copy=True)\n    b.sort()\n    if not issubclass(b.dtype.type, _nx.complexfloating):\n        if b.dtype.char in 'bhBH':\n            return b.astype('F')\n        elif b.dtype.char == 'g':\n            return b.astype('G')\n        else:\n            return b.astype('D')\n    else:\n        return b\n\n\ndef _trim_zeros(filt, trim=None):\n    return (filt,)\n\n\n@array_function_dispatch(_trim_zeros)\ndef trim_zeros(filt, trim='fb'):\n    \"\"\"\n    Trim the leading and/or trailing zeros from a 1-D array or sequence.\n\n    Parameters\n    ----------\n    filt : 1-D array or sequence\n        Input array.\n    trim : str, optional\n        A string with 'f' representing trim from front and 'b' to trim from\n        back. Default is 'fb', trim zeros from both front and back of the\n        array.\n\n    Returns\n    -------\n    trimmed : 1-D array or sequence\n        The result of trimming the input. The input data type is preserved.\n\n    Examples\n    --------\n    >>> a = np.array((0, 0, 0, 1, 2, 3, 0, 2, 1, 0))\n    >>> np.trim_zeros(a)\n    array([1, 2, 3, 0, 2, 1])\n\n    >>> np.trim_zeros(a, 'b')\n    array([0, 0, 0, ..., 0, 2, 1])\n\n    The input data type is preserved, list/tuple in means list/tuple out.\n\n    >>> np.trim_zeros([0, 1, 2, 0])\n    [1, 2]\n\n    \"\"\"\n\n    first = 0\n    trim = trim.upper()\n    if 'F' in trim:\n        for i in filt:\n            if i != 0.:\n                break\n            else:\n                first = first + 1\n    last = len(filt)\n    if 'B' in trim:\n        for i in filt[::-1]:\n            if i != 0.:\n                break\n            else:\n                last = last - 1\n    return filt[first:last]\n\n\ndef _extract_dispatcher(condition, arr):\n    return (condition, arr)\n\n\n@array_function_dispatch(_extract_dispatcher)\ndef extract(condition, arr):\n    \"\"\"\n    Return the elements of an array that satisfy some condition.\n\n    This is equivalent to ``np.compress(ravel(condition), ravel(arr))``.  If\n    `condition` is boolean ``np.extract`` is equivalent to ``arr[condition]``.\n\n    Note that `place` does the exact opposite of `extract`.\n\n    Parameters\n    ----------\n    condition : array_like\n        An array whose nonzero or True entries indicate the elements of `arr`\n        to extract.\n    arr : array_like\n        Input array of the same size as `condition`.\n\n    Returns\n    -------\n    extract : ndarray\n        Rank 1 array of values from `arr` where `condition` is True.\n\n    See Also\n    --------\n    take, put, copyto, compress, place\n\n    Examples\n    --------\n    >>> arr = np.arange(12).reshape((3, 4))\n    >>> arr\n    array([[ 0,  1,  2,  3],\n           [ 4,  5,  6,  7],\n           [ 8,  9, 10, 11]])\n    >>> condition = np.mod(arr, 3)==0\n    >>> condition\n    array([[ True, False, False,  True],\n           [False, False,  True, False],\n           [False,  True, False, False]])\n    >>> np.extract(condition, arr)\n    array([0, 3, 6, 9])\n\n\n    If `condition` is boolean:\n\n    >>> arr[condition]\n    array([0, 3, 6, 9])\n\n    \"\"\"\n    return _nx.take(ravel(arr), nonzero(ravel(condition))[0])\n\n\ndef _place_dispatcher(arr, mask, vals):\n    return (arr, mask, vals)\n\n\n@array_function_dispatch(_place_dispatcher)\ndef place(arr, mask, vals):\n    \"\"\"\n    Change elements of an array based on conditional and input values.\n\n    Similar to ``np.copyto(arr, vals, where=mask)``, the difference is that\n    `place` uses the first N elements of `vals`, where N is the number of\n    True values in `mask`, while `copyto` uses the elements where `mask`\n    is True.\n\n    Note that `extract` does the exact opposite of `place`.\n\n    Parameters\n    ----------\n    arr : ndarray\n        Array to put data into.\n    mask : array_like\n        Boolean mask array. Must have the same size as `a`.\n    vals : 1-D sequence\n        Values to put into `a`. Only the first N elements are used, where\n        N is the number of True values in `mask`. If `vals` is smaller\n        than N, it will be repeated, and if elements of `a` are to be masked,\n        this sequence must be non-empty.\n\n    See Also\n    --------\n    copyto, put, take, extract\n\n    Examples\n    --------\n    >>> arr = np.arange(6).reshape(2, 3)\n    >>> np.place(arr, arr>2, [44, 55])\n    >>> arr\n    array([[ 0,  1,  2],\n           [44, 55, 44]])\n\n    \"\"\"\n    return _place(arr, mask, vals)\n\n\ndef disp(mesg, device=None, linefeed=True):\n    \"\"\"\n    Display a message on a device.\n\n    Parameters\n    ----------\n    mesg : str\n        Message to display.\n    device : object\n        Device to write message. If None, defaults to ``sys.stdout`` which is\n        very similar to ``print``. `device` needs to have ``write()`` and\n        ``flush()`` methods.\n    linefeed : bool, optional\n        Option whether to print a line feed or not. Defaults to True.\n\n    Raises\n    ------\n    AttributeError\n        If `device` does not have a ``write()`` or ``flush()`` method.\n\n    Examples\n    --------\n    Besides ``sys.stdout``, a file-like object can also be used as it has\n    both required methods:\n\n    >>> from io import StringIO\n    >>> buf = StringIO()\n    >>> np.disp(u'\"Display\" in a file', device=buf)\n    >>> buf.getvalue()\n    '\"Display\" in a file\\\\n'\n\n    \"\"\"\n    if device is None:\n        device = sys.stdout\n    if linefeed:\n        device.write('%s\\n' % mesg)\n    else:\n        device.write('%s' % mesg)\n    device.flush()\n    return\n\n\n# See https://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html\n_DIMENSION_NAME = r'\\w+'\n_CORE_DIMENSION_LIST = '(?:{0:}(?:,{0:})*)?'.format(_DIMENSION_NAME)\n_ARGUMENT = r'\\({}\\)'.format(_CORE_DIMENSION_LIST)\n_ARGUMENT_LIST = '{0:}(?:,{0:})*'.format(_ARGUMENT)\n_SIGNATURE = '^{0:}->{0:}$'.format(_ARGUMENT_LIST)\n\n\ndef _parse_gufunc_signature(signature):\n    \"\"\"\n    Parse string signatures for a generalized universal function.\n\n    Arguments\n    ---------\n    signature : string\n        Generalized universal function signature, e.g., ``(m,n),(n,p)->(m,p)``\n        for ``np.matmul``.\n\n    Returns\n    -------\n    Tuple of input and output core dimensions parsed from the signature, each\n    of the form List[Tuple[str, ...]].\n    \"\"\"\n    signature = re.sub(r'\\s+', '', signature)\n\n    if not re.match(_SIGNATURE, signature):\n        raise ValueError(\n            'not a valid gufunc signature: {}'.format(signature))\n    return tuple([tuple(re.findall(_DIMENSION_NAME, arg))\n                  for arg in re.findall(_ARGUMENT, arg_list)]\n                 for arg_list in signature.split('->'))\n\n\ndef _update_dim_sizes(dim_sizes, arg, core_dims):\n    \"\"\"\n    Incrementally check and update core dimension sizes for a single argument.\n\n    Arguments\n    ---------\n    dim_sizes : Dict[str, int]\n        Sizes of existing core dimensions. Will be updated in-place.\n    arg : ndarray\n        Argument to examine.\n    core_dims : Tuple[str, ...]\n        Core dimensions for this argument.\n    \"\"\"\n    if not core_dims:\n        return\n\n    num_core_dims = len(core_dims)\n    if arg.ndim < num_core_dims:\n        raise ValueError(\n            '%d-dimensional argument does not have enough '\n            'dimensions for all core dimensions %r'\n            % (arg.ndim, core_dims))\n\n    core_shape = arg.shape[-num_core_dims:]\n    for dim, size in zip(core_dims, core_shape):\n        if dim in dim_sizes:\n            if size != dim_sizes[dim]:\n                raise ValueError(\n                    'inconsistent size for core dimension %r: %r vs %r'\n                    % (dim, size, dim_sizes[dim]))\n        else:\n            dim_sizes[dim] = size\n\n\ndef _parse_input_dimensions(args, input_core_dims):\n    \"\"\"\n    Parse broadcast and core dimensions for vectorize with a signature.\n\n    Arguments\n    ---------\n    args : Tuple[ndarray, ...]\n        Tuple of input arguments to examine.\n    input_core_dims : List[Tuple[str, ...]]\n        List of core dimensions corresponding to each input.\n\n    Returns\n    -------\n    broadcast_shape : Tuple[int, ...]\n        Common shape to broadcast all non-core dimensions to.\n    dim_sizes : Dict[str, int]\n        Common sizes for named core dimensions.\n    \"\"\"\n    broadcast_args = []\n    dim_sizes = {}\n    for arg, core_dims in zip(args, input_core_dims):\n        _update_dim_sizes(dim_sizes, arg, core_dims)\n        ndim = arg.ndim - len(core_dims)\n        dummy_array = np.lib.stride_tricks.as_strided(0, arg.shape[:ndim])\n        broadcast_args.append(dummy_array)\n    broadcast_shape = np.lib.stride_tricks._broadcast_shape(*broadcast_args)\n    return broadcast_shape, dim_sizes\n\n\ndef _calculate_shapes(broadcast_shape, dim_sizes, list_of_core_dims):\n    \"\"\"Helper for calculating broadcast shapes with core dimensions.\"\"\"\n    return [broadcast_shape + tuple(dim_sizes[dim] for dim in core_dims)\n            for core_dims in list_of_core_dims]\n\n\ndef _create_arrays(broadcast_shape, dim_sizes, list_of_core_dims, dtypes,\n                   results=None):\n    \"\"\"Helper for creating output arrays in vectorize.\"\"\"\n    shapes = _calculate_shapes(broadcast_shape, dim_sizes, list_of_core_dims)\n    if dtypes is None:\n        dtypes = [None] * len(shapes)\n    if results is None:\n        arrays = tuple(np.empty(shape=shape, dtype=dtype)\n                       for shape, dtype in zip(shapes, dtypes))\n    else:\n        arrays = tuple(np.empty_like(result, shape=shape, dtype=dtype)\n                       for result, shape, dtype\n                       in zip(results, shapes, dtypes))\n    return arrays\n\n\n@set_module('numpy')\nclass vectorize:\n    \"\"\"\n    vectorize(pyfunc=np._NoValue, otypes=None, doc=None, excluded=None,\n    cache=False, signature=None)\n\n    Returns an object that acts like pyfunc, but takes arrays as input.\n\n    Define a vectorized function which takes a nested sequence of objects or\n    numpy arrays as inputs and returns a single numpy array or a tuple of numpy\n    arrays. The vectorized function evaluates `pyfunc` over successive tuples\n    of the input arrays like the python map function, except it uses the\n    broadcasting rules of numpy.\n\n    The data type of the output of `vectorized` is determined by calling\n    the function with the first element of the input.  This can be avoided\n    by specifying the `otypes` argument.\n\n    Parameters\n    ----------\n    pyfunc : callable, optional\n        A python function or method.\n        Can be omitted to produce a decorator with keyword arguments.\n    otypes : str or list of dtypes, optional\n        The output data type. It must be specified as either a string of\n        typecode characters or a list of data type specifiers. There should\n        be one data type specifier for each output.\n    doc : str, optional\n        The docstring for the function. If None, the docstring will be the\n        ``pyfunc.__doc__``.\n    excluded : set, optional\n        Set of strings or integers representing the positional or keyword\n        arguments for which the function will not be vectorized.  These will be\n        passed directly to `pyfunc` unmodified.\n\n        .. versionadded:: 1.7.0\n\n    cache : bool, optional\n        If `True`, then cache the first function call that determines the number\n        of outputs if `otypes` is not provided.\n\n        .. versionadded:: 1.7.0\n\n    signature : string, optional\n        Generalized universal function signature, e.g., ``(m,n),(n)->(m)`` for\n        vectorized matrix-vector multiplication. If provided, ``pyfunc`` will\n        be called with (and expected to return) arrays with shapes given by the\n        size of corresponding core dimensions. By default, ``pyfunc`` is\n        assumed to take scalars as input and output.\n\n        .. versionadded:: 1.12.0\n\n    Returns\n    -------\n    out : callable\n        A vectorized function if ``pyfunc`` was provided,\n        a decorator otherwise.\n\n    See Also\n    --------\n    frompyfunc : Takes an arbitrary Python function and returns a ufunc\n\n    Notes\n    -----\n    The `vectorize` function is provided primarily for convenience, not for\n    performance. The implementation is essentially a for loop.\n\n    If `otypes` is not specified, then a call to the function with the\n    first argument will be used to determine the number of outputs.  The\n    results of this call will be cached if `cache` is `True` to prevent\n    calling the function twice.  However, to implement the cache, the\n    original function must be wrapped which will slow down subsequent\n    calls, so only do this if your function is expensive.\n\n    The new keyword argument interface and `excluded` argument support\n    further degrades performance.\n\n    References\n    ----------\n    .. [1] :doc:`/reference/c-api/generalized-ufuncs`\n\n    Examples\n    --------\n    >>> def myfunc(a, b):\n    ...     \"Return a-b if a>b, otherwise return a+b\"\n    ...     if a > b:\n    ...         return a - b\n    ...     else:\n    ...         return a + b\n\n    >>> vfunc = np.vectorize(myfunc)\n    >>> vfunc([1, 2, 3, 4], 2)\n    array([3, 4, 1, 2])\n\n    The docstring is taken from the input function to `vectorize` unless it\n    is specified:\n\n    >>> vfunc.__doc__\n    'Return a-b if a>b, otherwise return a+b'\n    >>> vfunc = np.vectorize(myfunc, doc='Vectorized `myfunc`')\n    >>> vfunc.__doc__\n    'Vectorized `myfunc`'\n\n    The output type is determined by evaluating the first element of the input,\n    unless it is specified:\n\n    >>> out = vfunc([1, 2, 3, 4], 2)\n    >>> type(out[0])\n    <class 'numpy.int64'>\n    >>> vfunc = np.vectorize(myfunc, otypes=[float])\n    >>> out = vfunc([1, 2, 3, 4], 2)\n    >>> type(out[0])\n    <class 'numpy.float64'>\n\n    The `excluded` argument can be used to prevent vectorizing over certain\n    arguments.  This can be useful for array-like arguments of a fixed length\n    such as the coefficients for a polynomial as in `polyval`:\n\n    >>> def mypolyval(p, x):\n    ...     _p = list(p)\n    ...     res = _p.pop(0)\n    ...     while _p:\n    ...         res = res*x + _p.pop(0)\n    ...     return res\n    >>> vpolyval = np.vectorize(mypolyval, excluded=['p'])\n    >>> vpolyval(p=[1, 2, 3], x=[0, 1])\n    array([3, 6])\n\n    Positional arguments may also be excluded by specifying their position:\n\n    >>> vpolyval.excluded.add(0)\n    >>> vpolyval([1, 2, 3], x=[0, 1])\n    array([3, 6])\n\n    The `signature` argument allows for vectorizing functions that act on\n    non-scalar arrays of fixed length. For example, you can use it for a\n    vectorized calculation of Pearson correlation coefficient and its p-value:\n\n    >>> import scipy.stats\n    >>> pearsonr = np.vectorize(scipy.stats.pearsonr,\n    ...                 signature='(n),(n)->(),()')\n    >>> pearsonr([[0, 1, 2, 3]], [[1, 2, 3, 4], [4, 3, 2, 1]])\n    (array([ 1., -1.]), array([ 0.,  0.]))\n\n    Or for a vectorized convolution:\n\n    >>> convolve = np.vectorize(np.convolve, signature='(n),(m)->(k)')\n    >>> convolve(np.eye(4), [1, 2, 1])\n    array([[1., 2., 1., 0., 0., 0.],\n           [0., 1., 2., 1., 0., 0.],\n           [0., 0., 1., 2., 1., 0.],\n           [0., 0., 0., 1., 2., 1.]])\n\n    Decorator syntax is supported.  The decorator can be called as\n    a function to provide keyword arguments.\n    >>>@np.vectorize\n    ...def identity(x):\n    ...    return x\n    ...\n    >>>identity([0, 1, 2])\n    array([0, 1, 2])\n    >>>@np.vectorize(otypes=[float])\n    ...def as_float(x):\n    ...    return x\n    ...\n    >>>as_float([0, 1, 2])\n    array([0., 1., 2.])\n    \"\"\"\n    def __init__(self, pyfunc=np._NoValue, otypes=None, doc=None,\n                 excluded=None, cache=False, signature=None):\n\n        if (pyfunc != np._NoValue) and (not callable(pyfunc)):\n            #Splitting the error message to keep\n            #the length below 79 characters.\n            part1 = \"When used as a decorator, \"\n            part2 = \"only accepts keyword arguments.\"\n            raise TypeError(part1 + part2)\n\n        self.pyfunc = pyfunc\n        self.cache = cache\n        self.signature = signature\n        if pyfunc != np._NoValue and hasattr(pyfunc, '__name__'):\n            self.__name__ = pyfunc.__name__\n\n        self._ufunc = {}    # Caching to improve default performance\n        self._doc = None\n        self.__doc__ = doc\n        if doc is None and hasattr(pyfunc, '__doc__'):\n            self.__doc__ = pyfunc.__doc__\n        else:\n            self._doc = doc\n\n        if isinstance(otypes, str):\n            for char in otypes:\n                if char not in typecodes['All']:\n                    raise ValueError(\"Invalid otype specified: %s\" % (char,))\n        elif iterable(otypes):\n            otypes = ''.join([_nx.dtype(x).char for x in otypes])\n        elif otypes is not None:\n            raise ValueError(\"Invalid otype specification\")\n        self.otypes = otypes\n\n        # Excluded variable support\n        if excluded is None:\n            excluded = set()\n        self.excluded = set(excluded)\n\n        if signature is not None:\n            self._in_and_out_core_dims = _parse_gufunc_signature(signature)\n        else:\n            self._in_and_out_core_dims = None\n\n    def _init_stage_2(self, pyfunc, *args, **kwargs):\n        self.__name__ = pyfunc.__name__\n        self.pyfunc = pyfunc\n        if self._doc is None:\n            self.__doc__ = pyfunc.__doc__\n        else:\n            self.__doc__ = self._doc\n\n    def _call_as_normal(self, *args, **kwargs):\n        \"\"\"\n        Return arrays with the results of `pyfunc` broadcast (vectorized) over\n        `args` and `kwargs` not in `excluded`.\n        \"\"\"\n        excluded = self.excluded\n        if not kwargs and not excluded:\n            func = self.pyfunc\n            vargs = args\n        else:\n            # The wrapper accepts only positional arguments: we use `names` and\n            # `inds` to mutate `the_args` and `kwargs` to pass to the original\n            # function.\n            nargs = len(args)\n\n            names = [_n for _n in kwargs if _n not in excluded]\n            inds = [_i for _i in range(nargs) if _i not in excluded]\n            the_args = list(args)\n\n            def func(*vargs):\n                for _n, _i in enumerate(inds):\n                    the_args[_i] = vargs[_n]\n                kwargs.update(zip(names, vargs[len(inds):]))\n                return self.pyfunc(*the_args, **kwargs)\n\n            vargs = [args[_i] for _i in inds]\n            vargs.extend([kwargs[_n] for _n in names])\n\n        return self._vectorize_call(func=func, args=vargs)\n\n    def __call__(self, *args, **kwargs):\n        if self.pyfunc is np._NoValue:\n            self._init_stage_2(*args, **kwargs)\n            return self\n\n        return self._call_as_normal(*args, **kwargs)\n\n    def _get_ufunc_and_otypes(self, func, args):\n        \"\"\"Return (ufunc, otypes).\"\"\"\n        # frompyfunc will fail if args is empty\n        if not args:\n            raise ValueError('args can not be empty')\n\n        if self.otypes is not None:\n            otypes = self.otypes\n\n            # self._ufunc is a dictionary whose keys are the number of\n            # arguments (i.e. len(args)) and whose values are ufuncs created\n            # by frompyfunc. len(args) can be different for different calls if\n            # self.pyfunc has parameters with default values.  We only use the\n            # cache when func is self.pyfunc, which occurs when the call uses\n            # only positional arguments and no arguments are excluded.\n\n            nin = len(args)\n            nout = len(self.otypes)\n            if func is not self.pyfunc or nin not in self._ufunc:\n                ufunc = frompyfunc(func, nin, nout)\n            else:\n                ufunc = None  # We'll get it from self._ufunc\n            if func is self.pyfunc:\n                ufunc = self._ufunc.setdefault(nin, ufunc)\n        else:\n            # Get number of outputs and output types by calling the function on\n            # the first entries of args.  We also cache the result to prevent\n            # the subsequent call when the ufunc is evaluated.\n            # Assumes that ufunc first evaluates the 0th elements in the input\n            # arrays (the input values are not checked to ensure this)\n            args = [asarray(arg) for arg in args]\n            if builtins.any(arg.size == 0 for arg in args):\n                raise ValueError('cannot call `vectorize` on size 0 inputs '\n                                 'unless `otypes` is set')\n\n            inputs = [arg.flat[0] for arg in args]\n            outputs = func(*inputs)\n\n            # Performance note: profiling indicates that -- for simple\n            # functions at least -- this wrapping can almost double the\n            # execution time.\n            # Hence we make it optional.\n            if self.cache:\n                _cache = [outputs]\n\n                def _func(*vargs):\n                    if _cache:\n                        return _cache.pop()\n                    else:\n                        return func(*vargs)\n            else:\n                _func = func\n\n            if isinstance(outputs, tuple):\n                nout = len(outputs)\n            else:\n                nout = 1\n                outputs = (outputs,)\n\n            otypes = ''.join([asarray(outputs[_k]).dtype.char\n                              for _k in range(nout)])\n\n            # Performance note: profiling indicates that creating the ufunc is\n            # not a significant cost compared with wrapping so it seems not\n            # worth trying to cache this.\n            ufunc = frompyfunc(_func, len(args), nout)\n\n        return ufunc, otypes\n\n    def _vectorize_call(self, func, args):\n        \"\"\"Vectorized call to `func` over positional `args`.\"\"\"\n        if self.signature is not None:\n            res = self._vectorize_call_with_signature(func, args)\n        elif not args:\n            res = func()\n        else:\n            ufunc, otypes = self._get_ufunc_and_otypes(func=func, args=args)\n\n            # Convert args to object arrays first\n            inputs = [asanyarray(a, dtype=object) for a in args]\n\n            outputs = ufunc(*inputs)\n\n            if ufunc.nout == 1:\n                res = asanyarray(outputs, dtype=otypes[0])\n            else:\n                res = tuple([asanyarray(x, dtype=t)\n                             for x, t in zip(outputs, otypes)])\n        return res\n\n    def _vectorize_call_with_signature(self, func, args):\n        \"\"\"Vectorized call over positional arguments with a signature.\"\"\"\n        input_core_dims, output_core_dims = self._in_and_out_core_dims\n\n        if len(args) != len(input_core_dims):\n            raise TypeError('wrong number of positional arguments: '\n                            'expected %r, got %r'\n                            % (len(input_core_dims), len(args)))\n        args = tuple(asanyarray(arg) for arg in args)\n\n        broadcast_shape, dim_sizes = _parse_input_dimensions(\n            args, input_core_dims)\n        input_shapes = _calculate_shapes(broadcast_shape, dim_sizes,\n                                         input_core_dims)\n        args = [np.broadcast_to(arg, shape, subok=True)\n                for arg, shape in zip(args, input_shapes)]\n\n        outputs = None\n        otypes = self.otypes\n        nout = len(output_core_dims)\n\n        for index in np.ndindex(*broadcast_shape):\n            results = func(*(arg[index] for arg in args))\n\n            n_results = len(results) if isinstance(results, tuple) else 1\n\n            if nout != n_results:\n                raise ValueError(\n                    'wrong number of outputs from pyfunc: expected %r, got %r'\n                    % (nout, n_results))\n\n            if nout == 1:\n                results = (results,)\n\n            if outputs is None:\n                for result, core_dims in zip(results, output_core_dims):\n                    _update_dim_sizes(dim_sizes, result, core_dims)\n\n                outputs = _create_arrays(broadcast_shape, dim_sizes,\n                                         output_core_dims, otypes, results)\n\n            for output, result in zip(outputs, results):\n                output[index] = result\n\n        if outputs is None:\n            # did not call the function even once\n            if otypes is None:\n                raise ValueError('cannot call `vectorize` on size 0 inputs '\n                                 'unless `otypes` is set')\n            if builtins.any(dim not in dim_sizes\n                            for dims in output_core_dims\n                            for dim in dims):\n                raise ValueError('cannot call `vectorize` with a signature '\n                                 'including new output dimensions on size 0 '\n                                 'inputs')\n            outputs = _create_arrays(broadcast_shape, dim_sizes,\n                                     output_core_dims, otypes)\n\n        return outputs[0] if nout == 1 else outputs\n\n\ndef _cov_dispatcher(m, y=None, rowvar=None, bias=None, ddof=None,\n                    fweights=None, aweights=None, *, dtype=None):\n    return (m, y, fweights, aweights)\n\n\n@array_function_dispatch(_cov_dispatcher)\ndef cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None,\n        aweights=None, *, dtype=None):\n    \"\"\"\n    Estimate a covariance matrix, given data and weights.\n\n    Covariance indicates the level to which two variables vary together.\n    If we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`,\n    then the covariance matrix element :math:`C_{ij}` is the covariance of\n    :math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance\n    of :math:`x_i`.\n\n    See the notes for an outline of the algorithm.\n\n    Parameters\n    ----------\n    m : array_like\n        A 1-D or 2-D array containing multiple variables and observations.\n        Each row of `m` represents a variable, and each column a single\n        observation of all those variables. Also see `rowvar` below.\n    y : array_like, optional\n        An additional set of variables and observations. `y` has the same form\n        as that of `m`.\n    rowvar : bool, optional\n        If `rowvar` is True (default), then each row represents a\n        variable, with observations in the columns. Otherwise, the relationship\n        is transposed: each column represents a variable, while the rows\n        contain observations.\n    bias : bool, optional\n        Default normalization (False) is by ``(N - 1)``, where ``N`` is the\n        number of observations given (unbiased estimate). If `bias` is True,\n        then normalization is by ``N``. These values can be overridden by using\n        the keyword ``ddof`` in numpy versions >= 1.5.\n    ddof : int, optional\n        If not ``None`` the default value implied by `bias` is overridden.\n        Note that ``ddof=1`` will return the unbiased estimate, even if both\n        `fweights` and `aweights` are specified, and ``ddof=0`` will return\n        the simple average. See the notes for the details. The default value\n        is ``None``.\n\n        .. versionadded:: 1.5\n    fweights : array_like, int, optional\n        1-D array of integer frequency weights; the number of times each\n        observation vector should be repeated.\n\n        .. versionadded:: 1.10\n    aweights : array_like, optional\n        1-D array of observation vector weights. These relative weights are\n        typically large for observations considered \"important\" and smaller for\n        observations considered less \"important\". If ``ddof=0`` the array of\n        weights can be used to assign probabilities to observation vectors.\n\n        .. versionadded:: 1.10\n    dtype : data-type, optional\n        Data-type of the result. By default, the return data-type will have\n        at least `numpy.float64` precision.\n\n        .. versionadded:: 1.20\n\n    Returns\n    -------\n    out : ndarray\n        The covariance matrix of the variables.\n\n    See Also\n    --------\n    corrcoef : Normalized covariance matrix\n\n    Notes\n    -----\n    Assume that the observations are in the columns of the observation\n    array `m` and let ``f = fweights`` and ``a = aweights`` for brevity. The\n    steps to compute the weighted covariance are as follows::\n\n        >>> m = np.arange(10, dtype=np.float64)\n        >>> f = np.arange(10) * 2\n        >>> a = np.arange(10) ** 2.\n        >>> ddof = 1\n        >>> w = f * a\n        >>> v1 = np.sum(w)\n        >>> v2 = np.sum(w * a)\n        >>> m -= np.sum(m * w, axis=None, keepdims=True) / v1\n        >>> cov = np.dot(m * w, m.T) * v1 / (v1**2 - ddof * v2)\n\n    Note that when ``a == 1``, the normalization factor\n    ``v1 / (v1**2 - ddof * v2)`` goes over to ``1 / (np.sum(f) - ddof)``\n    as it should.\n\n    Examples\n    --------\n    Consider two variables, :math:`x_0` and :math:`x_1`, which\n    correlate perfectly, but in opposite directions:\n\n    >>> x = np.array([[0, 2], [1, 1], [2, 0]]).T\n    >>> x\n    array([[0, 1, 2],\n           [2, 1, 0]])\n\n    Note how :math:`x_0` increases while :math:`x_1` decreases. The covariance\n    matrix shows this clearly:\n\n    >>> np.cov(x)\n    array([[ 1., -1.],\n           [-1.,  1.]])\n\n    Note that element :math:`C_{0,1}`, which shows the correlation between\n    :math:`x_0` and :math:`x_1`, is negative.\n\n    Further, note how `x` and `y` are combined:\n\n    >>> x = [-2.1, -1,  4.3]\n    >>> y = [3,  1.1,  0.12]\n    >>> X = np.stack((x, y), axis=0)\n    >>> np.cov(X)\n    array([[11.71      , -4.286     ], # may vary\n           [-4.286     ,  2.144133]])\n    >>> np.cov(x, y)\n    array([[11.71      , -4.286     ], # may vary\n           [-4.286     ,  2.144133]])\n    >>> np.cov(x)\n    array(11.71)\n\n    \"\"\"\n    # Check inputs\n    if ddof is not None and ddof != int(ddof):\n        raise ValueError(\n            \"ddof must be integer\")\n\n    # Handles complex arrays too\n    m = np.asarray(m)\n    if m.ndim > 2:\n        raise ValueError(\"m has more than 2 dimensions\")\n\n    if y is not None:\n        y = np.asarray(y)\n        if y.ndim > 2:\n            raise ValueError(\"y has more than 2 dimensions\")\n\n    if dtype is None:\n        if y is None:\n            dtype = np.result_type(m, np.float64)\n        else:\n            dtype = np.result_type(m, y, np.float64)\n\n    X = array(m, ndmin=2, dtype=dtype)\n    if not rowvar and X.shape[0] != 1:\n        X = X.T\n    if X.shape[0] == 0:\n        return np.array([]).reshape(0, 0)\n    if y is not None:\n        y = array(y, copy=False, ndmin=2, dtype=dtype)\n        if not rowvar and y.shape[0] != 1:\n            y = y.T\n        X = np.concatenate((X, y), axis=0)\n\n    if ddof is None:\n        if bias == 0:\n            ddof = 1\n        else:\n            ddof = 0\n\n    # Get the product of frequencies and weights\n    w = None\n    if fweights is not None:\n        fweights = np.asarray(fweights, dtype=float)\n        if not np.all(fweights == np.around(fweights)):\n            raise TypeError(\n                \"fweights must be integer\")\n        if fweights.ndim > 1:\n            raise RuntimeError(\n                \"cannot handle multidimensional fweights\")\n        if fweights.shape[0] != X.shape[1]:\n            raise RuntimeError(\n                \"incompatible numbers of samples and fweights\")\n        if any(fweights < 0):\n            raise ValueError(\n                \"fweights cannot be negative\")\n        w = fweights\n    if aweights is not None:\n        aweights = np.asarray(aweights, dtype=float)\n        if aweights.ndim > 1:\n            raise RuntimeError(\n                \"cannot handle multidimensional aweights\")\n        if aweights.shape[0] != X.shape[1]:\n            raise RuntimeError(\n                \"incompatible numbers of samples and aweights\")\n        if any(aweights < 0):\n            raise ValueError(\n                \"aweights cannot be negative\")\n        if w is None:\n            w = aweights\n        else:\n            w *= aweights\n\n    avg, w_sum = average(X, axis=1, weights=w, returned=True)\n    w_sum = w_sum[0]\n\n    # Determine the normalization\n    if w is None:\n        fact = X.shape[1] - ddof\n    elif ddof == 0:\n        fact = w_sum\n    elif aweights is None:\n        fact = w_sum - ddof\n    else:\n        fact = w_sum - ddof*sum(w*aweights)/w_sum\n\n    if fact <= 0:\n        warnings.warn(\"Degrees of freedom <= 0 for slice\",\n                      RuntimeWarning, stacklevel=2)\n        fact = 0.0\n\n    X -= avg[:, None]\n    if w is None:\n        X_T = X.T\n    else:\n        X_T = (X*w).T\n    c = dot(X, X_T.conj())\n    c *= np.true_divide(1, fact)\n    return c.squeeze()\n\n\ndef _corrcoef_dispatcher(x, y=None, rowvar=None, bias=None, ddof=None, *,\n                         dtype=None):\n    return (x, y)\n\n\n@array_function_dispatch(_corrcoef_dispatcher)\ndef corrcoef(x, y=None, rowvar=True, bias=np._NoValue, ddof=np._NoValue, *,\n             dtype=None):\n    \"\"\"\n    Return Pearson product-moment correlation coefficients.\n\n    Please refer to the documentation for `cov` for more detail.  The\n    relationship between the correlation coefficient matrix, `R`, and the\n    covariance matrix, `C`, is\n\n    .. math:: R_{ij} = \\\\frac{ C_{ij} } { \\\\sqrt{ C_{ii} C_{jj} } }\n\n    The values of `R` are between -1 and 1, inclusive.\n\n    Parameters\n    ----------\n    x : array_like\n        A 1-D or 2-D array containing multiple variables and observations.\n        Each row of `x` represents a variable, and each column a single\n        observation of all those variables. Also see `rowvar` below.\n    y : array_like, optional\n        An additional set of variables and observations. `y` has the same\n        shape as `x`.\n    rowvar : bool, optional\n        If `rowvar` is True (default), then each row represents a\n        variable, with observations in the columns. Otherwise, the relationship\n        is transposed: each column represents a variable, while the rows\n        contain observations.\n    bias : _NoValue, optional\n        Has no effect, do not use.\n\n        .. deprecated:: 1.10.0\n    ddof : _NoValue, optional\n        Has no effect, do not use.\n\n        .. deprecated:: 1.10.0\n    dtype : data-type, optional\n        Data-type of the result. By default, the return data-type will have\n        at least `numpy.float64` precision.\n\n        .. versionadded:: 1.20\n\n    Returns\n    -------\n    R : ndarray\n        The correlation coefficient matrix of the variables.\n\n    See Also\n    --------\n    cov : Covariance matrix\n\n    Notes\n    -----\n    Due to floating point rounding the resulting array may not be Hermitian,\n    the diagonal elements may not be 1, and the elements may not satisfy the\n    inequality abs(a) <= 1. The real and imaginary parts are clipped to the\n    interval [-1,  1] in an attempt to improve on that situation but is not\n    much help in the complex case.\n\n    This function accepts but discards arguments `bias` and `ddof`.  This is\n    for backwards compatibility with previous versions of this function.  These\n    arguments had no effect on the return values of the function and can be\n    safely ignored in this and previous versions of numpy.\n\n    Examples\n    --------\n    In this example we generate two random arrays, ``xarr`` and ``yarr``, and\n    compute the row-wise and column-wise Pearson correlation coefficients,\n    ``R``. Since ``rowvar`` is  true by  default, we first find the row-wise\n    Pearson correlation coefficients between the variables of ``xarr``.\n\n    >>> import numpy as np\n    >>> rng = np.random.default_rng(seed=42)\n    >>> xarr = rng.random((3, 3))\n    >>> xarr\n    array([[0.77395605, 0.43887844, 0.85859792],\n           [0.69736803, 0.09417735, 0.97562235],\n           [0.7611397 , 0.78606431, 0.12811363]])\n    >>> R1 = np.corrcoef(xarr)\n    >>> R1\n    array([[ 1.        ,  0.99256089, -0.68080986],\n           [ 0.99256089,  1.        , -0.76492172],\n           [-0.68080986, -0.76492172,  1.        ]])\n\n    If we add another set of variables and observations ``yarr``, we can\n    compute the row-wise Pearson correlation coefficients between the\n    variables in ``xarr`` and ``yarr``.\n\n    >>> yarr = rng.random((3, 3))\n    >>> yarr\n    array([[0.45038594, 0.37079802, 0.92676499],\n           [0.64386512, 0.82276161, 0.4434142 ],\n           [0.22723872, 0.55458479, 0.06381726]])\n    >>> R2 = np.corrcoef(xarr, yarr)\n    >>> R2\n    array([[ 1.        ,  0.99256089, -0.68080986,  0.75008178, -0.934284  ,\n            -0.99004057],\n           [ 0.99256089,  1.        , -0.76492172,  0.82502011, -0.97074098,\n            -0.99981569],\n           [-0.68080986, -0.76492172,  1.        , -0.99507202,  0.89721355,\n             0.77714685],\n           [ 0.75008178,  0.82502011, -0.99507202,  1.        , -0.93657855,\n            -0.83571711],\n           [-0.934284  , -0.97074098,  0.89721355, -0.93657855,  1.        ,\n             0.97517215],\n           [-0.99004057, -0.99981569,  0.77714685, -0.83571711,  0.97517215,\n             1.        ]])\n\n    Finally if we use the option ``rowvar=False``, the columns are now\n    being treated as the variables and we will find the column-wise Pearson\n    correlation coefficients between variables in ``xarr`` and ``yarr``.\n\n    >>> R3 = np.corrcoef(xarr, yarr, rowvar=False)\n    >>> R3\n    array([[ 1.        ,  0.77598074, -0.47458546, -0.75078643, -0.9665554 ,\n             0.22423734],\n           [ 0.77598074,  1.        , -0.92346708, -0.99923895, -0.58826587,\n            -0.44069024],\n           [-0.47458546, -0.92346708,  1.        ,  0.93773029,  0.23297648,\n             0.75137473],\n           [-0.75078643, -0.99923895,  0.93773029,  1.        ,  0.55627469,\n             0.47536961],\n           [-0.9665554 , -0.58826587,  0.23297648,  0.55627469,  1.        ,\n            -0.46666491],\n           [ 0.22423734, -0.44069024,  0.75137473,  0.47536961, -0.46666491,\n             1.        ]])\n\n    \"\"\"\n    if bias is not np._NoValue or ddof is not np._NoValue:\n        # 2015-03-15, 1.10\n        warnings.warn('bias and ddof have no effect and are deprecated',\n                      DeprecationWarning, stacklevel=2)\n    c = cov(x, y, rowvar, dtype=dtype)\n    try:\n        d = diag(c)\n    except ValueError:\n        # scalar covariance\n        # nan if incorrect value (nan, inf, 0), 1 otherwise\n        return c / c\n    stddev = sqrt(d.real)\n    c /= stddev[:, None]\n    c /= stddev[None, :]\n\n    # Clip real and imaginary parts to [-1, 1].  This does not guarantee\n    # abs(a[i,j]) <= 1 for complex arrays, but is the best we can do without\n    # excessive work.\n    np.clip(c.real, -1, 1, out=c.real)\n    if np.iscomplexobj(c):\n        np.clip(c.imag, -1, 1, out=c.imag)\n\n    return c\n\n\n@set_module('numpy')\ndef blackman(M):\n    \"\"\"\n    Return the Blackman window.\n\n    The Blackman window is a taper formed by using the first three\n    terms of a summation of cosines. It was designed to have close to the\n    minimal leakage possible.  It is close to optimal, only slightly worse\n    than a Kaiser window.\n\n    Parameters\n    ----------\n    M : int\n        Number of points in the output window. If zero or less, an empty\n        array is returned.\n\n    Returns\n    -------\n    out : ndarray\n        The window, with the maximum value normalized to one (the value one\n        appears only if the number of samples is odd).\n\n    See Also\n    --------\n    bartlett, hamming, hanning, kaiser\n\n    Notes\n    -----\n    The Blackman window is defined as\n\n    .. math::  w(n) = 0.42 - 0.5 \\\\cos(2\\\\pi n/M) + 0.08 \\\\cos(4\\\\pi n/M)\n\n    Most references to the Blackman window come from the signal processing\n    literature, where it is used as one of many windowing functions for\n    smoothing values.  It is also known as an apodization (which means\n    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n    and end of the sampled signal) or tapering function. It is known as a\n    \"near optimal\" tapering function, almost as good (by some measures)\n    as the kaiser window.\n\n    References\n    ----------\n    Blackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra,\n    Dover Publications, New York.\n\n    Oppenheim, A.V., and R.W. Schafer. Discrete-Time Signal Processing.\n    Upper Saddle River, NJ: Prentice-Hall, 1999, pp. 468-471.\n\n    Examples\n    --------\n    >>> import matplotlib.pyplot as plt\n    >>> np.blackman(12)\n    array([-1.38777878e-17,   3.26064346e-02,   1.59903635e-01, # may vary\n            4.14397981e-01,   7.36045180e-01,   9.67046769e-01,\n            9.67046769e-01,   7.36045180e-01,   4.14397981e-01,\n            1.59903635e-01,   3.26064346e-02,  -1.38777878e-17])\n\n    Plot the window and the frequency response:\n\n    >>> from numpy.fft import fft, fftshift\n    >>> window = np.blackman(51)\n    >>> plt.plot(window)\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Blackman window\")\n    Text(0.5, 1.0, 'Blackman window')\n    >>> plt.ylabel(\"Amplitude\")\n    Text(0, 0.5, 'Amplitude')\n    >>> plt.xlabel(\"Sample\")\n    Text(0.5, 0, 'Sample')\n    >>> plt.show()\n\n    >>> plt.figure()\n    <Figure size 640x480 with 0 Axes>\n    >>> A = fft(window, 2048) / 25.5\n    >>> mag = np.abs(fftshift(A))\n    >>> freq = np.linspace(-0.5, 0.5, len(A))\n    >>> with np.errstate(divide='ignore', invalid='ignore'):\n    ...     response = 20 * np.log10(mag)\n    ...\n    >>> response = np.clip(response, -100, 100)\n    >>> plt.plot(freq, response)\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Frequency response of Blackman window\")\n    Text(0.5, 1.0, 'Frequency response of Blackman window')\n    >>> plt.ylabel(\"Magnitude [dB]\")\n    Text(0, 0.5, 'Magnitude [dB]')\n    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n    >>> _ = plt.axis('tight')\n    >>> plt.show()\n\n    \"\"\"\n    # Ensures at least float64 via 0.0.  M should be an integer, but conversion\n    # to double is safe for a range.\n    values = np.array([0.0, M])\n    M = values[1]\n\n    if M < 1:\n        return array([], dtype=values.dtype)\n    if M == 1:\n        return ones(1, dtype=values.dtype)\n    n = arange(1-M, M, 2)\n    return 0.42 + 0.5*cos(pi*n/(M-1)) + 0.08*cos(2.0*pi*n/(M-1))\n\n\n@set_module('numpy')\ndef bartlett(M):\n    \"\"\"\n    Return the Bartlett window.\n\n    The Bartlett window is very similar to a triangular window, except\n    that the end points are at zero.  It is often used in signal\n    processing for tapering a signal, without generating too much\n    ripple in the frequency domain.\n\n    Parameters\n    ----------\n    M : int\n        Number of points in the output window. If zero or less, an\n        empty array is returned.\n\n    Returns\n    -------\n    out : array\n        The triangular window, with the maximum value normalized to one\n        (the value one appears only if the number of samples is odd), with\n        the first and last samples equal to zero.\n\n    See Also\n    --------\n    blackman, hamming, hanning, kaiser\n\n    Notes\n    -----\n    The Bartlett window is defined as\n\n    .. math:: w(n) = \\\\frac{2}{M-1} \\\\left(\n              \\\\frac{M-1}{2} - \\\\left|n - \\\\frac{M-1}{2}\\\\right|\n              \\\\right)\n\n    Most references to the Bartlett window come from the signal processing\n    literature, where it is used as one of many windowing functions for\n    smoothing values.  Note that convolution with this window produces linear\n    interpolation.  It is also known as an apodization (which means \"removing\n    the foot\", i.e. smoothing discontinuities at the beginning and end of the\n    sampled signal) or tapering function. The Fourier transform of the\n    Bartlett window is the product of two sinc functions. Note the excellent\n    discussion in Kanasewich [2]_.\n\n    References\n    ----------\n    .. [1] M.S. Bartlett, \"Periodogram Analysis and Continuous Spectra\",\n           Biometrika 37, 1-16, 1950.\n    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\",\n           The University of Alberta Press, 1975, pp. 109-110.\n    .. [3] A.V. Oppenheim and R.W. Schafer, \"Discrete-Time Signal\n           Processing\", Prentice-Hall, 1999, pp. 468-471.\n    .. [4] Wikipedia, \"Window function\",\n           https://en.wikipedia.org/wiki/Window_function\n    .. [5] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n           \"Numerical Recipes\", Cambridge University Press, 1986, page 429.\n\n    Examples\n    --------\n    >>> import matplotlib.pyplot as plt\n    >>> np.bartlett(12)\n    array([ 0.        ,  0.18181818,  0.36363636,  0.54545455,  0.72727273, # may vary\n            0.90909091,  0.90909091,  0.72727273,  0.54545455,  0.36363636,\n            0.18181818,  0.        ])\n\n    Plot the window and its frequency response (requires SciPy and matplotlib):\n\n    >>> from numpy.fft import fft, fftshift\n    >>> window = np.bartlett(51)\n    >>> plt.plot(window)\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Bartlett window\")\n    Text(0.5, 1.0, 'Bartlett window')\n    >>> plt.ylabel(\"Amplitude\")\n    Text(0, 0.5, 'Amplitude')\n    >>> plt.xlabel(\"Sample\")\n    Text(0.5, 0, 'Sample')\n    >>> plt.show()\n\n    >>> plt.figure()\n    <Figure size 640x480 with 0 Axes>\n    >>> A = fft(window, 2048) / 25.5\n    >>> mag = np.abs(fftshift(A))\n    >>> freq = np.linspace(-0.5, 0.5, len(A))\n    >>> with np.errstate(divide='ignore', invalid='ignore'):\n    ...     response = 20 * np.log10(mag)\n    ...\n    >>> response = np.clip(response, -100, 100)\n    >>> plt.plot(freq, response)\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Frequency response of Bartlett window\")\n    Text(0.5, 1.0, 'Frequency response of Bartlett window')\n    >>> plt.ylabel(\"Magnitude [dB]\")\n    Text(0, 0.5, 'Magnitude [dB]')\n    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n    >>> _ = plt.axis('tight')\n    >>> plt.show()\n\n    \"\"\"\n    # Ensures at least float64 via 0.0.  M should be an integer, but conversion\n    # to double is safe for a range.\n    values = np.array([0.0, M])\n    M = values[1]\n\n    if M < 1:\n        return array([], dtype=values.dtype)\n    if M == 1:\n        return ones(1, dtype=values.dtype)\n    n = arange(1-M, M, 2)\n    return where(less_equal(n, 0), 1 + n/(M-1), 1 - n/(M-1))\n\n\n@set_module('numpy')\ndef hanning(M):\n    \"\"\"\n    Return the Hanning window.\n\n    The Hanning window is a taper formed by using a weighted cosine.\n\n    Parameters\n    ----------\n    M : int\n        Number of points in the output window. If zero or less, an\n        empty array is returned.\n\n    Returns\n    -------\n    out : ndarray, shape(M,)\n        The window, with the maximum value normalized to one (the value\n        one appears only if `M` is odd).\n\n    See Also\n    --------\n    bartlett, blackman, hamming, kaiser\n\n    Notes\n    -----\n    The Hanning window is defined as\n\n    .. math::  w(n) = 0.5 - 0.5\\\\cos\\\\left(\\\\frac{2\\\\pi{n}}{M-1}\\\\right)\n               \\\\qquad 0 \\\\leq n \\\\leq M-1\n\n    The Hanning was named for Julius von Hann, an Austrian meteorologist.\n    It is also known as the Cosine Bell. Some authors prefer that it be\n    called a Hann window, to help avoid confusion with the very similar\n    Hamming window.\n\n    Most references to the Hanning window come from the signal processing\n    literature, where it is used as one of many windowing functions for\n    smoothing values.  It is also known as an apodization (which means\n    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n    and end of the sampled signal) or tapering function.\n\n    References\n    ----------\n    .. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power\n           spectra, Dover Publications, New York.\n    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\",\n           The University of Alberta Press, 1975, pp. 106-108.\n    .. [3] Wikipedia, \"Window function\",\n           https://en.wikipedia.org/wiki/Window_function\n    .. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n           \"Numerical Recipes\", Cambridge University Press, 1986, page 425.\n\n    Examples\n    --------\n    >>> np.hanning(12)\n    array([0.        , 0.07937323, 0.29229249, 0.57115742, 0.82743037,\n           0.97974649, 0.97974649, 0.82743037, 0.57115742, 0.29229249,\n           0.07937323, 0.        ])\n\n    Plot the window and its frequency response:\n\n    >>> import matplotlib.pyplot as plt\n    >>> from numpy.fft import fft, fftshift\n    >>> window = np.hanning(51)\n    >>> plt.plot(window)\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Hann window\")\n    Text(0.5, 1.0, 'Hann window')\n    >>> plt.ylabel(\"Amplitude\")\n    Text(0, 0.5, 'Amplitude')\n    >>> plt.xlabel(\"Sample\")\n    Text(0.5, 0, 'Sample')\n    >>> plt.show()\n\n    >>> plt.figure()\n    <Figure size 640x480 with 0 Axes>\n    >>> A = fft(window, 2048) / 25.5\n    >>> mag = np.abs(fftshift(A))\n    >>> freq = np.linspace(-0.5, 0.5, len(A))\n    >>> with np.errstate(divide='ignore', invalid='ignore'):\n    ...     response = 20 * np.log10(mag)\n    ...\n    >>> response = np.clip(response, -100, 100)\n    >>> plt.plot(freq, response)\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Frequency response of the Hann window\")\n    Text(0.5, 1.0, 'Frequency response of the Hann window')\n    >>> plt.ylabel(\"Magnitude [dB]\")\n    Text(0, 0.5, 'Magnitude [dB]')\n    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n    >>> plt.axis('tight')\n    ...\n    >>> plt.show()\n\n    \"\"\"\n    # Ensures at least float64 via 0.0.  M should be an integer, but conversion\n    # to double is safe for a range.\n    values = np.array([0.0, M])\n    M = values[1]\n\n    if M < 1:\n        return array([], dtype=values.dtype)\n    if M == 1:\n        return ones(1, dtype=values.dtype)\n    n = arange(1-M, M, 2)\n    return 0.5 + 0.5*cos(pi*n/(M-1))\n\n\n@set_module('numpy')\ndef hamming(M):\n    \"\"\"\n    Return the Hamming window.\n\n    The Hamming window is a taper formed by using a weighted cosine.\n\n    Parameters\n    ----------\n    M : int\n        Number of points in the output window. If zero or less, an\n        empty array is returned.\n\n    Returns\n    -------\n    out : ndarray\n        The window, with the maximum value normalized to one (the value\n        one appears only if the number of samples is odd).\n\n    See Also\n    --------\n    bartlett, blackman, hanning, kaiser\n\n    Notes\n    -----\n    The Hamming window is defined as\n\n    .. math::  w(n) = 0.54 - 0.46\\\\cos\\\\left(\\\\frac{2\\\\pi{n}}{M-1}\\\\right)\n               \\\\qquad 0 \\\\leq n \\\\leq M-1\n\n    The Hamming was named for R. W. Hamming, an associate of J. W. Tukey\n    and is described in Blackman and Tukey. It was recommended for\n    smoothing the truncated autocovariance function in the time domain.\n    Most references to the Hamming window come from the signal processing\n    literature, where it is used as one of many windowing functions for\n    smoothing values.  It is also known as an apodization (which means\n    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n    and end of the sampled signal) or tapering function.\n\n    References\n    ----------\n    .. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power\n           spectra, Dover Publications, New York.\n    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\", The\n           University of Alberta Press, 1975, pp. 109-110.\n    .. [3] Wikipedia, \"Window function\",\n           https://en.wikipedia.org/wiki/Window_function\n    .. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n           \"Numerical Recipes\", Cambridge University Press, 1986, page 425.\n\n    Examples\n    --------\n    >>> np.hamming(12)\n    array([ 0.08      ,  0.15302337,  0.34890909,  0.60546483,  0.84123594, # may vary\n            0.98136677,  0.98136677,  0.84123594,  0.60546483,  0.34890909,\n            0.15302337,  0.08      ])\n\n    Plot the window and the frequency response:\n\n    >>> import matplotlib.pyplot as plt\n    >>> from numpy.fft import fft, fftshift\n    >>> window = np.hamming(51)\n    >>> plt.plot(window)\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Hamming window\")\n    Text(0.5, 1.0, 'Hamming window')\n    >>> plt.ylabel(\"Amplitude\")\n    Text(0, 0.5, 'Amplitude')\n    >>> plt.xlabel(\"Sample\")\n    Text(0.5, 0, 'Sample')\n    >>> plt.show()\n\n    >>> plt.figure()\n    <Figure size 640x480 with 0 Axes>\n    >>> A = fft(window, 2048) / 25.5\n    >>> mag = np.abs(fftshift(A))\n    >>> freq = np.linspace(-0.5, 0.5, len(A))\n    >>> response = 20 * np.log10(mag)\n    >>> response = np.clip(response, -100, 100)\n    >>> plt.plot(freq, response)\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Frequency response of Hamming window\")\n    Text(0.5, 1.0, 'Frequency response of Hamming window')\n    >>> plt.ylabel(\"Magnitude [dB]\")\n    Text(0, 0.5, 'Magnitude [dB]')\n    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n    >>> plt.axis('tight')\n    ...\n    >>> plt.show()\n\n    \"\"\"\n    # Ensures at least float64 via 0.0.  M should be an integer, but conversion\n    # to double is safe for a range.\n    values = np.array([0.0, M])\n    M = values[1]\n\n    if M < 1:\n        return array([], dtype=values.dtype)\n    if M == 1:\n        return ones(1, dtype=values.dtype)\n    n = arange(1-M, M, 2)\n    return 0.54 + 0.46*cos(pi*n/(M-1))\n\n\n## Code from cephes for i0\n\n_i0A = [\n    -4.41534164647933937950E-18,\n    3.33079451882223809783E-17,\n    -2.43127984654795469359E-16,\n    1.71539128555513303061E-15,\n    -1.16853328779934516808E-14,\n    7.67618549860493561688E-14,\n    -4.85644678311192946090E-13,\n    2.95505266312963983461E-12,\n    -1.72682629144155570723E-11,\n    9.67580903537323691224E-11,\n    -5.18979560163526290666E-10,\n    2.65982372468238665035E-9,\n    -1.30002500998624804212E-8,\n    6.04699502254191894932E-8,\n    -2.67079385394061173391E-7,\n    1.11738753912010371815E-6,\n    -4.41673835845875056359E-6,\n    1.64484480707288970893E-5,\n    -5.75419501008210370398E-5,\n    1.88502885095841655729E-4,\n    -5.76375574538582365885E-4,\n    1.63947561694133579842E-3,\n    -4.32430999505057594430E-3,\n    1.05464603945949983183E-2,\n    -2.37374148058994688156E-2,\n    4.93052842396707084878E-2,\n    -9.49010970480476444210E-2,\n    1.71620901522208775349E-1,\n    -3.04682672343198398683E-1,\n    6.76795274409476084995E-1\n    ]\n\n_i0B = [\n    -7.23318048787475395456E-18,\n    -4.83050448594418207126E-18,\n    4.46562142029675999901E-17,\n    3.46122286769746109310E-17,\n    -2.82762398051658348494E-16,\n    -3.42548561967721913462E-16,\n    1.77256013305652638360E-15,\n    3.81168066935262242075E-15,\n    -9.55484669882830764870E-15,\n    -4.15056934728722208663E-14,\n    1.54008621752140982691E-14,\n    3.85277838274214270114E-13,\n    7.18012445138366623367E-13,\n    -1.79417853150680611778E-12,\n    -1.32158118404477131188E-11,\n    -3.14991652796324136454E-11,\n    1.18891471078464383424E-11,\n    4.94060238822496958910E-10,\n    3.39623202570838634515E-9,\n    2.26666899049817806459E-8,\n    2.04891858946906374183E-7,\n    2.89137052083475648297E-6,\n    6.88975834691682398426E-5,\n    3.36911647825569408990E-3,\n    8.04490411014108831608E-1\n    ]\n\n\ndef _chbevl(x, vals):\n    b0 = vals[0]\n    b1 = 0.0\n\n    for i in range(1, len(vals)):\n        b2 = b1\n        b1 = b0\n        b0 = x*b1 - b2 + vals[i]\n\n    return 0.5*(b0 - b2)\n\n\ndef _i0_1(x):\n    return exp(x) * _chbevl(x/2.0-2, _i0A)\n\n\ndef _i0_2(x):\n    return exp(x) * _chbevl(32.0/x - 2.0, _i0B) / sqrt(x)\n\n\ndef _i0_dispatcher(x):\n    return (x,)\n\n\n@array_function_dispatch(_i0_dispatcher)\ndef i0(x):\n    \"\"\"\n    Modified Bessel function of the first kind, order 0.\n\n    Usually denoted :math:`I_0`.\n\n    Parameters\n    ----------\n    x : array_like of float\n        Argument of the Bessel function.\n\n    Returns\n    -------\n    out : ndarray, shape = x.shape, dtype = float\n        The modified Bessel function evaluated at each of the elements of `x`.\n\n    See Also\n    --------\n    scipy.special.i0, scipy.special.iv, scipy.special.ive\n\n    Notes\n    -----\n    The scipy implementation is recommended over this function: it is a\n    proper ufunc written in C, and more than an order of magnitude faster.\n\n    We use the algorithm published by Clenshaw [1]_ and referenced by\n    Abramowitz and Stegun [2]_, for which the function domain is\n    partitioned into the two intervals [0,8] and (8,inf), and Chebyshev\n    polynomial expansions are employed in each interval. Relative error on\n    the domain [0,30] using IEEE arithmetic is documented [3]_ as having a\n    peak of 5.8e-16 with an rms of 1.4e-16 (n = 30000).\n\n    References\n    ----------\n    .. [1] C. W. Clenshaw, \"Chebyshev series for mathematical functions\", in\n           *National Physical Laboratory Mathematical Tables*, vol. 5, London:\n           Her Majesty's Stationery Office, 1962.\n    .. [2] M. Abramowitz and I. A. Stegun, *Handbook of Mathematical\n           Functions*, 10th printing, New York: Dover, 1964, pp. 379.\n           https://personal.math.ubc.ca/~cbm/aands/page_379.htm\n    .. [3] https://metacpan.org/pod/distribution/Math-Cephes/lib/Math/Cephes.pod#i0:-Modified-Bessel-function-of-order-zero\n\n    Examples\n    --------\n    >>> np.i0(0.)\n    array(1.0)\n    >>> np.i0([0, 1, 2, 3])\n    array([1.        , 1.26606588, 2.2795853 , 4.88079259])\n\n    \"\"\"\n    x = np.asanyarray(x)\n    if x.dtype.kind == 'c':\n        raise TypeError(\"i0 not supported for complex values\")\n    if x.dtype.kind != 'f':\n        x = x.astype(float)\n    x = np.abs(x)\n    return piecewise(x, [x <= 8.0], [_i0_1, _i0_2])\n\n## End of cephes code for i0\n\n\n@set_module('numpy')\ndef kaiser(M, beta):\n    \"\"\"\n    Return the Kaiser window.\n\n    The Kaiser window is a taper formed by using a Bessel function.\n\n    Parameters\n    ----------\n    M : int\n        Number of points in the output window. If zero or less, an\n        empty array is returned.\n    beta : float\n        Shape parameter for window.\n\n    Returns\n    -------\n    out : array\n        The window, with the maximum value normalized to one (the value\n        one appears only if the number of samples is odd).\n\n    See Also\n    --------\n    bartlett, blackman, hamming, hanning\n\n    Notes\n    -----\n    The Kaiser window is defined as\n\n    .. math::  w(n) = I_0\\\\left( \\\\beta \\\\sqrt{1-\\\\frac{4n^2}{(M-1)^2}}\n               \\\\right)/I_0(\\\\beta)\n\n    with\n\n    .. math:: \\\\quad -\\\\frac{M-1}{2} \\\\leq n \\\\leq \\\\frac{M-1}{2},\n\n    where :math:`I_0` is the modified zeroth-order Bessel function.\n\n    The Kaiser was named for Jim Kaiser, who discovered a simple\n    approximation to the DPSS window based on Bessel functions.  The Kaiser\n    window is a very good approximation to the Digital Prolate Spheroidal\n    Sequence, or Slepian window, which is the transform which maximizes the\n    energy in the main lobe of the window relative to total energy.\n\n    The Kaiser can approximate many other windows by varying the beta\n    parameter.\n\n    ====  =======================\n    beta  Window shape\n    ====  =======================\n    0     Rectangular\n    5     Similar to a Hamming\n    6     Similar to a Hanning\n    8.6   Similar to a Blackman\n    ====  =======================\n\n    A beta value of 14 is probably a good starting point. Note that as beta\n    gets large, the window narrows, and so the number of samples needs to be\n    large enough to sample the increasingly narrow spike, otherwise NaNs will\n    get returned.\n\n    Most references to the Kaiser window come from the signal processing\n    literature, where it is used as one of many windowing functions for\n    smoothing values.  It is also known as an apodization (which means\n    \"removing the foot\", i.e. smoothing discontinuities at the beginning\n    and end of the sampled signal) or tapering function.\n\n    References\n    ----------\n    .. [1] J. F. Kaiser, \"Digital Filters\" - Ch 7 in \"Systems analysis by\n           digital computer\", Editors: F.F. Kuo and J.F. Kaiser, p 218-285.\n           John Wiley and Sons, New York, (1966).\n    .. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\", The\n           University of Alberta Press, 1975, pp. 177-178.\n    .. [3] Wikipedia, \"Window function\",\n           https://en.wikipedia.org/wiki/Window_function\n\n    Examples\n    --------\n    >>> import matplotlib.pyplot as plt\n    >>> np.kaiser(12, 14)\n     array([7.72686684e-06, 3.46009194e-03, 4.65200189e-02, # may vary\n            2.29737120e-01, 5.99885316e-01, 9.45674898e-01,\n            9.45674898e-01, 5.99885316e-01, 2.29737120e-01,\n            4.65200189e-02, 3.46009194e-03, 7.72686684e-06])\n\n\n    Plot the window and the frequency response:\n\n    >>> from numpy.fft import fft, fftshift\n    >>> window = np.kaiser(51, 14)\n    >>> plt.plot(window)\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Kaiser window\")\n    Text(0.5, 1.0, 'Kaiser window')\n    >>> plt.ylabel(\"Amplitude\")\n    Text(0, 0.5, 'Amplitude')\n    >>> plt.xlabel(\"Sample\")\n    Text(0.5, 0, 'Sample')\n    >>> plt.show()\n\n    >>> plt.figure()\n    <Figure size 640x480 with 0 Axes>\n    >>> A = fft(window, 2048) / 25.5\n    >>> mag = np.abs(fftshift(A))\n    >>> freq = np.linspace(-0.5, 0.5, len(A))\n    >>> response = 20 * np.log10(mag)\n    >>> response = np.clip(response, -100, 100)\n    >>> plt.plot(freq, response)\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Frequency response of Kaiser window\")\n    Text(0.5, 1.0, 'Frequency response of Kaiser window')\n    >>> plt.ylabel(\"Magnitude [dB]\")\n    Text(0, 0.5, 'Magnitude [dB]')\n    >>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\n    Text(0.5, 0, 'Normalized frequency [cycles per sample]')\n    >>> plt.axis('tight')\n    (-0.5, 0.5, -100.0, ...) # may vary\n    >>> plt.show()\n\n    \"\"\"\n    # Ensures at least float64 via 0.0.  M should be an integer, but conversion\n    # to double is safe for a range.  (Simplified result_type with 0.0\n    # strongly typed.  result-type is not/less order sensitive, but that mainly\n    # matters for integers anyway.)\n    values = np.array([0.0, M, beta])\n    M = values[1]\n    beta = values[2]\n\n    if M == 1:\n        return np.ones(1, dtype=values.dtype)\n    n = arange(0, M)\n    alpha = (M-1)/2.0\n    return i0(beta * sqrt(1-((n-alpha)/alpha)**2.0))/i0(beta)\n\n\ndef _sinc_dispatcher(x):\n    return (x,)\n\n\n@array_function_dispatch(_sinc_dispatcher)\ndef sinc(x):\n    r\"\"\"\n    Return the normalized sinc function.\n\n    The sinc function is equal to :math:`\\sin(\\pi x)/(\\pi x)` for any argument\n    :math:`x\\ne 0`. ``sinc(0)`` takes the limit value 1, making ``sinc`` not\n    only everywhere continuous but also infinitely differentiable.\n\n    .. note::\n\n        Note the normalization factor of ``pi`` used in the definition.\n        This is the most commonly used definition in signal processing.\n        Use ``sinc(x / np.pi)`` to obtain the unnormalized sinc function\n        :math:`\\sin(x)/x` that is more common in mathematics.\n\n    Parameters\n    ----------\n    x : ndarray\n        Array (possibly multi-dimensional) of values for which to calculate\n        ``sinc(x)``.\n\n    Returns\n    -------\n    out : ndarray\n        ``sinc(x)``, which has the same shape as the input.\n\n    Notes\n    -----\n    The name sinc is short for \"sine cardinal\" or \"sinus cardinalis\".\n\n    The sinc function is used in various signal processing applications,\n    including in anti-aliasing, in the construction of a Lanczos resampling\n    filter, and in interpolation.\n\n    For bandlimited interpolation of discrete-time signals, the ideal\n    interpolation kernel is proportional to the sinc function.\n\n    References\n    ----------\n    .. [1] Weisstein, Eric W. \"Sinc Function.\" From MathWorld--A Wolfram Web\n           Resource. http://mathworld.wolfram.com/SincFunction.html\n    .. [2] Wikipedia, \"Sinc function\",\n           https://en.wikipedia.org/wiki/Sinc_function\n\n    Examples\n    --------\n    >>> import matplotlib.pyplot as plt\n    >>> x = np.linspace(-4, 4, 41)\n    >>> np.sinc(x)\n     array([-3.89804309e-17,  -4.92362781e-02,  -8.40918587e-02, # may vary\n            -8.90384387e-02,  -5.84680802e-02,   3.89804309e-17,\n            6.68206631e-02,   1.16434881e-01,   1.26137788e-01,\n            8.50444803e-02,  -3.89804309e-17,  -1.03943254e-01,\n            -1.89206682e-01,  -2.16236208e-01,  -1.55914881e-01,\n            3.89804309e-17,   2.33872321e-01,   5.04551152e-01,\n            7.56826729e-01,   9.35489284e-01,   1.00000000e+00,\n            9.35489284e-01,   7.56826729e-01,   5.04551152e-01,\n            2.33872321e-01,   3.89804309e-17,  -1.55914881e-01,\n           -2.16236208e-01,  -1.89206682e-01,  -1.03943254e-01,\n           -3.89804309e-17,   8.50444803e-02,   1.26137788e-01,\n            1.16434881e-01,   6.68206631e-02,   3.89804309e-17,\n            -5.84680802e-02,  -8.90384387e-02,  -8.40918587e-02,\n            -4.92362781e-02,  -3.89804309e-17])\n\n    >>> plt.plot(x, np.sinc(x))\n    [<matplotlib.lines.Line2D object at 0x...>]\n    >>> plt.title(\"Sinc Function\")\n    Text(0.5, 1.0, 'Sinc Function')\n    >>> plt.ylabel(\"Amplitude\")\n    Text(0, 0.5, 'Amplitude')\n    >>> plt.xlabel(\"X\")\n    Text(0.5, 0, 'X')\n    >>> plt.show()\n\n    \"\"\"\n    x = np.asanyarray(x)\n    y = pi * where(x == 0, 1.0e-20, x)\n    return sin(y)/y\n\n\ndef _msort_dispatcher(a):\n    return (a,)\n\n\n@array_function_dispatch(_msort_dispatcher)\ndef msort(a):\n    \"\"\"\n    Return a copy of an array sorted along the first axis.\n\n    .. deprecated:: 1.24\n\n       msort is deprecated, use ``np.sort(a, axis=0)`` instead.\n\n    Parameters\n    ----------\n    a : array_like\n        Array to be sorted.\n\n    Returns\n    -------\n    sorted_array : ndarray\n        Array of the same type and shape as `a`.\n\n    See Also\n    --------\n    sort\n\n    Notes\n    -----\n    ``np.msort(a)`` is equivalent to  ``np.sort(a, axis=0)``.\n\n    Examples\n    --------\n    >>> a = np.array([[1, 4], [3, 1]])\n    >>> np.msort(a)  # sort along the first axis\n    array([[1, 1],\n           [3, 4]])\n\n    \"\"\"\n    # 2022-10-20 1.24\n    warnings.warn(\n        \"msort is deprecated, use np.sort(a, axis=0) instead\",\n        DeprecationWarning,\n        stacklevel=2,\n    )\n    b = array(a, subok=True, copy=True)\n    b.sort(0)\n    return b\n\n\ndef _ureduce(a, func, keepdims=False, **kwargs):\n    \"\"\"\n    Internal Function.\n    Call `func` with `a` as first argument swapping the axes to use extended\n    axis on functions that don't support it natively.\n\n    Returns result and a.shape with axis dims set to 1.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array or object that can be converted to an array.\n    func : callable\n        Reduction function capable of receiving a single axis argument.\n        It is called with `a` as first argument followed by `kwargs`.\n    kwargs : keyword arguments\n        additional keyword arguments to pass to `func`.\n\n    Returns\n    -------\n    result : tuple\n        Result of func(a, **kwargs) and a.shape with axis dims set to 1\n        which can be used to reshape the result to the same shape a ufunc with\n        keepdims=True would produce.\n\n    \"\"\"\n    a = np.asanyarray(a)\n    axis = kwargs.get('axis', None)\n    out = kwargs.get('out', None)\n\n    if keepdims is np._NoValue:\n        keepdims = False\n\n    nd = a.ndim\n    if axis is not None:\n        axis = _nx.normalize_axis_tuple(axis, nd)\n\n        if keepdims:\n            if out is not None:\n                index_out = tuple(\n                    0 if i in axis else slice(None) for i in range(nd))\n                kwargs['out'] = out[(Ellipsis, ) + index_out]\n\n        if len(axis) == 1:\n            kwargs['axis'] = axis[0]\n        else:\n            keep = set(range(nd)) - set(axis)\n            nkeep = len(keep)\n            # swap axis that should not be reduced to front\n            for i, s in enumerate(sorted(keep)):\n                a = a.swapaxes(i, s)\n            # merge reduced axis\n            a = a.reshape(a.shape[:nkeep] + (-1,))\n            kwargs['axis'] = -1\n    else:\n        if keepdims:\n            if out is not None:\n                index_out = (0, ) * nd\n                kwargs['out'] = out[(Ellipsis, ) + index_out]\n\n    r = func(a, **kwargs)\n\n    if out is not None:\n        return out\n\n    if keepdims:\n        if axis is None:\n            index_r = (np.newaxis, ) * nd\n        else:\n            index_r = tuple(\n                np.newaxis if i in axis else slice(None)\n                for i in range(nd))\n        r = r[(Ellipsis, ) + index_r]\n\n    return r\n\n\ndef _median_dispatcher(\n        a, axis=None, out=None, overwrite_input=None, keepdims=None):\n    return (a, out)\n\n\n@array_function_dispatch(_median_dispatcher)\ndef median(a, axis=None, out=None, overwrite_input=False, keepdims=False):\n    \"\"\"\n    Compute the median along the specified axis.\n\n    Returns the median of the array elements.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array or object that can be converted to an array.\n    axis : {int, sequence of int, None}, optional\n        Axis or axes along which the medians are computed. The default\n        is to compute the median along a flattened version of the array.\n        A sequence of axes is supported since version 1.9.0.\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must\n        have the same shape and buffer length as the expected output,\n        but the type (of the output) will be cast if necessary.\n    overwrite_input : bool, optional\n       If True, then allow use of memory of input array `a` for\n       calculations. The input array will be modified by the call to\n       `median`. This will save memory when you do not need to preserve\n       the contents of the input array. Treat the input as undefined,\n       but it will probably be fully or partially sorted. Default is\n       False. If `overwrite_input` is ``True`` and `a` is not already an\n       `ndarray`, an error will be raised.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the original `arr`.\n\n        .. versionadded:: 1.9.0\n\n    Returns\n    -------\n    median : ndarray\n        A new array holding the result. If the input contains integers\n        or floats smaller than ``float64``, then the output data-type is\n        ``np.float64``.  Otherwise, the data-type of the output is the\n        same as that of the input. If `out` is specified, that array is\n        returned instead.\n\n    See Also\n    --------\n    mean, percentile\n\n    Notes\n    -----\n    Given a vector ``V`` of length ``N``, the median of ``V`` is the\n    middle value of a sorted copy of ``V``, ``V_sorted`` - i\n    e., ``V_sorted[(N-1)/2]``, when ``N`` is odd, and the average of the\n    two middle values of ``V_sorted`` when ``N`` is even.\n\n    Examples\n    --------\n    >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n    >>> a\n    array([[10,  7,  4],\n           [ 3,  2,  1]])\n    >>> np.median(a)\n    3.5\n    >>> np.median(a, axis=0)\n    array([6.5, 4.5, 2.5])\n    >>> np.median(a, axis=1)\n    array([7.,  2.])\n    >>> m = np.median(a, axis=0)\n    >>> out = np.zeros_like(m)\n    >>> np.median(a, axis=0, out=m)\n    array([6.5,  4.5,  2.5])\n    >>> m\n    array([6.5,  4.5,  2.5])\n    >>> b = a.copy()\n    >>> np.median(b, axis=1, overwrite_input=True)\n    array([7.,  2.])\n    >>> assert not np.all(a==b)\n    >>> b = a.copy()\n    >>> np.median(b, axis=None, overwrite_input=True)\n    3.5\n    >>> assert not np.all(a==b)\n\n    \"\"\"\n    return _ureduce(a, func=_median, keepdims=keepdims, axis=axis, out=out,\n                    overwrite_input=overwrite_input)\n\n\ndef _median(a, axis=None, out=None, overwrite_input=False):\n    # can't be reasonably be implemented in terms of percentile as we have to\n    # call mean to not break astropy\n    a = np.asanyarray(a)\n\n    # Set the partition indexes\n    if axis is None:\n        sz = a.size\n    else:\n        sz = a.shape[axis]\n    if sz % 2 == 0:\n        szh = sz // 2\n        kth = [szh - 1, szh]\n    else:\n        kth = [(sz - 1) // 2]\n\n    # We have to check for NaNs (as of writing 'M' doesn't actually work).\n    supports_nans = np.issubdtype(a.dtype, np.inexact) or a.dtype.kind in 'Mm'\n    if supports_nans:\n        kth.append(-1)\n\n    if overwrite_input:\n        if axis is None:\n            part = a.ravel()\n            part.partition(kth)\n        else:\n            a.partition(kth, axis=axis)\n            part = a\n    else:\n        part = partition(a, kth, axis=axis)\n\n    if part.shape == ():\n        # make 0-D arrays work\n        return part.item()\n    if axis is None:\n        axis = 0\n\n    indexer = [slice(None)] * part.ndim\n    index = part.shape[axis] // 2\n    if part.shape[axis] % 2 == 1:\n        # index with slice to allow mean (below) to work\n        indexer[axis] = slice(index, index+1)\n    else:\n        indexer[axis] = slice(index-1, index+1)\n    indexer = tuple(indexer)\n\n    # Use mean in both odd and even case to coerce data type,\n    # using out array if needed.\n    rout = mean(part[indexer], axis=axis, out=out)\n    if supports_nans and sz > 0:\n        # If nans are possible, warn and replace by nans like mean would.\n        rout = np.lib.utils._median_nancheck(part, rout, axis)\n\n    return rout\n\n\ndef _percentile_dispatcher(a, q, axis=None, out=None, overwrite_input=None,\n                           method=None, keepdims=None, *, interpolation=None):\n    return (a, q, out)\n\n\n@array_function_dispatch(_percentile_dispatcher)\ndef percentile(a,\n               q,\n               axis=None,\n               out=None,\n               overwrite_input=False,\n               method=\"linear\",\n               keepdims=False,\n               *,\n               interpolation=None):\n    \"\"\"\n    Compute the q-th percentile of the data along the specified axis.\n\n    Returns the q-th percentile(s) of the array elements.\n\n    Parameters\n    ----------\n    a : array_like of real numbers\n        Input array or object that can be converted to an array.\n    q : array_like of float\n        Percentage or sequence of percentages for the percentiles to compute.\n        Values must be between 0 and 100 inclusive.\n    axis : {int, tuple of int, None}, optional\n        Axis or axes along which the percentiles are computed. The\n        default is to compute the percentile(s) along a flattened\n        version of the array.\n\n        .. versionchanged:: 1.9.0\n            A tuple of axes is supported\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must\n        have the same shape and buffer length as the expected output,\n        but the type (of the output) will be cast if necessary.\n    overwrite_input : bool, optional\n        If True, then allow the input array `a` to be modified by intermediate\n        calculations, to save memory. In this case, the contents of the input\n        `a` after this function completes is undefined.\n    method : str, optional\n        This parameter specifies the method to use for estimating the\n        percentile.  There are many different methods, some unique to NumPy.\n        See the notes for explanation.  The options sorted by their R type\n        as summarized in the H&F paper [1]_ are:\n\n        1. 'inverted_cdf'\n        2. 'averaged_inverted_cdf'\n        3. 'closest_observation'\n        4. 'interpolated_inverted_cdf'\n        5. 'hazen'\n        6. 'weibull'\n        7. 'linear'  (default)\n        8. 'median_unbiased'\n        9. 'normal_unbiased'\n\n        The first three methods are discontinuous.  NumPy further defines the\n        following discontinuous variations of the default 'linear' (7.) option:\n\n        * 'lower'\n        * 'higher',\n        * 'midpoint'\n        * 'nearest'\n\n        .. versionchanged:: 1.22.0\n            This argument was previously called \"interpolation\" and only\n            offered the \"linear\" default and last four options.\n\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left in\n        the result as dimensions with size one. With this option, the\n        result will broadcast correctly against the original array `a`.\n\n        .. versionadded:: 1.9.0\n\n    interpolation : str, optional\n        Deprecated name for the method keyword argument.\n\n        .. deprecated:: 1.22.0\n\n    Returns\n    -------\n    percentile : scalar or ndarray\n        If `q` is a single percentile and `axis=None`, then the result\n        is a scalar. If multiple percentiles are given, first axis of\n        the result corresponds to the percentiles. The other axes are\n        the axes that remain after the reduction of `a`. If the input\n        contains integers or floats smaller than ``float64``, the output\n        data-type is ``float64``. Otherwise, the output data-type is the\n        same as that of the input. If `out` is specified, that array is\n        returned instead.\n\n    See Also\n    --------\n    mean\n    median : equivalent to ``percentile(..., 50)``\n    nanpercentile\n    quantile : equivalent to percentile, except q in the range [0, 1].\n\n    Notes\n    -----\n    Given a vector ``V`` of length ``n``, the q-th percentile of ``V`` is\n    the value ``q/100`` of the way from the minimum to the maximum in a\n    sorted copy of ``V``. The values and distances of the two nearest\n    neighbors as well as the `method` parameter will determine the\n    percentile if the normalized ranking does not match the location of\n    ``q`` exactly. This function is the same as the median if ``q=50``, the\n    same as the minimum if ``q=0`` and the same as the maximum if\n    ``q=100``.\n\n    The optional `method` parameter specifies the method to use when the\n    desired percentile lies between two indexes ``i`` and ``j = i + 1``.\n    In that case, we first determine ``i + g``, a virtual index that lies\n    between ``i`` and ``j``, where  ``i`` is the floor and ``g`` is the\n    fractional part of the index. The final result is, then, an interpolation\n    of ``a[i]`` and ``a[j]`` based on ``g``. During the computation of ``g``,\n    ``i`` and ``j`` are modified using correction constants ``alpha`` and\n    ``beta`` whose choices depend on the ``method`` used. Finally, note that\n    since Python uses 0-based indexing, the code subtracts another 1 from the\n    index internally.\n\n    The following formula determines the virtual index ``i + g``, the location\n    of the percentile in the sorted sample:\n\n    .. math::\n        i + g = (q / 100) * ( n - alpha - beta + 1 ) + alpha\n\n    The different methods then work as follows\n\n    inverted_cdf:\n        method 1 of H&F [1]_.\n        This method gives discontinuous results:\n\n        * if g > 0 ; then take j\n        * if g = 0 ; then take i\n\n    averaged_inverted_cdf:\n        method 2 of H&F [1]_.\n        This method give discontinuous results:\n\n        * if g > 0 ; then take j\n        * if g = 0 ; then average between bounds\n\n    closest_observation:\n        method 3 of H&F [1]_.\n        This method give discontinuous results:\n\n        * if g > 0 ; then take j\n        * if g = 0 and index is odd ; then take j\n        * if g = 0 and index is even ; then take i\n\n    interpolated_inverted_cdf:\n        method 4 of H&F [1]_.\n        This method give continuous results using:\n\n        * alpha = 0\n        * beta = 1\n\n    hazen:\n        method 5 of H&F [1]_.\n        This method give continuous results using:\n\n        * alpha = 1/2\n        * beta = 1/2\n\n    weibull:\n        method 6 of H&F [1]_.\n        This method give continuous results using:\n\n        * alpha = 0\n        * beta = 0\n\n    linear:\n        method 7 of H&F [1]_.\n        This method give continuous results using:\n\n        * alpha = 1\n        * beta = 1\n\n    median_unbiased:\n        method 8 of H&F [1]_.\n        This method is probably the best method if the sample\n        distribution function is unknown (see reference).\n        This method give continuous results using:\n\n        * alpha = 1/3\n        * beta = 1/3\n\n    normal_unbiased:\n        method 9 of H&F [1]_.\n        This method is probably the best method if the sample\n        distribution function is known to be normal.\n        This method give continuous results using:\n\n        * alpha = 3/8\n        * beta = 3/8\n\n    lower:\n        NumPy method kept for backwards compatibility.\n        Takes ``i`` as the interpolation point.\n\n    higher:\n        NumPy method kept for backwards compatibility.\n        Takes ``j`` as the interpolation point.\n\n    nearest:\n        NumPy method kept for backwards compatibility.\n        Takes ``i`` or ``j``, whichever is nearest.\n\n    midpoint:\n        NumPy method kept for backwards compatibility.\n        Uses ``(i + j) / 2``.\n\n    Examples\n    --------\n    >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n    >>> a\n    array([[10,  7,  4],\n           [ 3,  2,  1]])\n    >>> np.percentile(a, 50)\n    3.5\n    >>> np.percentile(a, 50, axis=0)\n    array([6.5, 4.5, 2.5])\n    >>> np.percentile(a, 50, axis=1)\n    array([7.,  2.])\n    >>> np.percentile(a, 50, axis=1, keepdims=True)\n    array([[7.],\n           [2.]])\n\n    >>> m = np.percentile(a, 50, axis=0)\n    >>> out = np.zeros_like(m)\n    >>> np.percentile(a, 50, axis=0, out=out)\n    array([6.5, 4.5, 2.5])\n    >>> m\n    array([6.5, 4.5, 2.5])\n\n    >>> b = a.copy()\n    >>> np.percentile(b, 50, axis=1, overwrite_input=True)\n    array([7.,  2.])\n    >>> assert not np.all(a == b)\n\n    The different methods can be visualized graphically:\n\n    .. plot::\n\n        import matplotlib.pyplot as plt\n\n        a = np.arange(4)\n        p = np.linspace(0, 100, 6001)\n        ax = plt.gca()\n        lines = [\n            ('linear', '-', 'C0'),\n            ('inverted_cdf', ':', 'C1'),\n            # Almost the same as `inverted_cdf`:\n            ('averaged_inverted_cdf', '-.', 'C1'),\n            ('closest_observation', ':', 'C2'),\n            ('interpolated_inverted_cdf', '--', 'C1'),\n            ('hazen', '--', 'C3'),\n            ('weibull', '-.', 'C4'),\n            ('median_unbiased', '--', 'C5'),\n            ('normal_unbiased', '-.', 'C6'),\n            ]\n        for method, style, color in lines:\n            ax.plot(\n                p, np.percentile(a, p, method=method),\n                label=method, linestyle=style, color=color)\n        ax.set(\n            title='Percentiles for different methods and data: ' + str(a),\n            xlabel='Percentile',\n            ylabel='Estimated percentile value',\n            yticks=a)\n        ax.legend(bbox_to_anchor=(1.03, 1))\n        plt.tight_layout()\n        plt.show()\n\n    References\n    ----------\n    .. [1] R. J. Hyndman and Y. Fan,\n       \"Sample quantiles in statistical packages,\"\n       The American Statistician, 50(4), pp. 361-365, 1996\n\n    \"\"\"\n    if interpolation is not None:\n        method = _check_interpolation_as_method(\n            method, interpolation, \"percentile\")\n\n    a = np.asanyarray(a)\n    if a.dtype.kind == \"c\":\n        raise TypeError(\"a must be an array of real numbers\")\n\n    q = np.true_divide(q, 100)\n    q = asanyarray(q)  # undo any decay that the ufunc performed (see gh-13105)\n    if not _quantile_is_valid(q):\n        raise ValueError(\"Percentiles must be in the range [0, 100]\")\n    return _quantile_unchecked(\n        a, q, axis, out, overwrite_input, method, keepdims)\n\n\ndef _quantile_dispatcher(a, q, axis=None, out=None, overwrite_input=None,\n                         method=None, keepdims=None, *, interpolation=None):\n    return (a, q, out)\n\n\n@array_function_dispatch(_quantile_dispatcher)\ndef quantile(a,\n             q,\n             axis=None,\n             out=None,\n             overwrite_input=False,\n             method=\"linear\",\n             keepdims=False,\n             *,\n             interpolation=None):\n    \"\"\"\n    Compute the q-th quantile of the data along the specified axis.\n\n    .. versionadded:: 1.15.0\n\n    Parameters\n    ----------\n    a : array_like of real numbers\n        Input array or object that can be converted to an array.\n    q : array_like of float\n        Probability or sequence of probabilities for the quantiles to compute.\n        Values must be between 0 and 1 inclusive.\n    axis : {int, tuple of int, None}, optional\n        Axis or axes along which the quantiles are computed. The default is\n        to compute the quantile(s) along a flattened version of the array.\n    out : ndarray, optional\n        Alternative output array in which to place the result. It must have\n        the same shape and buffer length as the expected output, but the\n        type (of the output) will be cast if necessary.\n    overwrite_input : bool, optional\n        If True, then allow the input array `a` to be modified by\n        intermediate calculations, to save memory. In this case, the\n        contents of the input `a` after this function completes is\n        undefined.\n    method : str, optional\n        This parameter specifies the method to use for estimating the\n        quantile.  There are many different methods, some unique to NumPy.\n        See the notes for explanation.  The options sorted by their R type\n        as summarized in the H&F paper [1]_ are:\n\n        1. 'inverted_cdf'\n        2. 'averaged_inverted_cdf'\n        3. 'closest_observation'\n        4. 'interpolated_inverted_cdf'\n        5. 'hazen'\n        6. 'weibull'\n        7. 'linear'  (default)\n        8. 'median_unbiased'\n        9. 'normal_unbiased'\n\n        The first three methods are discontinuous.  NumPy further defines the\n        following discontinuous variations of the default 'linear' (7.) option:\n\n        * 'lower'\n        * 'higher',\n        * 'midpoint'\n        * 'nearest'\n\n        .. versionchanged:: 1.22.0\n            This argument was previously called \"interpolation\" and only\n            offered the \"linear\" default and last four options.\n\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left in\n        the result as dimensions with size one. With this option, the\n        result will broadcast correctly against the original array `a`.\n\n    interpolation : str, optional\n        Deprecated name for the method keyword argument.\n\n        .. deprecated:: 1.22.0\n\n    Returns\n    -------\n    quantile : scalar or ndarray\n        If `q` is a single probability and `axis=None`, then the result\n        is a scalar. If multiple probabilies levels are given, first axis of\n        the result corresponds to the quantiles. The other axes are\n        the axes that remain after the reduction of `a`. If the input\n        contains integers or floats smaller than ``float64``, the output\n        data-type is ``float64``. Otherwise, the output data-type is the\n        same as that of the input. If `out` is specified, that array is\n        returned instead.\n\n    See Also\n    --------\n    mean\n    percentile : equivalent to quantile, but with q in the range [0, 100].\n    median : equivalent to ``quantile(..., 0.5)``\n    nanquantile\n\n    Notes\n    -----\n    Given a vector ``V`` of length ``n``, the q-th quantile of ``V`` is\n    the value ``q`` of the way from the minimum to the maximum in a\n    sorted copy of ``V``. The values and distances of the two nearest\n    neighbors as well as the `method` parameter will determine the\n    quantile if the normalized ranking does not match the location of\n    ``q`` exactly. This function is the same as the median if ``q=0.5``, the\n    same as the minimum if ``q=0.0`` and the same as the maximum if\n    ``q=1.0``.\n\n    The optional `method` parameter specifies the method to use when the\n    desired quantile lies between two indexes ``i`` and ``j = i + 1``.\n    In that case, we first determine ``i + g``, a virtual index that lies\n    between ``i`` and ``j``, where  ``i`` is the floor and ``g`` is the\n    fractional part of the index. The final result is, then, an interpolation\n    of ``a[i]`` and ``a[j]`` based on ``g``. During the computation of ``g``,\n    ``i`` and ``j`` are modified using correction constants ``alpha`` and\n    ``beta`` whose choices depend on the ``method`` used. Finally, note that\n    since Python uses 0-based indexing, the code subtracts another 1 from the\n    index internally.\n\n    The following formula determines the virtual index ``i + g``, the location\n    of the quantile in the sorted sample:\n\n    .. math::\n        i + g = q * ( n - alpha - beta + 1 ) + alpha\n\n    The different methods then work as follows\n\n    inverted_cdf:\n        method 1 of H&F [1]_.\n        This method gives discontinuous results:\n\n        * if g > 0 ; then take j\n        * if g = 0 ; then take i\n\n    averaged_inverted_cdf:\n        method 2 of H&F [1]_.\n        This method gives discontinuous results:\n\n        * if g > 0 ; then take j\n        * if g = 0 ; then average between bounds\n\n    closest_observation:\n        method 3 of H&F [1]_.\n        This method gives discontinuous results:\n\n        * if g > 0 ; then take j\n        * if g = 0 and index is odd ; then take j\n        * if g = 0 and index is even ; then take i\n\n    interpolated_inverted_cdf:\n        method 4 of H&F [1]_.\n        This method gives continuous results using:\n\n        * alpha = 0\n        * beta = 1\n\n    hazen:\n        method 5 of H&F [1]_.\n        This method gives continuous results using:\n\n        * alpha = 1/2\n        * beta = 1/2\n\n    weibull:\n        method 6 of H&F [1]_.\n        This method gives continuous results using:\n\n        * alpha = 0\n        * beta = 0\n\n    linear:\n        method 7 of H&F [1]_.\n        This method gives continuous results using:\n\n        * alpha = 1\n        * beta = 1\n\n    median_unbiased:\n        method 8 of H&F [1]_.\n        This method is probably the best method if the sample\n        distribution function is unknown (see reference).\n        This method gives continuous results using:\n\n        * alpha = 1/3\n        * beta = 1/3\n\n    normal_unbiased:\n        method 9 of H&F [1]_.\n        This method is probably the best method if the sample\n        distribution function is known to be normal.\n        This method gives continuous results using:\n\n        * alpha = 3/8\n        * beta = 3/8\n\n    lower:\n        NumPy method kept for backwards compatibility.\n        Takes ``i`` as the interpolation point.\n\n    higher:\n        NumPy method kept for backwards compatibility.\n        Takes ``j`` as the interpolation point.\n\n    nearest:\n        NumPy method kept for backwards compatibility.\n        Takes ``i`` or ``j``, whichever is nearest.\n\n    midpoint:\n        NumPy method kept for backwards compatibility.\n        Uses ``(i + j) / 2``.\n\n    Examples\n    --------\n    >>> a = np.array([[10, 7, 4], [3, 2, 1]])\n    >>> a\n    array([[10,  7,  4],\n           [ 3,  2,  1]])\n    >>> np.quantile(a, 0.5)\n    3.5\n    >>> np.quantile(a, 0.5, axis=0)\n    array([6.5, 4.5, 2.5])\n    >>> np.quantile(a, 0.5, axis=1)\n    array([7.,  2.])\n    >>> np.quantile(a, 0.5, axis=1, keepdims=True)\n    array([[7.],\n           [2.]])\n    >>> m = np.quantile(a, 0.5, axis=0)\n    >>> out = np.zeros_like(m)\n    >>> np.quantile(a, 0.5, axis=0, out=out)\n    array([6.5, 4.5, 2.5])\n    >>> m\n    array([6.5, 4.5, 2.5])\n    >>> b = a.copy()\n    >>> np.quantile(b, 0.5, axis=1, overwrite_input=True)\n    array([7.,  2.])\n    >>> assert not np.all(a == b)\n\n    See also `numpy.percentile` for a visualization of most methods.\n\n    References\n    ----------\n    .. [1] R. J. Hyndman and Y. Fan,\n       \"Sample quantiles in statistical packages,\"\n       The American Statistician, 50(4), pp. 361-365, 1996\n\n    \"\"\"\n    if interpolation is not None:\n        method = _check_interpolation_as_method(\n            method, interpolation, \"quantile\")\n\n    a = np.asanyarray(a)\n    if a.dtype.kind == \"c\":\n        raise TypeError(\"a must be an array of real numbers\")\n\n    q = np.asanyarray(q)\n    if not _quantile_is_valid(q):\n        raise ValueError(\"Quantiles must be in the range [0, 1]\")\n    return _quantile_unchecked(\n        a, q, axis, out, overwrite_input, method, keepdims)\n\n\ndef _quantile_unchecked(a,\n                        q,\n                        axis=None,\n                        out=None,\n                        overwrite_input=False,\n                        method=\"linear\",\n                        keepdims=False):\n    \"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\n    return _ureduce(a,\n                    func=_quantile_ureduce_func,\n                    q=q,\n                    keepdims=keepdims,\n                    axis=axis,\n                    out=out,\n                    overwrite_input=overwrite_input,\n                    method=method)\n\n\ndef _quantile_is_valid(q):\n    # avoid expensive reductions, relevant for arrays with < O(1000) elements\n    if q.ndim == 1 and q.size < 10:\n        for i in range(q.size):\n            if not (0.0 <= q[i] <= 1.0):\n                return False\n    else:\n        if not (np.all(0 <= q) and np.all(q <= 1)):\n            return False\n    return True\n\n\ndef _check_interpolation_as_method(method, interpolation, fname):\n    # Deprecated NumPy 1.22, 2021-11-08\n    warnings.warn(\n        f\"the `interpolation=` argument to {fname} was renamed to \"\n        \"`method=`, which has additional options.\\n\"\n        \"Users of the modes 'nearest', 'lower', 'higher', or \"\n        \"'midpoint' are encouraged to review the method they used. \"\n        \"(Deprecated NumPy 1.22)\",\n        DeprecationWarning, stacklevel=4)\n    if method != \"linear\":\n        # sanity check, we assume this basically never happens\n        raise TypeError(\n            \"You shall not pass both `method` and `interpolation`!\\n\"\n            \"(`interpolation` is Deprecated in favor of `method`)\")\n    return interpolation\n\n\ndef _compute_virtual_index(n, quantiles, alpha: float, beta: float):\n    \"\"\"\n    Compute the floating point indexes of an array for the linear\n    interpolation of quantiles.\n    n : array_like\n        The sample sizes.\n    quantiles : array_like\n        The quantiles values.\n    alpha : float\n        A constant used to correct the index computed.\n    beta : float\n        A constant used to correct the index computed.\n\n    alpha and beta values depend on the chosen method\n    (see quantile documentation)\n\n    Reference:\n    Hyndman&Fan paper \"Sample Quantiles in Statistical Packages\",\n    DOI: 10.1080/00031305.1996.10473566\n    \"\"\"\n    return n * quantiles + (\n            alpha + quantiles * (1 - alpha - beta)\n    ) - 1\n\n\ndef _get_gamma(virtual_indexes, previous_indexes, method):\n    \"\"\"\n    Compute gamma (a.k.a 'm' or 'weight') for the linear interpolation\n    of quantiles.\n\n    virtual_indexes : array_like\n        The indexes where the percentile is supposed to be found in the sorted\n        sample.\n    previous_indexes : array_like\n        The floor values of virtual_indexes.\n    interpolation : dict\n        The interpolation method chosen, which may have a specific rule\n        modifying gamma.\n\n    gamma is usually the fractional part of virtual_indexes but can be modified\n    by the interpolation method.\n    \"\"\"\n    gamma = np.asanyarray(virtual_indexes - previous_indexes)\n    gamma = method[\"fix_gamma\"](gamma, virtual_indexes)\n    return np.asanyarray(gamma)\n\n\ndef _lerp(a, b, t, out=None):\n    \"\"\"\n    Compute the linear interpolation weighted by gamma on each point of\n    two same shape array.\n\n    a : array_like\n        Left bound.\n    b : array_like\n        Right bound.\n    t : array_like\n        The interpolation weight.\n    out : array_like\n        Output array.\n    \"\"\"\n    diff_b_a = subtract(b, a)\n    # asanyarray is a stop-gap until gh-13105\n    lerp_interpolation = asanyarray(add(a, diff_b_a * t, out=out))\n    subtract(b, diff_b_a * (1 - t), out=lerp_interpolation, where=t >= 0.5)\n    if lerp_interpolation.ndim == 0 and out is None:\n        lerp_interpolation = lerp_interpolation[()]  # unpack 0d arrays\n    return lerp_interpolation\n\n\ndef _get_gamma_mask(shape, default_value, conditioned_value, where):\n    out = np.full(shape, default_value)\n    np.copyto(out, conditioned_value, where=where, casting=\"unsafe\")\n    return out\n\n\ndef _discret_interpolation_to_boundaries(index, gamma_condition_fun):\n    previous = np.floor(index)\n    next = previous + 1\n    gamma = index - previous\n    res = _get_gamma_mask(shape=index.shape,\n                          default_value=next,\n                          conditioned_value=previous,\n                          where=gamma_condition_fun(gamma, index)\n                          ).astype(np.intp)\n    # Some methods can lead to out-of-bound integers, clip them:\n    res[res < 0] = 0\n    return res\n\n\ndef _closest_observation(n, quantiles):\n    gamma_fun = lambda gamma, index: (gamma == 0) & (np.floor(index) % 2 == 0)\n    return _discret_interpolation_to_boundaries((n * quantiles) - 1 - 0.5,\n                                                gamma_fun)\n\n\ndef _inverted_cdf(n, quantiles):\n    gamma_fun = lambda gamma, _: (gamma == 0)\n    return _discret_interpolation_to_boundaries((n * quantiles) - 1,\n                                                gamma_fun)\n\n\ndef _quantile_ureduce_func(\n        a: np.array,\n        q: np.array,\n        axis: int = None,\n        out=None,\n        overwrite_input: bool = False,\n        method=\"linear\",\n) -> np.array:\n    if q.ndim > 2:\n        # The code below works fine for nd, but it might not have useful\n        # semantics. For now, keep the supported dimensions the same as it was\n        # before.\n        raise ValueError(\"q must be a scalar or 1d\")\n    if overwrite_input:\n        if axis is None:\n            axis = 0\n            arr = a.ravel()\n        else:\n            arr = a\n    else:\n        if axis is None:\n            axis = 0\n            arr = a.flatten()\n        else:\n            arr = a.copy()\n    result = _quantile(arr,\n                       quantiles=q,\n                       axis=axis,\n                       method=method,\n                       out=out)\n    return result\n\n\ndef _get_indexes(arr, virtual_indexes, valid_values_count):\n    \"\"\"\n    Get the valid indexes of arr neighbouring virtual_indexes.\n    Note\n    This is a companion function to linear interpolation of\n    Quantiles\n\n    Returns\n    -------\n    (previous_indexes, next_indexes): Tuple\n        A Tuple of virtual_indexes neighbouring indexes\n    \"\"\"\n    previous_indexes = np.asanyarray(np.floor(virtual_indexes))\n    next_indexes = np.asanyarray(previous_indexes + 1)\n    indexes_above_bounds = virtual_indexes >= valid_values_count - 1\n    # When indexes is above max index, take the max value of the array\n    if indexes_above_bounds.any():\n        previous_indexes[indexes_above_bounds] = -1\n        next_indexes[indexes_above_bounds] = -1\n    # When indexes is below min index, take the min value of the array\n    indexes_below_bounds = virtual_indexes < 0\n    if indexes_below_bounds.any():\n        previous_indexes[indexes_below_bounds] = 0\n        next_indexes[indexes_below_bounds] = 0\n    if np.issubdtype(arr.dtype, np.inexact):\n        # After the sort, slices having NaNs will have for last element a NaN\n        virtual_indexes_nans = np.isnan(virtual_indexes)\n        if virtual_indexes_nans.any():\n            previous_indexes[virtual_indexes_nans] = -1\n            next_indexes[virtual_indexes_nans] = -1\n    previous_indexes = previous_indexes.astype(np.intp)\n    next_indexes = next_indexes.astype(np.intp)\n    return previous_indexes, next_indexes\n\n\ndef _quantile(\n        arr: np.array,\n        quantiles: np.array,\n        axis: int = -1,\n        method=\"linear\",\n        out=None,\n):\n    \"\"\"\n    Private function that doesn't support extended axis or keepdims.\n    These methods are extended to this function using _ureduce\n    See nanpercentile for parameter usage\n    It computes the quantiles of the array for the given axis.\n    A linear interpolation is performed based on the `interpolation`.\n\n    By default, the method is \"linear\" where alpha == beta == 1 which\n    performs the 7th method of Hyndman&Fan.\n    With \"median_unbiased\" we get alpha == beta == 1/3\n    thus the 8th method of Hyndman&Fan.\n    \"\"\"\n    # --- Setup\n    arr = np.asanyarray(arr)\n    values_count = arr.shape[axis]\n    # The dimensions of `q` are prepended to the output shape, so we need the\n    # axis being sampled from `arr` to be last.\n\n    if axis != 0:  # But moveaxis is slow, so only call it if necessary.\n        arr = np.moveaxis(arr, axis, destination=0)\n    # --- Computation of indexes\n    # Index where to find the value in the sorted array.\n    # Virtual because it is a floating point value, not an valid index.\n    # The nearest neighbours are used for interpolation\n    try:\n        method = _QuantileMethods[method]\n    except KeyError:\n        raise ValueError(\n            f\"{method!r} is not a valid method. Use one of: \"\n            f\"{_QuantileMethods.keys()}\") from None\n    virtual_indexes = method[\"get_virtual_index\"](values_count, quantiles)\n    virtual_indexes = np.asanyarray(virtual_indexes)\n\n    supports_nans = (\n            np.issubdtype(arr.dtype, np.inexact) or arr.dtype.kind in 'Mm')\n\n    if np.issubdtype(virtual_indexes.dtype, np.integer):\n        # No interpolation needed, take the points along axis\n        if supports_nans:\n            # may contain nan, which would sort to the end\n            arr.partition(concatenate((virtual_indexes.ravel(), [-1])), axis=0)\n            slices_having_nans = np.isnan(arr[-1, ...])\n        else:\n            # cannot contain nan\n            arr.partition(virtual_indexes.ravel(), axis=0)\n            slices_having_nans = np.array(False, dtype=bool)\n        result = take(arr, virtual_indexes, axis=0, out=out)\n    else:\n        previous_indexes, next_indexes = _get_indexes(arr,\n                                                      virtual_indexes,\n                                                      values_count)\n        # --- Sorting\n        arr.partition(\n            np.unique(np.concatenate(([0, -1],\n                                      previous_indexes.ravel(),\n                                      next_indexes.ravel(),\n                                      ))),\n            axis=0)\n        if supports_nans:\n            slices_having_nans = np.isnan(arr[-1, ...])\n        else:\n            slices_having_nans = None\n        # --- Get values from indexes\n        previous = arr[previous_indexes]\n        next = arr[next_indexes]\n        # --- Linear interpolation\n        gamma = _get_gamma(virtual_indexes, previous_indexes, method)\n        result_shape = virtual_indexes.shape + (1,) * (arr.ndim - 1)\n        gamma = gamma.reshape(result_shape)\n        result = _lerp(previous,\n                       next,\n                       gamma,\n                       out=out)\n    if np.any(slices_having_nans):\n        if result.ndim == 0 and out is None:\n            # can't write to a scalar, but indexing will be correct\n            result = arr[-1]\n        else:\n            np.copyto(result, arr[-1, ...], where=slices_having_nans)\n    return result\n\n\ndef _trapz_dispatcher(y, x=None, dx=None, axis=None):\n    return (y, x)\n\n\n@array_function_dispatch(_trapz_dispatcher)\ndef trapz(y, x=None, dx=1.0, axis=-1):\n    r\"\"\"\n    Integrate along the given axis using the composite trapezoidal rule.\n\n    If `x` is provided, the integration happens in sequence along its\n    elements - they are not sorted.\n\n    Integrate `y` (`x`) along each 1d slice on the given axis, compute\n    :math:`\\int y(x) dx`.\n    When `x` is specified, this integrates along the parametric curve,\n    computing :math:`\\int_t y(t) dt =\n    \\int_t y(t) \\left.\\frac{dx}{dt}\\right|_{x=x(t)} dt`.\n\n    Parameters\n    ----------\n    y : array_like\n        Input array to integrate.\n    x : array_like, optional\n        The sample points corresponding to the `y` values. If `x` is None,\n        the sample points are assumed to be evenly spaced `dx` apart. The\n        default is None.\n    dx : scalar, optional\n        The spacing between sample points when `x` is None. The default is 1.\n    axis : int, optional\n        The axis along which to integrate.\n\n    Returns\n    -------\n    trapz : float or ndarray\n        Definite integral of `y` = n-dimensional array as approximated along\n        a single axis by the trapezoidal rule. If `y` is a 1-dimensional array,\n        then the result is a float. If `n` is greater than 1, then the result\n        is an `n`-1 dimensional array.\n\n    See Also\n    --------\n    sum, cumsum\n\n    Notes\n    -----\n    Image [2]_ illustrates trapezoidal rule -- y-axis locations of points\n    will be taken from `y` array, by default x-axis distances between\n    points will be 1.0, alternatively they can be provided with `x` array\n    or with `dx` scalar.  Return value will be equal to combined area under\n    the red lines.\n\n\n    References\n    ----------\n    .. [1] Wikipedia page: https://en.wikipedia.org/wiki/Trapezoidal_rule\n\n    .. [2] Illustration image:\n           https://en.wikipedia.org/wiki/File:Composite_trapezoidal_rule_illustration.png\n\n    Examples\n    --------\n    Use the trapezoidal rule on evenly spaced points:\n\n    >>> np.trapz([1, 2, 3])\n    4.0\n\n    The spacing between sample points can be selected by either the\n    ``x`` or ``dx`` arguments:\n\n    >>> np.trapz([1, 2, 3], x=[4, 6, 8])\n    8.0\n    >>> np.trapz([1, 2, 3], dx=2)\n    8.0\n\n    Using a decreasing ``x`` corresponds to integrating in reverse:\n\n    >>> np.trapz([1, 2, 3], x=[8, 6, 4])\n    -8.0\n\n    More generally ``x`` is used to integrate along a parametric curve. We can\n    estimate the integral :math:`\\int_0^1 x^2 = 1/3` using:\n\n    >>> x = np.linspace(0, 1, num=50)\n    >>> y = x**2\n    >>> np.trapz(y, x)\n    0.33340274885464394\n\n    Or estimate the area of a circle, noting we repeat the sample which closes\n    the curve:\n\n    >>> theta = np.linspace(0, 2 * np.pi, num=1000, endpoint=True)\n    >>> np.trapz(np.cos(theta), x=np.sin(theta))\n    3.141571941375841\n\n    ``np.trapz`` can be applied along a specified axis to do multiple\n    computations in one call:\n\n    >>> a = np.arange(6).reshape(2, 3)\n    >>> a\n    array([[0, 1, 2],\n           [3, 4, 5]])\n    >>> np.trapz(a, axis=0)\n    array([1.5, 2.5, 3.5])\n    >>> np.trapz(a, axis=1)\n    array([2.,  8.])\n    \"\"\"\n    y = asanyarray(y)\n    if x is None:\n        d = dx\n    else:\n        x = asanyarray(x)\n        if x.ndim == 1:\n            d = diff(x)\n            # reshape to correct shape\n            shape = [1]*y.ndim\n            shape[axis] = d.shape[0]\n            d = d.reshape(shape)\n        else:\n            d = diff(x, axis=axis)\n    nd = y.ndim\n    slice1 = [slice(None)]*nd\n    slice2 = [slice(None)]*nd\n    slice1[axis] = slice(1, None)\n    slice2[axis] = slice(None, -1)\n    try:\n        ret = (d * (y[tuple(slice1)] + y[tuple(slice2)]) / 2.0).sum(axis)\n    except ValueError:\n        # Operations didn't work, cast to ndarray\n        d = np.asarray(d)\n        y = np.asarray(y)\n        ret = add.reduce(d * (y[tuple(slice1)]+y[tuple(slice2)])/2.0, axis)\n    return ret\n\n\n# __array_function__ has no __code__ or other attributes normal Python funcs we\n# wrap everything into a C callable. SciPy however, tries to \"clone\" `trapz`\n# into a new Python function which requires `__code__` and a few other\n# attributes. So we create a dummy clone and copy over its attributes allowing\n# SciPy <= 1.10 to work: https://github.com/scipy/scipy/issues/17811\nassert not hasattr(trapz, \"__code__\")\n\ndef _fake_trapz(y, x=None, dx=1.0, axis=-1):\n    return trapz(y, x=x, dx=dx, axis=axis)\n\n\ntrapz.__code__ = _fake_trapz.__code__\ntrapz.__globals__ = _fake_trapz.__globals__\ntrapz.__defaults__ = _fake_trapz.__defaults__\ntrapz.__closure__ = _fake_trapz.__closure__\ntrapz.__kwdefaults__ = _fake_trapz.__kwdefaults__\n\n\ndef _meshgrid_dispatcher(*xi, copy=None, sparse=None, indexing=None):\n    return xi\n\n\n# Based on scitools meshgrid\n@array_function_dispatch(_meshgrid_dispatcher)\ndef meshgrid(*xi, copy=True, sparse=False, indexing='xy'):\n    \"\"\"\n    Return a list of coordinate matrices from coordinate vectors.\n\n    Make N-D coordinate arrays for vectorized evaluations of\n    N-D scalar/vector fields over N-D grids, given\n    one-dimensional coordinate arrays x1, x2,..., xn.\n\n    .. versionchanged:: 1.9\n       1-D and 0-D cases are allowed.\n\n    Parameters\n    ----------\n    x1, x2,..., xn : array_like\n        1-D arrays representing the coordinates of a grid.\n    indexing : {'xy', 'ij'}, optional\n        Cartesian ('xy', default) or matrix ('ij') indexing of output.\n        See Notes for more details.\n\n        .. versionadded:: 1.7.0\n    sparse : bool, optional\n        If True the shape of the returned coordinate array for dimension *i*\n        is reduced from ``(N1, ..., Ni, ... Nn)`` to\n        ``(1, ..., 1, Ni, 1, ..., 1)``.  These sparse coordinate grids are\n        intended to be use with :ref:`basics.broadcasting`.  When all\n        coordinates are used in an expression, broadcasting still leads to a\n        fully-dimensonal result array.\n\n        Default is False.\n\n        .. versionadded:: 1.7.0\n    copy : bool, optional\n        If False, a view into the original arrays are returned in order to\n        conserve memory.  Default is True.  Please note that\n        ``sparse=False, copy=False`` will likely return non-contiguous\n        arrays.  Furthermore, more than one element of a broadcast array\n        may refer to a single memory location.  If you need to write to the\n        arrays, make copies first.\n\n        .. versionadded:: 1.7.0\n\n    Returns\n    -------\n    X1, X2,..., XN : list of ndarrays\n        For vectors `x1`, `x2`,..., `xn` with lengths ``Ni=len(xi)``,\n        returns ``(N1, N2, N3,..., Nn)`` shaped arrays if indexing='ij'\n        or ``(N2, N1, N3,..., Nn)`` shaped arrays if indexing='xy'\n        with the elements of `xi` repeated to fill the matrix along\n        the first dimension for `x1`, the second for `x2` and so on.\n\n    Notes\n    -----\n    This function supports both indexing conventions through the indexing\n    keyword argument.  Giving the string 'ij' returns a meshgrid with\n    matrix indexing, while 'xy' returns a meshgrid with Cartesian indexing.\n    In the 2-D case with inputs of length M and N, the outputs are of shape\n    (N, M) for 'xy' indexing and (M, N) for 'ij' indexing.  In the 3-D case\n    with inputs of length M, N and P, outputs are of shape (N, M, P) for\n    'xy' indexing and (M, N, P) for 'ij' indexing.  The difference is\n    illustrated by the following code snippet::\n\n        xv, yv = np.meshgrid(x, y, indexing='ij')\n        for i in range(nx):\n            for j in range(ny):\n                # treat xv[i,j], yv[i,j]\n\n        xv, yv = np.meshgrid(x, y, indexing='xy')\n        for i in range(nx):\n            for j in range(ny):\n                # treat xv[j,i], yv[j,i]\n\n    In the 1-D and 0-D case, the indexing and sparse keywords have no effect.\n\n    See Also\n    --------\n    mgrid : Construct a multi-dimensional \"meshgrid\" using indexing notation.\n    ogrid : Construct an open multi-dimensional \"meshgrid\" using indexing\n            notation.\n    how-to-index\n\n    Examples\n    --------\n    >>> nx, ny = (3, 2)\n    >>> x = np.linspace(0, 1, nx)\n    >>> y = np.linspace(0, 1, ny)\n    >>> xv, yv = np.meshgrid(x, y)\n    >>> xv\n    array([[0. , 0.5, 1. ],\n           [0. , 0.5, 1. ]])\n    >>> yv\n    array([[0.,  0.,  0.],\n           [1.,  1.,  1.]])\n\n    The result of `meshgrid` is a coordinate grid:\n\n    >>> import matplotlib.pyplot as plt\n    >>> plt.plot(xv, yv, marker='o', color='k', linestyle='none')\n    >>> plt.show()\n\n    You can create sparse output arrays to save memory and computation time.\n\n    >>> xv, yv = np.meshgrid(x, y, sparse=True)\n    >>> xv\n    array([[0. ,  0.5,  1. ]])\n    >>> yv\n    array([[0.],\n           [1.]])\n\n    `meshgrid` is very useful to evaluate functions on a grid. If the\n    function depends on all coordinates, both dense and sparse outputs can be\n    used.\n\n    >>> x = np.linspace(-5, 5, 101)\n    >>> y = np.linspace(-5, 5, 101)\n    >>> # full coordinate arrays\n    >>> xx, yy = np.meshgrid(x, y)\n    >>> zz = np.sqrt(xx**2 + yy**2)\n    >>> xx.shape, yy.shape, zz.shape\n    ((101, 101), (101, 101), (101, 101))\n    >>> # sparse coordinate arrays\n    >>> xs, ys = np.meshgrid(x, y, sparse=True)\n    >>> zs = np.sqrt(xs**2 + ys**2)\n    >>> xs.shape, ys.shape, zs.shape\n    ((1, 101), (101, 1), (101, 101))\n    >>> np.array_equal(zz, zs)\n    True\n\n    >>> h = plt.contourf(x, y, zs)\n    >>> plt.axis('scaled')\n    >>> plt.colorbar()\n    >>> plt.show()\n    \"\"\"\n    ndim = len(xi)\n\n    if indexing not in ['xy', 'ij']:\n        raise ValueError(\n            \"Valid values for `indexing` are 'xy' and 'ij'.\")\n\n    s0 = (1,) * ndim\n    output = [np.asanyarray(x).reshape(s0[:i] + (-1,) + s0[i + 1:])\n              for i, x in enumerate(xi)]\n\n    if indexing == 'xy' and ndim > 1:\n        # switch first and second axis\n        output[0].shape = (1, -1) + s0[2:]\n        output[1].shape = (-1, 1) + s0[2:]\n\n    if not sparse:\n        # Return the full N-D matrix (not only the 1-D vector)\n        output = np.broadcast_arrays(*output, subok=True)\n\n    if copy:\n        output = [x.copy() for x in output]\n\n    return output\n\n\ndef _delete_dispatcher(arr, obj, axis=None):\n    return (arr, obj)\n\n\n@array_function_dispatch(_delete_dispatcher)\ndef delete(arr, obj, axis=None):\n    \"\"\"\n    Return a new array with sub-arrays along an axis deleted. For a one\n    dimensional array, this returns those entries not returned by\n    `arr[obj]`.\n\n    Parameters\n    ----------\n    arr : array_like\n        Input array.\n    obj : slice, int or array of ints\n        Indicate indices of sub-arrays to remove along the specified axis.\n\n        .. versionchanged:: 1.19.0\n            Boolean indices are now treated as a mask of elements to remove,\n            rather than being cast to the integers 0 and 1.\n\n    axis : int, optional\n        The axis along which to delete the subarray defined by `obj`.\n        If `axis` is None, `obj` is applied to the flattened array.\n\n    Returns\n    -------\n    out : ndarray\n        A copy of `arr` with the elements specified by `obj` removed. Note\n        that `delete` does not occur in-place. If `axis` is None, `out` is\n        a flattened array.\n\n    See Also\n    --------\n    insert : Insert elements into an array.\n    append : Append elements at the end of an array.\n\n    Notes\n    -----\n    Often it is preferable to use a boolean mask. For example:\n\n    >>> arr = np.arange(12) + 1\n    >>> mask = np.ones(len(arr), dtype=bool)\n    >>> mask[[0,2,4]] = False\n    >>> result = arr[mask,...]\n\n    Is equivalent to ``np.delete(arr, [0,2,4], axis=0)``, but allows further\n    use of `mask`.\n\n    Examples\n    --------\n    >>> arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n    >>> arr\n    array([[ 1,  2,  3,  4],\n           [ 5,  6,  7,  8],\n           [ 9, 10, 11, 12]])\n    >>> np.delete(arr, 1, 0)\n    array([[ 1,  2,  3,  4],\n           [ 9, 10, 11, 12]])\n\n    >>> np.delete(arr, np.s_[::2], 1)\n    array([[ 2,  4],\n           [ 6,  8],\n           [10, 12]])\n    >>> np.delete(arr, [1,3,5], None)\n    array([ 1,  3,  5,  7,  8,  9, 10, 11, 12])\n\n    \"\"\"\n    wrap = None\n    if type(arr) is not ndarray:\n        try:\n            wrap = arr.__array_wrap__\n        except AttributeError:\n            pass\n\n    arr = asarray(arr)\n    ndim = arr.ndim\n    arrorder = 'F' if arr.flags.fnc else 'C'\n    if axis is None:\n        if ndim != 1:\n            arr = arr.ravel()\n        # needed for np.matrix, which is still not 1d after being ravelled\n        ndim = arr.ndim\n        axis = ndim - 1\n    else:\n        axis = normalize_axis_index(axis, ndim)\n\n    slobj = [slice(None)]*ndim\n    N = arr.shape[axis]\n    newshape = list(arr.shape)\n\n    if isinstance(obj, slice):\n        start, stop, step = obj.indices(N)\n        xr = range(start, stop, step)\n        numtodel = len(xr)\n\n        if numtodel <= 0:\n            if wrap:\n                return wrap(arr.copy(order=arrorder))\n            else:\n                return arr.copy(order=arrorder)\n\n        # Invert if step is negative:\n        if step < 0:\n            step = -step\n            start = xr[-1]\n            stop = xr[0] + 1\n\n        newshape[axis] -= numtodel\n        new = empty(newshape, arr.dtype, arrorder)\n        # copy initial chunk\n        if start == 0:\n            pass\n        else:\n            slobj[axis] = slice(None, start)\n            new[tuple(slobj)] = arr[tuple(slobj)]\n        # copy end chunk\n        if stop == N:\n            pass\n        else:\n            slobj[axis] = slice(stop-numtodel, None)\n            slobj2 = [slice(None)]*ndim\n            slobj2[axis] = slice(stop, None)\n            new[tuple(slobj)] = arr[tuple(slobj2)]\n        # copy middle pieces\n        if step == 1:\n            pass\n        else:  # use array indexing.\n            keep = ones(stop-start, dtype=bool)\n            keep[:stop-start:step] = False\n            slobj[axis] = slice(start, stop-numtodel)\n            slobj2 = [slice(None)]*ndim\n            slobj2[axis] = slice(start, stop)\n            arr = arr[tuple(slobj2)]\n            slobj2[axis] = keep\n            new[tuple(slobj)] = arr[tuple(slobj2)]\n        if wrap:\n            return wrap(new)\n        else:\n            return new\n\n    if isinstance(obj, (int, integer)) and not isinstance(obj, bool):\n        single_value = True\n    else:\n        single_value = False\n        _obj = obj\n        obj = np.asarray(obj)\n        # `size == 0` to allow empty lists similar to indexing, but (as there)\n        # is really too generic:\n        if obj.size == 0 and not isinstance(_obj, np.ndarray):\n            obj = obj.astype(intp)\n        elif obj.size == 1 and obj.dtype.kind in \"ui\":\n            # For a size 1 integer array we can use the single-value path\n            # (most dtypes, except boolean, should just fail later).\n            obj = obj.item()\n            single_value = True\n\n    if single_value:\n        # optimization for a single value\n        if (obj < -N or obj >= N):\n            raise IndexError(\n                \"index %i is out of bounds for axis %i with \"\n                \"size %i\" % (obj, axis, N))\n        if (obj < 0):\n            obj += N\n        newshape[axis] -= 1\n        new = empty(newshape, arr.dtype, arrorder)\n        slobj[axis] = slice(None, obj)\n        new[tuple(slobj)] = arr[tuple(slobj)]\n        slobj[axis] = slice(obj, None)\n        slobj2 = [slice(None)]*ndim\n        slobj2[axis] = slice(obj+1, None)\n        new[tuple(slobj)] = arr[tuple(slobj2)]\n    else:\n        if obj.dtype == bool:\n            if obj.shape != (N,):\n                raise ValueError('boolean array argument obj to delete '\n                                 'must be one dimensional and match the axis '\n                                 'length of {}'.format(N))\n\n            # optimization, the other branch is slower\n            keep = ~obj\n        else:\n            keep = ones(N, dtype=bool)\n            keep[obj,] = False\n\n        slobj[axis] = keep\n        new = arr[tuple(slobj)]\n\n    if wrap:\n        return wrap(new)\n    else:\n        return new\n\n\ndef _insert_dispatcher(arr, obj, values, axis=None):\n    return (arr, obj, values)\n\n\n@array_function_dispatch(_insert_dispatcher)\ndef insert(arr, obj, values, axis=None):\n    \"\"\"\n    Insert values along the given axis before the given indices.\n\n    Parameters\n    ----------\n    arr : array_like\n        Input array.\n    obj : int, slice or sequence of ints\n        Object that defines the index or indices before which `values` is\n        inserted.\n\n        .. versionadded:: 1.8.0\n\n        Support for multiple insertions when `obj` is a single scalar or a\n        sequence with one element (similar to calling insert multiple\n        times).\n    values : array_like\n        Values to insert into `arr`. If the type of `values` is different\n        from that of `arr`, `values` is converted to the type of `arr`.\n        `values` should be shaped so that ``arr[...,obj,...] = values``\n        is legal.\n    axis : int, optional\n        Axis along which to insert `values`.  If `axis` is None then `arr`\n        is flattened first.\n\n    Returns\n    -------\n    out : ndarray\n        A copy of `arr` with `values` inserted.  Note that `insert`\n        does not occur in-place: a new array is returned. If\n        `axis` is None, `out` is a flattened array.\n\n    See Also\n    --------\n    append : Append elements at the end of an array.\n    concatenate : Join a sequence of arrays along an existing axis.\n    delete : Delete elements from an array.\n\n    Notes\n    -----\n    Note that for higher dimensional inserts ``obj=0`` behaves very different\n    from ``obj=[0]`` just like ``arr[:,0,:] = values`` is different from\n    ``arr[:,[0],:] = values``.\n\n    Examples\n    --------\n    >>> a = np.array([[1, 1], [2, 2], [3, 3]])\n    >>> a\n    array([[1, 1],\n           [2, 2],\n           [3, 3]])\n    >>> np.insert(a, 1, 5)\n    array([1, 5, 1, ..., 2, 3, 3])\n    >>> np.insert(a, 1, 5, axis=1)\n    array([[1, 5, 1],\n           [2, 5, 2],\n           [3, 5, 3]])\n\n    Difference between sequence and scalars:\n\n    >>> np.insert(a, [1], [[1],[2],[3]], axis=1)\n    array([[1, 1, 1],\n           [2, 2, 2],\n           [3, 3, 3]])\n    >>> np.array_equal(np.insert(a, 1, [1, 2, 3], axis=1),\n    ...                np.insert(a, [1], [[1],[2],[3]], axis=1))\n    True\n\n    >>> b = a.flatten()\n    >>> b\n    array([1, 1, 2, 2, 3, 3])\n    >>> np.insert(b, [2, 2], [5, 6])\n    array([1, 1, 5, ..., 2, 3, 3])\n\n    >>> np.insert(b, slice(2, 4), [5, 6])\n    array([1, 1, 5, ..., 2, 3, 3])\n\n    >>> np.insert(b, [2, 2], [7.13, False]) # type casting\n    array([1, 1, 7, ..., 2, 3, 3])\n\n    >>> x = np.arange(8).reshape(2, 4)\n    >>> idx = (1, 3)\n    >>> np.insert(x, idx, 999, axis=1)\n    array([[  0, 999,   1,   2, 999,   3],\n           [  4, 999,   5,   6, 999,   7]])\n\n    \"\"\"\n    wrap = None\n    if type(arr) is not ndarray:\n        try:\n            wrap = arr.__array_wrap__\n        except AttributeError:\n            pass\n\n    arr = asarray(arr)\n    ndim = arr.ndim\n    arrorder = 'F' if arr.flags.fnc else 'C'\n    if axis is None:\n        if ndim != 1:\n            arr = arr.ravel()\n        # needed for np.matrix, which is still not 1d after being ravelled\n        ndim = arr.ndim\n        axis = ndim - 1\n    else:\n        axis = normalize_axis_index(axis, ndim)\n    slobj = [slice(None)]*ndim\n    N = arr.shape[axis]\n    newshape = list(arr.shape)\n\n    if isinstance(obj, slice):\n        # turn it into a range object\n        indices = arange(*obj.indices(N), dtype=intp)\n    else:\n        # need to copy obj, because indices will be changed in-place\n        indices = np.array(obj)\n        if indices.dtype == bool:\n            # See also delete\n            # 2012-10-11, NumPy 1.8\n            warnings.warn(\n                \"in the future insert will treat boolean arrays and \"\n                \"array-likes as a boolean index instead of casting it to \"\n                \"integer\", FutureWarning, stacklevel=2)\n            indices = indices.astype(intp)\n            # Code after warning period:\n            #if obj.ndim != 1:\n            #    raise ValueError('boolean array argument obj to insert '\n            #                     'must be one dimensional')\n            #indices = np.flatnonzero(obj)\n        elif indices.ndim > 1:\n            raise ValueError(\n                \"index array argument obj to insert must be one dimensional \"\n                \"or scalar\")\n    if indices.size == 1:\n        index = indices.item()\n        if index < -N or index > N:\n            raise IndexError(f\"index {obj} is out of bounds for axis {axis} \"\n                             f\"with size {N}\")\n        if (index < 0):\n            index += N\n\n        # There are some object array corner cases here, but we cannot avoid\n        # that:\n        values = array(values, copy=False, ndmin=arr.ndim, dtype=arr.dtype)\n        if indices.ndim == 0:\n            # broadcasting is very different here, since a[:,0,:] = ... behaves\n            # very different from a[:,[0],:] = ...! This changes values so that\n            # it works likes the second case. (here a[:,0:1,:])\n            values = np.moveaxis(values, 0, axis)\n        numnew = values.shape[axis]\n        newshape[axis] += numnew\n        new = empty(newshape, arr.dtype, arrorder)\n        slobj[axis] = slice(None, index)\n        new[tuple(slobj)] = arr[tuple(slobj)]\n        slobj[axis] = slice(index, index+numnew)\n        new[tuple(slobj)] = values\n        slobj[axis] = slice(index+numnew, None)\n        slobj2 = [slice(None)] * ndim\n        slobj2[axis] = slice(index, None)\n        new[tuple(slobj)] = arr[tuple(slobj2)]\n        if wrap:\n            return wrap(new)\n        return new\n    elif indices.size == 0 and not isinstance(obj, np.ndarray):\n        # Can safely cast the empty list to intp\n        indices = indices.astype(intp)\n\n    indices[indices < 0] += N\n\n    numnew = len(indices)\n    order = indices.argsort(kind='mergesort')   # stable sort\n    indices[order] += np.arange(numnew)\n\n    newshape[axis] += numnew\n    old_mask = ones(newshape[axis], dtype=bool)\n    old_mask[indices] = False\n\n    new = empty(newshape, arr.dtype, arrorder)\n    slobj2 = [slice(None)]*ndim\n    slobj[axis] = indices\n    slobj2[axis] = old_mask\n    new[tuple(slobj)] = values\n    new[tuple(slobj2)] = arr\n\n    if wrap:\n        return wrap(new)\n    return new\n\n\ndef _append_dispatcher(arr, values, axis=None):\n    return (arr, values)\n\n\n@array_function_dispatch(_append_dispatcher)\ndef append(arr, values, axis=None):\n    \"\"\"\n    Append values to the end of an array.\n\n    Parameters\n    ----------\n    arr : array_like\n        Values are appended to a copy of this array.\n    values : array_like\n        These values are appended to a copy of `arr`.  It must be of the\n        correct shape (the same shape as `arr`, excluding `axis`).  If\n        `axis` is not specified, `values` can be any shape and will be\n        flattened before use.\n    axis : int, optional\n        The axis along which `values` are appended.  If `axis` is not\n        given, both `arr` and `values` are flattened before use.\n\n    Returns\n    -------\n    append : ndarray\n        A copy of `arr` with `values` appended to `axis`.  Note that\n        `append` does not occur in-place: a new array is allocated and\n        filled.  If `axis` is None, `out` is a flattened array.\n\n    See Also\n    --------\n    insert : Insert elements into an array.\n    delete : Delete elements from an array.\n\n    Examples\n    --------\n    >>> np.append([1, 2, 3], [[4, 5, 6], [7, 8, 9]])\n    array([1, 2, 3, ..., 7, 8, 9])\n\n    When `axis` is specified, `values` must have the correct shape.\n\n    >>> np.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0)\n    array([[1, 2, 3],\n           [4, 5, 6],\n           [7, 8, 9]])\n    >>> np.append([[1, 2, 3], [4, 5, 6]], [7, 8, 9], axis=0)\n    Traceback (most recent call last):\n        ...\n    ValueError: all the input arrays must have same number of dimensions, but\n    the array at index 0 has 2 dimension(s) and the array at index 1 has 1\n    dimension(s)\n\n    \"\"\"\n    arr = asanyarray(arr)\n    if axis is None:\n        if arr.ndim != 1:\n            arr = arr.ravel()\n        values = ravel(values)\n        axis = arr.ndim-1\n    return concatenate((arr, values), axis=axis)\n\n\ndef _digitize_dispatcher(x, bins, right=None):\n    return (x, bins)\n\n\n@array_function_dispatch(_digitize_dispatcher)\ndef digitize(x, bins, right=False):\n    \"\"\"\n    Return the indices of the bins to which each value in input array belongs.\n\n    =========  =============  ============================\n    `right`    order of bins  returned index `i` satisfies\n    =========  =============  ============================\n    ``False``  increasing     ``bins[i-1] <= x < bins[i]``\n    ``True``   increasing     ``bins[i-1] < x <= bins[i]``\n    ``False``  decreasing     ``bins[i-1] > x >= bins[i]``\n    ``True``   decreasing     ``bins[i-1] >= x > bins[i]``\n    =========  =============  ============================\n\n    If values in `x` are beyond the bounds of `bins`, 0 or ``len(bins)`` is\n    returned as appropriate.\n\n    Parameters\n    ----------\n    x : array_like\n        Input array to be binned. Prior to NumPy 1.10.0, this array had to\n        be 1-dimensional, but can now have any shape.\n    bins : array_like\n        Array of bins. It has to be 1-dimensional and monotonic.\n    right : bool, optional\n        Indicating whether the intervals include the right or the left bin\n        edge. Default behavior is (right==False) indicating that the interval\n        does not include the right edge. The left bin end is open in this\n        case, i.e., bins[i-1] <= x < bins[i] is the default behavior for\n        monotonically increasing bins.\n\n    Returns\n    -------\n    indices : ndarray of ints\n        Output array of indices, of same shape as `x`.\n\n    Raises\n    ------\n    ValueError\n        If `bins` is not monotonic.\n    TypeError\n        If the type of the input is complex.\n\n    See Also\n    --------\n    bincount, histogram, unique, searchsorted\n\n    Notes\n    -----\n    If values in `x` are such that they fall outside the bin range,\n    attempting to index `bins` with the indices that `digitize` returns\n    will result in an IndexError.\n\n    .. versionadded:: 1.10.0\n\n    `np.digitize` is  implemented in terms of `np.searchsorted`. This means\n    that a binary search is used to bin the values, which scales much better\n    for larger number of bins than the previous linear search. It also removes\n    the requirement for the input array to be 1-dimensional.\n\n    For monotonically _increasing_ `bins`, the following are equivalent::\n\n        np.digitize(x, bins, right=True)\n        np.searchsorted(bins, x, side='left')\n\n    Note that as the order of the arguments are reversed, the side must be too.\n    The `searchsorted` call is marginally faster, as it does not do any\n    monotonicity checks. Perhaps more importantly, it supports all dtypes.\n\n    Examples\n    --------\n    >>> x = np.array([0.2, 6.4, 3.0, 1.6])\n    >>> bins = np.array([0.0, 1.0, 2.5, 4.0, 10.0])\n    >>> inds = np.digitize(x, bins)\n    >>> inds\n    array([1, 4, 3, 2])\n    >>> for n in range(x.size):\n    ...   print(bins[inds[n]-1], \"<=\", x[n], \"<\", bins[inds[n]])\n    ...\n    0.0 <= 0.2 < 1.0\n    4.0 <= 6.4 < 10.0\n    2.5 <= 3.0 < 4.0\n    1.0 <= 1.6 < 2.5\n\n    >>> x = np.array([1.2, 10.0, 12.4, 15.5, 20.])\n    >>> bins = np.array([0, 5, 10, 15, 20])\n    >>> np.digitize(x,bins,right=True)\n    array([1, 2, 3, 4, 4])\n    >>> np.digitize(x,bins,right=False)\n    array([1, 3, 3, 4, 5])\n    \"\"\"\n    x = _nx.asarray(x)\n    bins = _nx.asarray(bins)\n\n    # here for compatibility, searchsorted below is happy to take this\n    if np.issubdtype(x.dtype, _nx.complexfloating):\n        raise TypeError(\"x may not be complex\")\n\n    mono = _monotonicity(bins)\n    if mono == 0:\n        raise ValueError(\"bins must be monotonically increasing or decreasing\")\n\n    # this is backwards because the arguments below are swapped\n    side = 'left' if right else 'right'\n    if mono == -1:\n        # reverse the bins, and invert the results\n        return len(bins) - _nx.searchsorted(bins[::-1], x, side=side)\n    else:\n        return _nx.searchsorted(bins, x, side=side)\n",5732],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py":["\"\"\"\nArray methods which are called by both the C-code for the method\nand the Python code for the NumPy-namespace function\n\n\"\"\"\nimport warnings\nfrom contextlib import nullcontext\n\nfrom numpy.core import multiarray as mu\nfrom numpy.core import umath as um\nfrom numpy.core.multiarray import asanyarray\nfrom numpy.core import numerictypes as nt\nfrom numpy.core import _exceptions\nfrom numpy.core._ufunc_config import _no_nep50_warning\nfrom numpy._globals import _NoValue\nfrom numpy.compat import pickle, os_fspath\n\n# save those O(100) nanoseconds!\numr_maximum = um.maximum.reduce\numr_minimum = um.minimum.reduce\numr_sum = um.add.reduce\numr_prod = um.multiply.reduce\numr_any = um.logical_or.reduce\numr_all = um.logical_and.reduce\n\n# Complex types to -> (2,)float view for fast-path computation in _var()\n_complex_to_float = {\n    nt.dtype(nt.csingle) : nt.dtype(nt.single),\n    nt.dtype(nt.cdouble) : nt.dtype(nt.double),\n}\n# Special case for windows: ensure double takes precedence\nif nt.dtype(nt.longdouble) != nt.dtype(nt.double):\n    _complex_to_float.update({\n        nt.dtype(nt.clongdouble) : nt.dtype(nt.longdouble),\n    })\n\n# avoid keyword arguments to speed up parsing, saves about 15%-20% for very\n# small reductions\ndef _amax(a, axis=None, out=None, keepdims=False,\n          initial=_NoValue, where=True):\n    return umr_maximum(a, axis, None, out, keepdims, initial, where)\n\ndef _amin(a, axis=None, out=None, keepdims=False,\n          initial=_NoValue, where=True):\n    return umr_minimum(a, axis, None, out, keepdims, initial, where)\n\ndef _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n         initial=_NoValue, where=True):\n    return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\ndef _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n          initial=_NoValue, where=True):\n    return umr_prod(a, axis, dtype, out, keepdims, initial, where)\n\ndef _any(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):\n    # Parsing keyword arguments is currently fairly slow, so avoid it for now\n    if where is True:\n        return umr_any(a, axis, dtype, out, keepdims)\n    return umr_any(a, axis, dtype, out, keepdims, where=where)\n\ndef _all(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):\n    # Parsing keyword arguments is currently fairly slow, so avoid it for now\n    if where is True:\n        return umr_all(a, axis, dtype, out, keepdims)\n    return umr_all(a, axis, dtype, out, keepdims, where=where)\n\ndef _count_reduce_items(arr, axis, keepdims=False, where=True):\n    # fast-path for the default case\n    if where is True:\n        # no boolean mask given, calculate items according to axis\n        if axis is None:\n            axis = tuple(range(arr.ndim))\n        elif not isinstance(axis, tuple):\n            axis = (axis,)\n        items = 1\n        for ax in axis:\n            items *= arr.shape[mu.normalize_axis_index(ax, arr.ndim)]\n        items = nt.intp(items)\n    else:\n        # TODO: Optimize case when `where` is broadcast along a non-reduction\n        # axis and full sum is more excessive than needed.\n\n        # guarded to protect circular imports\n        from numpy.lib.stride_tricks import broadcast_to\n        # count True values in (potentially broadcasted) boolean mask\n        items = umr_sum(broadcast_to(where, arr.shape), axis, nt.intp, None,\n                        keepdims)\n    return items\n\ndef _clip(a, min=None, max=None, out=None, **kwargs):\n    if min is None and max is None:\n        raise ValueError(\"One of max or min must be given\")\n\n    if min is None:\n        return um.minimum(a, max, out=out, **kwargs)\n    elif max is None:\n        return um.maximum(a, min, out=out, **kwargs)\n    else:\n        return um.clip(a, min, max, out=out, **kwargs)\n\ndef _mean(a, axis=None, dtype=None, out=None, keepdims=False, *, where=True):\n    arr = asanyarray(a)\n\n    is_float16_result = False\n\n    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n    if rcount == 0 if where is True else umr_any(rcount == 0, axis=None):\n        warnings.warn(\"Mean of empty slice.\", RuntimeWarning, stacklevel=2)\n\n    # Cast bool, unsigned int, and int to float64 by default\n    if dtype is None:\n        if issubclass(arr.dtype.type, (nt.integer, nt.bool_)):\n            dtype = mu.dtype('f8')\n        elif issubclass(arr.dtype.type, nt.float16):\n            dtype = mu.dtype('f4')\n            is_float16_result = True\n\n    ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n    if isinstance(ret, mu.ndarray):\n        with _no_nep50_warning():\n            ret = um.true_divide(\n                    ret, rcount, out=ret, casting='unsafe', subok=False)\n        if is_float16_result and out is None:\n            ret = arr.dtype.type(ret)\n    elif hasattr(ret, 'dtype'):\n        if is_float16_result:\n            ret = arr.dtype.type(ret / rcount)\n        else:\n            ret = ret.dtype.type(ret / rcount)\n    else:\n        ret = ret / rcount\n\n    return ret\n\ndef _var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,\n         where=True):\n    arr = asanyarray(a)\n\n    rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n    # Make this warning show up on top.\n    if ddof >= rcount if where is True else umr_any(ddof >= rcount, axis=None):\n        warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning,\n                      stacklevel=2)\n\n    # Cast bool, unsigned int, and int to float64 by default\n    if dtype is None and issubclass(arr.dtype.type, (nt.integer, nt.bool_)):\n        dtype = mu.dtype('f8')\n\n    # Compute the mean.\n    # Note that if dtype is not of inexact type then arraymean will\n    # not be either.\n    arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n    # The shape of rcount has to match arrmean to not change the shape of out\n    # in broadcasting. Otherwise, it cannot be stored back to arrmean.\n    if rcount.ndim == 0:\n        # fast-path for default case when where is True\n        div = rcount\n    else:\n        # matching rcount to arrmean when where is specified as array\n        div = rcount.reshape(arrmean.shape)\n    if isinstance(arrmean, mu.ndarray):\n        with _no_nep50_warning():\n            arrmean = um.true_divide(arrmean, div, out=arrmean,\n                                     casting='unsafe', subok=False)\n    elif hasattr(arrmean, \"dtype\"):\n        arrmean = arrmean.dtype.type(arrmean / rcount)\n    else:\n        arrmean = arrmean / rcount\n\n    # Compute sum of squared deviations from mean\n    # Note that x may not be inexact and that we need it to be an array,\n    # not a scalar.\n    x = asanyarray(arr - arrmean)\n\n    if issubclass(arr.dtype.type, (nt.floating, nt.integer)):\n        x = um.multiply(x, x, out=x)\n    # Fast-paths for built-in complex types\n    elif x.dtype in _complex_to_float:\n        xv = x.view(dtype=(_complex_to_float[x.dtype], (2,)))\n        um.multiply(xv, xv, out=xv)\n        x = um.add(xv[..., 0], xv[..., 1], out=x.real).real\n    # Most general case; includes handling object arrays containing imaginary\n    # numbers and complex types with non-native byteorder\n    else:\n        x = um.multiply(x, um.conjugate(x), out=x).real\n\n    ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n\n    # Compute degrees of freedom and make sure it is not negative.\n    rcount = um.maximum(rcount - ddof, 0)\n\n    # divide by degrees of freedom\n    if isinstance(ret, mu.ndarray):\n        with _no_nep50_warning():\n            ret = um.true_divide(\n                    ret, rcount, out=ret, casting='unsafe', subok=False)\n    elif hasattr(ret, 'dtype'):\n        ret = ret.dtype.type(ret / rcount)\n    else:\n        ret = ret / rcount\n\n    return ret\n\ndef _std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *,\n         where=True):\n    ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n               keepdims=keepdims, where=where)\n\n    if isinstance(ret, mu.ndarray):\n        ret = um.sqrt(ret, out=ret)\n    elif hasattr(ret, 'dtype'):\n        ret = ret.dtype.type(um.sqrt(ret))\n    else:\n        ret = um.sqrt(ret)\n\n    return ret\n\ndef _ptp(a, axis=None, out=None, keepdims=False):\n    return um.subtract(\n        umr_maximum(a, axis, None, out, keepdims),\n        umr_minimum(a, axis, None, None, keepdims),\n        out\n    )\n\ndef _dump(self, file, protocol=2):\n    if hasattr(file, 'write'):\n        ctx = nullcontext(file)\n    else:\n        ctx = open(os_fspath(file), \"wb\")\n    with ctx as f:\n        pickle.dump(self, f, protocol=protocol)\n\ndef _dumps(self, protocol=2):\n    return pickle.dumps(self, protocol=protocol)\n",234],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_ufunc_config.py":["\"\"\"\nFunctions for changing global ufunc configuration\n\nThis provides helpers which wrap `umath.geterrobj` and `umath.seterrobj`\n\"\"\"\nimport collections.abc\nimport contextlib\nimport contextvars\n\nfrom .._utils import set_module\nfrom .umath import (\n    UFUNC_BUFSIZE_DEFAULT,\n    ERR_IGNORE, ERR_WARN, ERR_RAISE, ERR_CALL, ERR_PRINT, ERR_LOG, ERR_DEFAULT,\n    SHIFT_DIVIDEBYZERO, SHIFT_OVERFLOW, SHIFT_UNDERFLOW, SHIFT_INVALID,\n)\nfrom . import umath\n\n__all__ = [\n    \"seterr\", \"geterr\", \"setbufsize\", \"getbufsize\", \"seterrcall\", \"geterrcall\",\n    \"errstate\", '_no_nep50_warning'\n]\n\n_errdict = {\"ignore\": ERR_IGNORE,\n            \"warn\": ERR_WARN,\n            \"raise\": ERR_RAISE,\n            \"call\": ERR_CALL,\n            \"print\": ERR_PRINT,\n            \"log\": ERR_LOG}\n\n_errdict_rev = {value: key for key, value in _errdict.items()}\n\n\n@set_module('numpy')\ndef seterr(all=None, divide=None, over=None, under=None, invalid=None):\n    \"\"\"\n    Set how floating-point errors are handled.\n\n    Note that operations on integer scalar types (such as `int16`) are\n    handled like floating point, and are affected by these settings.\n\n    Parameters\n    ----------\n    all : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n        Set treatment for all types of floating-point errors at once:\n\n        - ignore: Take no action when the exception occurs.\n        - warn: Print a `RuntimeWarning` (via the Python `warnings` module).\n        - raise: Raise a `FloatingPointError`.\n        - call: Call a function specified using the `seterrcall` function.\n        - print: Print a warning directly to ``stdout``.\n        - log: Record error in a Log object specified by `seterrcall`.\n\n        The default is not to change the current behavior.\n    divide : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n        Treatment for division by zero.\n    over : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n        Treatment for floating-point overflow.\n    under : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n        Treatment for floating-point underflow.\n    invalid : {'ignore', 'warn', 'raise', 'call', 'print', 'log'}, optional\n        Treatment for invalid floating-point operation.\n\n    Returns\n    -------\n    old_settings : dict\n        Dictionary containing the old settings.\n\n    See also\n    --------\n    seterrcall : Set a callback function for the 'call' mode.\n    geterr, geterrcall, errstate\n\n    Notes\n    -----\n    The floating-point exceptions are defined in the IEEE 754 standard [1]_:\n\n    - Division by zero: infinite result obtained from finite numbers.\n    - Overflow: result too large to be expressed.\n    - Underflow: result so close to zero that some precision\n      was lost.\n    - Invalid operation: result is not an expressible number, typically\n      indicates that a NaN was produced.\n\n    .. [1] https://en.wikipedia.org/wiki/IEEE_754\n\n    Examples\n    --------\n    >>> old_settings = np.seterr(all='ignore')  #seterr to known value\n    >>> np.seterr(over='raise')\n    {'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'}\n    >>> np.seterr(**old_settings)  # reset to default\n    {'divide': 'ignore', 'over': 'raise', 'under': 'ignore', 'invalid': 'ignore'}\n\n    >>> np.int16(32000) * np.int16(3)\n    30464\n    >>> old_settings = np.seterr(all='warn', over='raise')\n    >>> np.int16(32000) * np.int16(3)\n    Traceback (most recent call last):\n      File \"<stdin>\", line 1, in <module>\n    FloatingPointError: overflow encountered in scalar multiply\n\n    >>> old_settings = np.seterr(all='print')\n    >>> np.geterr()\n    {'divide': 'print', 'over': 'print', 'under': 'print', 'invalid': 'print'}\n    >>> np.int16(32000) * np.int16(3)\n    30464\n\n    \"\"\"\n\n    pyvals = umath.geterrobj()\n    old = geterr()\n\n    if divide is None:\n        divide = all or old['divide']\n    if over is None:\n        over = all or old['over']\n    if under is None:\n        under = all or old['under']\n    if invalid is None:\n        invalid = all or old['invalid']\n\n    maskvalue = ((_errdict[divide] << SHIFT_DIVIDEBYZERO) +\n                 (_errdict[over] << SHIFT_OVERFLOW) +\n                 (_errdict[under] << SHIFT_UNDERFLOW) +\n                 (_errdict[invalid] << SHIFT_INVALID))\n\n    pyvals[1] = maskvalue\n    umath.seterrobj(pyvals)\n    return old\n\n\n@set_module('numpy')\ndef geterr():\n    \"\"\"\n    Get the current way of handling floating-point errors.\n\n    Returns\n    -------\n    res : dict\n        A dictionary with keys \"divide\", \"over\", \"under\", and \"invalid\",\n        whose values are from the strings \"ignore\", \"print\", \"log\", \"warn\",\n        \"raise\", and \"call\". The keys represent possible floating-point\n        exceptions, and the values define how these exceptions are handled.\n\n    See Also\n    --------\n    geterrcall, seterr, seterrcall\n\n    Notes\n    -----\n    For complete documentation of the types of floating-point exceptions and\n    treatment options, see `seterr`.\n\n    Examples\n    --------\n    >>> np.geterr()\n    {'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}\n    >>> np.arange(3.) / np.arange(3.)\n    array([nan,  1.,  1.])\n\n    >>> oldsettings = np.seterr(all='warn', over='raise')\n    >>> np.geterr()\n    {'divide': 'warn', 'over': 'raise', 'under': 'warn', 'invalid': 'warn'}\n    >>> np.arange(3.) / np.arange(3.)\n    array([nan,  1.,  1.])\n\n    \"\"\"\n    maskvalue = umath.geterrobj()[1]\n    mask = 7\n    res = {}\n    val = (maskvalue >> SHIFT_DIVIDEBYZERO) & mask\n    res['divide'] = _errdict_rev[val]\n    val = (maskvalue >> SHIFT_OVERFLOW) & mask\n    res['over'] = _errdict_rev[val]\n    val = (maskvalue >> SHIFT_UNDERFLOW) & mask\n    res['under'] = _errdict_rev[val]\n    val = (maskvalue >> SHIFT_INVALID) & mask\n    res['invalid'] = _errdict_rev[val]\n    return res\n\n\n@set_module('numpy')\ndef setbufsize(size):\n    \"\"\"\n    Set the size of the buffer used in ufuncs.\n\n    Parameters\n    ----------\n    size : int\n        Size of buffer.\n\n    \"\"\"\n    if size > 10e6:\n        raise ValueError(\"Buffer size, %s, is too big.\" % size)\n    if size < 5:\n        raise ValueError(\"Buffer size, %s, is too small.\" % size)\n    if size % 16 != 0:\n        raise ValueError(\"Buffer size, %s, is not a multiple of 16.\" % size)\n\n    pyvals = umath.geterrobj()\n    old = getbufsize()\n    pyvals[0] = size\n    umath.seterrobj(pyvals)\n    return old\n\n\n@set_module('numpy')\ndef getbufsize():\n    \"\"\"\n    Return the size of the buffer used in ufuncs.\n\n    Returns\n    -------\n    getbufsize : int\n        Size of ufunc buffer in bytes.\n\n    \"\"\"\n    return umath.geterrobj()[0]\n\n\n@set_module('numpy')\ndef seterrcall(func):\n    \"\"\"\n    Set the floating-point error callback function or log object.\n\n    There are two ways to capture floating-point error messages.  The first\n    is to set the error-handler to 'call', using `seterr`.  Then, set\n    the function to call using this function.\n\n    The second is to set the error-handler to 'log', using `seterr`.\n    Floating-point errors then trigger a call to the 'write' method of\n    the provided object.\n\n    Parameters\n    ----------\n    func : callable f(err, flag) or object with write method\n        Function to call upon floating-point errors ('call'-mode) or\n        object whose 'write' method is used to log such message ('log'-mode).\n\n        The call function takes two arguments. The first is a string describing\n        the type of error (such as \"divide by zero\", \"overflow\", \"underflow\",\n        or \"invalid value\"), and the second is the status flag.  The flag is a\n        byte, whose four least-significant bits indicate the type of error, one\n        of \"divide\", \"over\", \"under\", \"invalid\"::\n\n          [0 0 0 0 divide over under invalid]\n\n        In other words, ``flags = divide + 2*over + 4*under + 8*invalid``.\n\n        If an object is provided, its write method should take one argument,\n        a string.\n\n    Returns\n    -------\n    h : callable, log instance or None\n        The old error handler.\n\n    See Also\n    --------\n    seterr, geterr, geterrcall\n\n    Examples\n    --------\n    Callback upon error:\n\n    >>> def err_handler(type, flag):\n    ...     print(\"Floating point error (%s), with flag %s\" % (type, flag))\n    ...\n\n    >>> saved_handler = np.seterrcall(err_handler)\n    >>> save_err = np.seterr(all='call')\n\n    >>> np.array([1, 2, 3]) / 0.0\n    Floating point error (divide by zero), with flag 1\n    array([inf, inf, inf])\n\n    >>> np.seterrcall(saved_handler)\n    <function err_handler at 0x...>\n    >>> np.seterr(**save_err)\n    {'divide': 'call', 'over': 'call', 'under': 'call', 'invalid': 'call'}\n\n    Log error message:\n\n    >>> class Log:\n    ...     def write(self, msg):\n    ...         print(\"LOG: %s\" % msg)\n    ...\n\n    >>> log = Log()\n    >>> saved_handler = np.seterrcall(log)\n    >>> save_err = np.seterr(all='log')\n\n    >>> np.array([1, 2, 3]) / 0.0\n    LOG: Warning: divide by zero encountered in divide\n    array([inf, inf, inf])\n\n    >>> np.seterrcall(saved_handler)\n    <numpy.core.numeric.Log object at 0x...>\n    >>> np.seterr(**save_err)\n    {'divide': 'log', 'over': 'log', 'under': 'log', 'invalid': 'log'}\n\n    \"\"\"\n    if func is not None and not isinstance(func, collections.abc.Callable):\n        if (not hasattr(func, 'write') or\n                not isinstance(func.write, collections.abc.Callable)):\n            raise ValueError(\"Only callable can be used as callback\")\n    pyvals = umath.geterrobj()\n    old = geterrcall()\n    pyvals[2] = func\n    umath.seterrobj(pyvals)\n    return old\n\n\n@set_module('numpy')\ndef geterrcall():\n    \"\"\"\n    Return the current callback function used on floating-point errors.\n\n    When the error handling for a floating-point error (one of \"divide\",\n    \"over\", \"under\", or \"invalid\") is set to 'call' or 'log', the function\n    that is called or the log instance that is written to is returned by\n    `geterrcall`. This function or log instance has been set with\n    `seterrcall`.\n\n    Returns\n    -------\n    errobj : callable, log instance or None\n        The current error handler. If no handler was set through `seterrcall`,\n        ``None`` is returned.\n\n    See Also\n    --------\n    seterrcall, seterr, geterr\n\n    Notes\n    -----\n    For complete documentation of the types of floating-point exceptions and\n    treatment options, see `seterr`.\n\n    Examples\n    --------\n    >>> np.geterrcall()  # we did not yet set a handler, returns None\n\n    >>> oldsettings = np.seterr(all='call')\n    >>> def err_handler(type, flag):\n    ...     print(\"Floating point error (%s), with flag %s\" % (type, flag))\n    >>> oldhandler = np.seterrcall(err_handler)\n    >>> np.array([1, 2, 3]) / 0.0\n    Floating point error (divide by zero), with flag 1\n    array([inf, inf, inf])\n\n    >>> cur_handler = np.geterrcall()\n    >>> cur_handler is err_handler\n    True\n\n    \"\"\"\n    return umath.geterrobj()[2]\n\n\nclass _unspecified:\n    pass\n\n\n_Unspecified = _unspecified()\n\n\n@set_module('numpy')\nclass errstate(contextlib.ContextDecorator):\n    \"\"\"\n    errstate(**kwargs)\n\n    Context manager for floating-point error handling.\n\n    Using an instance of `errstate` as a context manager allows statements in\n    that context to execute with a known error handling behavior. Upon entering\n    the context the error handling is set with `seterr` and `seterrcall`, and\n    upon exiting it is reset to what it was before.\n\n    ..  versionchanged:: 1.17.0\n        `errstate` is also usable as a function decorator, saving\n        a level of indentation if an entire function is wrapped.\n        See :py:class:`contextlib.ContextDecorator` for more information.\n\n    Parameters\n    ----------\n    kwargs : {divide, over, under, invalid}\n        Keyword arguments. The valid keywords are the possible floating-point\n        exceptions. Each keyword should have a string value that defines the\n        treatment for the particular error. Possible values are\n        {'ignore', 'warn', 'raise', 'call', 'print', 'log'}.\n\n    See Also\n    --------\n    seterr, geterr, seterrcall, geterrcall\n\n    Notes\n    -----\n    For complete documentation of the types of floating-point exceptions and\n    treatment options, see `seterr`.\n\n    Examples\n    --------\n    >>> olderr = np.seterr(all='ignore')  # Set error handling to known state.\n\n    >>> np.arange(3) / 0.\n    array([nan, inf, inf])\n    >>> with np.errstate(divide='warn'):\n    ...     np.arange(3) / 0.\n    array([nan, inf, inf])\n\n    >>> np.sqrt(-1)\n    nan\n    >>> with np.errstate(invalid='raise'):\n    ...     np.sqrt(-1)\n    Traceback (most recent call last):\n      File \"<stdin>\", line 2, in <module>\n    FloatingPointError: invalid value encountered in sqrt\n\n    Outside the context the error handling behavior has not changed:\n\n    >>> np.geterr()\n    {'divide': 'ignore', 'over': 'ignore', 'under': 'ignore', 'invalid': 'ignore'}\n\n    \"\"\"\n\n    def __init__(self, *, call=_Unspecified, **kwargs):\n        self.call = call\n        self.kwargs = kwargs\n\n    def __enter__(self):\n        self.oldstate = seterr(**self.kwargs)\n        if self.call is not _Unspecified:\n            self.oldcall = seterrcall(self.call)\n\n    def __exit__(self, *exc_info):\n        seterr(**self.oldstate)\n        if self.call is not _Unspecified:\n            seterrcall(self.oldcall)\n\n\ndef _setdef():\n    defval = [UFUNC_BUFSIZE_DEFAULT, ERR_DEFAULT, None]\n    umath.seterrobj(defval)\n\n\n# set the default values\n_setdef()\n\n\nNO_NEP50_WARNING = contextvars.ContextVar(\"_no_nep50_warning\", default=False)\n\n@set_module('numpy')\n@contextlib.contextmanager\ndef _no_nep50_warning():\n    \"\"\"\n    Context manager to disable NEP 50 warnings.  This context manager is\n    only relevant if the NEP 50 warnings are enabled globally (which is not\n    thread/context safe).\n\n    This warning context manager itself is fully safe, however.\n    \"\"\"\n    token = NO_NEP50_WARNING.set(True)\n    try:\n        yield\n    finally:\n        NO_NEP50_WARNING.reset(token)\n",466],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py":["\"\"\"Wrappers for forwarding stdout/stderr over zmq\"\"\"\n\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License.\n\nimport asyncio\nimport atexit\nimport contextvars\nimport io\nimport os\nimport sys\nimport threading\nimport traceback\nimport warnings\nfrom binascii import b2a_hex\nfrom collections import defaultdict, deque\nfrom io import StringIO, TextIOBase\nfrom threading import local\nfrom typing import Any, Callable, Deque, Dict, Optional\n\nimport zmq\nfrom jupyter_client.session import extract_header\nfrom tornado.ioloop import IOLoop\nfrom zmq.eventloop.zmqstream import ZMQStream\n\n# -----------------------------------------------------------------------------\n# Globals\n# -----------------------------------------------------------------------------\n\nMASTER = 0\nCHILD = 1\n\nPIPE_BUFFER_SIZE = 1000\n\n# -----------------------------------------------------------------------------\n# IO classes\n# -----------------------------------------------------------------------------\n\n\nclass IOPubThread:\n    \"\"\"An object for sending IOPub messages in a background thread\n\n    Prevents a blocking main thread from delaying output from threads.\n\n    IOPubThread(pub_socket).background_socket is a Socket-API-providing object\n    whose IO is always run in a thread.\n    \"\"\"\n\n    def __init__(self, socket, pipe=False):\n        \"\"\"Create IOPub thread\n\n        Parameters\n        ----------\n        socket : zmq.PUB Socket\n            the socket on which messages will be sent.\n        pipe : bool\n            Whether this process should listen for IOPub messages\n            piped from subprocesses.\n        \"\"\"\n        self.socket = socket\n        self._stopped = False\n        self.background_socket = BackgroundSocket(self)\n        self._master_pid = os.getpid()\n        self._pipe_flag = pipe\n        self.io_loop = IOLoop(make_current=False)\n        if pipe:\n            self._setup_pipe_in()\n        self._local = threading.local()\n        self._events: Deque[Callable[..., Any]] = deque()\n        self._event_pipes: Dict[threading.Thread, Any] = {}\n        self._event_pipe_gc_lock: threading.Lock = threading.Lock()\n        self._event_pipe_gc_seconds: float = 10\n        self._event_pipe_gc_task: Optional[asyncio.Task[Any]] = None\n        self._setup_event_pipe()\n        self.thread = threading.Thread(target=self._thread_main, name=\"IOPub\")\n        self.thread.daemon = True\n        self.thread.pydev_do_not_trace = True  # type:ignore[attr-defined]\n        self.thread.is_pydev_daemon_thread = True  # type:ignore[attr-defined]\n        self.thread.name = \"IOPub\"\n\n    def _thread_main(self):\n        \"\"\"The inner loop that's actually run in a thread\"\"\"\n\n        def _start_event_gc():\n            self._event_pipe_gc_task = asyncio.ensure_future(self._run_event_pipe_gc())\n\n        self.io_loop.run_sync(_start_event_gc)\n\n        if not self._stopped:\n            # avoid race if stop called before start thread gets here\n            # probably only comes up in tests\n            self.io_loop.start()\n\n        if self._event_pipe_gc_task is not None:\n            # cancel gc task to avoid pending task warnings\n            async def _cancel():\n                self._event_pipe_gc_task.cancel()  # type:ignore[union-attr]\n\n            if not self._stopped:\n                self.io_loop.run_sync(_cancel)\n            else:\n                self._event_pipe_gc_task.cancel()\n\n        self.io_loop.close(all_fds=True)\n\n    def _setup_event_pipe(self):\n        \"\"\"Create the PULL socket listening for events that should fire in this thread.\"\"\"\n        ctx = self.socket.context\n        pipe_in = ctx.socket(zmq.PULL)\n        pipe_in.linger = 0\n\n        _uuid = b2a_hex(os.urandom(16)).decode(\"ascii\")\n        iface = self._event_interface = \"inproc://%s\" % _uuid\n        pipe_in.bind(iface)\n        self._event_puller = ZMQStream(pipe_in, self.io_loop)\n        self._event_puller.on_recv(self._handle_event)\n\n    async def _run_event_pipe_gc(self):\n        \"\"\"Task to run event pipe gc continuously\"\"\"\n        while True:\n            await asyncio.sleep(self._event_pipe_gc_seconds)\n            try:\n                await self._event_pipe_gc()\n            except Exception as e:\n                print(f\"Exception in IOPubThread._event_pipe_gc: {e}\", file=sys.__stderr__)\n\n    async def _event_pipe_gc(self):\n        \"\"\"run a single garbage collection on event pipes\"\"\"\n        if not self._event_pipes:\n            # don't acquire the lock if there's nothing to do\n            return\n        with self._event_pipe_gc_lock:\n            for thread, socket in list(self._event_pipes.items()):\n                if not thread.is_alive():\n                    socket.close()\n                    del self._event_pipes[thread]\n\n    @property\n    def _event_pipe(self):\n        \"\"\"thread-local event pipe for signaling events that should be processed in the thread\"\"\"\n        try:\n            event_pipe = self._local.event_pipe\n        except AttributeError:\n            # new thread, new event pipe\n            ctx = self.socket.context\n            event_pipe = ctx.socket(zmq.PUSH)\n            event_pipe.linger = 0\n            event_pipe.connect(self._event_interface)\n            self._local.event_pipe = event_pipe\n            # associate event pipes to their threads\n            # so they can be closed explicitly\n            # implicit close on __del__ throws a ResourceWarning\n            with self._event_pipe_gc_lock:\n                self._event_pipes[threading.current_thread()] = event_pipe\n        return event_pipe\n\n    def _handle_event(self, msg):\n        \"\"\"Handle an event on the event pipe\n\n        Content of the message is ignored.\n\n        Whenever *an* event arrives on the event stream,\n        *all* waiting events are processed in order.\n        \"\"\"\n        # freeze event count so new writes don't extend the queue\n        # while we are processing\n        n_events = len(self._events)\n        for _ in range(n_events):\n            event_f = self._events.popleft()\n            event_f()\n\n    def _setup_pipe_in(self):\n        \"\"\"setup listening pipe for IOPub from forked subprocesses\"\"\"\n        ctx = self.socket.context\n\n        # use UUID to authenticate pipe messages\n        self._pipe_uuid = os.urandom(16)\n\n        pipe_in = ctx.socket(zmq.PULL)\n        pipe_in.linger = 0\n\n        try:\n            self._pipe_port = pipe_in.bind_to_random_port(\"tcp://127.0.0.1\")\n        except zmq.ZMQError as e:\n            warnings.warn(\n                \"Couldn't bind IOPub Pipe to 127.0.0.1: %s\" % e\n                + \"\\nsubprocess output will be unavailable.\",\n                stacklevel=2,\n            )\n            self._pipe_flag = False\n            pipe_in.close()\n            return\n        self._pipe_in = ZMQStream(pipe_in, self.io_loop)\n        self._pipe_in.on_recv(self._handle_pipe_msg)\n\n    def _handle_pipe_msg(self, msg):\n        \"\"\"handle a pipe message from a subprocess\"\"\"\n        if not self._pipe_flag or not self._is_master_process():\n            return\n        if msg[0] != self._pipe_uuid:\n            print(\"Bad pipe message: %s\", msg, file=sys.__stderr__)\n            return\n        self.send_multipart(msg[1:])\n\n    def _setup_pipe_out(self):\n        # must be new context after fork\n        ctx = zmq.Context()\n        pipe_out = ctx.socket(zmq.PUSH)\n        pipe_out.linger = 3000  # 3s timeout for pipe_out sends before discarding the message\n        pipe_out.connect(\"tcp://127.0.0.1:%i\" % self._pipe_port)\n        return ctx, pipe_out\n\n    def _is_master_process(self):\n        return os.getpid() == self._master_pid\n\n    def _check_mp_mode(self):\n        \"\"\"check for forks, and switch to zmq pipeline if necessary\"\"\"\n        if not self._pipe_flag or self._is_master_process():\n            return MASTER\n        return CHILD\n\n    def start(self):\n        \"\"\"Start the IOPub thread\"\"\"\n        self.thread.name = \"IOPub\"\n        self.thread.start()\n        # make sure we don't prevent process exit\n        # I'm not sure why setting daemon=True above isn't enough, but it doesn't appear to be.\n        atexit.register(self.stop)\n\n    def stop(self):\n        \"\"\"Stop the IOPub thread\"\"\"\n        self._stopped = True\n        if not self.thread.is_alive():\n            return\n        self.io_loop.add_callback(self.io_loop.stop)\n\n        self.thread.join(timeout=30)\n        if self.thread.is_alive():\n            # avoid infinite hang if stop fails\n            msg = \"IOPub thread did not terminate in 30 seconds\"\n            raise TimeoutError(msg)\n        # close *all* event pipes, created in any thread\n        # event pipes can only be used from other threads while self.thread.is_alive()\n        # so after thread.join, this should be safe\n        for _thread, event_pipe in self._event_pipes.items():\n            event_pipe.close()\n\n    def close(self):\n        \"\"\"Close the IOPub thread.\"\"\"\n        if self.closed:\n            return\n        self.socket.close()\n        self.socket = None\n\n    @property\n    def closed(self):\n        return self.socket is None\n\n    def schedule(self, f):\n        \"\"\"Schedule a function to be called in our IO thread.\n\n        If the thread is not running, call immediately.\n        \"\"\"\n        if self.thread.is_alive():\n            self._events.append(f)\n            # wake event thread (message content is ignored)\n            self._event_pipe.send(b\"\")\n        else:\n            f()\n\n    def send_multipart(self, *args, **kwargs):\n        \"\"\"send_multipart schedules actual zmq send in my thread.\n\n        If my thread isn't running (e.g. forked process), send immediately.\n        \"\"\"\n        self.schedule(lambda: self._really_send(*args, **kwargs))\n\n    def _really_send(self, msg, *args, **kwargs):\n        \"\"\"The callback that actually sends messages\"\"\"\n        if self.closed:\n            return\n\n        mp_mode = self._check_mp_mode()\n\n        if mp_mode != CHILD:\n            # we are master, do a regular send\n            self.socket.send_multipart(msg, *args, **kwargs)\n        else:\n            # we are a child, pipe to master\n            # new context/socket for every pipe-out\n            # since forks don't teardown politely, use ctx.term to ensure send has completed\n            ctx, pipe_out = self._setup_pipe_out()\n            pipe_out.send_multipart([self._pipe_uuid, *msg], *args, **kwargs)\n            pipe_out.close()\n            ctx.term()\n\n\nclass BackgroundSocket:\n    \"\"\"Wrapper around IOPub thread that provides zmq send[_multipart]\"\"\"\n\n    io_thread = None\n\n    def __init__(self, io_thread):\n        \"\"\"Initialize the socket.\"\"\"\n        self.io_thread = io_thread\n\n    def __getattr__(self, attr):\n        \"\"\"Wrap socket attr access for backward-compatibility\"\"\"\n        if attr.startswith(\"__\") and attr.endswith(\"__\"):\n            # don't wrap magic methods\n            super().__getattr__(attr)  # type:ignore[misc]\n        assert self.io_thread is not None\n        if hasattr(self.io_thread.socket, attr):\n            warnings.warn(\n                f\"Accessing zmq Socket attribute {attr} on BackgroundSocket\"\n                f\" is deprecated since ipykernel 4.3.0\"\n                f\" use .io_thread.socket.{attr}\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            return getattr(self.io_thread.socket, attr)\n        return super().__getattr__(attr)  # type:ignore[misc]\n\n    def __setattr__(self, attr, value):\n        \"\"\"Set an attribute on the socket.\"\"\"\n        if attr == \"io_thread\" or (attr.startswith(\"__\") and attr.endswith(\"__\")):\n            super().__setattr__(attr, value)\n        else:\n            warnings.warn(\n                f\"Setting zmq Socket attribute {attr} on BackgroundSocket\"\n                f\" is deprecated since ipykernel 4.3.0\"\n                f\" use .io_thread.socket.{attr}\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            assert self.io_thread is not None\n            setattr(self.io_thread.socket, attr, value)\n\n    def send(self, msg, *args, **kwargs):\n        \"\"\"Send a message to the socket.\"\"\"\n        return self.send_multipart([msg], *args, **kwargs)\n\n    def send_multipart(self, *args, **kwargs):\n        \"\"\"Schedule send in IO thread\"\"\"\n        assert self.io_thread is not None\n        return self.io_thread.send_multipart(*args, **kwargs)\n\n\nclass OutStream(TextIOBase):\n    \"\"\"A file like object that publishes the stream to a 0MQ PUB socket.\n\n    Output is handed off to an IO Thread\n    \"\"\"\n\n    # timeout for flush to avoid infinite hang\n    # in case of misbehavior\n    flush_timeout = 10\n    # The time interval between automatic flushes, in seconds.\n    flush_interval = 0.2\n    topic = None\n    encoding = \"UTF-8\"\n    _exc: Optional[Any] = None\n\n    def fileno(self):\n        \"\"\"\n        Things like subprocess will peak and write to the fileno() of stderr/stdout.\n        \"\"\"\n        if getattr(self, \"_original_stdstream_copy\", None) is not None:\n            return self._original_stdstream_copy\n        msg = \"fileno\"\n        raise io.UnsupportedOperation(msg)\n\n    def _watch_pipe_fd(self):\n        \"\"\"\n        We've redirected standards streams 0 and 1 into a pipe.\n\n        We need to watch in a thread and redirect them to the right places.\n\n        1) the ZMQ channels to show in notebook interfaces,\n        2) the original stdout/err, to capture errors in terminals.\n\n        We cannot schedule this on the ioloop thread, as this might be blocking.\n\n        \"\"\"\n\n        try:\n            bts = os.read(self._fid, PIPE_BUFFER_SIZE)\n            while bts and self._should_watch:\n                self.write(bts.decode(errors=\"replace\"))\n                os.write(self._original_stdstream_copy, bts)\n                bts = os.read(self._fid, PIPE_BUFFER_SIZE)\n        except Exception:\n            self._exc = sys.exc_info()\n\n    def __init__(\n        self,\n        session,\n        pub_thread,\n        name,\n        pipe=None,\n        echo=None,\n        *,\n        watchfd=True,\n        isatty=False,\n    ):\n        \"\"\"\n        Parameters\n        ----------\n        session : object\n            the session object\n        pub_thread : threading.Thread\n            the publication thread\n        name : str {'stderr', 'stdout'}\n            the name of the standard stream to replace\n        pipe : object\n            the pipe object\n        echo : bool\n            whether to echo output\n        watchfd : bool (default, True)\n            Watch the file descriptor corresponding to the replaced stream.\n            This is useful if you know some underlying code will write directly\n            the file descriptor by its number. It will spawn a watching thread,\n            that will swap the give file descriptor for a pipe, read from the\n            pipe, and insert this into the current Stream.\n        isatty : bool (default, False)\n            Indication of whether this stream has terminal capabilities (e.g. can handle colors)\n\n        \"\"\"\n        if pipe is not None:\n            warnings.warn(\n                \"pipe argument to OutStream is deprecated and ignored since ipykernel 4.2.3.\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n        # This is necessary for compatibility with Python built-in streams\n        self.session = session\n        if not isinstance(pub_thread, IOPubThread):\n            # Backward-compat: given socket, not thread. Wrap in a thread.\n            warnings.warn(\n                \"Since IPykernel 4.3, OutStream should be created with \"\n                \"IOPubThread, not %r\" % pub_thread,\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            pub_thread = IOPubThread(pub_thread)\n            pub_thread.start()\n        self.pub_thread = pub_thread\n        self.name = name\n        self.topic = b\"stream.\" + name.encode()\n        self._parent_header: contextvars.ContextVar[Dict[str, Any]] = contextvars.ContextVar(\n            \"parent_header\"\n        )\n        self._parent_header.set({})\n        self._thread_to_parent = {}\n        self._thread_to_parent_header = {}\n        self._parent_header_global = {}\n        self._master_pid = os.getpid()\n        self._flush_pending = False\n        self._subprocess_flush_pending = False\n        self._io_loop = pub_thread.io_loop\n        self._buffer_lock = threading.RLock()\n        self._buffers = defaultdict(StringIO)\n        self.echo = None\n        self._isatty = bool(isatty)\n        self._should_watch = False\n        self._local = local()\n\n        if (\n            watchfd\n            and (\n                (sys.platform.startswith(\"linux\") or sys.platform.startswith(\"darwin\"))\n                # Pytest set its own capture. Don't redirect from within pytest.\n                and (\"PYTEST_CURRENT_TEST\" not in os.environ)\n            )\n            # allow forcing watchfd (mainly for tests)\n            or watchfd == \"force\"\n        ):\n            self._should_watch = True\n            self._setup_stream_redirects(name)\n\n        if echo:\n            if hasattr(echo, \"read\") and hasattr(echo, \"write\"):\n                # make sure we aren't trying to echo on the FD we're watching!\n                # that would cause an infinite loop, always echoing on itself\n                if self._should_watch:\n                    try:\n                        echo_fd = echo.fileno()\n                    except Exception:\n                        echo_fd = None\n\n                    if echo_fd is not None and echo_fd == self._original_stdstream_fd:\n                        # echo on the _copy_ we made during\n                        # this is the actual terminal FD now\n                        echo = io.TextIOWrapper(\n                            io.FileIO(\n                                self._original_stdstream_copy,\n                                \"w\",\n                            )\n                        )\n                self.echo = echo\n            else:\n                msg = \"echo argument must be a file-like object\"\n                raise ValueError(msg)\n\n    @property\n    def parent_header(self):\n        try:\n            # asyncio-specific\n            return self._parent_header.get()\n        except LookupError:\n            try:\n                # thread-specific\n                identity = threading.current_thread().ident\n                # retrieve the outermost (oldest ancestor,\n                # discounting the kernel thread) thread identity\n                while identity in self._thread_to_parent:\n                    identity = self._thread_to_parent[identity]\n                # use the header of the oldest ancestor\n                return self._thread_to_parent_header[identity]\n            except KeyError:\n                # global (fallback)\n                return self._parent_header_global\n\n    @parent_header.setter\n    def parent_header(self, value):\n        self._parent_header_global = value\n        return self._parent_header.set(value)\n\n    def isatty(self):\n        \"\"\"Return a bool indicating whether this is an 'interactive' stream.\n\n        Returns:\n            Boolean\n        \"\"\"\n        return self._isatty\n\n    def _setup_stream_redirects(self, name):\n        pr, pw = os.pipe()\n        fno = self._original_stdstream_fd = getattr(sys, name).fileno()\n        self._original_stdstream_copy = os.dup(fno)\n        os.dup2(pw, fno)\n\n        self._fid = pr\n\n        self._exc = None\n        self.watch_fd_thread = threading.Thread(target=self._watch_pipe_fd)\n        self.watch_fd_thread.daemon = True\n        self.watch_fd_thread.start()\n\n    def _is_master_process(self):\n        return os.getpid() == self._master_pid\n\n    def set_parent(self, parent):\n        \"\"\"Set the parent header.\"\"\"\n        self.parent_header = extract_header(parent)\n\n    def close(self):\n        \"\"\"Close the stream.\"\"\"\n        if self._should_watch:\n            self._should_watch = False\n            # thread won't wake unless there's something to read\n            # writing something after _should_watch will not be echoed\n            os.write(self._original_stdstream_fd, b\"\\0\")\n            self.watch_fd_thread.join()\n            # restore original FDs\n            os.dup2(self._original_stdstream_copy, self._original_stdstream_fd)\n            os.close(self._original_stdstream_copy)\n        if self._exc:\n            etype, value, tb = self._exc\n            traceback.print_exception(etype, value, tb)\n        self.pub_thread = None\n\n    @property\n    def closed(self):\n        return self.pub_thread is None\n\n    def _schedule_flush(self):\n        \"\"\"schedule a flush in the IO thread\n\n        call this on write, to indicate that flush should be called soon.\n        \"\"\"\n        if self._flush_pending:\n            return\n        self._flush_pending = True\n\n        # add_timeout has to be handed to the io thread via event pipe\n        def _schedule_in_thread():\n            self._io_loop.call_later(self.flush_interval, self._flush)\n\n        self.pub_thread.schedule(_schedule_in_thread)\n\n    def flush(self):\n        \"\"\"trigger actual zmq send\n\n        send will happen in the background thread\n        \"\"\"\n        if (\n            self.pub_thread\n            and self.pub_thread.thread is not None\n            and self.pub_thread.thread.is_alive()\n            and self.pub_thread.thread.ident != threading.current_thread().ident\n        ):\n            # request flush on the background thread\n            self.pub_thread.schedule(self._flush)\n            # wait for flush to actually get through, if we can.\n            evt = threading.Event()\n            self.pub_thread.schedule(evt.set)\n            # and give a timeout to avoid\n            if not evt.wait(self.flush_timeout):\n                # write directly to __stderr__ instead of warning because\n                # if this is happening sys.stderr may be the problem.\n                print(\"IOStream.flush timed out\", file=sys.__stderr__)\n        else:\n            self._flush()\n\n    def _flush(self):\n        \"\"\"This is where the actual send happens.\n\n        _flush should generally be called in the IO thread,\n        unless the thread has been destroyed (e.g. forked subprocess).\n        \"\"\"\n        self._flush_pending = False\n        self._subprocess_flush_pending = False\n\n        if self.echo is not None:\n            try:\n                self.echo.flush()\n            except OSError as e:\n                if self.echo is not sys.__stderr__:\n                    print(f\"Flush failed: {e}\", file=sys.__stderr__)\n\n        for parent, data in self._flush_buffers():\n            if data:\n                # FIXME: this disables Session's fork-safe check,\n                # since pub_thread is itself fork-safe.\n                # There should be a better way to do this.\n                self.session.pid = os.getpid()\n                content = {\"name\": self.name, \"text\": data}\n                msg = self.session.msg(\"stream\", content, parent=parent)\n\n                # Each transform either returns a new\n                # message or None. If None is returned,\n                # the message has been 'used' and we return.\n                for hook in self._hooks:\n                    msg = hook(msg)\n                    if msg is None:\n                        return\n\n                self.session.send(\n                    self.pub_thread,\n                    msg,\n                    ident=self.topic,\n                )\n\n    def write(self, string: str) -> Optional[int]:  # type:ignore[override]\n        \"\"\"Write to current stream after encoding if necessary\n\n        Returns\n        -------\n        len : int\n            number of items from input parameter written to stream.\n\n        \"\"\"\n        parent = self.parent_header\n\n        if not isinstance(string, str):\n            msg = f\"write() argument must be str, not {type(string)}\"  # type:ignore[unreachable]\n            raise TypeError(msg)\n\n        if self.echo is not None:\n            try:\n                self.echo.write(string)\n            except OSError as e:\n                if self.echo is not sys.__stderr__:\n                    print(f\"Write failed: {e}\", file=sys.__stderr__)\n\n        if self.pub_thread is None:\n            msg = \"I/O operation on closed file\"\n            raise ValueError(msg)\n\n        is_child = not self._is_master_process()\n        # only touch the buffer in the IO thread to avoid races\n        with self._buffer_lock:\n            self._buffers[frozenset(parent.items())].write(string)\n        if is_child:\n            # mp.Pool cannot be trusted to flush promptly (or ever),\n            # and this helps.\n            if self._subprocess_flush_pending:\n                return None\n            self._subprocess_flush_pending = True\n            # We can not rely on self._io_loop.call_later from a subprocess\n            self.pub_thread.schedule(self._flush)\n        else:\n            self._schedule_flush()\n\n        return len(string)\n\n    def writelines(self, sequence):\n        \"\"\"Write lines to the stream.\"\"\"\n        if self.pub_thread is None:\n            msg = \"I/O operation on closed file\"\n            raise ValueError(msg)\n        for string in sequence:\n            self.write(string)\n\n    def writable(self):\n        \"\"\"Test whether the stream is writable.\"\"\"\n        return True\n\n    def _flush_buffers(self):\n        \"\"\"clear the current buffer and return the current buffer data.\"\"\"\n        buffers = self._rotate_buffers()\n        for frozen_parent, buffer in buffers.items():\n            data = buffer.getvalue()\n            buffer.close()\n            yield dict(frozen_parent), data\n\n    def _rotate_buffers(self):\n        \"\"\"Returns the current buffer and replaces it with an empty buffer.\"\"\"\n        with self._buffer_lock:\n            old_buffers = self._buffers\n            self._buffers = defaultdict(StringIO)\n        return old_buffers\n\n    @property\n    def _hooks(self):\n        if not hasattr(self._local, \"hooks\"):\n            # create new list for a new thread\n            self._local.hooks = []\n        return self._local.hooks\n\n    def register_hook(self, hook):\n        \"\"\"\n        Registers a hook with the thread-local storage.\n\n        Parameters\n        ----------\n        hook : Any callable object\n\n        Returns\n        -------\n        Either a publishable message, or `None`.\n        The hook callable must return a message from\n        the __call__ method if they still require the\n        `session.send` method to be called after transformation.\n        Returning `None` will halt that execution path, and\n        session.send will not be called.\n        \"\"\"\n        self._hooks.append(hook)\n\n    def unregister_hook(self, hook):\n        \"\"\"\n        Un-registers a hook with the thread-local storage.\n\n        Parameters\n        ----------\n        hook : Any callable object which has previously been\n            registered as a hook.\n\n        Returns\n        -------\n        bool - `True` if the hook was removed, `False` if it wasn't\n            found.\n        \"\"\"\n        try:\n            self._hooks.remove(hook)\n            return True\n        except ValueError:\n            return False\n",769],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\dateutil\\tz\\tz.py":["# -*- coding: utf-8 -*-\n\"\"\"\nThis module offers timezone implementations subclassing the abstract\n:py:class:`datetime.tzinfo` type. There are classes to handle tzfile format\nfiles (usually are in :file:`/etc/localtime`, :file:`/usr/share/zoneinfo`,\netc), TZ environment string (in all known formats), given ranges (with help\nfrom relative deltas), local machine timezone, fixed offset timezone, and UTC\ntimezone.\n\"\"\"\nimport datetime\nimport struct\nimport time\nimport sys\nimport os\nimport bisect\nimport weakref\nfrom collections import OrderedDict\n\nimport six\nfrom six import string_types\nfrom six.moves import _thread\nfrom ._common import tzname_in_python2, _tzinfo\nfrom ._common import tzrangebase, enfold\nfrom ._common import _validate_fromutc_inputs\n\nfrom ._factories import _TzSingleton, _TzOffsetFactory\nfrom ._factories import _TzStrFactory\ntry:\n    from .win import tzwin, tzwinlocal\nexcept ImportError:\n    tzwin = tzwinlocal = None\n\n# For warning about rounding tzinfo\nfrom warnings import warn\n\nZERO = datetime.timedelta(0)\nEPOCH = datetime.datetime(1970, 1, 1, 0, 0)\nEPOCHORDINAL = EPOCH.toordinal()\n\n\n@six.add_metaclass(_TzSingleton)\nclass tzutc(datetime.tzinfo):\n    \"\"\"\n    This is a tzinfo object that represents the UTC time zone.\n\n    **Examples:**\n\n    .. doctest::\n\n        >>> from datetime import *\n        >>> from dateutil.tz import *\n\n        >>> datetime.now()\n        datetime.datetime(2003, 9, 27, 9, 40, 1, 521290)\n\n        >>> datetime.now(tzutc())\n        datetime.datetime(2003, 9, 27, 12, 40, 12, 156379, tzinfo=tzutc())\n\n        >>> datetime.now(tzutc()).tzname()\n        'UTC'\n\n    .. versionchanged:: 2.7.0\n        ``tzutc()`` is now a singleton, so the result of ``tzutc()`` will\n        always return the same object.\n\n        .. doctest::\n\n            >>> from dateutil.tz import tzutc, UTC\n            >>> tzutc() is tzutc()\n            True\n            >>> tzutc() is UTC\n            True\n    \"\"\"\n    def utcoffset(self, dt):\n        return ZERO\n\n    def dst(self, dt):\n        return ZERO\n\n    @tzname_in_python2\n    def tzname(self, dt):\n        return \"UTC\"\n\n    def is_ambiguous(self, dt):\n        \"\"\"\n        Whether or not the \"wall time\" of a given datetime is ambiguous in this\n        zone.\n\n        :param dt:\n            A :py:class:`datetime.datetime`, naive or time zone aware.\n\n\n        :return:\n            Returns ``True`` if ambiguous, ``False`` otherwise.\n\n        .. versionadded:: 2.6.0\n        \"\"\"\n        return False\n\n    @_validate_fromutc_inputs\n    def fromutc(self, dt):\n        \"\"\"\n        Fast track version of fromutc() returns the original ``dt`` object for\n        any valid :py:class:`datetime.datetime` object.\n        \"\"\"\n        return dt\n\n    def __eq__(self, other):\n        if not isinstance(other, (tzutc, tzoffset)):\n            return NotImplemented\n\n        return (isinstance(other, tzutc) or\n                (isinstance(other, tzoffset) and other._offset == ZERO))\n\n    __hash__ = None\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    def __repr__(self):\n        return \"%s()\" % self.__class__.__name__\n\n    __reduce__ = object.__reduce__\n\n\n#: Convenience constant providing a :class:`tzutc()` instance\n#:\n#: .. versionadded:: 2.7.0\nUTC = tzutc()\n\n\n@six.add_metaclass(_TzOffsetFactory)\nclass tzoffset(datetime.tzinfo):\n    \"\"\"\n    A simple class for representing a fixed offset from UTC.\n\n    :param name:\n        The timezone name, to be returned when ``tzname()`` is called.\n    :param offset:\n        The time zone offset in seconds, or (since version 2.6.0, represented\n        as a :py:class:`datetime.timedelta` object).\n    \"\"\"\n    def __init__(self, name, offset):\n        self._name = name\n\n        try:\n            # Allow a timedelta\n            offset = offset.total_seconds()\n        except (TypeError, AttributeError):\n            pass\n\n        self._offset = datetime.timedelta(seconds=_get_supported_offset(offset))\n\n    def utcoffset(self, dt):\n        return self._offset\n\n    def dst(self, dt):\n        return ZERO\n\n    @tzname_in_python2\n    def tzname(self, dt):\n        return self._name\n\n    @_validate_fromutc_inputs\n    def fromutc(self, dt):\n        return dt + self._offset\n\n    def is_ambiguous(self, dt):\n        \"\"\"\n        Whether or not the \"wall time\" of a given datetime is ambiguous in this\n        zone.\n\n        :param dt:\n            A :py:class:`datetime.datetime`, naive or time zone aware.\n        :return:\n            Returns ``True`` if ambiguous, ``False`` otherwise.\n\n        .. versionadded:: 2.6.0\n        \"\"\"\n        return False\n\n    def __eq__(self, other):\n        if not isinstance(other, tzoffset):\n            return NotImplemented\n\n        return self._offset == other._offset\n\n    __hash__ = None\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    def __repr__(self):\n        return \"%s(%s, %s)\" % (self.__class__.__name__,\n                               repr(self._name),\n                               int(self._offset.total_seconds()))\n\n    __reduce__ = object.__reduce__\n\n\nclass tzlocal(_tzinfo):\n    \"\"\"\n    A :class:`tzinfo` subclass built around the ``time`` timezone functions.\n    \"\"\"\n    def __init__(self):\n        super(tzlocal, self).__init__()\n\n        self._std_offset = datetime.timedelta(seconds=-time.timezone)\n        if time.daylight:\n            self._dst_offset = datetime.timedelta(seconds=-time.altzone)\n        else:\n            self._dst_offset = self._std_offset\n\n        self._dst_saved = self._dst_offset - self._std_offset\n        self._hasdst = bool(self._dst_saved)\n        self._tznames = tuple(time.tzname)\n\n    def utcoffset(self, dt):\n        if dt is None and self._hasdst:\n            return None\n\n        if self._isdst(dt):\n            return self._dst_offset\n        else:\n            return self._std_offset\n\n    def dst(self, dt):\n        if dt is None and self._hasdst:\n            return None\n\n        if self._isdst(dt):\n            return self._dst_offset - self._std_offset\n        else:\n            return ZERO\n\n    @tzname_in_python2\n    def tzname(self, dt):\n        return self._tznames[self._isdst(dt)]\n\n    def is_ambiguous(self, dt):\n        \"\"\"\n        Whether or not the \"wall time\" of a given datetime is ambiguous in this\n        zone.\n\n        :param dt:\n            A :py:class:`datetime.datetime`, naive or time zone aware.\n\n\n        :return:\n            Returns ``True`` if ambiguous, ``False`` otherwise.\n\n        .. versionadded:: 2.6.0\n        \"\"\"\n        naive_dst = self._naive_is_dst(dt)\n        return (not naive_dst and\n                (naive_dst != self._naive_is_dst(dt - self._dst_saved)))\n\n    def _naive_is_dst(self, dt):\n        timestamp = _datetime_to_timestamp(dt)\n        return time.localtime(timestamp + time.timezone).tm_isdst\n\n    def _isdst(self, dt, fold_naive=True):\n        # We can't use mktime here. It is unstable when deciding if\n        # the hour near to a change is DST or not.\n        #\n        # timestamp = time.mktime((dt.year, dt.month, dt.day, dt.hour,\n        #                         dt.minute, dt.second, dt.weekday(), 0, -1))\n        # return time.localtime(timestamp).tm_isdst\n        #\n        # The code above yields the following result:\n        #\n        # >>> import tz, datetime\n        # >>> t = tz.tzlocal()\n        # >>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()\n        # 'BRDT'\n        # >>> datetime.datetime(2003,2,16,0,tzinfo=t).tzname()\n        # 'BRST'\n        # >>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()\n        # 'BRST'\n        # >>> datetime.datetime(2003,2,15,22,tzinfo=t).tzname()\n        # 'BRDT'\n        # >>> datetime.datetime(2003,2,15,23,tzinfo=t).tzname()\n        # 'BRDT'\n        #\n        # Here is a more stable implementation:\n        #\n        if not self._hasdst:\n            return False\n\n        # Check for ambiguous times:\n        dstval = self._naive_is_dst(dt)\n        fold = getattr(dt, 'fold', None)\n\n        if self.is_ambiguous(dt):\n            if fold is not None:\n                return not self._fold(dt)\n            else:\n                return True\n\n        return dstval\n\n    def __eq__(self, other):\n        if isinstance(other, tzlocal):\n            return (self._std_offset == other._std_offset and\n                    self._dst_offset == other._dst_offset)\n        elif isinstance(other, tzutc):\n            return (not self._hasdst and\n                    self._tznames[0] in {'UTC', 'GMT'} and\n                    self._std_offset == ZERO)\n        elif isinstance(other, tzoffset):\n            return (not self._hasdst and\n                    self._tznames[0] == other._name and\n                    self._std_offset == other._offset)\n        else:\n            return NotImplemented\n\n    __hash__ = None\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    def __repr__(self):\n        return \"%s()\" % self.__class__.__name__\n\n    __reduce__ = object.__reduce__\n\n\nclass _ttinfo(object):\n    __slots__ = [\"offset\", \"delta\", \"isdst\", \"abbr\",\n                 \"isstd\", \"isgmt\", \"dstoffset\"]\n\n    def __init__(self):\n        for attr in self.__slots__:\n            setattr(self, attr, None)\n\n    def __repr__(self):\n        l = []\n        for attr in self.__slots__:\n            value = getattr(self, attr)\n            if value is not None:\n                l.append(\"%s=%s\" % (attr, repr(value)))\n        return \"%s(%s)\" % (self.__class__.__name__, \", \".join(l))\n\n    def __eq__(self, other):\n        if not isinstance(other, _ttinfo):\n            return NotImplemented\n\n        return (self.offset == other.offset and\n                self.delta == other.delta and\n                self.isdst == other.isdst and\n                self.abbr == other.abbr and\n                self.isstd == other.isstd and\n                self.isgmt == other.isgmt and\n                self.dstoffset == other.dstoffset)\n\n    __hash__ = None\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    def __getstate__(self):\n        state = {}\n        for name in self.__slots__:\n            state[name] = getattr(self, name, None)\n        return state\n\n    def __setstate__(self, state):\n        for name in self.__slots__:\n            if name in state:\n                setattr(self, name, state[name])\n\n\nclass _tzfile(object):\n    \"\"\"\n    Lightweight class for holding the relevant transition and time zone\n    information read from binary tzfiles.\n    \"\"\"\n    attrs = ['trans_list', 'trans_list_utc', 'trans_idx', 'ttinfo_list',\n             'ttinfo_std', 'ttinfo_dst', 'ttinfo_before', 'ttinfo_first']\n\n    def __init__(self, **kwargs):\n        for attr in self.attrs:\n            setattr(self, attr, kwargs.get(attr, None))\n\n\nclass tzfile(_tzinfo):\n    \"\"\"\n    This is a ``tzinfo`` subclass that allows one to use the ``tzfile(5)``\n    format timezone files to extract current and historical zone information.\n\n    :param fileobj:\n        This can be an opened file stream or a file name that the time zone\n        information can be read from.\n\n    :param filename:\n        This is an optional parameter specifying the source of the time zone\n        information in the event that ``fileobj`` is a file object. If omitted\n        and ``fileobj`` is a file stream, this parameter will be set either to\n        ``fileobj``'s ``name`` attribute or to ``repr(fileobj)``.\n\n    See `Sources for Time Zone and Daylight Saving Time Data\n    <https://data.iana.org/time-zones/tz-link.html>`_ for more information.\n    Time zone files can be compiled from the `IANA Time Zone database files\n    <https://www.iana.org/time-zones>`_ with the `zic time zone compiler\n    <https://www.freebsd.org/cgi/man.cgi?query=zic&sektion=8>`_\n\n    .. note::\n\n        Only construct a ``tzfile`` directly if you have a specific timezone\n        file on disk that you want to read into a Python ``tzinfo`` object.\n        If you want to get a ``tzfile`` representing a specific IANA zone,\n        (e.g. ``'America/New_York'``), you should call\n        :func:`dateutil.tz.gettz` with the zone identifier.\n\n\n    **Examples:**\n\n    Using the US Eastern time zone as an example, we can see that a ``tzfile``\n    provides time zone information for the standard Daylight Saving offsets:\n\n    .. testsetup:: tzfile\n\n        from dateutil.tz import gettz\n        from datetime import datetime\n\n    .. doctest:: tzfile\n\n        >>> NYC = gettz('America/New_York')\n        >>> NYC\n        tzfile('/usr/share/zoneinfo/America/New_York')\n\n        >>> print(datetime(2016, 1, 3, tzinfo=NYC))     # EST\n        2016-01-03 00:00:00-05:00\n\n        >>> print(datetime(2016, 7, 7, tzinfo=NYC))     # EDT\n        2016-07-07 00:00:00-04:00\n\n\n    The ``tzfile`` structure contains a fully history of the time zone,\n    so historical dates will also have the right offsets. For example, before\n    the adoption of the UTC standards, New York used local solar  mean time:\n\n    .. doctest:: tzfile\n\n       >>> print(datetime(1901, 4, 12, tzinfo=NYC))    # LMT\n       1901-04-12 00:00:00-04:56\n\n    And during World War II, New York was on \"Eastern War Time\", which was a\n    state of permanent daylight saving time:\n\n    .. doctest:: tzfile\n\n        >>> print(datetime(1944, 2, 7, tzinfo=NYC))    # EWT\n        1944-02-07 00:00:00-04:00\n\n    \"\"\"\n\n    def __init__(self, fileobj, filename=None):\n        super(tzfile, self).__init__()\n\n        file_opened_here = False\n        if isinstance(fileobj, string_types):\n            self._filename = fileobj\n            fileobj = open(fileobj, 'rb')\n            file_opened_here = True\n        elif filename is not None:\n            self._filename = filename\n        elif hasattr(fileobj, \"name\"):\n            self._filename = fileobj.name\n        else:\n            self._filename = repr(fileobj)\n\n        if fileobj is not None:\n            if not file_opened_here:\n                fileobj = _nullcontext(fileobj)\n\n            with fileobj as file_stream:\n                tzobj = self._read_tzfile(file_stream)\n\n            self._set_tzdata(tzobj)\n\n    def _set_tzdata(self, tzobj):\n        \"\"\" Set the time zone data of this object from a _tzfile object \"\"\"\n        # Copy the relevant attributes over as private attributes\n        for attr in _tzfile.attrs:\n            setattr(self, '_' + attr, getattr(tzobj, attr))\n\n    def _read_tzfile(self, fileobj):\n        out = _tzfile()\n\n        # From tzfile(5):\n        #\n        # The time zone information files used by tzset(3)\n        # begin with the magic characters \"TZif\" to identify\n        # them as time zone information files, followed by\n        # sixteen bytes reserved for future use, followed by\n        # six four-byte values of type long, written in a\n        # ``standard'' byte order (the high-order  byte\n        # of the value is written first).\n        if fileobj.read(4).decode() != \"TZif\":\n            raise ValueError(\"magic not found\")\n\n        fileobj.read(16)\n\n        (\n            # The number of UTC/local indicators stored in the file.\n            ttisgmtcnt,\n\n            # The number of standard/wall indicators stored in the file.\n            ttisstdcnt,\n\n            # The number of leap seconds for which data is\n            # stored in the file.\n            leapcnt,\n\n            # The number of \"transition times\" for which data\n            # is stored in the file.\n            timecnt,\n\n            # The number of \"local time types\" for which data\n            # is stored in the file (must not be zero).\n            typecnt,\n\n            # The  number  of  characters  of \"time zone\n            # abbreviation strings\" stored in the file.\n            charcnt,\n\n        ) = struct.unpack(\">6l\", fileobj.read(24))\n\n        # The above header is followed by tzh_timecnt four-byte\n        # values  of  type long,  sorted  in ascending order.\n        # These values are written in ``standard'' byte order.\n        # Each is used as a transition time (as  returned  by\n        # time(2)) at which the rules for computing local time\n        # change.\n\n        if timecnt:\n            out.trans_list_utc = list(struct.unpack(\">%dl\" % timecnt,\n                                                    fileobj.read(timecnt*4)))\n        else:\n            out.trans_list_utc = []\n\n        # Next come tzh_timecnt one-byte values of type unsigned\n        # char; each one tells which of the different types of\n        # ``local time'' types described in the file is associated\n        # with the same-indexed transition time. These values\n        # serve as indices into an array of ttinfo structures that\n        # appears next in the file.\n\n        if timecnt:\n            out.trans_idx = struct.unpack(\">%dB\" % timecnt,\n                                          fileobj.read(timecnt))\n        else:\n            out.trans_idx = []\n\n        # Each ttinfo structure is written as a four-byte value\n        # for tt_gmtoff  of  type long,  in  a  standard  byte\n        # order, followed  by a one-byte value for tt_isdst\n        # and a one-byte  value  for  tt_abbrind.   In  each\n        # structure, tt_gmtoff  gives  the  number  of\n        # seconds to be added to UTC, tt_isdst tells whether\n        # tm_isdst should be set by  localtime(3),  and\n        # tt_abbrind serves  as an index into the array of\n        # time zone abbreviation characters that follow the\n        # ttinfo structure(s) in the file.\n\n        ttinfo = []\n\n        for i in range(typecnt):\n            ttinfo.append(struct.unpack(\">lbb\", fileobj.read(6)))\n\n        abbr = fileobj.read(charcnt).decode()\n\n        # Then there are tzh_leapcnt pairs of four-byte\n        # values, written in  standard byte  order;  the\n        # first  value  of  each pair gives the time (as\n        # returned by time(2)) at which a leap second\n        # occurs;  the  second  gives the  total  number of\n        # leap seconds to be applied after the given time.\n        # The pairs of values are sorted in ascending order\n        # by time.\n\n        # Not used, for now (but seek for correct file position)\n        if leapcnt:\n            fileobj.seek(leapcnt * 8, os.SEEK_CUR)\n\n        # Then there are tzh_ttisstdcnt standard/wall\n        # indicators, each stored as a one-byte value;\n        # they tell whether the transition times associated\n        # with local time types were specified as standard\n        # time or wall clock time, and are used when\n        # a time zone file is used in handling POSIX-style\n        # time zone environment variables.\n\n        if ttisstdcnt:\n            isstd = struct.unpack(\">%db\" % ttisstdcnt,\n                                  fileobj.read(ttisstdcnt))\n\n        # Finally, there are tzh_ttisgmtcnt UTC/local\n        # indicators, each stored as a one-byte value;\n        # they tell whether the transition times associated\n        # with local time types were specified as UTC or\n        # local time, and are used when a time zone file\n        # is used in handling POSIX-style time zone envi-\n        # ronment variables.\n\n        if ttisgmtcnt:\n            isgmt = struct.unpack(\">%db\" % ttisgmtcnt,\n                                  fileobj.read(ttisgmtcnt))\n\n        # Build ttinfo list\n        out.ttinfo_list = []\n        for i in range(typecnt):\n            gmtoff, isdst, abbrind = ttinfo[i]\n            gmtoff = _get_supported_offset(gmtoff)\n            tti = _ttinfo()\n            tti.offset = gmtoff\n            tti.dstoffset = datetime.timedelta(0)\n            tti.delta = datetime.timedelta(seconds=gmtoff)\n            tti.isdst = isdst\n            tti.abbr = abbr[abbrind:abbr.find('\\x00', abbrind)]\n            tti.isstd = (ttisstdcnt > i and isstd[i] != 0)\n            tti.isgmt = (ttisgmtcnt > i and isgmt[i] != 0)\n            out.ttinfo_list.append(tti)\n\n        # Replace ttinfo indexes for ttinfo objects.\n        out.trans_idx = [out.ttinfo_list[idx] for idx in out.trans_idx]\n\n        # Set standard, dst, and before ttinfos. before will be\n        # used when a given time is before any transitions,\n        # and will be set to the first non-dst ttinfo, or to\n        # the first dst, if all of them are dst.\n        out.ttinfo_std = None\n        out.ttinfo_dst = None\n        out.ttinfo_before = None\n        if out.ttinfo_list:\n            if not out.trans_list_utc:\n                out.ttinfo_std = out.ttinfo_first = out.ttinfo_list[0]\n            else:\n                for i in range(timecnt-1, -1, -1):\n                    tti = out.trans_idx[i]\n                    if not out.ttinfo_std and not tti.isdst:\n                        out.ttinfo_std = tti\n                    elif not out.ttinfo_dst and tti.isdst:\n                        out.ttinfo_dst = tti\n\n                    if out.ttinfo_std and out.ttinfo_dst:\n                        break\n                else:\n                    if out.ttinfo_dst and not out.ttinfo_std:\n                        out.ttinfo_std = out.ttinfo_dst\n\n                for tti in out.ttinfo_list:\n                    if not tti.isdst:\n                        out.ttinfo_before = tti\n                        break\n                else:\n                    out.ttinfo_before = out.ttinfo_list[0]\n\n        # Now fix transition times to become relative to wall time.\n        #\n        # I'm not sure about this. In my tests, the tz source file\n        # is setup to wall time, and in the binary file isstd and\n        # isgmt are off, so it should be in wall time. OTOH, it's\n        # always in gmt time. Let me know if you have comments\n        # about this.\n        lastdst = None\n        lastoffset = None\n        lastdstoffset = None\n        lastbaseoffset = None\n        out.trans_list = []\n\n        for i, tti in enumerate(out.trans_idx):\n            offset = tti.offset\n            dstoffset = 0\n\n            if lastdst is not None:\n                if tti.isdst:\n                    if not lastdst:\n                        dstoffset = offset - lastoffset\n\n                    if not dstoffset and lastdstoffset:\n                        dstoffset = lastdstoffset\n\n                    tti.dstoffset = datetime.timedelta(seconds=dstoffset)\n                    lastdstoffset = dstoffset\n\n            # If a time zone changes its base offset during a DST transition,\n            # then you need to adjust by the previous base offset to get the\n            # transition time in local time. Otherwise you use the current\n            # base offset. Ideally, I would have some mathematical proof of\n            # why this is true, but I haven't really thought about it enough.\n            baseoffset = offset - dstoffset\n            adjustment = baseoffset\n            if (lastbaseoffset is not None and baseoffset != lastbaseoffset\n                    and tti.isdst != lastdst):\n                # The base DST has changed\n                adjustment = lastbaseoffset\n\n            lastdst = tti.isdst\n            lastoffset = offset\n            lastbaseoffset = baseoffset\n\n            out.trans_list.append(out.trans_list_utc[i] + adjustment)\n\n        out.trans_idx = tuple(out.trans_idx)\n        out.trans_list = tuple(out.trans_list)\n        out.trans_list_utc = tuple(out.trans_list_utc)\n\n        return out\n\n    def _find_last_transition(self, dt, in_utc=False):\n        # If there's no list, there are no transitions to find\n        if not self._trans_list:\n            return None\n\n        timestamp = _datetime_to_timestamp(dt)\n\n        # Find where the timestamp fits in the transition list - if the\n        # timestamp is a transition time, it's part of the \"after\" period.\n        trans_list = self._trans_list_utc if in_utc else self._trans_list\n        idx = bisect.bisect_right(trans_list, timestamp)\n\n        # We want to know when the previous transition was, so subtract off 1\n        return idx - 1\n\n    def _get_ttinfo(self, idx):\n        # For no list or after the last transition, default to _ttinfo_std\n        if idx is None or (idx + 1) >= len(self._trans_list):\n            return self._ttinfo_std\n\n        # If there is a list and the time is before it, return _ttinfo_before\n        if idx < 0:\n            return self._ttinfo_before\n\n        return self._trans_idx[idx]\n\n    def _find_ttinfo(self, dt):\n        idx = self._resolve_ambiguous_time(dt)\n\n        return self._get_ttinfo(idx)\n\n    def fromutc(self, dt):\n        \"\"\"\n        The ``tzfile`` implementation of :py:func:`datetime.tzinfo.fromutc`.\n\n        :param dt:\n            A :py:class:`datetime.datetime` object.\n\n        :raises TypeError:\n            Raised if ``dt`` is not a :py:class:`datetime.datetime` object.\n\n        :raises ValueError:\n            Raised if this is called with a ``dt`` which does not have this\n            ``tzinfo`` attached.\n\n        :return:\n            Returns a :py:class:`datetime.datetime` object representing the\n            wall time in ``self``'s time zone.\n        \"\"\"\n        # These isinstance checks are in datetime.tzinfo, so we'll preserve\n        # them, even if we don't care about duck typing.\n        if not isinstance(dt, datetime.datetime):\n            raise TypeError(\"fromutc() requires a datetime argument\")\n\n        if dt.tzinfo is not self:\n            raise ValueError(\"dt.tzinfo is not self\")\n\n        # First treat UTC as wall time and get the transition we're in.\n        idx = self._find_last_transition(dt, in_utc=True)\n        tti = self._get_ttinfo(idx)\n\n        dt_out = dt + datetime.timedelta(seconds=tti.offset)\n\n        fold = self.is_ambiguous(dt_out, idx=idx)\n\n        return enfold(dt_out, fold=int(fold))\n\n    def is_ambiguous(self, dt, idx=None):\n        \"\"\"\n        Whether or not the \"wall time\" of a given datetime is ambiguous in this\n        zone.\n\n        :param dt:\n            A :py:class:`datetime.datetime`, naive or time zone aware.\n\n\n        :return:\n            Returns ``True`` if ambiguous, ``False`` otherwise.\n\n        .. versionadded:: 2.6.0\n        \"\"\"\n        if idx is None:\n            idx = self._find_last_transition(dt)\n\n        # Calculate the difference in offsets from current to previous\n        timestamp = _datetime_to_timestamp(dt)\n        tti = self._get_ttinfo(idx)\n\n        if idx is None or idx <= 0:\n            return False\n\n        od = self._get_ttinfo(idx - 1).offset - tti.offset\n        tt = self._trans_list[idx]          # Transition time\n\n        return timestamp < tt + od\n\n    def _resolve_ambiguous_time(self, dt):\n        idx = self._find_last_transition(dt)\n\n        # If we have no transitions, return the index\n        _fold = self._fold(dt)\n        if idx is None or idx == 0:\n            return idx\n\n        # If it's ambiguous and we're in a fold, shift to a different index.\n        idx_offset = int(not _fold and self.is_ambiguous(dt, idx))\n\n        return idx - idx_offset\n\n    def utcoffset(self, dt):\n        if dt is None:\n            return None\n\n        if not self._ttinfo_std:\n            return ZERO\n\n        return self._find_ttinfo(dt).delta\n\n    def dst(self, dt):\n        if dt is None:\n            return None\n\n        if not self._ttinfo_dst:\n            return ZERO\n\n        tti = self._find_ttinfo(dt)\n\n        if not tti.isdst:\n            return ZERO\n\n        # The documentation says that utcoffset()-dst() must\n        # be constant for every dt.\n        return tti.dstoffset\n\n    @tzname_in_python2\n    def tzname(self, dt):\n        if not self._ttinfo_std or dt is None:\n            return None\n        return self._find_ttinfo(dt).abbr\n\n    def __eq__(self, other):\n        if not isinstance(other, tzfile):\n            return NotImplemented\n        return (self._trans_list == other._trans_list and\n                self._trans_idx == other._trans_idx and\n                self._ttinfo_list == other._ttinfo_list)\n\n    __hash__ = None\n\n    def __ne__(self, other):\n        return not (self == other)\n\n    def __repr__(self):\n        return \"%s(%s)\" % (self.__class__.__name__, repr(self._filename))\n\n    def __reduce__(self):\n        return self.__reduce_ex__(None)\n\n    def __reduce_ex__(self, protocol):\n        return (self.__class__, (None, self._filename), self.__dict__)\n\n\nclass tzrange(tzrangebase):\n    \"\"\"\n    The ``tzrange`` object is a time zone specified by a set of offsets and\n    abbreviations, equivalent to the way the ``TZ`` variable can be specified\n    in POSIX-like systems, but using Python delta objects to specify DST\n    start, end and offsets.\n\n    :param stdabbr:\n        The abbreviation for standard time (e.g. ``'EST'``).\n\n    :param stdoffset:\n        An integer or :class:`datetime.timedelta` object or equivalent\n        specifying the base offset from UTC.\n\n        If unspecified, +00:00 is used.\n\n    :param dstabbr:\n        The abbreviation for DST / \"Summer\" time (e.g. ``'EDT'``).\n\n        If specified, with no other DST information, DST is assumed to occur\n        and the default behavior or ``dstoffset``, ``start`` and ``end`` is\n        used. If unspecified and no other DST information is specified, it\n        is assumed that this zone has no DST.\n\n        If this is unspecified and other DST information is *is* specified,\n        DST occurs in the zone but the time zone abbreviation is left\n        unchanged.\n\n    :param dstoffset:\n        A an integer or :class:`datetime.timedelta` object or equivalent\n        specifying the UTC offset during DST. If unspecified and any other DST\n        information is specified, it is assumed to be the STD offset +1 hour.\n\n    :param start:\n        A :class:`relativedelta.relativedelta` object or equivalent specifying\n        the time and time of year that daylight savings time starts. To\n        specify, for example, that DST starts at 2AM on the 2nd Sunday in\n        March, pass:\n\n            ``relativedelta(hours=2, month=3, day=1, weekday=SU(+2))``\n\n        If unspecified and any other DST information is specified, the default\n        value is 2 AM on the first Sunday in April.\n\n    :param end:\n        A :class:`relativedelta.relativedelta` object or equivalent\n        representing the time and time of year that daylight savings time\n        ends, with the same specification method as in ``start``. One note is\n        that this should point to the first time in the *standard* zone, so if\n        a transition occurs at 2AM in the DST zone and the clocks are set back\n        1 hour to 1AM, set the ``hours`` parameter to +1.\n\n\n    **Examples:**\n\n    .. testsetup:: tzrange\n\n        from dateutil.tz import tzrange, tzstr\n\n    .. doctest:: tzrange\n\n        >>> tzstr('EST5EDT') == tzrange(\"EST\", -18000, \"EDT\")\n        True\n\n        >>> from dateutil.relativedelta import *\n        >>> range1 = tzrange(\"EST\", -18000, \"EDT\")\n        >>> range2 = tzrange(\"EST\", -18000, \"EDT\", -14400,\n        ...                  relativedelta(hours=+2, month=4, day=1,\n        ...                                weekday=SU(+1)),\n        ...                  relativedelta(hours=+1, month=10, day=31,\n        ...                                weekday=SU(-1)))\n        >>> tzstr('EST5EDT') == range1 == range2\n        True\n\n    \"\"\"\n    def __init__(self, stdabbr, stdoffset=None,\n                 dstabbr=None, dstoffset=None,\n                 start=None, end=None):\n\n        global relativedelta\n        from dateutil import relativedelta\n\n        self._std_abbr = stdabbr\n        self._dst_abbr = dstabbr\n\n        try:\n            stdoffset = stdoffset.total_seconds()\n        except (TypeError, AttributeError):\n            pass\n\n        try:\n            dstoffset = dstoffset.total_seconds()\n        except (TypeError, AttributeError):\n            pass\n\n        if stdoffset is not None:\n            self._std_offset = datetime.timedelta(seconds=stdoffset)\n        else:\n            self._std_offset = ZERO\n\n        if dstoffset is not None:\n            self._dst_offset = datetime.timedelta(seconds=dstoffset)\n        elif dstabbr and stdoffset is not None:\n            self._dst_offset = self._std_offset + datetime.timedelta(hours=+1)\n        else:\n            self._dst_offset = ZERO\n\n        if dstabbr and start is None:\n            self._start_delta = relativedelta.relativedelta(\n                hours=+2, month=4, day=1, weekday=relativedelta.SU(+1))\n        else:\n            self._start_delta = start\n\n        if dstabbr and end is None:\n            self._end_delta = relativedelta.relativedelta(\n                hours=+1, month=10, day=31, weekday=relativedelta.SU(-1))\n        else:\n            self._end_delta = end\n\n        self._dst_base_offset_ = self._dst_offset - self._std_offset\n        self.hasdst = bool(self._start_delta)\n\n    def transitions(self, year):\n        \"\"\"\n        For a given year, get the DST on and off transition times, expressed\n        always on the standard time side. For zones with no transitions, this\n        function returns ``None``.\n\n        :param year:\n            The year whose transitions you would like to query.\n\n        :return:\n            Returns a :class:`tuple` of :class:`datetime.datetime` objects,\n            ``(dston, dstoff)`` for zones with an annual DST transition, or\n            ``None`` for fixed offset zones.\n        \"\"\"\n        if not self.hasdst:\n            return None\n\n        base_year = datetime.datetime(year, 1, 1)\n\n        start = base_year + self._start_delta\n        end = base_year + self._end_delta\n\n        return (start, end)\n\n    def __eq__(self, other):\n        if not isinstance(other, tzrange):\n            return NotImplemented\n\n        return (self._std_abbr == other._std_abbr and\n                self._dst_abbr == other._dst_abbr and\n                self._std_offset == other._std_offset and\n                self._dst_offset == other._dst_offset and\n                self._start_delta == other._start_delta and\n                self._end_delta == other._end_delta)\n\n    @property\n    def _dst_base_offset(self):\n        return self._dst_base_offset_\n\n\n@six.add_metaclass(_TzStrFactory)\nclass tzstr(tzrange):\n    \"\"\"\n    ``tzstr`` objects are time zone objects specified by a time-zone string as\n    it would be passed to a ``TZ`` variable on POSIX-style systems (see\n    the `GNU C Library: TZ Variable`_ for more details).\n\n    There is one notable exception, which is that POSIX-style time zones use an\n    inverted offset format, so normally ``GMT+3`` would be parsed as an offset\n    3 hours *behind* GMT. The ``tzstr`` time zone object will parse this as an\n    offset 3 hours *ahead* of GMT. If you would like to maintain the POSIX\n    behavior, pass a ``True`` value to ``posix_offset``.\n\n    The :class:`tzrange` object provides the same functionality, but is\n    specified using :class:`relativedelta.relativedelta` objects. rather than\n    strings.\n\n    :param s:\n        A time zone string in ``TZ`` variable format. This can be a\n        :class:`bytes` (2.x: :class:`str`), :class:`str` (2.x:\n        :class:`unicode`) or a stream emitting unicode characters\n        (e.g. :class:`StringIO`).\n\n    :param posix_offset:\n        Optional. If set to ``True``, interpret strings such as ``GMT+3`` or\n        ``UTC+3`` as being 3 hours *behind* UTC rather than ahead, per the\n        POSIX standard.\n\n    .. caution::\n\n        Prior to version 2.7.0, this function also supported time zones\n        in the format:\n\n            * ``EST5EDT,4,0,6,7200,10,0,26,7200,3600``\n            * ``EST5EDT,4,1,0,7200,10,-1,0,7200,3600``\n\n        This format is non-standard and has been deprecated; this function\n        will raise a :class:`DeprecatedTZFormatWarning` until\n        support is removed in a future version.\n\n    .. _`GNU C Library: TZ Variable`:\n        https://www.gnu.org/software/libc/manual/html_node/TZ-Variable.html\n    \"\"\"\n    def __init__(self, s, posix_offset=False):\n        global parser\n        from dateutil.parser import _parser as parser\n\n        self._s = s\n\n        res = parser._parsetz(s)\n        if res is None or res.any_unused_tokens:\n            raise ValueError(\"unknown string format\")\n\n        # Here we break the compatibility with the TZ variable handling.\n        # GMT-3 actually *means* the timezone -3.\n        if res.stdabbr in (\"GMT\", \"UTC\") and not posix_offset:\n            res.stdoffset *= -1\n\n        # We must initialize it first, since _delta() needs\n        # _std_offset and _dst_offset set. Use False in start/end\n        # to avoid building it two times.\n        tzrange.__init__(self, res.stdabbr, res.stdoffset,\n                         res.dstabbr, res.dstoffset,\n                         start=False, end=False)\n\n        if not res.dstabbr:\n            self._start_delta = None\n            self._end_delta = None\n        else:\n            self._start_delta = self._delta(res.start)\n            if self._start_delta:\n                self._end_delta = self._delta(res.end, isend=1)\n\n        self.hasdst = bool(self._start_delta)\n\n    def _delta(self, x, isend=0):\n        from dateutil import relativedelta\n        kwargs = {}\n        if x.month is not None:\n            kwargs[\"month\"] = x.month\n            if x.weekday is not None:\n                kwargs[\"weekday\"] = relativedelta.weekday(x.weekday, x.week)\n                if x.week > 0:\n                    kwargs[\"day\"] = 1\n                else:\n                    kwargs[\"day\"] = 31\n            elif x.day:\n                kwargs[\"day\"] = x.day\n        elif x.yday is not None:\n            kwargs[\"yearday\"] = x.yday\n        elif x.jyday is not None:\n            kwargs[\"nlyearday\"] = x.jyday\n        if not kwargs:\n            # Default is to start on first sunday of april, and end\n            # on last sunday of october.\n            if not isend:\n                kwargs[\"month\"] = 4\n                kwargs[\"day\"] = 1\n                kwargs[\"weekday\"] = relativedelta.SU(+1)\n            else:\n                kwargs[\"month\"] = 10\n                kwargs[\"day\"] = 31\n                kwargs[\"weekday\"] = relativedelta.SU(-1)\n        if x.time is not None:\n            kwargs[\"seconds\"] = x.time\n        else:\n            # Default is 2AM.\n            kwargs[\"seconds\"] = 7200\n        if isend:\n            # Convert to standard time, to follow the documented way\n            # of working with the extra hour. See the documentation\n            # of the tzinfo class.\n            delta = self._dst_offset - self._std_offset\n            kwargs[\"seconds\"] -= delta.seconds + delta.days * 86400\n        return relativedelta.relativedelta(**kwargs)\n\n    def __repr__(self):\n        return \"%s(%s)\" % (self.__class__.__name__, repr(self._s))\n\n\nclass _tzicalvtzcomp(object):\n    def __init__(self, tzoffsetfrom, tzoffsetto, isdst,\n                 tzname=None, rrule=None):\n        self.tzoffsetfrom = datetime.timedelta(seconds=tzoffsetfrom)\n        self.tzoffsetto = datetime.timedelta(seconds=tzoffsetto)\n        self.tzoffsetdiff = self.tzoffsetto - self.tzoffsetfrom\n        self.isdst = isdst\n        self.tzname = tzname\n        self.rrule = rrule\n\n\nclass _tzicalvtz(_tzinfo):\n    def __init__(self, tzid, comps=[]):\n        super(_tzicalvtz, self).__init__()\n\n        self._tzid = tzid\n        self._comps = comps\n        self._cachedate = []\n        self._cachecomp = []\n        self._cache_lock = _thread.allocate_lock()\n\n    def _find_comp(self, dt):\n        if len(self._comps) == 1:\n            return self._comps[0]\n\n        dt = dt.replace(tzinfo=None)\n\n        try:\n            with self._cache_lock:\n                return self._cachecomp[self._cachedate.index(\n                    (dt, self._fold(dt)))]\n        except ValueError:\n            pass\n\n        lastcompdt = None\n        lastcomp = None\n\n        for comp in self._comps:\n            compdt = self._find_compdt(comp, dt)\n\n            if compdt and (not lastcompdt or lastcompdt < compdt):\n                lastcompdt = compdt\n                lastcomp = comp\n\n        if not lastcomp:\n            # RFC says nothing about what to do when a given\n            # time is before the first onset date. We'll look for the\n            # first standard component, or the first component, if\n            # none is found.\n            for comp in self._comps:\n                if not comp.isdst:\n                    lastcomp = comp\n                    break\n            else:\n                lastcomp = comp[0]\n\n        with self._cache_lock:\n            self._cachedate.insert(0, (dt, self._fold(dt)))\n            self._cachecomp.insert(0, lastcomp)\n\n            if len(self._cachedate) > 10:\n                self._cachedate.pop()\n                self._cachecomp.pop()\n\n        return lastcomp\n\n    def _find_compdt(self, comp, dt):\n        if comp.tzoffsetdiff < ZERO and self._fold(dt):\n            dt -= comp.tzoffsetdiff\n\n        compdt = comp.rrule.before(dt, inc=True)\n\n        return compdt\n\n    def utcoffset(self, dt):\n        if dt is None:\n            return None\n\n        return self._find_comp(dt).tzoffsetto\n\n    def dst(self, dt):\n        comp = self._find_comp(dt)\n        if comp.isdst:\n            return comp.tzoffsetdiff\n        else:\n            return ZERO\n\n    @tzname_in_python2\n    def tzname(self, dt):\n        return self._find_comp(dt).tzname\n\n    def __repr__(self):\n        return \"<tzicalvtz %s>\" % repr(self._tzid)\n\n    __reduce__ = object.__reduce__\n\n\nclass tzical(object):\n    \"\"\"\n    This object is designed to parse an iCalendar-style ``VTIMEZONE`` structure\n    as set out in `RFC 5545`_ Section 4.6.5 into one or more `tzinfo` objects.\n\n    :param `fileobj`:\n        A file or stream in iCalendar format, which should be UTF-8 encoded\n        with CRLF endings.\n\n    .. _`RFC 5545`: https://tools.ietf.org/html/rfc5545\n    \"\"\"\n    def __init__(self, fileobj):\n        global rrule\n        from dateutil import rrule\n\n        if isinstance(fileobj, string_types):\n            self._s = fileobj\n            # ical should be encoded in UTF-8 with CRLF\n            fileobj = open(fileobj, 'r')\n        else:\n            self._s = getattr(fileobj, 'name', repr(fileobj))\n            fileobj = _nullcontext(fileobj)\n\n        self._vtz = {}\n\n        with fileobj as fobj:\n            self._parse_rfc(fobj.read())\n\n    def keys(self):\n        \"\"\"\n        Retrieves the available time zones as a list.\n        \"\"\"\n        return list(self._vtz.keys())\n\n    def get(self, tzid=None):\n        \"\"\"\n        Retrieve a :py:class:`datetime.tzinfo` object by its ``tzid``.\n\n        :param tzid:\n            If there is exactly one time zone available, omitting ``tzid``\n            or passing :py:const:`None` value returns it. Otherwise a valid\n            key (which can be retrieved from :func:`keys`) is required.\n\n        :raises ValueError:\n            Raised if ``tzid`` is not specified but there are either more\n            or fewer than 1 zone defined.\n\n        :returns:\n            Returns either a :py:class:`datetime.tzinfo` object representing\n            the relevant time zone or :py:const:`None` if the ``tzid`` was\n            not found.\n        \"\"\"\n        if tzid is None:\n            if len(self._vtz) == 0:\n                raise ValueError(\"no timezones defined\")\n            elif len(self._vtz) > 1:\n                raise ValueError(\"more than one timezone available\")\n            tzid = next(iter(self._vtz))\n\n        return self._vtz.get(tzid)\n\n    def _parse_offset(self, s):\n        s = s.strip()\n        if not s:\n            raise ValueError(\"empty offset\")\n        if s[0] in ('+', '-'):\n            signal = (-1, +1)[s[0] == '+']\n            s = s[1:]\n        else:\n            signal = +1\n        if len(s) == 4:\n            return (int(s[:2]) * 3600 + int(s[2:]) * 60) * signal\n        elif len(s) == 6:\n            return (int(s[:2]) * 3600 + int(s[2:4]) * 60 + int(s[4:])) * signal\n        else:\n            raise ValueError(\"invalid offset: \" + s)\n\n    def _parse_rfc(self, s):\n        lines = s.splitlines()\n        if not lines:\n            raise ValueError(\"empty string\")\n\n        # Unfold\n        i = 0\n        while i < len(lines):\n            line = lines[i].rstrip()\n            if not line:\n                del lines[i]\n            elif i > 0 and line[0] == \" \":\n                lines[i-1] += line[1:]\n                del lines[i]\n            else:\n                i += 1\n\n        tzid = None\n        comps = []\n        invtz = False\n        comptype = None\n        for line in lines:\n            if not line:\n                continue\n            name, value = line.split(':', 1)\n            parms = name.split(';')\n            if not parms:\n                raise ValueError(\"empty property name\")\n            name = parms[0].upper()\n            parms = parms[1:]\n            if invtz:\n                if name == \"BEGIN\":\n                    if value in (\"STANDARD\", \"DAYLIGHT\"):\n                        # Process component\n                        pass\n                    else:\n                        raise ValueError(\"unknown component: \"+value)\n                    comptype = value\n                    founddtstart = False\n                    tzoffsetfrom = None\n                    tzoffsetto = None\n                    rrulelines = []\n                    tzname = None\n                elif name == \"END\":\n                    if value == \"VTIMEZONE\":\n                        if comptype:\n                            raise ValueError(\"component not closed: \"+comptype)\n                        if not tzid:\n                            raise ValueError(\"mandatory TZID not found\")\n                        if not comps:\n                            raise ValueError(\n                                \"at least one component is needed\")\n                        # Process vtimezone\n                        self._vtz[tzid] = _tzicalvtz(tzid, comps)\n                        invtz = False\n                    elif value == comptype:\n                        if not founddtstart:\n                            raise ValueError(\"mandatory DTSTART not found\")\n                        if tzoffsetfrom is None:\n                            raise ValueError(\n                                \"mandatory TZOFFSETFROM not found\")\n                        if tzoffsetto is None:\n                            raise ValueError(\n                                \"mandatory TZOFFSETFROM not found\")\n                        # Process component\n                        rr = None\n                        if rrulelines:\n                            rr = rrule.rrulestr(\"\\n\".join(rrulelines),\n                                                compatible=True,\n                                                ignoretz=True,\n                                                cache=True)\n                        comp = _tzicalvtzcomp(tzoffsetfrom, tzoffsetto,\n                                              (comptype == \"DAYLIGHT\"),\n                                              tzname, rr)\n                        comps.append(comp)\n                        comptype = None\n                    else:\n                        raise ValueError(\"invalid component end: \"+value)\n                elif comptype:\n                    if name == \"DTSTART\":\n                        # DTSTART in VTIMEZONE takes a subset of valid RRULE\n                        # values under RFC 5545.\n                        for parm in parms:\n                            if parm != 'VALUE=DATE-TIME':\n                                msg = ('Unsupported DTSTART param in ' +\n                                       'VTIMEZONE: ' + parm)\n                                raise ValueError(msg)\n                        rrulelines.append(line)\n                        founddtstart = True\n                    elif name in (\"RRULE\", \"RDATE\", \"EXRULE\", \"EXDATE\"):\n                        rrulelines.append(line)\n                    elif name == \"TZOFFSETFROM\":\n                        if parms:\n                            raise ValueError(\n                                \"unsupported %s parm: %s \" % (name, parms[0]))\n                        tzoffsetfrom = self._parse_offset(value)\n                    elif name == \"TZOFFSETTO\":\n                        if parms:\n                            raise ValueError(\n                                \"unsupported TZOFFSETTO parm: \"+parms[0])\n                        tzoffsetto = self._parse_offset(value)\n                    elif name == \"TZNAME\":\n                        if parms:\n                            raise ValueError(\n                                \"unsupported TZNAME parm: \"+parms[0])\n                        tzname = value\n                    elif name == \"COMMENT\":\n                        pass\n                    else:\n                        raise ValueError(\"unsupported property: \"+name)\n                else:\n                    if name == \"TZID\":\n                        if parms:\n                            raise ValueError(\n                                \"unsupported TZID parm: \"+parms[0])\n                        tzid = value\n                    elif name in (\"TZURL\", \"LAST-MODIFIED\", \"COMMENT\"):\n                        pass\n                    else:\n                        raise ValueError(\"unsupported property: \"+name)\n            elif name == \"BEGIN\" and value == \"VTIMEZONE\":\n                tzid = None\n                comps = []\n                invtz = True\n\n    def __repr__(self):\n        return \"%s(%s)\" % (self.__class__.__name__, repr(self._s))\n\n\nif sys.platform != \"win32\":\n    TZFILES = [\"/etc/localtime\", \"localtime\"]\n    TZPATHS = [\"/usr/share/zoneinfo\",\n               \"/usr/lib/zoneinfo\",\n               \"/usr/share/lib/zoneinfo\",\n               \"/etc/zoneinfo\"]\nelse:\n    TZFILES = []\n    TZPATHS = []\n\n\ndef __get_gettz():\n    tzlocal_classes = (tzlocal,)\n    if tzwinlocal is not None:\n        tzlocal_classes += (tzwinlocal,)\n\n    class GettzFunc(object):\n        \"\"\"\n        Retrieve a time zone object from a string representation\n\n        This function is intended to retrieve the :py:class:`tzinfo` subclass\n        that best represents the time zone that would be used if a POSIX\n        `TZ variable`_ were set to the same value.\n\n        If no argument or an empty string is passed to ``gettz``, local time\n        is returned:\n\n        .. code-block:: python3\n\n            >>> gettz()\n            tzfile('/etc/localtime')\n\n        This function is also the preferred way to map IANA tz database keys\n        to :class:`tzfile` objects:\n\n        .. code-block:: python3\n\n            >>> gettz('Pacific/Kiritimati')\n            tzfile('/usr/share/zoneinfo/Pacific/Kiritimati')\n\n        On Windows, the standard is extended to include the Windows-specific\n        zone names provided by the operating system:\n\n        .. code-block:: python3\n\n            >>> gettz('Egypt Standard Time')\n            tzwin('Egypt Standard Time')\n\n        Passing a GNU ``TZ`` style string time zone specification returns a\n        :class:`tzstr` object:\n\n        .. code-block:: python3\n\n            >>> gettz('AEST-10AEDT-11,M10.1.0/2,M4.1.0/3')\n            tzstr('AEST-10AEDT-11,M10.1.0/2,M4.1.0/3')\n\n        :param name:\n            A time zone name (IANA, or, on Windows, Windows keys), location of\n            a ``tzfile(5)`` zoneinfo file or ``TZ`` variable style time zone\n            specifier. An empty string, no argument or ``None`` is interpreted\n            as local time.\n\n        :return:\n            Returns an instance of one of ``dateutil``'s :py:class:`tzinfo`\n            subclasses.\n\n        .. versionchanged:: 2.7.0\n\n            After version 2.7.0, any two calls to ``gettz`` using the same\n            input strings will return the same object:\n\n            .. code-block:: python3\n\n                >>> tz.gettz('America/Chicago') is tz.gettz('America/Chicago')\n                True\n\n            In addition to improving performance, this ensures that\n            `\"same zone\" semantics`_ are used for datetimes in the same zone.\n\n\n        .. _`TZ variable`:\n            https://www.gnu.org/software/libc/manual/html_node/TZ-Variable.html\n\n        .. _`\"same zone\" semantics`:\n            https://blog.ganssle.io/articles/2018/02/aware-datetime-arithmetic.html\n        \"\"\"\n        def __init__(self):\n\n            self.__instances = weakref.WeakValueDictionary()\n            self.__strong_cache_size = 8\n            self.__strong_cache = OrderedDict()\n            self._cache_lock = _thread.allocate_lock()\n\n        def __call__(self, name=None):\n            with self._cache_lock:\n                rv = self.__instances.get(name, None)\n\n                if rv is None:\n                    rv = self.nocache(name=name)\n                    if not (name is None\n                            or isinstance(rv, tzlocal_classes)\n                            or rv is None):\n                        # tzlocal is slightly more complicated than the other\n                        # time zone providers because it depends on environment\n                        # at construction time, so don't cache that.\n                        #\n                        # We also cannot store weak references to None, so we\n                        # will also not store that.\n                        self.__instances[name] = rv\n                    else:\n                        # No need for strong caching, return immediately\n                        return rv\n\n                self.__strong_cache[name] = self.__strong_cache.pop(name, rv)\n\n                if len(self.__strong_cache) > self.__strong_cache_size:\n                    self.__strong_cache.popitem(last=False)\n\n            return rv\n\n        def set_cache_size(self, size):\n            with self._cache_lock:\n                self.__strong_cache_size = size\n                while len(self.__strong_cache) > size:\n                    self.__strong_cache.popitem(last=False)\n\n        def cache_clear(self):\n            with self._cache_lock:\n                self.__instances = weakref.WeakValueDictionary()\n                self.__strong_cache.clear()\n\n        @staticmethod\n        def nocache(name=None):\n            \"\"\"A non-cached version of gettz\"\"\"\n            tz = None\n            if not name:\n                try:\n                    name = os.environ[\"TZ\"]\n                except KeyError:\n                    pass\n            if name is None or name in (\"\", \":\"):\n                for filepath in TZFILES:\n                    if not os.path.isabs(filepath):\n                        filename = filepath\n                        for path in TZPATHS:\n                            filepath = os.path.join(path, filename)\n                            if os.path.isfile(filepath):\n                                break\n                        else:\n                            continue\n                    if os.path.isfile(filepath):\n                        try:\n                            tz = tzfile(filepath)\n                            break\n                        except (IOError, OSError, ValueError):\n                            pass\n                else:\n                    tz = tzlocal()\n            else:\n                try:\n                    if name.startswith(\":\"):\n                        name = name[1:]\n                except TypeError as e:\n                    if isinstance(name, bytes):\n                        new_msg = \"gettz argument should be str, not bytes\"\n                        six.raise_from(TypeError(new_msg), e)\n                    else:\n                        raise\n                if os.path.isabs(name):\n                    if os.path.isfile(name):\n                        tz = tzfile(name)\n                    else:\n                        tz = None\n                else:\n                    for path in TZPATHS:\n                        filepath = os.path.join(path, name)\n                        if not os.path.isfile(filepath):\n                            filepath = filepath.replace(' ', '_')\n                            if not os.path.isfile(filepath):\n                                continue\n                        try:\n                            tz = tzfile(filepath)\n                            break\n                        except (IOError, OSError, ValueError):\n                            pass\n                    else:\n                        tz = None\n                        if tzwin is not None:\n                            try:\n                                tz = tzwin(name)\n                            except (WindowsError, UnicodeEncodeError):\n                                # UnicodeEncodeError is for Python 2.7 compat\n                                tz = None\n\n                        if not tz:\n                            from dateutil.zoneinfo import get_zonefile_instance\n                            tz = get_zonefile_instance().get(name)\n\n                        if not tz:\n                            for c in name:\n                                # name is not a tzstr unless it has at least\n                                # one offset. For short values of \"name\", an\n                                # explicit for loop seems to be the fastest way\n                                # To determine if a string contains a digit\n                                if c in \"0123456789\":\n                                    try:\n                                        tz = tzstr(name)\n                                    except ValueError:\n                                        pass\n                                    break\n                            else:\n                                if name in (\"GMT\", \"UTC\"):\n                                    tz = UTC\n                                elif name in time.tzname:\n                                    tz = tzlocal()\n            return tz\n\n    return GettzFunc()\n\n\ngettz = __get_gettz()\ndel __get_gettz\n\n\ndef datetime_exists(dt, tz=None):\n    \"\"\"\n    Given a datetime and a time zone, determine whether or not a given datetime\n    would fall in a gap.\n\n    :param dt:\n        A :class:`datetime.datetime` (whose time zone will be ignored if ``tz``\n        is provided.)\n\n    :param tz:\n        A :class:`datetime.tzinfo` with support for the ``fold`` attribute. If\n        ``None`` or not provided, the datetime's own time zone will be used.\n\n    :return:\n        Returns a boolean value whether or not the \"wall time\" exists in\n        ``tz``.\n\n    .. versionadded:: 2.7.0\n    \"\"\"\n    if tz is None:\n        if dt.tzinfo is None:\n            raise ValueError('Datetime is naive and no time zone provided.')\n        tz = dt.tzinfo\n\n    dt = dt.replace(tzinfo=None)\n\n    # This is essentially a test of whether or not the datetime can survive\n    # a round trip to UTC.\n    dt_rt = dt.replace(tzinfo=tz).astimezone(UTC).astimezone(tz)\n    dt_rt = dt_rt.replace(tzinfo=None)\n\n    return dt == dt_rt\n\n\ndef datetime_ambiguous(dt, tz=None):\n    \"\"\"\n    Given a datetime and a time zone, determine whether or not a given datetime\n    is ambiguous (i.e if there are two times differentiated only by their DST\n    status).\n\n    :param dt:\n        A :class:`datetime.datetime` (whose time zone will be ignored if ``tz``\n        is provided.)\n\n    :param tz:\n        A :class:`datetime.tzinfo` with support for the ``fold`` attribute. If\n        ``None`` or not provided, the datetime's own time zone will be used.\n\n    :return:\n        Returns a boolean value whether or not the \"wall time\" is ambiguous in\n        ``tz``.\n\n    .. versionadded:: 2.6.0\n    \"\"\"\n    if tz is None:\n        if dt.tzinfo is None:\n            raise ValueError('Datetime is naive and no time zone provided.')\n\n        tz = dt.tzinfo\n\n    # If a time zone defines its own \"is_ambiguous\" function, we'll use that.\n    is_ambiguous_fn = getattr(tz, 'is_ambiguous', None)\n    if is_ambiguous_fn is not None:\n        try:\n            return tz.is_ambiguous(dt)\n        except Exception:\n            pass\n\n    # If it doesn't come out and tell us it's ambiguous, we'll just check if\n    # the fold attribute has any effect on this particular date and time.\n    dt = dt.replace(tzinfo=tz)\n    wall_0 = enfold(dt, fold=0)\n    wall_1 = enfold(dt, fold=1)\n\n    same_offset = wall_0.utcoffset() == wall_1.utcoffset()\n    same_dst = wall_0.dst() == wall_1.dst()\n\n    return not (same_offset and same_dst)\n\n\ndef resolve_imaginary(dt):\n    \"\"\"\n    Given a datetime that may be imaginary, return an existing datetime.\n\n    This function assumes that an imaginary datetime represents what the\n    wall time would be in a zone had the offset transition not occurred, so\n    it will always fall forward by the transition's change in offset.\n\n    .. doctest::\n\n        >>> from dateutil import tz\n        >>> from datetime import datetime\n        >>> NYC = tz.gettz('America/New_York')\n        >>> print(tz.resolve_imaginary(datetime(2017, 3, 12, 2, 30, tzinfo=NYC)))\n        2017-03-12 03:30:00-04:00\n\n        >>> KIR = tz.gettz('Pacific/Kiritimati')\n        >>> print(tz.resolve_imaginary(datetime(1995, 1, 1, 12, 30, tzinfo=KIR)))\n        1995-01-02 12:30:00+14:00\n\n    As a note, :func:`datetime.astimezone` is guaranteed to produce a valid,\n    existing datetime, so a round-trip to and from UTC is sufficient to get\n    an extant datetime, however, this generally \"falls back\" to an earlier time\n    rather than falling forward to the STD side (though no guarantees are made\n    about this behavior).\n\n    :param dt:\n        A :class:`datetime.datetime` which may or may not exist.\n\n    :return:\n        Returns an existing :class:`datetime.datetime`. If ``dt`` was not\n        imaginary, the datetime returned is guaranteed to be the same object\n        passed to the function.\n\n    .. versionadded:: 2.7.0\n    \"\"\"\n    if dt.tzinfo is not None and not datetime_exists(dt):\n\n        curr_offset = (dt + datetime.timedelta(hours=24)).utcoffset()\n        old_offset = (dt - datetime.timedelta(hours=24)).utcoffset()\n\n        dt += curr_offset - old_offset\n\n    return dt\n\n\ndef _datetime_to_timestamp(dt):\n    \"\"\"\n    Convert a :class:`datetime.datetime` object to an epoch timestamp in\n    seconds since January 1, 1970, ignoring the time zone.\n    \"\"\"\n    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()\n\n\nif sys.version_info >= (3, 6):\n    def _get_supported_offset(second_offset):\n        return second_offset\nelse:\n    def _get_supported_offset(second_offset):\n        # For python pre-3.6, round to full-minutes if that's not the case.\n        # Python's datetime doesn't accept sub-minute timezones. Check\n        # http://python.org/sf/1447945 or https://bugs.python.org/issue5288\n        # for some information.\n        old_offset = second_offset\n        calculated_offset = 60 * ((second_offset + 30) // 60)\n        return calculated_offset\n\n\ntry:\n    # Python 3.7 feature\n    from contextlib import nullcontext as _nullcontext\nexcept ImportError:\n    class _nullcontext(object):\n        \"\"\"\n        Class for wrapping contexts so that they are passed through in a\n        with statement.\n        \"\"\"\n        def __init__(self, context):\n            self.context = context\n\n        def __enter__(self):\n            return self.context\n\n        def __exit__(*args, **kwargs):\n            pass\n\n# vim:ts=4:sw=4:et\n",1849],"C:\\Users\\adam\\miniconda3\\Lib\\threading.py":["\"\"\"Thread module emulating a subset of Java's threading model.\"\"\"\n\nimport os as _os\nimport sys as _sys\nimport _thread\nimport functools\n\nfrom time import monotonic as _time\nfrom _weakrefset import WeakSet\nfrom itertools import islice as _islice, count as _count\ntry:\n    from _collections import deque as _deque\nexcept ImportError:\n    from collections import deque as _deque\n\n# Note regarding PEP 8 compliant names\n#  This threading model was originally inspired by Java, and inherited\n# the convention of camelCase function and method names from that\n# language. Those original names are not in any imminent danger of\n# being deprecated (even for Py3k),so this module provides them as an\n# alias for the PEP 8 compliant names\n# Note that using the new PEP 8 compliant names facilitates substitution\n# with the multiprocessing module, which doesn't provide the old\n# Java inspired names.\n\n__all__ = ['get_ident', 'active_count', 'Condition', 'current_thread',\n           'enumerate', 'main_thread', 'TIMEOUT_MAX',\n           'Event', 'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Thread',\n           'Barrier', 'BrokenBarrierError', 'Timer', 'ThreadError',\n           'setprofile', 'settrace', 'local', 'stack_size',\n           'excepthook', 'ExceptHookArgs', 'gettrace', 'getprofile']\n\n# Rename some stuff so \"from threading import *\" is safe\n_start_new_thread = _thread.start_new_thread\n_allocate_lock = _thread.allocate_lock\n_set_sentinel = _thread._set_sentinel\nget_ident = _thread.get_ident\ntry:\n    get_native_id = _thread.get_native_id\n    _HAVE_THREAD_NATIVE_ID = True\n    __all__.append('get_native_id')\nexcept AttributeError:\n    _HAVE_THREAD_NATIVE_ID = False\nThreadError = _thread.error\ntry:\n    _CRLock = _thread.RLock\nexcept AttributeError:\n    _CRLock = None\nTIMEOUT_MAX = _thread.TIMEOUT_MAX\ndel _thread\n\n\n# Support for profile and trace hooks\n\n_profile_hook = None\n_trace_hook = None\n\ndef setprofile(func):\n    \"\"\"Set a profile function for all threads started from the threading module.\n\n    The func will be passed to sys.setprofile() for each thread, before its\n    run() method is called.\n\n    \"\"\"\n    global _profile_hook\n    _profile_hook = func\n\ndef getprofile():\n    \"\"\"Get the profiler function as set by threading.setprofile().\"\"\"\n    return _profile_hook\n\ndef settrace(func):\n    \"\"\"Set a trace function for all threads started from the threading module.\n\n    The func will be passed to sys.settrace() for each thread, before its run()\n    method is called.\n\n    \"\"\"\n    global _trace_hook\n    _trace_hook = func\n\ndef gettrace():\n    \"\"\"Get the trace function as set by threading.settrace().\"\"\"\n    return _trace_hook\n\n# Synchronization classes\n\nLock = _allocate_lock\n\ndef RLock(*args, **kwargs):\n    \"\"\"Factory function that returns a new reentrant lock.\n\n    A reentrant lock must be released by the thread that acquired it. Once a\n    thread has acquired a reentrant lock, the same thread may acquire it again\n    without blocking; the thread must release it once for each time it has\n    acquired it.\n\n    \"\"\"\n    if _CRLock is None:\n        return _PyRLock(*args, **kwargs)\n    return _CRLock(*args, **kwargs)\n\nclass _RLock:\n    \"\"\"This class implements reentrant lock objects.\n\n    A reentrant lock must be released by the thread that acquired it. Once a\n    thread has acquired a reentrant lock, the same thread may acquire it\n    again without blocking; the thread must release it once for each time it\n    has acquired it.\n\n    \"\"\"\n\n    def __init__(self):\n        self._block = _allocate_lock()\n        self._owner = None\n        self._count = 0\n\n    def __repr__(self):\n        owner = self._owner\n        try:\n            owner = _active[owner].name\n        except KeyError:\n            pass\n        return \"<%s %s.%s object owner=%r count=%d at %s>\" % (\n            \"locked\" if self._block.locked() else \"unlocked\",\n            self.__class__.__module__,\n            self.__class__.__qualname__,\n            owner,\n            self._count,\n            hex(id(self))\n        )\n\n    def _at_fork_reinit(self):\n        self._block._at_fork_reinit()\n        self._owner = None\n        self._count = 0\n\n    def acquire(self, blocking=True, timeout=-1):\n        \"\"\"Acquire a lock, blocking or non-blocking.\n\n        When invoked without arguments: if this thread already owns the lock,\n        increment the recursion level by one, and return immediately. Otherwise,\n        if another thread owns the lock, block until the lock is unlocked. Once\n        the lock is unlocked (not owned by any thread), then grab ownership, set\n        the recursion level to one, and return. If more than one thread is\n        blocked waiting until the lock is unlocked, only one at a time will be\n        able to grab ownership of the lock. There is no return value in this\n        case.\n\n        When invoked with the blocking argument set to true, do the same thing\n        as when called without arguments, and return true.\n\n        When invoked with the blocking argument set to false, do not block. If a\n        call without an argument would block, return false immediately;\n        otherwise, do the same thing as when called without arguments, and\n        return true.\n\n        When invoked with the floating-point timeout argument set to a positive\n        value, block for at most the number of seconds specified by timeout\n        and as long as the lock cannot be acquired.  Return true if the lock has\n        been acquired, false if the timeout has elapsed.\n\n        \"\"\"\n        me = get_ident()\n        if self._owner == me:\n            self._count += 1\n            return 1\n        rc = self._block.acquire(blocking, timeout)\n        if rc:\n            self._owner = me\n            self._count = 1\n        return rc\n\n    __enter__ = acquire\n\n    def release(self):\n        \"\"\"Release a lock, decrementing the recursion level.\n\n        If after the decrement it is zero, reset the lock to unlocked (not owned\n        by any thread), and if any other threads are blocked waiting for the\n        lock to become unlocked, allow exactly one of them to proceed. If after\n        the decrement the recursion level is still nonzero, the lock remains\n        locked and owned by the calling thread.\n\n        Only call this method when the calling thread owns the lock. A\n        RuntimeError is raised if this method is called when the lock is\n        unlocked.\n\n        There is no return value.\n\n        \"\"\"\n        if self._owner != get_ident():\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        self._count = count = self._count - 1\n        if not count:\n            self._owner = None\n            self._block.release()\n\n    def __exit__(self, t, v, tb):\n        self.release()\n\n    # Internal methods used by condition variables\n\n    def _acquire_restore(self, state):\n        self._block.acquire()\n        self._count, self._owner = state\n\n    def _release_save(self):\n        if self._count == 0:\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        count = self._count\n        self._count = 0\n        owner = self._owner\n        self._owner = None\n        self._block.release()\n        return (count, owner)\n\n    def _is_owned(self):\n        return self._owner == get_ident()\n\n_PyRLock = _RLock\n\n\nclass Condition:\n    \"\"\"Class that implements a condition variable.\n\n    A condition variable allows one or more threads to wait until they are\n    notified by another thread.\n\n    If the lock argument is given and not None, it must be a Lock or RLock\n    object, and it is used as the underlying lock. Otherwise, a new RLock object\n    is created and used as the underlying lock.\n\n    \"\"\"\n\n    def __init__(self, lock=None):\n        if lock is None:\n            lock = RLock()\n        self._lock = lock\n        # Export the lock's acquire() and release() methods\n        self.acquire = lock.acquire\n        self.release = lock.release\n        # If the lock defines _release_save() and/or _acquire_restore(),\n        # these override the default implementations (which just call\n        # release() and acquire() on the lock).  Ditto for _is_owned().\n        try:\n            self._release_save = lock._release_save\n        except AttributeError:\n            pass\n        try:\n            self._acquire_restore = lock._acquire_restore\n        except AttributeError:\n            pass\n        try:\n            self._is_owned = lock._is_owned\n        except AttributeError:\n            pass\n        self._waiters = _deque()\n\n    def _at_fork_reinit(self):\n        self._lock._at_fork_reinit()\n        self._waiters.clear()\n\n    def __enter__(self):\n        return self._lock.__enter__()\n\n    def __exit__(self, *args):\n        return self._lock.__exit__(*args)\n\n    def __repr__(self):\n        return \"<Condition(%s, %d)>\" % (self._lock, len(self._waiters))\n\n    def _release_save(self):\n        self._lock.release()           # No state to save\n\n    def _acquire_restore(self, x):\n        self._lock.acquire()           # Ignore saved state\n\n    def _is_owned(self):\n        # Return True if lock is owned by current_thread.\n        # This method is called only if _lock doesn't have _is_owned().\n        if self._lock.acquire(False):\n            self._lock.release()\n            return False\n        else:\n            return True\n\n    def wait(self, timeout=None):\n        \"\"\"Wait until notified or until a timeout occurs.\n\n        If the calling thread has not acquired the lock when this method is\n        called, a RuntimeError is raised.\n\n        This method releases the underlying lock, and then blocks until it is\n        awakened by a notify() or notify_all() call for the same condition\n        variable in another thread, or until the optional timeout occurs. Once\n        awakened or timed out, it re-acquires the lock and returns.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof).\n\n        When the underlying lock is an RLock, it is not released using its\n        release() method, since this may not actually unlock the lock when it\n        was acquired multiple times recursively. Instead, an internal interface\n        of the RLock class is used, which really unlocks it even when it has\n        been recursively acquired several times. Another internal interface is\n        then used to restore the recursion level when the lock is reacquired.\n\n        \"\"\"\n        if not self._is_owned():\n            raise RuntimeError(\"cannot wait on un-acquired lock\")\n        waiter = _allocate_lock()\n        waiter.acquire()\n        self._waiters.append(waiter)\n        saved_state = self._release_save()\n        gotit = False\n        try:    # restore state no matter what (e.g., KeyboardInterrupt)\n            if timeout is None:\n                waiter.acquire()\n                gotit = True\n            else:\n                if timeout > 0:\n                    gotit = waiter.acquire(True, timeout)\n                else:\n                    gotit = waiter.acquire(False)\n            return gotit\n        finally:\n            self._acquire_restore(saved_state)\n            if not gotit:\n                try:\n                    self._waiters.remove(waiter)\n                except ValueError:\n                    pass\n\n    def wait_for(self, predicate, timeout=None):\n        \"\"\"Wait until a condition evaluates to True.\n\n        predicate should be a callable which result will be interpreted as a\n        boolean value.  A timeout may be provided giving the maximum time to\n        wait.\n\n        \"\"\"\n        endtime = None\n        waittime = timeout\n        result = predicate()\n        while not result:\n            if waittime is not None:\n                if endtime is None:\n                    endtime = _time() + waittime\n                else:\n                    waittime = endtime - _time()\n                    if waittime <= 0:\n                        break\n            self.wait(waittime)\n            result = predicate()\n        return result\n\n    def notify(self, n=1):\n        \"\"\"Wake up one or more threads waiting on this condition, if any.\n\n        If the calling thread has not acquired the lock when this method is\n        called, a RuntimeError is raised.\n\n        This method wakes up at most n of the threads waiting for the condition\n        variable; it is a no-op if no threads are waiting.\n\n        \"\"\"\n        if not self._is_owned():\n            raise RuntimeError(\"cannot notify on un-acquired lock\")\n        waiters = self._waiters\n        while waiters and n > 0:\n            waiter = waiters[0]\n            try:\n                waiter.release()\n            except RuntimeError:\n                # gh-92530: The previous call of notify() released the lock,\n                # but was interrupted before removing it from the queue.\n                # It can happen if a signal handler raises an exception,\n                # like CTRL+C which raises KeyboardInterrupt.\n                pass\n            else:\n                n -= 1\n            try:\n                waiters.remove(waiter)\n            except ValueError:\n                pass\n\n    def notify_all(self):\n        \"\"\"Wake up all threads waiting on this condition.\n\n        If the calling thread has not acquired the lock when this method\n        is called, a RuntimeError is raised.\n\n        \"\"\"\n        self.notify(len(self._waiters))\n\n    def notifyAll(self):\n        \"\"\"Wake up all threads waiting on this condition.\n\n        This method is deprecated, use notify_all() instead.\n\n        \"\"\"\n        import warnings\n        warnings.warn('notifyAll() is deprecated, use notify_all() instead',\n                      DeprecationWarning, stacklevel=2)\n        self.notify_all()\n\n\nclass Semaphore:\n    \"\"\"This class implements semaphore objects.\n\n    Semaphores manage a counter representing the number of release() calls minus\n    the number of acquire() calls, plus an initial value. The acquire() method\n    blocks if necessary until it can return without making the counter\n    negative. If not given, value defaults to 1.\n\n    \"\"\"\n\n    # After Tim Peters' semaphore class, but not quite the same (no maximum)\n\n    def __init__(self, value=1):\n        if value < 0:\n            raise ValueError(\"semaphore initial value must be >= 0\")\n        self._cond = Condition(Lock())\n        self._value = value\n\n    def __repr__(self):\n        cls = self.__class__\n        return (f\"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}:\"\n                f\" value={self._value}>\")\n\n    def acquire(self, blocking=True, timeout=None):\n        \"\"\"Acquire a semaphore, decrementing the internal counter by one.\n\n        When invoked without arguments: if the internal counter is larger than\n        zero on entry, decrement it by one and return immediately. If it is zero\n        on entry, block, waiting until some other thread has called release() to\n        make it larger than zero. This is done with proper interlocking so that\n        if multiple acquire() calls are blocked, release() will wake exactly one\n        of them up. The implementation may pick one at random, so the order in\n        which blocked threads are awakened should not be relied on. There is no\n        return value in this case.\n\n        When invoked with blocking set to true, do the same thing as when called\n        without arguments, and return true.\n\n        When invoked with blocking set to false, do not block. If a call without\n        an argument would block, return false immediately; otherwise, do the\n        same thing as when called without arguments, and return true.\n\n        When invoked with a timeout other than None, it will block for at\n        most timeout seconds.  If acquire does not complete successfully in\n        that interval, return false.  Return true otherwise.\n\n        \"\"\"\n        if not blocking and timeout is not None:\n            raise ValueError(\"can't specify timeout for non-blocking acquire\")\n        rc = False\n        endtime = None\n        with self._cond:\n            while self._value == 0:\n                if not blocking:\n                    break\n                if timeout is not None:\n                    if endtime is None:\n                        endtime = _time() + timeout\n                    else:\n                        timeout = endtime - _time()\n                        if timeout <= 0:\n                            break\n                self._cond.wait(timeout)\n            else:\n                self._value -= 1\n                rc = True\n        return rc\n\n    __enter__ = acquire\n\n    def release(self, n=1):\n        \"\"\"Release a semaphore, incrementing the internal counter by one or more.\n\n        When the counter is zero on entry and another thread is waiting for it\n        to become larger than zero again, wake up that thread.\n\n        \"\"\"\n        if n < 1:\n            raise ValueError('n must be one or more')\n        with self._cond:\n            self._value += n\n            for i in range(n):\n                self._cond.notify()\n\n    def __exit__(self, t, v, tb):\n        self.release()\n\n\nclass BoundedSemaphore(Semaphore):\n    \"\"\"Implements a bounded semaphore.\n\n    A bounded semaphore checks to make sure its current value doesn't exceed its\n    initial value. If it does, ValueError is raised. In most situations\n    semaphores are used to guard resources with limited capacity.\n\n    If the semaphore is released too many times it's a sign of a bug. If not\n    given, value defaults to 1.\n\n    Like regular semaphores, bounded semaphores manage a counter representing\n    the number of release() calls minus the number of acquire() calls, plus an\n    initial value. The acquire() method blocks if necessary until it can return\n    without making the counter negative. If not given, value defaults to 1.\n\n    \"\"\"\n\n    def __init__(self, value=1):\n        Semaphore.__init__(self, value)\n        self._initial_value = value\n\n    def __repr__(self):\n        cls = self.__class__\n        return (f\"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}:\"\n                f\" value={self._value}/{self._initial_value}>\")\n\n    def release(self, n=1):\n        \"\"\"Release a semaphore, incrementing the internal counter by one or more.\n\n        When the counter is zero on entry and another thread is waiting for it\n        to become larger than zero again, wake up that thread.\n\n        If the number of releases exceeds the number of acquires,\n        raise a ValueError.\n\n        \"\"\"\n        if n < 1:\n            raise ValueError('n must be one or more')\n        with self._cond:\n            if self._value + n > self._initial_value:\n                raise ValueError(\"Semaphore released too many times\")\n            self._value += n\n            for i in range(n):\n                self._cond.notify()\n\n\nclass Event:\n    \"\"\"Class implementing event objects.\n\n    Events manage a flag that can be set to true with the set() method and reset\n    to false with the clear() method. The wait() method blocks until the flag is\n    true.  The flag is initially false.\n\n    \"\"\"\n\n    # After Tim Peters' event class (without is_posted())\n\n    def __init__(self):\n        self._cond = Condition(Lock())\n        self._flag = False\n\n    def __repr__(self):\n        cls = self.__class__\n        status = 'set' if self._flag else 'unset'\n        return f\"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}: {status}>\"\n\n    def _at_fork_reinit(self):\n        # Private method called by Thread._reset_internal_locks()\n        self._cond._at_fork_reinit()\n\n    def is_set(self):\n        \"\"\"Return true if and only if the internal flag is true.\"\"\"\n        return self._flag\n\n    def isSet(self):\n        \"\"\"Return true if and only if the internal flag is true.\n\n        This method is deprecated, use is_set() instead.\n\n        \"\"\"\n        import warnings\n        warnings.warn('isSet() is deprecated, use is_set() instead',\n                      DeprecationWarning, stacklevel=2)\n        return self.is_set()\n\n    def set(self):\n        \"\"\"Set the internal flag to true.\n\n        All threads waiting for it to become true are awakened. Threads\n        that call wait() once the flag is true will not block at all.\n\n        \"\"\"\n        with self._cond:\n            self._flag = True\n            self._cond.notify_all()\n\n    def clear(self):\n        \"\"\"Reset the internal flag to false.\n\n        Subsequently, threads calling wait() will block until set() is called to\n        set the internal flag to true again.\n\n        \"\"\"\n        with self._cond:\n            self._flag = False\n\n    def wait(self, timeout=None):\n        \"\"\"Block until the internal flag is true.\n\n        If the internal flag is true on entry, return immediately. Otherwise,\n        block until another thread calls set() to set the flag to true, or until\n        the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof).\n\n        This method returns the internal flag on exit, so it will always return\n        True except if a timeout is given and the operation times out.\n\n        \"\"\"\n        with self._cond:\n            signaled = self._flag\n            if not signaled:\n                signaled = self._cond.wait(timeout)\n            return signaled\n\n\n# A barrier class.  Inspired in part by the pthread_barrier_* api and\n# the CyclicBarrier class from Java.  See\n# http://sourceware.org/pthreads-win32/manual/pthread_barrier_init.html and\n# http://java.sun.com/j2se/1.5.0/docs/api/java/util/concurrent/\n#        CyclicBarrier.html\n# for information.\n# We maintain two main states, 'filling' and 'draining' enabling the barrier\n# to be cyclic.  Threads are not allowed into it until it has fully drained\n# since the previous cycle.  In addition, a 'resetting' state exists which is\n# similar to 'draining' except that threads leave with a BrokenBarrierError,\n# and a 'broken' state in which all threads get the exception.\nclass Barrier:\n    \"\"\"Implements a Barrier.\n\n    Useful for synchronizing a fixed number of threads at known synchronization\n    points.  Threads block on 'wait()' and are simultaneously awoken once they\n    have all made that call.\n\n    \"\"\"\n\n    def __init__(self, parties, action=None, timeout=None):\n        \"\"\"Create a barrier, initialised to 'parties' threads.\n\n        'action' is a callable which, when supplied, will be called by one of\n        the threads after they have all entered the barrier and just prior to\n        releasing them all. If a 'timeout' is provided, it is used as the\n        default for all subsequent 'wait()' calls.\n\n        \"\"\"\n        self._cond = Condition(Lock())\n        self._action = action\n        self._timeout = timeout\n        self._parties = parties\n        self._state = 0  # 0 filling, 1 draining, -1 resetting, -2 broken\n        self._count = 0\n\n    def __repr__(self):\n        cls = self.__class__\n        if self.broken:\n            return f\"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}: broken>\"\n        return (f\"<{cls.__module__}.{cls.__qualname__} at {id(self):#x}:\"\n                f\" waiters={self.n_waiting}/{self.parties}>\")\n\n    def wait(self, timeout=None):\n        \"\"\"Wait for the barrier.\n\n        When the specified number of threads have started waiting, they are all\n        simultaneously awoken. If an 'action' was provided for the barrier, one\n        of the threads will have executed that callback prior to returning.\n        Returns an individual index number from 0 to 'parties-1'.\n\n        \"\"\"\n        if timeout is None:\n            timeout = self._timeout\n        with self._cond:\n            self._enter() # Block while the barrier drains.\n            index = self._count\n            self._count += 1\n            try:\n                if index + 1 == self._parties:\n                    # We release the barrier\n                    self._release()\n                else:\n                    # We wait until someone releases us\n                    self._wait(timeout)\n                return index\n            finally:\n                self._count -= 1\n                # Wake up any threads waiting for barrier to drain.\n                self._exit()\n\n    # Block until the barrier is ready for us, or raise an exception\n    # if it is broken.\n    def _enter(self):\n        while self._state in (-1, 1):\n            # It is draining or resetting, wait until done\n            self._cond.wait()\n        #see if the barrier is in a broken state\n        if self._state < 0:\n            raise BrokenBarrierError\n        assert self._state == 0\n\n    # Optionally run the 'action' and release the threads waiting\n    # in the barrier.\n    def _release(self):\n        try:\n            if self._action:\n                self._action()\n            # enter draining state\n            self._state = 1\n            self._cond.notify_all()\n        except:\n            #an exception during the _action handler.  Break and reraise\n            self._break()\n            raise\n\n    # Wait in the barrier until we are released.  Raise an exception\n    # if the barrier is reset or broken.\n    def _wait(self, timeout):\n        if not self._cond.wait_for(lambda : self._state != 0, timeout):\n            #timed out.  Break the barrier\n            self._break()\n            raise BrokenBarrierError\n        if self._state < 0:\n            raise BrokenBarrierError\n        assert self._state == 1\n\n    # If we are the last thread to exit the barrier, signal any threads\n    # waiting for the barrier to drain.\n    def _exit(self):\n        if self._count == 0:\n            if self._state in (-1, 1):\n                #resetting or draining\n                self._state = 0\n                self._cond.notify_all()\n\n    def reset(self):\n        \"\"\"Reset the barrier to the initial state.\n\n        Any threads currently waiting will get the BrokenBarrier exception\n        raised.\n\n        \"\"\"\n        with self._cond:\n            if self._count > 0:\n                if self._state == 0:\n                    #reset the barrier, waking up threads\n                    self._state = -1\n                elif self._state == -2:\n                    #was broken, set it to reset state\n                    #which clears when the last thread exits\n                    self._state = -1\n            else:\n                self._state = 0\n            self._cond.notify_all()\n\n    def abort(self):\n        \"\"\"Place the barrier into a 'broken' state.\n\n        Useful in case of error.  Any currently waiting threads and threads\n        attempting to 'wait()' will have BrokenBarrierError raised.\n\n        \"\"\"\n        with self._cond:\n            self._break()\n\n    def _break(self):\n        # An internal error was detected.  The barrier is set to\n        # a broken state all parties awakened.\n        self._state = -2\n        self._cond.notify_all()\n\n    @property\n    def parties(self):\n        \"\"\"Return the number of threads required to trip the barrier.\"\"\"\n        return self._parties\n\n    @property\n    def n_waiting(self):\n        \"\"\"Return the number of threads currently waiting at the barrier.\"\"\"\n        # We don't need synchronization here since this is an ephemeral result\n        # anyway.  It returns the correct value in the steady state.\n        if self._state == 0:\n            return self._count\n        return 0\n\n    @property\n    def broken(self):\n        \"\"\"Return True if the barrier is in a broken state.\"\"\"\n        return self._state == -2\n\n# exception raised by the Barrier class\nclass BrokenBarrierError(RuntimeError):\n    pass\n\n\n# Helper to generate new thread names\n_counter = _count(1).__next__\ndef _newname(name_template):\n    return name_template % _counter()\n\n# Active thread administration.\n#\n# bpo-44422: Use a reentrant lock to allow reentrant calls to functions like\n# threading.enumerate().\n_active_limbo_lock = RLock()\n_active = {}    # maps thread id to Thread object\n_limbo = {}\n_dangling = WeakSet()\n\n# Set of Thread._tstate_lock locks of non-daemon threads used by _shutdown()\n# to wait until all Python thread states get deleted:\n# see Thread._set_tstate_lock().\n_shutdown_locks_lock = _allocate_lock()\n_shutdown_locks = set()\n\ndef _maintain_shutdown_locks():\n    \"\"\"\n    Drop any shutdown locks that don't correspond to running threads anymore.\n\n    Calling this from time to time avoids an ever-growing _shutdown_locks\n    set when Thread objects are not joined explicitly. See bpo-37788.\n\n    This must be called with _shutdown_locks_lock acquired.\n    \"\"\"\n    # If a lock was released, the corresponding thread has exited\n    to_remove = [lock for lock in _shutdown_locks if not lock.locked()]\n    _shutdown_locks.difference_update(to_remove)\n\n\n# Main class for threads\n\nclass Thread:\n    \"\"\"A class that represents a thread of control.\n\n    This class can be safely subclassed in a limited fashion. There are two ways\n    to specify the activity: by passing a callable object to the constructor, or\n    by overriding the run() method in a subclass.\n\n    \"\"\"\n\n    _initialized = False\n\n    def __init__(self, group=None, target=None, name=None,\n                 args=(), kwargs=None, *, daemon=None):\n        \"\"\"This constructor should always be called with keyword arguments. Arguments are:\n\n        *group* should be None; reserved for future extension when a ThreadGroup\n        class is implemented.\n\n        *target* is the callable object to be invoked by the run()\n        method. Defaults to None, meaning nothing is called.\n\n        *name* is the thread name. By default, a unique name is constructed of\n        the form \"Thread-N\" where N is a small decimal number.\n\n        *args* is a list or tuple of arguments for the target invocation. Defaults to ().\n\n        *kwargs* is a dictionary of keyword arguments for the target\n        invocation. Defaults to {}.\n\n        If a subclass overrides the constructor, it must make sure to invoke\n        the base class constructor (Thread.__init__()) before doing anything\n        else to the thread.\n\n        \"\"\"\n        assert group is None, \"group argument must be None for now\"\n        if kwargs is None:\n            kwargs = {}\n        if name:\n            name = str(name)\n        else:\n            name = _newname(\"Thread-%d\")\n            if target is not None:\n                try:\n                    target_name = target.__name__\n                    name += f\" ({target_name})\"\n                except AttributeError:\n                    pass\n\n        self._target = target\n        self._name = name\n        self._args = args\n        self._kwargs = kwargs\n        if daemon is not None:\n            self._daemonic = daemon\n        else:\n            self._daemonic = current_thread().daemon\n        self._ident = None\n        if _HAVE_THREAD_NATIVE_ID:\n            self._native_id = None\n        self._tstate_lock = None\n        self._started = Event()\n        self._is_stopped = False\n        self._initialized = True\n        # Copy of sys.stderr used by self._invoke_excepthook()\n        self._stderr = _sys.stderr\n        self._invoke_excepthook = _make_invoke_excepthook()\n        # For debugging and _after_fork()\n        _dangling.add(self)\n\n    def _reset_internal_locks(self, is_alive):\n        # private!  Called by _after_fork() to reset our internal locks as\n        # they may be in an invalid state leading to a deadlock or crash.\n        self._started._at_fork_reinit()\n        if is_alive:\n            # bpo-42350: If the fork happens when the thread is already stopped\n            # (ex: after threading._shutdown() has been called), _tstate_lock\n            # is None. Do nothing in this case.\n            if self._tstate_lock is not None:\n                self._tstate_lock._at_fork_reinit()\n                self._tstate_lock.acquire()\n        else:\n            # The thread isn't alive after fork: it doesn't have a tstate\n            # anymore.\n            self._is_stopped = True\n            self._tstate_lock = None\n\n    def __repr__(self):\n        assert self._initialized, \"Thread.__init__() was not called\"\n        status = \"initial\"\n        if self._started.is_set():\n            status = \"started\"\n        self.is_alive() # easy way to get ._is_stopped set when appropriate\n        if self._is_stopped:\n            status = \"stopped\"\n        if self._daemonic:\n            status += \" daemon\"\n        if self._ident is not None:\n            status += \" %s\" % self._ident\n        return \"<%s(%s, %s)>\" % (self.__class__.__name__, self._name, status)\n\n    def start(self):\n        \"\"\"Start the thread's activity.\n\n        It must be called at most once per thread object. It arranges for the\n        object's run() method to be invoked in a separate thread of control.\n\n        This method will raise a RuntimeError if called more than once on the\n        same thread object.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"thread.__init__() not called\")\n\n        if self._started.is_set():\n            raise RuntimeError(\"threads can only be started once\")\n\n        with _active_limbo_lock:\n            _limbo[self] = self\n        try:\n            _start_new_thread(self._bootstrap, ())\n        except Exception:\n            with _active_limbo_lock:\n                del _limbo[self]\n            raise\n        self._started.wait()\n\n    def run(self):\n        \"\"\"Method representing the thread's activity.\n\n        You may override this method in a subclass. The standard run() method\n        invokes the callable object passed to the object's constructor as the\n        target argument, if any, with sequential and keyword arguments taken\n        from the args and kwargs arguments, respectively.\n\n        \"\"\"\n        try:\n            if self._target is not None:\n                self._target(*self._args, **self._kwargs)\n        finally:\n            # Avoid a refcycle if the thread is running a function with\n            # an argument that has a member that points to the thread.\n            del self._target, self._args, self._kwargs\n\n    def _bootstrap(self):\n        # Wrapper around the real bootstrap code that ignores\n        # exceptions during interpreter cleanup.  Those typically\n        # happen when a daemon thread wakes up at an unfortunate\n        # moment, finds the world around it destroyed, and raises some\n        # random exception *** while trying to report the exception in\n        # _bootstrap_inner() below ***.  Those random exceptions\n        # don't help anybody, and they confuse users, so we suppress\n        # them.  We suppress them only when it appears that the world\n        # indeed has already been destroyed, so that exceptions in\n        # _bootstrap_inner() during normal business hours are properly\n        # reported.  Also, we only suppress them for daemonic threads;\n        # if a non-daemonic encounters this, something else is wrong.\n        try:\n            self._bootstrap_inner()\n        except:\n            if self._daemonic and _sys is None:\n                return\n            raise\n\n    def _set_ident(self):\n        self._ident = get_ident()\n\n    if _HAVE_THREAD_NATIVE_ID:\n        def _set_native_id(self):\n            self._native_id = get_native_id()\n\n    def _set_tstate_lock(self):\n        \"\"\"\n        Set a lock object which will be released by the interpreter when\n        the underlying thread state (see pystate.h) gets deleted.\n        \"\"\"\n        self._tstate_lock = _set_sentinel()\n        self._tstate_lock.acquire()\n\n        if not self.daemon:\n            with _shutdown_locks_lock:\n                _maintain_shutdown_locks()\n                _shutdown_locks.add(self._tstate_lock)\n\n    def _bootstrap_inner(self):\n        try:\n            self._set_ident()\n            self._set_tstate_lock()\n            if _HAVE_THREAD_NATIVE_ID:\n                self._set_native_id()\n            self._started.set()\n            with _active_limbo_lock:\n                _active[self._ident] = self\n                del _limbo[self]\n\n            if _trace_hook:\n                _sys.settrace(_trace_hook)\n            if _profile_hook:\n                _sys.setprofile(_profile_hook)\n\n            try:\n                self.run()\n            except:\n                self._invoke_excepthook(self)\n        finally:\n            self._delete()\n\n    def _stop(self):\n        # After calling ._stop(), .is_alive() returns False and .join() returns\n        # immediately.  ._tstate_lock must be released before calling ._stop().\n        #\n        # Normal case:  C code at the end of the thread's life\n        # (release_sentinel in _threadmodule.c) releases ._tstate_lock, and\n        # that's detected by our ._wait_for_tstate_lock(), called by .join()\n        # and .is_alive().  Any number of threads _may_ call ._stop()\n        # simultaneously (for example, if multiple threads are blocked in\n        # .join() calls), and they're not serialized.  That's harmless -\n        # they'll just make redundant rebindings of ._is_stopped and\n        # ._tstate_lock.  Obscure:  we rebind ._tstate_lock last so that the\n        # \"assert self._is_stopped\" in ._wait_for_tstate_lock() always works\n        # (the assert is executed only if ._tstate_lock is None).\n        #\n        # Special case:  _main_thread releases ._tstate_lock via this\n        # module's _shutdown() function.\n        lock = self._tstate_lock\n        if lock is not None:\n            assert not lock.locked()\n        self._is_stopped = True\n        self._tstate_lock = None\n        if not self.daemon:\n            with _shutdown_locks_lock:\n                # Remove our lock and other released locks from _shutdown_locks\n                _maintain_shutdown_locks()\n\n    def _delete(self):\n        \"Remove current thread from the dict of currently running threads.\"\n        with _active_limbo_lock:\n            del _active[get_ident()]\n            # There must not be any python code between the previous line\n            # and after the lock is released.  Otherwise a tracing function\n            # could try to acquire the lock again in the same thread, (in\n            # current_thread()), and would block.\n\n    def join(self, timeout=None):\n        \"\"\"Wait until the thread terminates.\n\n        This blocks the calling thread until the thread whose join() method is\n        called terminates -- either normally or through an unhandled exception\n        or until the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof). As join() always returns None, you must call\n        is_alive() after join() to decide whether a timeout happened -- if the\n        thread is still alive, the join() call timed out.\n\n        When the timeout argument is not present or None, the operation will\n        block until the thread terminates.\n\n        A thread can be join()ed many times.\n\n        join() raises a RuntimeError if an attempt is made to join the current\n        thread as that would cause a deadlock. It is also an error to join() a\n        thread before it has been started and attempts to do so raises the same\n        exception.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if not self._started.is_set():\n            raise RuntimeError(\"cannot join thread before it is started\")\n        if self is current_thread():\n            raise RuntimeError(\"cannot join current thread\")\n\n        if timeout is None:\n            self._wait_for_tstate_lock()\n        else:\n            # the behavior of a negative timeout isn't documented, but\n            # historically .join(timeout=x) for x<0 has acted as if timeout=0\n            self._wait_for_tstate_lock(timeout=max(timeout, 0))\n\n    def _wait_for_tstate_lock(self, block=True, timeout=-1):\n        # Issue #18808: wait for the thread state to be gone.\n        # At the end of the thread's life, after all knowledge of the thread\n        # is removed from C data structures, C code releases our _tstate_lock.\n        # This method passes its arguments to _tstate_lock.acquire().\n        # If the lock is acquired, the C code is done, and self._stop() is\n        # called.  That sets ._is_stopped to True, and ._tstate_lock to None.\n        lock = self._tstate_lock\n        if lock is None:\n            # already determined that the C code is done\n            assert self._is_stopped\n            return\n\n        try:\n            if lock.acquire(block, timeout):\n                lock.release()\n                self._stop()\n        except:\n            if lock.locked():\n                # bpo-45274: lock.acquire() acquired the lock, but the function\n                # was interrupted with an exception before reaching the\n                # lock.release(). It can happen if a signal handler raises an\n                # exception, like CTRL+C which raises KeyboardInterrupt.\n                lock.release()\n                self._stop()\n            raise\n\n    @property\n    def name(self):\n        \"\"\"A string used for identification purposes only.\n\n        It has no semantics. Multiple threads may be given the same name. The\n        initial name is set by the constructor.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._name\n\n    @name.setter\n    def name(self, name):\n        assert self._initialized, \"Thread.__init__() not called\"\n        self._name = str(name)\n\n    @property\n    def ident(self):\n        \"\"\"Thread identifier of this thread or None if it has not been started.\n\n        This is a nonzero integer. See the get_ident() function. Thread\n        identifiers may be recycled when a thread exits and another thread is\n        created. The identifier is available even after the thread has exited.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._ident\n\n    if _HAVE_THREAD_NATIVE_ID:\n        @property\n        def native_id(self):\n            \"\"\"Native integral thread ID of this thread, or None if it has not been started.\n\n            This is a non-negative integer. See the get_native_id() function.\n            This represents the Thread ID as reported by the kernel.\n\n            \"\"\"\n            assert self._initialized, \"Thread.__init__() not called\"\n            return self._native_id\n\n    def is_alive(self):\n        \"\"\"Return whether the thread is alive.\n\n        This method returns True just before the run() method starts until just\n        after the run() method terminates. See also the module function\n        enumerate().\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        if self._is_stopped or not self._started.is_set():\n            return False\n        self._wait_for_tstate_lock(False)\n        return not self._is_stopped\n\n    @property\n    def daemon(self):\n        \"\"\"A boolean value indicating whether this thread is a daemon thread.\n\n        This must be set before start() is called, otherwise RuntimeError is\n        raised. Its initial value is inherited from the creating thread; the\n        main thread is not a daemon thread and therefore all threads created in\n        the main thread default to daemon = False.\n\n        The entire Python program exits when only daemon threads are left.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._daemonic\n\n    @daemon.setter\n    def daemon(self, daemonic):\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if self._started.is_set():\n            raise RuntimeError(\"cannot set daemon status of active thread\")\n        self._daemonic = daemonic\n\n    def isDaemon(self):\n        \"\"\"Return whether this thread is a daemon.\n\n        This method is deprecated, use the daemon attribute instead.\n\n        \"\"\"\n        import warnings\n        warnings.warn('isDaemon() is deprecated, get the daemon attribute instead',\n                      DeprecationWarning, stacklevel=2)\n        return self.daemon\n\n    def setDaemon(self, daemonic):\n        \"\"\"Set whether this thread is a daemon.\n\n        This method is deprecated, use the .daemon property instead.\n\n        \"\"\"\n        import warnings\n        warnings.warn('setDaemon() is deprecated, set the daemon attribute instead',\n                      DeprecationWarning, stacklevel=2)\n        self.daemon = daemonic\n\n    def getName(self):\n        \"\"\"Return a string used for identification purposes only.\n\n        This method is deprecated, use the name attribute instead.\n\n        \"\"\"\n        import warnings\n        warnings.warn('getName() is deprecated, get the name attribute instead',\n                      DeprecationWarning, stacklevel=2)\n        return self.name\n\n    def setName(self, name):\n        \"\"\"Set the name string for this thread.\n\n        This method is deprecated, use the name attribute instead.\n\n        \"\"\"\n        import warnings\n        warnings.warn('setName() is deprecated, set the name attribute instead',\n                      DeprecationWarning, stacklevel=2)\n        self.name = name\n\n\ntry:\n    from _thread import (_excepthook as excepthook,\n                         _ExceptHookArgs as ExceptHookArgs)\nexcept ImportError:\n    # Simple Python implementation if _thread._excepthook() is not available\n    from traceback import print_exception as _print_exception\n    from collections import namedtuple\n\n    _ExceptHookArgs = namedtuple(\n        'ExceptHookArgs',\n        'exc_type exc_value exc_traceback thread')\n\n    def ExceptHookArgs(args):\n        return _ExceptHookArgs(*args)\n\n    def excepthook(args, /):\n        \"\"\"\n        Handle uncaught Thread.run() exception.\n        \"\"\"\n        if args.exc_type == SystemExit:\n            # silently ignore SystemExit\n            return\n\n        if _sys is not None and _sys.stderr is not None:\n            stderr = _sys.stderr\n        elif args.thread is not None:\n            stderr = args.thread._stderr\n            if stderr is None:\n                # do nothing if sys.stderr is None and sys.stderr was None\n                # when the thread was created\n                return\n        else:\n            # do nothing if sys.stderr is None and args.thread is None\n            return\n\n        if args.thread is not None:\n            name = args.thread.name\n        else:\n            name = get_ident()\n        print(f\"Exception in thread {name}:\",\n              file=stderr, flush=True)\n        _print_exception(args.exc_type, args.exc_value, args.exc_traceback,\n                         file=stderr)\n        stderr.flush()\n\n\n# Original value of threading.excepthook\n__excepthook__ = excepthook\n\n\ndef _make_invoke_excepthook():\n    # Create a local namespace to ensure that variables remain alive\n    # when _invoke_excepthook() is called, even if it is called late during\n    # Python shutdown. It is mostly needed for daemon threads.\n\n    old_excepthook = excepthook\n    old_sys_excepthook = _sys.excepthook\n    if old_excepthook is None:\n        raise RuntimeError(\"threading.excepthook is None\")\n    if old_sys_excepthook is None:\n        raise RuntimeError(\"sys.excepthook is None\")\n\n    sys_exc_info = _sys.exc_info\n    local_print = print\n    local_sys = _sys\n\n    def invoke_excepthook(thread):\n        global excepthook\n        try:\n            hook = excepthook\n            if hook is None:\n                hook = old_excepthook\n\n            args = ExceptHookArgs([*sys_exc_info(), thread])\n\n            hook(args)\n        except Exception as exc:\n            exc.__suppress_context__ = True\n            del exc\n\n            if local_sys is not None and local_sys.stderr is not None:\n                stderr = local_sys.stderr\n            else:\n                stderr = thread._stderr\n\n            local_print(\"Exception in threading.excepthook:\",\n                        file=stderr, flush=True)\n\n            if local_sys is not None and local_sys.excepthook is not None:\n                sys_excepthook = local_sys.excepthook\n            else:\n                sys_excepthook = old_sys_excepthook\n\n            sys_excepthook(*sys_exc_info())\n        finally:\n            # Break reference cycle (exception stored in a variable)\n            args = None\n\n    return invoke_excepthook\n\n\n# The timer class was contributed by Itamar Shtull-Trauring\n\nclass Timer(Thread):\n    \"\"\"Call a function after a specified number of seconds:\n\n            t = Timer(30.0, f, args=None, kwargs=None)\n            t.start()\n            t.cancel()     # stop the timer's action if it's still waiting\n\n    \"\"\"\n\n    def __init__(self, interval, function, args=None, kwargs=None):\n        Thread.__init__(self)\n        self.interval = interval\n        self.function = function\n        self.args = args if args is not None else []\n        self.kwargs = kwargs if kwargs is not None else {}\n        self.finished = Event()\n\n    def cancel(self):\n        \"\"\"Stop the timer if it hasn't finished yet.\"\"\"\n        self.finished.set()\n\n    def run(self):\n        self.finished.wait(self.interval)\n        if not self.finished.is_set():\n            self.function(*self.args, **self.kwargs)\n        self.finished.set()\n\n\n# Special thread class to represent the main thread\n\nclass _MainThread(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=\"MainThread\", daemon=False)\n        self._set_tstate_lock()\n        self._started.set()\n        self._set_ident()\n        if _HAVE_THREAD_NATIVE_ID:\n            self._set_native_id()\n        with _active_limbo_lock:\n            _active[self._ident] = self\n\n\n# Dummy thread class to represent threads not started here.\n# These aren't garbage collected when they die, nor can they be waited for.\n# If they invoke anything in threading.py that calls current_thread(), they\n# leave an entry in the _active dict forever after.\n# Their purpose is to return *something* from current_thread().\n# They are marked as daemon threads so we won't wait for them\n# when we exit (conform previous semantics).\n\nclass _DummyThread(Thread):\n\n    def __init__(self):\n        Thread.__init__(self, name=_newname(\"Dummy-%d\"), daemon=True)\n\n        self._started.set()\n        self._set_ident()\n        if _HAVE_THREAD_NATIVE_ID:\n            self._set_native_id()\n        with _active_limbo_lock:\n            _active[self._ident] = self\n\n    def _stop(self):\n        pass\n\n    def is_alive(self):\n        assert not self._is_stopped and self._started.is_set()\n        return True\n\n    def join(self, timeout=None):\n        assert False, \"cannot join a dummy thread\"\n\n\n# Global API functions\n\ndef current_thread():\n    \"\"\"Return the current Thread object, corresponding to the caller's thread of control.\n\n    If the caller's thread of control was not created through the threading\n    module, a dummy thread object with limited functionality is returned.\n\n    \"\"\"\n    try:\n        return _active[get_ident()]\n    except KeyError:\n        return _DummyThread()\n\ndef currentThread():\n    \"\"\"Return the current Thread object, corresponding to the caller's thread of control.\n\n    This function is deprecated, use current_thread() instead.\n\n    \"\"\"\n    import warnings\n    warnings.warn('currentThread() is deprecated, use current_thread() instead',\n                  DeprecationWarning, stacklevel=2)\n    return current_thread()\n\ndef active_count():\n    \"\"\"Return the number of Thread objects currently alive.\n\n    The returned count is equal to the length of the list returned by\n    enumerate().\n\n    \"\"\"\n    with _active_limbo_lock:\n        return len(_active) + len(_limbo)\n\ndef activeCount():\n    \"\"\"Return the number of Thread objects currently alive.\n\n    This function is deprecated, use active_count() instead.\n\n    \"\"\"\n    import warnings\n    warnings.warn('activeCount() is deprecated, use active_count() instead',\n                  DeprecationWarning, stacklevel=2)\n    return active_count()\n\ndef _enumerate():\n    # Same as enumerate(), but without the lock. Internal use only.\n    return list(_active.values()) + list(_limbo.values())\n\ndef enumerate():\n    \"\"\"Return a list of all Thread objects currently alive.\n\n    The list includes daemonic threads, dummy thread objects created by\n    current_thread(), and the main thread. It excludes terminated threads and\n    threads that have not yet been started.\n\n    \"\"\"\n    with _active_limbo_lock:\n        return list(_active.values()) + list(_limbo.values())\n\n\n_threading_atexits = []\n_SHUTTING_DOWN = False\n\ndef _register_atexit(func, *arg, **kwargs):\n    \"\"\"CPython internal: register *func* to be called before joining threads.\n\n    The registered *func* is called with its arguments just before all\n    non-daemon threads are joined in `_shutdown()`. It provides a similar\n    purpose to `atexit.register()`, but its functions are called prior to\n    threading shutdown instead of interpreter shutdown.\n\n    For similarity to atexit, the registered functions are called in reverse.\n    \"\"\"\n    if _SHUTTING_DOWN:\n        raise RuntimeError(\"can't register atexit after shutdown\")\n\n    call = functools.partial(func, *arg, **kwargs)\n    _threading_atexits.append(call)\n\n\nfrom _thread import stack_size\n\n# Create the main thread object,\n# and make it available for the interpreter\n# (Py_Main) as threading._shutdown.\n\n_main_thread = _MainThread()\n\ndef _shutdown():\n    \"\"\"\n    Wait until the Python thread state of all non-daemon threads get deleted.\n    \"\"\"\n    # Obscure:  other threads may be waiting to join _main_thread.  That's\n    # dubious, but some code does it.  We can't wait for C code to release\n    # the main thread's tstate_lock - that won't happen until the interpreter\n    # is nearly dead.  So we release it here.  Note that just calling _stop()\n    # isn't enough:  other threads may already be waiting on _tstate_lock.\n    if _main_thread._is_stopped:\n        # _shutdown() was already called\n        return\n\n    global _SHUTTING_DOWN\n    _SHUTTING_DOWN = True\n\n    # Call registered threading atexit functions before threads are joined.\n    # Order is reversed, similar to atexit.\n    for atexit_call in reversed(_threading_atexits):\n        atexit_call()\n\n    # Main thread\n    if _main_thread.ident == get_ident():\n        tlock = _main_thread._tstate_lock\n        # The main thread isn't finished yet, so its thread state lock can't\n        # have been released.\n        assert tlock is not None\n        assert tlock.locked()\n        tlock.release()\n        _main_thread._stop()\n    else:\n        # bpo-1596321: _shutdown() must be called in the main thread.\n        # If the threading module was not imported by the main thread,\n        # _main_thread is the thread which imported the threading module.\n        # In this case, ignore _main_thread, similar behavior than for threads\n        # spawned by C libraries or using _thread.start_new_thread().\n        pass\n\n    # Join all non-deamon threads\n    while True:\n        with _shutdown_locks_lock:\n            locks = list(_shutdown_locks)\n            _shutdown_locks.clear()\n\n        if not locks:\n            break\n\n        for lock in locks:\n            # mimic Thread.join()\n            lock.acquire()\n            lock.release()\n\n        # new threads can be spawned while we were waiting for the other\n        # threads to complete\n\n\ndef main_thread():\n    \"\"\"Return the main thread object.\n\n    In normal conditions, the main thread is the thread from which the\n    Python interpreter was started.\n    \"\"\"\n    return _main_thread\n\n# get thread-local implementation, either from the thread\n# module, or from the python fallback\n\ntry:\n    from _thread import _local as local\nexcept ImportError:\n    from _threading_local import local\n\n\ndef _after_fork():\n    \"\"\"\n    Cleanup threading module state that should not exist after a fork.\n    \"\"\"\n    # Reset _active_limbo_lock, in case we forked while the lock was held\n    # by another (non-forked) thread.  http://bugs.python.org/issue874900\n    global _active_limbo_lock, _main_thread\n    global _shutdown_locks_lock, _shutdown_locks\n    _active_limbo_lock = RLock()\n\n    # fork() only copied the current thread; clear references to others.\n    new_active = {}\n\n    try:\n        current = _active[get_ident()]\n    except KeyError:\n        # fork() was called in a thread which was not spawned\n        # by threading.Thread. For example, a thread spawned\n        # by thread.start_new_thread().\n        current = _MainThread()\n\n    _main_thread = current\n\n    # reset _shutdown() locks: threads re-register their _tstate_lock below\n    _shutdown_locks_lock = _allocate_lock()\n    _shutdown_locks = set()\n\n    with _active_limbo_lock:\n        # Dangling thread instances must still have their locks reset,\n        # because someone may join() them.\n        threads = set(_enumerate())\n        threads.update(_dangling)\n        for thread in threads:\n            # Any lock/condition variable may be currently locked or in an\n            # invalid state, so we reinitialize them.\n            if thread is current:\n                # There is only one active thread. We reset the ident to\n                # its new value since it can have changed.\n                thread._reset_internal_locks(True)\n                ident = get_ident()\n                thread._ident = ident\n                new_active[ident] = thread\n            else:\n                # All the others are already stopped.\n                thread._reset_internal_locks(False)\n                thread._stop()\n\n        _limbo.clear()\n        _active.clear()\n        _active.update(new_active)\n        assert len(_active) == 1\n\n\nif hasattr(_os, \"register_at_fork\"):\n    _os.register_at_fork(after_in_child=_after_fork)\n",1661],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\zmq\\sugar\\socket.py":["\"\"\"0MQ Socket pure Python methods.\"\"\"\n\n# Copyright (C) PyZMQ Developers\n# Distributed under the terms of the Modified BSD License.\n\n\nimport errno\nimport pickle\nimport random\nimport sys\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Generic,\n    List,\n    Optional,\n    Sequence,\n    Type,\n    TypeVar,\n    Union,\n    cast,\n    overload,\n)\nfrom warnings import warn\n\nimport zmq\nfrom zmq._typing import Literal\nfrom zmq.backend import Socket as SocketBase\nfrom zmq.error import ZMQBindError, ZMQError\nfrom zmq.utils import jsonapi\nfrom zmq.utils.interop import cast_int_addr\n\nfrom ..constants import SocketOption, SocketType, _OptType\nfrom .attrsettr import AttributeSetter\nfrom .poll import Poller\n\ntry:\n    DEFAULT_PROTOCOL = pickle.DEFAULT_PROTOCOL\nexcept AttributeError:\n    DEFAULT_PROTOCOL = pickle.HIGHEST_PROTOCOL\n\nT = TypeVar(\"T\", bound=\"Socket\")\n\n\nclass _SocketContext(Generic[T]):\n    \"\"\"Context Manager for socket bind/unbind\"\"\"\n\n    socket: T\n    kind: str\n    addr: str\n\n    def __repr__(self):\n        return f\"<SocketContext({self.kind}={self.addr!r})>\"\n\n    def __init__(self: \"_SocketContext[T]\", socket: T, kind: str, addr: str):\n        assert kind in {\"bind\", \"connect\"}\n        self.socket = socket\n        self.kind = kind\n        self.addr = addr\n\n    def __enter__(self: \"_SocketContext[T]\") -> T:\n        return self.socket\n\n    def __exit__(self, *args):\n        if self.socket.closed:\n            return\n        if self.kind == \"bind\":\n            self.socket.unbind(self.addr)\n        elif self.kind == \"connect\":\n            self.socket.disconnect(self.addr)\n\n\nST = TypeVar(\"ST\")\n\n\nclass Socket(SocketBase, AttributeSetter, Generic[ST]):\n    \"\"\"The ZMQ socket object\n\n    To create a Socket, first create a Context::\n\n        ctx = zmq.Context.instance()\n\n    then call ``ctx.socket(socket_type)``::\n\n        s = ctx.socket(zmq.ROUTER)\n\n    .. versionadded:: 25\n\n        Sockets can now be shadowed by passing another Socket.\n        This helps in creating an async copy of a sync socket or vice versa::\n\n            s = zmq.Socket(async_socket)\n\n        Which previously had to be::\n\n            s = zmq.Socket.shadow(async_socket.underlying)\n    \"\"\"\n\n    _shadow = False\n    _shadow_obj = None\n    _monitor_socket = None\n    _type_name = 'UNKNOWN'\n\n    @overload\n    def __init__(\n        self: \"Socket[bytes]\",\n        ctx_or_socket: \"zmq.Context\",\n        socket_type: int,\n        *,\n        copy_threshold: Optional[int] = None,\n    ):\n        ...\n\n    @overload\n    def __init__(\n        self: \"Socket[bytes]\",\n        *,\n        shadow: Union[\"Socket\", int],\n        copy_threshold: Optional[int] = None,\n    ):\n        ...\n\n    @overload\n    def __init__(\n        self: \"Socket[bytes]\",\n        ctx_or_socket: \"Socket\",\n    ):\n        ...\n\n    def __init__(\n        self: \"Socket[bytes]\",\n        ctx_or_socket: Optional[Union[\"zmq.Context\", \"Socket\"]] = None,\n        socket_type: int = 0,\n        *,\n        shadow: Union[\"Socket\", int] = 0,\n        copy_threshold: Optional[int] = None,\n    ):\n        if isinstance(ctx_or_socket, zmq.Socket):\n            # positional Socket(other_socket)\n            shadow = ctx_or_socket\n            ctx_or_socket = None\n\n        shadow_address: int = 0\n\n        if shadow:\n            self._shadow = True\n            # hold a reference to the shadow object\n            self._shadow_obj = shadow\n            if not isinstance(shadow, int):\n                try:\n                    shadow = cast(int, shadow.underlying)\n                except AttributeError:\n                    pass\n            shadow_address = cast_int_addr(shadow)\n        else:\n            self._shadow = False\n\n        super().__init__(\n            ctx_or_socket,\n            socket_type,\n            shadow=shadow_address,\n            copy_threshold=copy_threshold,\n        )\n\n        try:\n            socket_type = cast(int, self.get(zmq.TYPE))\n        except Exception:\n            pass\n        else:\n            try:\n                self.__dict__[\"type\"] = stype = SocketType(socket_type)\n            except ValueError:\n                self._type_name = str(socket_type)\n            else:\n                self._type_name = stype.name\n\n    def __del__(self):\n        if not self._shadow and not self.closed:\n            if warn is not None:\n                # warn can be None during process teardown\n                warn(\n                    f\"Unclosed socket {self}\",\n                    ResourceWarning,\n                    stacklevel=2,\n                    source=self,\n                )\n            self.close()\n\n    _repr_cls = \"zmq.Socket\"\n\n    def __repr__(self):\n        cls = self.__class__\n        # look up _repr_cls on exact class, not inherited\n        _repr_cls = cls.__dict__.get(\"_repr_cls\", None)\n        if _repr_cls is None:\n            _repr_cls = f\"{cls.__module__}.{cls.__name__}\"\n\n        closed = ' closed' if self._closed else ''\n\n        return f\"<{_repr_cls}(zmq.{self._type_name}) at {hex(id(self))}{closed}>\"\n\n    # socket as context manager:\n    def __enter__(self: T) -> T:\n        \"\"\"Sockets are context managers\n\n        .. versionadded:: 14.4\n        \"\"\"\n        return self\n\n    def __exit__(self, *args, **kwargs):\n        self.close()\n\n    # -------------------------------------------------------------------------\n    # Socket creation\n    # -------------------------------------------------------------------------\n\n    def __copy__(self: T, memo=None) -> T:\n        \"\"\"Copying a Socket creates a shadow copy\"\"\"\n        return self.__class__.shadow(self.underlying)\n\n    __deepcopy__ = __copy__\n\n    @classmethod\n    def shadow(cls: Type[T], address: Union[int, \"zmq.Socket\"]) -> T:\n        \"\"\"Shadow an existing libzmq socket\n\n        address is a zmq.Socket or an integer (or FFI pointer)\n        representing the address of the libzmq socket.\n\n        .. versionadded:: 14.1\n\n        .. versionadded:: 25\n            Support for shadowing `zmq.Socket` objects,\n            instead of just integer addresses.\n        \"\"\"\n        return cls(shadow=address)\n\n    def close(self, linger=None) -> None:\n        \"\"\"\n        Close the socket.\n\n        If linger is specified, LINGER sockopt will be set prior to closing.\n\n        Note: closing a zmq Socket may not close the underlying sockets\n        if there are undelivered messages.\n        Only after all messages are delivered or discarded by reaching the socket's LINGER timeout\n        (default: forever)\n        will the underlying sockets be closed.\n\n        This can be called to close the socket by hand. If this is not\n        called, the socket will automatically be closed when it is\n        garbage collected,\n        in which case you may see a ResourceWarning about the unclosed socket.\n        \"\"\"\n        if self.context:\n            self.context._rm_socket(self)\n        super().close(linger=linger)\n\n    # -------------------------------------------------------------------------\n    # Connect/Bind context managers\n    # -------------------------------------------------------------------------\n\n    def _connect_cm(self: T, addr: str) -> _SocketContext[T]:\n        \"\"\"Context manager to disconnect on exit\n\n        .. versionadded:: 20.0\n        \"\"\"\n        return _SocketContext(self, 'connect', addr)\n\n    def _bind_cm(self: T, addr: str) -> _SocketContext[T]:\n        \"\"\"Context manager to unbind on exit\n\n        .. versionadded:: 20.0\n        \"\"\"\n        return _SocketContext(self, 'bind', addr)\n\n    def bind(self: T, addr: str) -> _SocketContext[T]:\n        \"\"\"s.bind(addr)\n\n        Bind the socket to an address.\n\n        This causes the socket to listen on a network port. Sockets on the\n        other side of this connection will use ``Socket.connect(addr)`` to\n        connect to this socket.\n\n        Returns a context manager which will call unbind on exit.\n\n        .. versionadded:: 20.0\n            Can be used as a context manager.\n\n        Parameters\n        ----------\n        addr : str\n            The address string. This has the form 'protocol://interface:port',\n            for example 'tcp://127.0.0.1:5555'. Protocols supported include\n            tcp, udp, pgm, epgm, inproc and ipc. If the address is unicode, it is\n            encoded to utf-8 first.\n\n        \"\"\"\n        try:\n            super().bind(addr)\n        except ZMQError as e:\n            e.strerror += f\" (addr={addr!r})\"\n            raise\n        return self._bind_cm(addr)\n\n    def connect(self: T, addr: str) -> _SocketContext[T]:\n        \"\"\"s.connect(addr)\n\n        Connect to a remote 0MQ socket.\n\n        Returns a context manager which will call disconnect on exit.\n\n        .. versionadded:: 20.0\n            Can be used as a context manager.\n\n        Parameters\n        ----------\n        addr : str\n            The address string. This has the form 'protocol://interface:port',\n            for example 'tcp://127.0.0.1:5555'. Protocols supported are\n            tcp, udp, pgm, inproc and ipc. If the address is unicode, it is\n            encoded to utf-8 first.\n\n        \"\"\"\n        try:\n            super().connect(addr)\n        except ZMQError as e:\n            e.strerror += f\" (addr={addr!r})\"\n            raise\n        return self._connect_cm(addr)\n\n    # -------------------------------------------------------------------------\n    # Deprecated aliases\n    # -------------------------------------------------------------------------\n\n    @property\n    def socket_type(self) -> int:\n        warn(\"Socket.socket_type is deprecated, use Socket.type\", DeprecationWarning)\n        return cast(int, self.type)\n\n    # -------------------------------------------------------------------------\n    # Hooks for sockopt completion\n    # -------------------------------------------------------------------------\n\n    def __dir__(self):\n        keys = dir(self.__class__)\n        keys.extend(SocketOption.__members__)\n        return keys\n\n    # -------------------------------------------------------------------------\n    # Getting/Setting options\n    # -------------------------------------------------------------------------\n    setsockopt = SocketBase.set\n    getsockopt = SocketBase.get\n\n    def __setattr__(self, key, value):\n        \"\"\"Override to allow setting zmq.[UN]SUBSCRIBE even though we have a subscribe method\"\"\"\n        if key in self.__dict__:\n            object.__setattr__(self, key, value)\n            return\n        _key = key.lower()\n        if _key in ('subscribe', 'unsubscribe'):\n            if isinstance(value, str):\n                value = value.encode('utf8')\n            if _key == 'subscribe':\n                self.set(zmq.SUBSCRIBE, value)\n            else:\n                self.set(zmq.UNSUBSCRIBE, value)\n            return\n        super().__setattr__(key, value)\n\n    def fileno(self) -> int:\n        \"\"\"Return edge-triggered file descriptor for this socket.\n\n        This is a read-only edge-triggered file descriptor for both read and write events on this socket.\n        It is important that all available events be consumed when an event is detected,\n        otherwise the read event will not trigger again.\n\n        .. versionadded:: 17.0\n        \"\"\"\n        return self.FD\n\n    def subscribe(self, topic: Union[str, bytes]) -> None:\n        \"\"\"Subscribe to a topic\n\n        Only for SUB sockets.\n\n        .. versionadded:: 15.3\n        \"\"\"\n        if isinstance(topic, str):\n            topic = topic.encode('utf8')\n        self.set(zmq.SUBSCRIBE, topic)\n\n    def unsubscribe(self, topic: Union[str, bytes]) -> None:\n        \"\"\"Unsubscribe from a topic\n\n        Only for SUB sockets.\n\n        .. versionadded:: 15.3\n        \"\"\"\n        if isinstance(topic, str):\n            topic = topic.encode('utf8')\n        self.set(zmq.UNSUBSCRIBE, topic)\n\n    def set_string(self, option: int, optval: str, encoding='utf-8') -> None:\n        \"\"\"Set socket options with a unicode object.\n\n        This is simply a wrapper for setsockopt to protect from encoding ambiguity.\n\n        See the 0MQ documentation for details on specific options.\n\n        Parameters\n        ----------\n        option : int\n            The name of the option to set. Can be any of: SUBSCRIBE,\n            UNSUBSCRIBE, IDENTITY\n        optval : str\n            The value of the option to set.\n        encoding : str\n            The encoding to be used, default is utf8\n        \"\"\"\n        if not isinstance(optval, str):\n            raise TypeError(f\"strings only, not {type(optval)}: {optval!r}\")\n        return self.set(option, optval.encode(encoding))\n\n    setsockopt_unicode = setsockopt_string = set_string\n\n    def get_string(self, option: int, encoding='utf-8') -> str:\n        \"\"\"Get the value of a socket option.\n\n        See the 0MQ documentation for details on specific options.\n\n        Parameters\n        ----------\n        option : int\n            The option to retrieve.\n\n        Returns\n        -------\n        optval : str\n            The value of the option as a unicode string.\n        \"\"\"\n        if SocketOption(option)._opt_type != _OptType.bytes:\n            raise TypeError(f\"option {option} will not return a string to be decoded\")\n        return cast(bytes, self.get(option)).decode(encoding)\n\n    getsockopt_unicode = getsockopt_string = get_string\n\n    def bind_to_random_port(\n        self: T,\n        addr: str,\n        min_port: int = 49152,\n        max_port: int = 65536,\n        max_tries: int = 100,\n    ) -> int:\n        \"\"\"Bind this socket to a random port in a range.\n\n        If the port range is unspecified, the system will choose the port.\n\n        Parameters\n        ----------\n        addr : str\n            The address string without the port to pass to ``Socket.bind()``.\n        min_port : int, optional\n            The minimum port in the range of ports to try (inclusive).\n        max_port : int, optional\n            The maximum port in the range of ports to try (exclusive).\n        max_tries : int, optional\n            The maximum number of bind attempts to make.\n\n        Returns\n        -------\n        port : int\n            The port the socket was bound to.\n\n        Raises\n        ------\n        ZMQBindError\n            if `max_tries` reached before successful bind\n        \"\"\"\n        if (\n            (zmq.zmq_version_info() >= (3, 2))\n            and min_port == 49152\n            and max_port == 65536\n        ):\n            # if LAST_ENDPOINT is supported, and min_port / max_port weren't specified,\n            # we can bind to port 0 and let the OS do the work\n            self.bind(\"%s:*\" % addr)\n            url = cast(bytes, self.last_endpoint).decode('ascii', 'replace')\n            _, port_s = url.rsplit(':', 1)\n            return int(port_s)\n\n        for i in range(max_tries):\n            try:\n                port = random.randrange(min_port, max_port)\n                self.bind(f'{addr}:{port}')\n            except ZMQError as exception:\n                en = exception.errno\n                if en == zmq.EADDRINUSE:\n                    continue\n                elif sys.platform == 'win32' and en == errno.EACCES:\n                    continue\n                else:\n                    raise\n            else:\n                return port\n        raise ZMQBindError(\"Could not bind socket to random port.\")\n\n    def get_hwm(self) -> int:\n        \"\"\"Get the High Water Mark.\n\n        On libzmq  3, this gets SNDHWM if available, otherwise RCVHWM\n        \"\"\"\n        major = zmq.zmq_version_info()[0]\n        if major >= 3:\n            # return sndhwm, fallback on rcvhwm\n            try:\n                return cast(int, self.get(zmq.SNDHWM))\n            except zmq.ZMQError:\n                pass\n\n            return cast(int, self.get(zmq.RCVHWM))\n        else:\n            return cast(int, self.get(zmq.HWM))\n\n    def set_hwm(self, value: int) -> None:\n        \"\"\"Set the High Water Mark.\n\n        On libzmq  3, this sets both SNDHWM and RCVHWM\n\n\n        .. warning::\n\n            New values only take effect for subsequent socket\n            bind/connects.\n        \"\"\"\n        major = zmq.zmq_version_info()[0]\n        if major >= 3:\n            raised = None\n            try:\n                self.sndhwm = value\n            except Exception as e:\n                raised = e\n            try:\n                self.rcvhwm = value\n            except Exception as e:\n                raised = e\n\n            if raised:\n                raise raised\n        else:\n            self.set(zmq.HWM, value)\n\n    hwm = property(\n        get_hwm,\n        set_hwm,\n        None,\n        \"\"\"Property for High Water Mark.\n\n        Setting hwm sets both SNDHWM and RCVHWM as appropriate.\n        It gets SNDHWM if available, otherwise RCVHWM.\n        \"\"\",\n    )\n\n    # -------------------------------------------------------------------------\n    # Sending and receiving messages\n    # -------------------------------------------------------------------------\n\n    @overload\n    def send(\n        self,\n        data: Any,\n        flags: int = ...,\n        copy: bool = ...,\n        *,\n        track: Literal[True],\n        routing_id: Optional[int] = ...,\n        group: Optional[str] = ...,\n    ) -> \"zmq.MessageTracker\":\n        ...\n\n    @overload\n    def send(\n        self,\n        data: Any,\n        flags: int = ...,\n        copy: bool = ...,\n        *,\n        track: Literal[False],\n        routing_id: Optional[int] = ...,\n        group: Optional[str] = ...,\n    ) -> None:\n        ...\n\n    @overload\n    def send(\n        self,\n        data: Any,\n        flags: int = ...,\n        *,\n        copy: bool = ...,\n        routing_id: Optional[int] = ...,\n        group: Optional[str] = ...,\n    ) -> None:\n        ...\n\n    @overload\n    def send(\n        self,\n        data: Any,\n        flags: int = ...,\n        copy: bool = ...,\n        track: bool = ...,\n        routing_id: Optional[int] = ...,\n        group: Optional[str] = ...,\n    ) -> Optional[\"zmq.MessageTracker\"]:\n        ...\n\n    def send(\n        self,\n        data: Any,\n        flags: int = 0,\n        copy: bool = True,\n        track: bool = False,\n        routing_id: Optional[int] = None,\n        group: Optional[str] = None,\n    ) -> Optional[\"zmq.MessageTracker\"]:\n        \"\"\"Send a single zmq message frame on this socket.\n\n        This queues the message to be sent by the IO thread at a later time.\n\n        With flags=NOBLOCK, this raises :class:`ZMQError` if the queue is full;\n        otherwise, this waits until space is available.\n        See :class:`Poller` for more general non-blocking I/O.\n\n        Parameters\n        ----------\n        data : bytes, Frame, memoryview\n            The content of the message. This can be any object that provides\n            the Python buffer API (i.e. `memoryview(data)` can be called).\n        flags : int\n            0, NOBLOCK, SNDMORE, or NOBLOCK|SNDMORE.\n        copy : bool\n            Should the message be sent in a copying or non-copying manner.\n        track : bool\n            Should the message be tracked for notification that ZMQ has\n            finished with it? (ignored if copy=True)\n        routing_id : int\n            For use with SERVER sockets\n        group : str\n            For use with RADIO sockets\n\n        Returns\n        -------\n        None : if `copy` or not track\n            None if message was sent, raises an exception otherwise.\n        MessageTracker : if track and not copy\n            a MessageTracker object, whose `pending` property will\n            be True until the send is completed.\n\n        Raises\n        ------\n        TypeError\n            If a unicode object is passed\n        ValueError\n            If `track=True`, but an untracked Frame is passed.\n        ZMQError\n            If the send does not succeed for any reason (including\n            if NOBLOCK is set and the outgoing queue is full).\n\n\n        .. versionchanged:: 17.0\n\n            DRAFT support for routing_id and group arguments.\n        \"\"\"\n        if routing_id is not None:\n            if not isinstance(data, zmq.Frame):\n                data = zmq.Frame(\n                    data,\n                    track=track,\n                    copy=copy or None,\n                    copy_threshold=self.copy_threshold,\n                )\n            data.routing_id = routing_id\n        if group is not None:\n            if not isinstance(data, zmq.Frame):\n                data = zmq.Frame(\n                    data,\n                    track=track,\n                    copy=copy or None,\n                    copy_threshold=self.copy_threshold,\n                )\n            data.group = group\n        return super().send(data, flags=flags, copy=copy, track=track)\n\n    def send_multipart(\n        self,\n        msg_parts: Sequence,\n        flags: int = 0,\n        copy: bool = True,\n        track: bool = False,\n        **kwargs,\n    ):\n        \"\"\"Send a sequence of buffers as a multipart message.\n\n        The zmq.SNDMORE flag is added to all msg parts before the last.\n\n        Parameters\n        ----------\n        msg_parts : iterable\n            A sequence of objects to send as a multipart message. Each element\n            can be any sendable object (Frame, bytes, buffer-providers)\n        flags : int, optional\n            Any valid flags for :func:`Socket.send`.\n            SNDMORE is added automatically for frames before the last.\n        copy : bool, optional\n            Should the frame(s) be sent in a copying or non-copying manner.\n            If copy=False, frames smaller than self.copy_threshold bytes\n            will be copied anyway.\n        track : bool, optional\n            Should the frame(s) be tracked for notification that ZMQ has\n            finished with it (ignored if copy=True).\n\n        Returns\n        -------\n        None : if copy or not track\n        MessageTracker : if track and not copy\n            a MessageTracker object, whose `pending` property will\n            be True until the last send is completed.\n        \"\"\"\n        # typecheck parts before sending:\n        for i, msg in enumerate(msg_parts):\n            if isinstance(msg, (zmq.Frame, bytes, memoryview)):\n                continue\n            try:\n                memoryview(msg)\n            except Exception:\n                rmsg = repr(msg)\n                if len(rmsg) > 32:\n                    rmsg = rmsg[:32] + '...'\n                raise TypeError(\n                    \"Frame %i (%s) does not support the buffer interface.\"\n                    % (\n                        i,\n                        rmsg,\n                    )\n                )\n        for msg in msg_parts[:-1]:\n            self.send(msg, zmq.SNDMORE | flags, copy=copy, track=track)\n        # Send the last part without the extra SNDMORE flag.\n        return self.send(msg_parts[-1], flags, copy=copy, track=track)\n\n    @overload\n    def recv_multipart(\n        self, flags: int = ..., *, copy: Literal[True], track: bool = ...\n    ) -> List[bytes]:\n        ...\n\n    @overload\n    def recv_multipart(\n        self, flags: int = ..., *, copy: Literal[False], track: bool = ...\n    ) -> List[zmq.Frame]:\n        ...\n\n    @overload\n    def recv_multipart(self, flags: int = ..., *, track: bool = ...) -> List[bytes]:\n        ...\n\n    @overload\n    def recv_multipart(\n        self, flags: int = 0, copy: bool = True, track: bool = False\n    ) -> Union[List[zmq.Frame], List[bytes]]:\n        ...\n\n    def recv_multipart(\n        self, flags: int = 0, copy: bool = True, track: bool = False\n    ) -> Union[List[zmq.Frame], List[bytes]]:\n        \"\"\"Receive a multipart message as a list of bytes or Frame objects\n\n        Parameters\n        ----------\n        flags : int, optional\n            Any valid flags for :func:`Socket.recv`.\n        copy : bool, optional\n            Should the message frame(s) be received in a copying or non-copying manner?\n            If False a Frame object is returned for each part, if True a copy of\n            the bytes is made for each frame.\n        track : bool, optional\n            Should the message frame(s) be tracked for notification that ZMQ has\n            finished with it? (ignored if copy=True)\n\n        Returns\n        -------\n        msg_parts : list\n            A list of frames in the multipart message; either Frames or bytes,\n            depending on `copy`.\n\n        Raises\n        ------\n        ZMQError\n            for any of the reasons :func:`~Socket.recv` might fail\n        \"\"\"\n        parts = [self.recv(flags, copy=copy, track=track)]\n        # have first part already, only loop while more to receive\n        while self.getsockopt(zmq.RCVMORE):\n            part = self.recv(flags, copy=copy, track=track)\n            parts.append(part)\n        # cast List[Union] to Union[List]\n        # how do we get mypy to recognize that return type is invariant on `copy`?\n        return cast(Union[List[zmq.Frame], List[bytes]], parts)\n\n    def _deserialize(\n        self,\n        recvd: bytes,\n        load: Callable[[bytes], Any],\n    ) -> Any:\n        \"\"\"Deserialize a received message\n\n        Override in subclass (e.g. Futures) if recvd is not the raw bytes.\n\n        The default implementation expects bytes and returns the deserialized message immediately.\n\n        Parameters\n        ----------\n\n        load: callable\n            Callable that deserializes bytes\n        recvd:\n            The object returned by self.recv\n\n        \"\"\"\n        return load(recvd)\n\n    def send_serialized(self, msg, serialize, flags=0, copy=True, **kwargs):\n        \"\"\"Send a message with a custom serialization function.\n\n        .. versionadded:: 17\n\n        Parameters\n        ----------\n        msg : The message to be sent. Can be any object serializable by `serialize`.\n        serialize : callable\n            The serialization function to use.\n            serialize(msg) should return an iterable of sendable message frames\n            (e.g. bytes objects), which will be passed to send_multipart.\n        flags : int, optional\n            Any valid flags for :func:`Socket.send`.\n        copy : bool, optional\n            Whether to copy the frames.\n\n        \"\"\"\n        frames = serialize(msg)\n        return self.send_multipart(frames, flags=flags, copy=copy, **kwargs)\n\n    def recv_serialized(self, deserialize, flags=0, copy=True):\n        \"\"\"Receive a message with a custom deserialization function.\n\n        .. versionadded:: 17\n\n        Parameters\n        ----------\n        deserialize : callable\n            The deserialization function to use.\n            deserialize will be called with one argument: the list of frames\n            returned by recv_multipart() and can return any object.\n        flags : int, optional\n            Any valid flags for :func:`Socket.recv`.\n        copy : bool, optional\n            Whether to recv bytes or Frame objects.\n\n        Returns\n        -------\n        obj : object\n            The object returned by the deserialization function.\n\n        Raises\n        ------\n        ZMQError\n            for any of the reasons :func:`~Socket.recv` might fail\n        \"\"\"\n        frames = self.recv_multipart(flags=flags, copy=copy)\n        return self._deserialize(frames, deserialize)\n\n    def send_string(\n        self,\n        u: str,\n        flags: int = 0,\n        copy: bool = True,\n        encoding: str = 'utf-8',\n        **kwargs,\n    ) -> Optional[\"zmq.Frame\"]:\n        \"\"\"Send a Python unicode string as a message with an encoding.\n\n        0MQ communicates with raw bytes, so you must encode/decode\n        text (str) around 0MQ.\n\n        Parameters\n        ----------\n        u : str\n            The unicode string to send.\n        flags : int, optional\n            Any valid flags for :func:`Socket.send`.\n        encoding : str [default: 'utf-8']\n            The encoding to be used\n        \"\"\"\n        if not isinstance(u, str):\n            raise TypeError(\"str objects only\")\n        return self.send(u.encode(encoding), flags=flags, copy=copy, **kwargs)\n\n    send_unicode = send_string\n\n    def recv_string(self, flags: int = 0, encoding: str = 'utf-8') -> str:\n        \"\"\"Receive a unicode string, as sent by send_string.\n\n        Parameters\n        ----------\n        flags : int\n            Any valid flags for :func:`Socket.recv`.\n        encoding : str [default: 'utf-8']\n            The encoding to be used\n\n        Returns\n        -------\n        s : str\n            The Python unicode string that arrives as encoded bytes.\n\n        Raises\n        ------\n        ZMQError\n            for any of the reasons :func:`~Socket.recv` might fail\n        \"\"\"\n        msg = self.recv(flags=flags)\n        return self._deserialize(msg, lambda buf: buf.decode(encoding))\n\n    recv_unicode = recv_string\n\n    def send_pyobj(\n        self, obj: Any, flags: int = 0, protocol: int = DEFAULT_PROTOCOL, **kwargs\n    ) -> Optional[zmq.Frame]:\n        \"\"\"Send a Python object as a message using pickle to serialize.\n\n        Parameters\n        ----------\n        obj : Python object\n            The Python object to send.\n        flags : int\n            Any valid flags for :func:`Socket.send`.\n        protocol : int\n            The pickle protocol number to use. The default is pickle.DEFAULT_PROTOCOL\n            where defined, and pickle.HIGHEST_PROTOCOL elsewhere.\n        \"\"\"\n        msg = pickle.dumps(obj, protocol)\n        return self.send(msg, flags=flags, **kwargs)\n\n    def recv_pyobj(self, flags: int = 0) -> Any:\n        \"\"\"Receive a Python object as a message using pickle to serialize.\n\n        Parameters\n        ----------\n        flags : int\n            Any valid flags for :func:`Socket.recv`.\n\n        Returns\n        -------\n        obj : Python object\n            The Python object that arrives as a message.\n\n        Raises\n        ------\n        ZMQError\n            for any of the reasons :func:`~Socket.recv` might fail\n        \"\"\"\n        msg = self.recv(flags)\n        return self._deserialize(msg, pickle.loads)\n\n    def send_json(self, obj: Any, flags: int = 0, **kwargs) -> None:\n        \"\"\"Send a Python object as a message using json to serialize.\n\n        Keyword arguments are passed on to json.dumps\n\n        Parameters\n        ----------\n        obj : Python object\n            The Python object to send\n        flags : int\n            Any valid flags for :func:`Socket.send`\n        \"\"\"\n        send_kwargs = {}\n        for key in ('routing_id', 'group'):\n            if key in kwargs:\n                send_kwargs[key] = kwargs.pop(key)\n        msg = jsonapi.dumps(obj, **kwargs)\n        return self.send(msg, flags=flags, **send_kwargs)\n\n    def recv_json(self, flags: int = 0, **kwargs) -> Union[List, str, int, float, Dict]:\n        \"\"\"Receive a Python object as a message using json to serialize.\n\n        Keyword arguments are passed on to json.loads\n\n        Parameters\n        ----------\n        flags : int\n            Any valid flags for :func:`Socket.recv`.\n\n        Returns\n        -------\n        obj : Python object\n            The Python object that arrives as a message.\n\n        Raises\n        ------\n        ZMQError\n            for any of the reasons :func:`~Socket.recv` might fail\n        \"\"\"\n        msg = self.recv(flags)\n        return self._deserialize(msg, lambda buf: jsonapi.loads(buf, **kwargs))\n\n    _poller_class = Poller\n\n    def poll(self, timeout=None, flags=zmq.POLLIN) -> int:\n        \"\"\"Poll the socket for events.\n        See :class:`Poller` to wait for multiple sockets at once.\n\n        Parameters\n        ----------\n        timeout : int [default: None]\n            The timeout (in milliseconds) to wait for an event. If unspecified\n            (or specified None), will wait forever for an event.\n        flags : int [default: POLLIN]\n            POLLIN, POLLOUT, or POLLIN|POLLOUT. The event flags to poll for.\n\n        Returns\n        -------\n        event_mask : int\n            The poll event mask (POLLIN, POLLOUT),\n            0 if the timeout was reached without an event.\n        \"\"\"\n\n        if self.closed:\n            raise ZMQError(zmq.ENOTSUP)\n\n        p = self._poller_class()\n        p.register(self, flags)\n        evts = dict(p.poll(timeout))\n        # return 0 if no events, otherwise return event bitfield\n        return evts.get(self, 0)\n\n    def get_monitor_socket(\n        self: T, events: Optional[int] = None, addr: Optional[str] = None\n    ) -> T:\n        \"\"\"Return a connected PAIR socket ready to receive the event notifications.\n\n        .. versionadded:: libzmq-4.0\n        .. versionadded:: 14.0\n\n        Parameters\n        ----------\n        events : int [default: ZMQ_EVENT_ALL]\n            The bitmask defining which events are wanted.\n        addr :  string [default: None]\n            The optional endpoint for the monitoring sockets.\n\n        Returns\n        -------\n        socket :  (PAIR)\n            The socket is already connected and ready to receive messages.\n        \"\"\"\n        # safe-guard, method only available on libzmq >= 4\n        if zmq.zmq_version_info() < (4,):\n            raise NotImplementedError(\n                \"get_monitor_socket requires libzmq >= 4, have %s\" % zmq.zmq_version()\n            )\n\n        # if already monitoring, return existing socket\n        if self._monitor_socket:\n            if self._monitor_socket.closed:\n                self._monitor_socket = None\n            else:\n                return self._monitor_socket\n\n        if addr is None:\n            # create endpoint name from internal fd\n            addr = f\"inproc://monitor.s-{self.FD}\"\n        if events is None:\n            # use all events\n            events = zmq.EVENT_ALL\n        # attach monitoring socket\n        self.monitor(addr, events)\n        # create new PAIR socket and connect it\n        self._monitor_socket = self.context.socket(zmq.PAIR)\n        self._monitor_socket.connect(addr)\n        return self._monitor_socket\n\n    def disable_monitor(self) -> None:\n        \"\"\"Shutdown the PAIR socket (created using get_monitor_socket)\n        that is serving socket events.\n\n        .. versionadded:: 14.4\n        \"\"\"\n        self._monitor_socket = None\n        self.monitor(None, 0)\n\n\n__all__ = ['Socket']\n",1106],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py":["# Extra utilities for working with context managers that should have been\n# in the standard library but are not\n\nimport functools\nimport inspect\nimport warnings\nimport sys\nfrom typing import Any, Callable, TypeVar, cast\n\n# Used for annotating the decorator usage of _DecoratorContextManager (e.g.,\n# 'no_grad' and 'enable_grad').\n# See https://mypy.readthedocs.io/en/latest/generics.html#declaring-decorators\nFuncType = Callable[..., Any]\nF = TypeVar('F', bound=FuncType)\n\n\ndef _wrap_generator(ctx_factory, func):\n    \"\"\"\n    Wrap each generator invocation with the context manager factory.\n\n    The input should be a function that returns a context manager,\n    not a context manager itself, to handle one-shot context managers.\n    \"\"\"\n    @functools.wraps(func)\n    def generator_context(*args, **kwargs):\n        gen = func(*args, **kwargs)\n\n        # Generators are suspended and unsuspended at `yield`, hence we\n        # make sure the grad mode is properly set every time the execution\n        # flow returns into the wrapped generator and restored when it\n        # returns through our `yield` to our caller (see PR #49017).\n        try:\n            # Issuing `None` to a generator fires it up\n            with ctx_factory():\n                response = gen.send(None)\n\n            while True:\n                try:\n                    # Forward the response to our caller and get its next request\n                    request = yield response\n\n                except GeneratorExit:\n                    # Inform the still active generator about its imminent closure\n                    with ctx_factory():\n                        gen.close()\n                    raise\n\n                except BaseException:\n                    # Propagate the exception thrown at us by the caller\n                    with ctx_factory():\n                        response = gen.throw(*sys.exc_info())\n\n                else:\n                    # Pass the last request to the generator and get its response\n                    with ctx_factory():\n                        response = gen.send(request)\n\n        # We let the exceptions raised above by the generator's `.throw` or\n        # `.send` methods bubble up to our caller, except for StopIteration\n        except StopIteration as e:\n            # The generator informed us that it is done: take whatever its\n            # returned value (if any) was and indicate that we're done too\n            # by returning it (see docs for python's return-statement).\n            return e.value\n\n    return generator_context\n\n\ndef context_decorator(ctx, func):\n    \"\"\"\n    Like contextlib.ContextDecorator.\n\n    But with the following differences:\n    1. Is done by wrapping, rather than inheritance, so it works with context\n       managers that are implemented from C and thus cannot easily inherit from\n       Python classes\n    2. Wraps generators in the intuitive way (c.f. https://bugs.python.org/issue37743)\n    3. Errors out if you try to wrap a class, because it is ambiguous whether\n       or not you intended to wrap only the constructor\n\n    The input argument can either be a context manager (in which case it must\n    be a multi-shot context manager that can be directly invoked multiple times)\n    or a callable that produces a context manager.\n    \"\"\"\n    assert not (callable(ctx) and hasattr(ctx, '__enter__')), (\n        f\"Passed in {ctx} is both callable and also a valid context manager \"\n        \"(has __enter__), making it ambiguous which interface to use.  If you \"\n        \"intended to pass a context manager factory, rewrite your call as \"\n        \"context_decorator(lambda: ctx()); if you intended to pass a context \"\n        \"manager directly, rewrite your call as context_decorator(lambda: ctx)\"\n    )\n\n    if not callable(ctx):\n        def ctx_factory():\n            return ctx\n    else:\n        ctx_factory = ctx\n\n    if inspect.isclass(func):\n        raise RuntimeError(\n            \"Cannot decorate classes; it is ambiguous whether or not only the \"\n            \"constructor or all methods should have the context manager applied; \"\n            \"additionally, decorating a class at definition-site will prevent \"\n            \"use of the identifier as a conventional type.  \"\n            \"To specify which methods to decorate, decorate each of them \"\n            \"individually.\"\n        )\n\n    if inspect.isgeneratorfunction(func):\n        return _wrap_generator(ctx_factory, func)\n\n    @functools.wraps(func)\n    def decorate_context(*args, **kwargs):\n        with ctx_factory():\n            return func(*args, **kwargs)\n\n    return decorate_context\n\n\nclass _DecoratorContextManager:\n    \"\"\"Allow a context manager to be used as a decorator.\"\"\"\n\n    def __call__(self, orig_func: F) -> F:\n        if inspect.isclass(orig_func):\n            warnings.warn(\"Decorating classes is deprecated and will be disabled in \"\n                          \"future versions. You should only decorate functions or methods. \"\n                          \"To preserve the current behavior of class decoration, you can \"\n                          \"directly decorate the `__init__` method and nothing else.\")\n            func = cast(F, lambda *args, **kwargs: orig_func(*args, **kwargs))\n        else:\n            func = orig_func\n\n        return cast(F, context_decorator(self.clone, func))\n\n    def __enter__(self) -> None:\n        raise NotImplementedError\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        raise NotImplementedError\n\n    def clone(self):\n        # override this method if your children class takes __init__ parameters\n        return self.__class__()\n\n\nclass _NoParamDecoratorContextManager(_DecoratorContextManager):\n    \"\"\"Allow a context manager to be used as a decorator without parentheses.\"\"\"\n\n    def __new__(cls, orig_func=None):\n        if orig_func is None:\n            return super().__new__(cls)\n        return cls()(orig_func)\n",152],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_jit_internal.py":["\"\"\"\nThe weak_script annotation needs to be here instead of inside torch/jit/ so it\ncan be used in other places in torch/ (namely torch.nn) without running into\ncircular dependency problems\n\"\"\"\n\nimport ast\nimport builtins\nimport collections\nimport contextlib\nimport enum\nimport inspect\nimport io\nimport pickle\nimport sys\nimport threading\nimport types\nimport typing\nimport warnings\nimport weakref\nfrom textwrap import dedent\nfrom typing import (  # noqa: F401\n    Any,\n    Callable,\n    Dict,\n    Final,\n    ForwardRef,\n    Generic,\n    get_args,  # new in 3.8\n    get_origin,  # new in 3.8\n    List,\n    Optional,\n    Tuple,\n    Type,\n    TypeVar,\n    Union,\n)\n\nimport torch\n\n# This is needed. `torch._jit_internal` is imported before `torch.distributed.__init__`.\n# Explicitly ask to import `torch.distributed.__init__` first.\n# Otherwise, \"AttributeError: module 'torch' has no attribute 'distributed'\" is raised.\nimport torch.distributed.rpc\nimport torch.package._mangling as package_mangling\nfrom torch._awaits import _Await\nfrom torch._C import _Await as CAwait, Future as CFuture\nfrom torch._sources import fake_range, get_source_lines_and_file, parse_def\nfrom torch.futures import Future\n\nIS_PY39_PLUS: Final[bool] = sys.version_info >= (3, 9)\nIS_PY310_PLUS: Final[bool] = sys.version_info >= (3, 10)\n\nBuiltinUnionType: Union[Type, Tuple[Type, ...]]\nif sys.version_info >= (3, 10):\n    # NOTE: IS_PY310_PLUS doesn't work with mypy.\n    # cf. https://mypy.readthedocs.io/en/stable/common_issues.html#python-version-and-system-platform-checks\n    BuiltinUnionType = types.UnionType\nelse:\n    BuiltinUnionType = ()  # trick: this makes isinstance short circuit.\n\nLockType: Type\ntry:\n    import _thread\n\n    LockType = _thread.LockType\nexcept ImportError:\n    import _dummy_thread\n\n    LockType = _dummy_thread.LockType\n\n# Wrapper functions that can call either of 2 functions depending on a boolean\n# argument\nboolean_dispatched: \"weakref.WeakKeyDictionary[Callable, Dict[str, Callable]]\" = (\n    weakref.WeakKeyDictionary()\n)  # noqa: T484\n\n\nFAKE_FILENAME_PREFIX = \"__torch_jit_dataclass\"\n\n\nclass SourceLoader:\n    def __init__(self):\n        self.content = {}\n\n    def cache(self, fn, source):\n        self.content[fn] = source\n\n    def get_source(self, fn):\n        return self.content.get(fn)\n\n\nloader = SourceLoader()\n\n\ndef createResolutionCallbackFromEnv(lookup_base):\n    \"\"\"\n    Creates a resolution callback that will look up qualified names in an\n    environment, starting with `lookup_base` for the base of any qualified\n    names, then proceeding down the lookup chain with the resolved object.\n\n    You should not use this directly, it should only be used from the other\n    createResolutionCallbackFrom* functions.\n    \"\"\"\n\n    def lookupInModule(qualified_name, module):\n        if \".\" in qualified_name:\n            parts = qualified_name.split(\".\")\n            base = parts[0]\n            remaining_pieces = \".\".join(parts[1:])\n            module_value = getattr(module, base)\n            return lookupInModule(remaining_pieces, module_value)\n        else:\n            return getattr(module, qualified_name)\n\n    def parseNestedExpr(expr, module) -> Tuple[Any, int]:\n        i = 0\n        while i < len(expr) and expr[i] not in (\",\", \"[\", \"]\"):\n            i += 1\n\n        # Special case logic for the empty Tuple as a subscript (used\n        # in the type annotation `Tuple[()]`)\n        if expr[:i] == \"()\":\n            return (), i\n\n        base = lookupInModule(expr[:i].strip(), module)\n        assert base is not None, f\"Unresolvable type {expr[:i]}\"\n        if i == len(expr) or expr[i] != \"[\":\n            return base, i\n\n        assert expr[i] == \"[\"\n        parts = []\n        while expr[i] != \"]\":\n            part_len = 0\n            i += 1\n            part, part_len = parseNestedExpr(expr[i:], module)\n            parts.append(part)\n            i += part_len\n        if len(parts) > 1:\n            return base[tuple(parts)], i + 1\n        else:\n            return base[parts[0]], i + 1\n\n    def parseExpr(expr, module):\n        try:\n            value, len_parsed = parseNestedExpr(expr, module)\n            assert len_parsed == len(\n                expr\n            ), \"whole expression was not parsed, falling back to c++ parser\"\n            return value\n        except Exception:\n            \"\"\"\n            The python resolver fails in several cases in known unit tests, and is intended\n            to fall back gracefully to the c++ resolver in general.  For example, python 2 style\n            annotations which are frequent in our unit tests often fail with types e.g. int not\n            resolvable from the calling frame.\n            \"\"\"\n            return None\n\n    return lambda expr: parseExpr(expr, lookup_base)\n\n\ndef createResolutionCallbackFromFrame(frames_up: int = 0):\n    \"\"\"\n    Creates a function which, given a string variable name,\n    returns the value of the variable in the scope of the caller of\n    the function which called createResolutionCallbackFromFrame (by default).\n\n    This is used to enable access in-scope Python variables inside\n    TorchScript fragments.\n\n    frames_up is number of additional frames to go up on the stack.\n    The default value is 0, which correspond to the frame of the caller\n    of createResolutionCallbackFromFrame. Also for example, if frames_up is set\n    to 1, then the frame of the caller's caller of createResolutionCallbackFromFrame\n    will be taken.\n\n    For example, the following program prints 2::\n\n        def bar():\n            cb = createResolutionCallbackFromFrame(1)\n            print(cb(\"foo\"))\n\n        def baz():\n            foo = 2\n            bar()\n\n        baz()\n    \"\"\"\n    frame = inspect.currentframe()\n    i = 0\n    while i < frames_up + 1:\n        assert frame is not None\n        frame = frame.f_back\n        i += 1\n\n    assert frame is not None\n    f_locals = frame.f_locals\n    f_globals = frame.f_globals\n\n    class env:\n        def __getattr__(self, key):\n            if key in f_locals:\n                return f_locals[key]\n            elif key in f_globals:\n                return f_globals[key]\n            elif key in dir(builtins):\n                return getattr(builtins, key)\n\n    return createResolutionCallbackFromEnv(env())\n\n\ndef get_closure(fn):\n    \"\"\"\n    Get a dictionary of closed over variables from a function\n    \"\"\"\n    captures = {}\n    captures.update(fn.__globals__)\n\n    for index, captured_name in enumerate(fn.__code__.co_freevars):\n        captures[captured_name] = fn.__closure__[index].cell_contents\n\n    return captures\n\n\n# [local resolution in python]\n# Depending on where a variable is defined, and where it is used, we may\n# or may not be able to recover its value when recursively compiling a\n# script function. Remember in the general case, a module or function is\n# first defined and then later scripted. This means we do not have a\n# chance to capture the active frames when the function is defined. Hence any\n# name resolution has to happen later on the created closure. The way\n# python captures type annotations restricts what we can recover. The\n# follow example illustrates the different cases:\n#\n#         class MyGlobalClass:\n#         ...\n#         def my_local_scope():\n#             @torch.jit.script\n#             class MyClass:\n#                 ...\n#             @torch.jit.script\n#             class MyClassUsedAsVar:\n#                 ...\n#             def eg(x: MyClass, y: MyGlobalClass):\n#                 a_local_capture : Foo\n#                 return MyClassUsedAsVar(x)\n#\n# MyGlobalClass is defined in the __globals__ dictionary of function\n# 'eg', so it is always recoverable. my_local_scope introduces a new local\n# variable scope in the function. Classes defined here are only visible as\n# local variables. For the case of MyClassUsedAsVar, it is captured\n# because it is used as a variable inside the body of the function, and we\n# can resolve it using the captures returned from `get_closure`. However,\n# the type annotations are not captured by the closure. In Python\n# 3.0--3.9, the _value_ of MyClass and MyGlobalClass will be available as\n# annotations on `eg``, but starting in Python 4.0, they will represented as\n# strings and no longer present. Furthermore, since the body of `eg` does\n# not reference those names, they do not appear in the list of closed over\n# variables. In Python 2.x, type annotations are in comments, leading to a\n# similar situation where their definitions are not available. We anticipate\n# that most users will not run into this issue because their modules and\n# functions will be defined at a global scope like MyGlobalClass. In cases\n# where they are not, it is possible to work around issues by declaring the\n# values global in the function.\n# In Python 3.9 declaring class as global will make it invisible to\n# `inspect.getsource`, see https://bugs.python.org/issue42666 .\n# This could be worked around by manualy adding it to `global()` dictionary.\n\n\ndef createResolutionCallbackFromClosure(fn):\n    \"\"\"\n    Create a resolutionCallback by introspecting the function instead of\n    looking up the stack for the enclosing scope\n    \"\"\"\n    closure = get_closure(fn)\n\n    class closure_lookup:\n        # This is a class since `closure` is a dict and it's easier in\n        # `env_helper` if everything just works with `getattr` calls\n        def __getattr__(self, key):\n            if key in closure:\n                return closure[key]\n            elif hasattr(typing, key):\n                return getattr(typing, key)\n            elif hasattr(builtins, key):\n                return getattr(builtins, key)\n            return None\n\n    return createResolutionCallbackFromEnv(closure_lookup())\n\n\ndef can_compile_class(cls) -> bool:\n    # If any of the functions on a type don't have a code object, this type can't\n    # be compiled and is probably a builtin / bound from C\n    if is_ignored_fn(cls):\n        return False\n\n    # Ignore the following list of built-in classes.\n    ignored_builtin_classes = (torch.nn.Module, tuple, list, Exception)\n    if issubclass(cls, ignored_builtin_classes):\n        return False\n\n    names = cls.__dict__\n    fns = [\n        getattr(cls, name)\n        for name in names\n        if inspect.isroutine(getattr(cls, name, None))\n    ]\n    has_code = [hasattr(fn, \"__code__\") for fn in fns]\n    return all(has_code)\n\n\ndef get_callable_argument_names(fn) -> List[str]:\n    \"\"\"\n    Gets names of all POSITIONAL_OR_KEYWORD arguments for callable `fn`.\n    Returns an empty list when other types of arguments are present.\n\n    This is used by `torch.jit.trace` to assign meaningful argument names to\n    traced functions and modules.\n\n    Args:\n        fn: A callable.\n    Returns:\n        Argument names: List[str]\n    \"\"\"\n    # inspect.signature may fail, give up in that case.\n    try:\n        callable_signature = inspect.signature(fn)\n    except Exception:\n        return []\n\n    argument_names = []\n    for name, param in callable_signature.parameters.items():\n        # All four other types of arguments do not map to individual values\n        # with a keyword as name.\n        if not param.kind == param.POSITIONAL_OR_KEYWORD:\n            continue\n\n        argument_names.append(name)\n\n    return argument_names\n\n\ndef get_annotation_str(annotation):\n    \"\"\"\n    Convert an AST node containing a type annotation to the string present in the source\n    that represents the same annotation.\n    \"\"\"\n    if isinstance(annotation, ast.Name):\n        return annotation.id\n    elif isinstance(annotation, ast.Attribute):\n        return \".\".join([get_annotation_str(annotation.value), annotation.attr])\n    elif isinstance(annotation, ast.Subscript):\n        # In Python3.9+ subscript indicies are not wrapped in ast.Index\n        subscript_slice = annotation.slice if IS_PY39_PLUS else annotation.slice.value  # type: ignore[attr-defined]\n        return f\"{get_annotation_str(annotation.value)}[{get_annotation_str(subscript_slice)}]\"\n    elif isinstance(annotation, ast.Tuple):\n        return \",\".join([get_annotation_str(elt) for elt in annotation.elts])\n    elif isinstance(annotation, (ast.Constant, ast.NameConstant)):\n        return f\"{annotation.value}\"\n\n    # If an AST node is not handled here, it's probably handled in ScriptTypeParser.\n    return None\n\n\ndef get_type_hint_captures(fn):\n    \"\"\"\n    Get a dictionary containing type resolution mappings necessary to resolve types\n    for the literal annotations on 'fn'. These are not considered to be closed-over by fn\n    and must be obtained separately (e.g. using this function).\n\n    Args:\n        fn: A callable.\n    Returns:\n        A Dict[str, Any] containing a mapping from the literal annotations used on\n        fn to the Python objects they refer to.\n    \"\"\"\n    # First, try to get the source of the function. We'll need to parse it to find the actual string names\n    # that were used to annotate the types, since inspect.signature() will only return the class object that\n    # the annotation refers to, not the string name. If we can't get the source, simply return an empty dict.\n    # This may happen in cases where the function is synthesized dynamically at runtime.\n    src = loader.get_source(fn)\n    if src is None:\n        src = inspect.getsource(fn)\n\n    # Gather a dictionary of parameter name -> type, skipping any parameters whose annotated\n    # types are strings. These are only understood by TorchScript in the context of a type annotation\n    # that refers to a class in its own definition, but trying to include a mapping for this in the result\n    # function would cause infinite recursion because the class is currently being compiled.\n    # In addition, there is logic in ScriptTypeParser to handle this.\n    signature = inspect.signature(fn)\n    name_to_type = {\n        name: parameter.annotation\n        for name, parameter in signature.parameters.items()\n        if parameter.annotation is not inspect.Parameter.empty\n        and not isinstance(parameter.annotation, str)\n    }\n\n    # Then, get the literal type annotations from the function declaration\n    # by source inspection. This accounts for the case in which aliases are used\n    # to annotate the arguments (e.g device_t = torch.device, and then d: device_t).\n    # frontend.py cannot be used here because it includes _jit_internal, so use ast instead.\n    a = ast.parse(dedent(src))\n    if len(a.body) != 1 or not isinstance(a.body[0], ast.FunctionDef):\n        raise RuntimeError(f\"Expected {fn} to be a function\")\n    f = a.body[0]\n\n    # Prepare a dictionary of source annotation -> type, which will be the final result of this function,\n    # by using the parsed AST (f) to reconstruct source annotations as strings for each parameter and mapping\n    # them to the type object corresponding to the annotation via name_to_type using the parameter name.\n    annotation_to_type = {}\n\n    for arg in f.args.args:\n        # Get the source type annotation string for this argument if possible.\n        arg_annotation_str = (\n            get_annotation_str(arg.annotation) if arg.annotation else None\n        )\n\n        # If the argument has no annotation or get_annotation_str cannot convert it to a string,\n        # arg_annotation_str will be None. Skip this arg; ScriptTypeParser will probably handle\n        # this in the latter case.\n        if arg_annotation_str is None:\n            continue\n\n        # Insert {arg_annotation_str: type} into annotation_to_type if possible. One reason arg_name may not\n        # be present in name_to_type is that the annotation itself is a string and not a type object\n        # (common for self-refential annotations in classes). Once again, let ScriptTypeParser handle this.\n        arg_name = arg.arg\n        if arg_name in name_to_type:\n            annotation_to_type[arg_annotation_str] = name_to_type[arg_name]\n\n    # If there is a valid return annotation, include it in annotation_to_type. As with argument annotations,\n    # the literal annotation has to be convertible to a string by get_annotation_str, and the actual type\n    # of the annotation cannot be a string.\n    literal_return_annotation = get_annotation_str(f.returns)\n    valid_literal_annotation = literal_return_annotation is not None\n    return_annotation = signature.return_annotation\n    valid_return_annotation_type = (\n        return_annotation is not inspect.Parameter.empty\n        and not isinstance(return_annotation, str)\n    )\n    if valid_literal_annotation and valid_return_annotation_type:\n        annotation_to_type[literal_return_annotation] = return_annotation\n\n    return annotation_to_type\n\n\ndef createResolutionCallbackForClassMethods(cls):\n    \"\"\"\n    This looks at all the methods defined in a class and pulls their closed-over\n    variables into a dictionary and uses that to resolve variables.\n    \"\"\"\n    # cls is a type here, so `ismethod` is false since the methods on the type\n    # aren't bound to anything, so Python treats them as regular functions\n    fns = [\n        getattr(cls, name)\n        for name in cls.__dict__\n        if inspect.isroutine(getattr(cls, name))\n    ]\n    # Skip built-ins, as they do not have global scope nor type hints\n    # Needed to support `enum.Enum` derived classes in Python-3.11\n    # That adds `_new_member_` property which is an alias to `__new__`\n    fns = [fn for fn in fns if not inspect.isbuiltin(fn) and hasattr(fn, \"__globals__\")]\n    captures = {}\n\n    for fn in fns:\n        captures.update(get_closure(fn))\n        captures.update(get_type_hint_captures(fn))\n\n    def lookup_in_class(key):\n        if key in captures:\n            return captures[key]\n        else:\n            return getattr(builtins, key, None)\n\n    return lookup_in_class\n\n\ndef boolean_dispatch(\n    arg_name, arg_index, default, if_true, if_false, module_name, func_name\n):\n    \"\"\"\n    Dispatches to either of 2 script functions based on a boolean argument.\n    In TorchScript, the boolean argument must be constant so that the correct\n    function to use can be determined at compile time.\n    \"\"\"\n\n    def fn(*args, **kwargs):\n        dispatch_flag = default\n        if arg_name in kwargs:\n            dispatch_flag = kwargs[arg_name]\n        elif arg_index < len(args):\n            dispatch_flag = args[arg_index]\n\n        if dispatch_flag:\n            return if_true(*args, **kwargs)\n        else:\n            return if_false(*args, **kwargs)\n\n    if if_true.__doc__ is None and if_false.__doc__ is not None:\n        doc = if_false.__doc__\n        if_true.__doc__ = doc\n    elif if_false.__doc__ is None and if_true.__doc__ is not None:\n        doc = if_true.__doc__\n        if_false.__doc__ = doc\n    elif if_false.__doc__ is None and if_true.__doc__ is None:\n        # neither function has a docstring\n        doc = None\n    else:\n        raise RuntimeError(\"only one function can have a docstring\")\n    fn.__doc__ = doc\n\n    if module_name is not None:\n        fn.__module__ = module_name\n    if func_name is not None:\n        fn.__name__ = func_name\n\n    boolean_dispatched[fn] = {\n        \"if_true\": if_true,\n        \"if_false\": if_false,\n        \"index\": arg_index,\n        \"default\": default,\n        \"arg_name\": arg_name,\n    }\n    return fn\n\n\nclass FunctionModifiers:\n    \"\"\"\n    Used to denote the behavior of a function in TorchScript. See export() and\n    ignore() for details.\n    \"\"\"\n\n    UNUSED = \"unused (ignored and replaced with raising of an exception)\"\n    IGNORE = \"ignore (leave as a call to Python, cannot be torch.jit.save'd)\"\n    EXPORT = \"export (compile this function even if nothing calls it)\"\n    DEFAULT = \"default (compile if called from a exported function / forward)\"\n    COPY_TO_SCRIPT_WRAPPER = (\n        \"if this method is not scripted, copy the python method onto the scripted model\"\n    )\n    _DROP = \"_drop (function is fully ignored, declaration can be unscriptable)\"\n\n\ndef export(fn):\n    \"\"\"\n    This decorator indicates that a method on an ``nn.Module`` is used as an entry point into a\n    :class:`ScriptModule` and should be compiled.\n\n    ``forward`` implicitly is assumed to be an entry point, so it does not need this decorator.\n    Functions and methods called from ``forward`` are compiled as they are seen\n    by the compiler, so they do not need this decorator either.\n\n    Example (using ``@torch.jit.export`` on a method):\n\n    .. testcode::\n\n        import torch\n        import torch.nn as nn\n\n        class MyModule(nn.Module):\n            def implicitly_compiled_method(self, x):\n                return x + 99\n\n            # `forward` is implicitly decorated with `@torch.jit.export`,\n            # so adding it here would have no effect\n            def forward(self, x):\n                return x + 10\n\n            @torch.jit.export\n            def another_forward(self, x):\n                # When the compiler sees this call, it will compile\n                # `implicitly_compiled_method`\n                return self.implicitly_compiled_method(x)\n\n            def unused_method(self, x):\n                return x - 20\n\n        # `m` will contain compiled methods:\n        #     `forward`\n        #     `another_forward`\n        #     `implicitly_compiled_method`\n        # `unused_method` will not be compiled since it was not called from\n        # any compiled methods and wasn't decorated with `@torch.jit.export`\n        m = torch.jit.script(MyModule())\n    \"\"\"\n    fn._torchscript_modifier = FunctionModifiers.EXPORT\n    return fn\n\n\ndef unused(fn):\n    \"\"\"\n    This decorator indicates to the compiler that a function or method should\n    be ignored and replaced with the raising of an exception. This allows you\n    to leave code in your model that is not yet TorchScript compatible and still\n    export your model.\n\n        Example (using ``@torch.jit.unused`` on a method)::\n\n            import torch\n            import torch.nn as nn\n\n            class MyModule(nn.Module):\n                def __init__(self, use_memory_efficient):\n                    super().__init__()\n                    self.use_memory_efficient = use_memory_efficient\n\n                @torch.jit.unused\n                def memory_efficient(self, x):\n                    import pdb\n                    pdb.set_trace()\n                    return x + 10\n\n                def forward(self, x):\n                    # Use not-yet-scriptable memory efficient mode\n                    if self.use_memory_efficient:\n                        return self.memory_efficient(x)\n                    else:\n                        return x + 10\n\n            m = torch.jit.script(MyModule(use_memory_efficient=False))\n            m.save(\"m.pt\")\n\n            m = torch.jit.script(MyModule(use_memory_efficient=True))\n            # exception raised\n            m(torch.rand(100))\n    \"\"\"\n    if isinstance(fn, property):\n        prop = fn\n        setattr(  # noqa: B010\n            prop.fget, \"_torchscript_modifier\", FunctionModifiers.UNUSED\n        )\n\n        if prop.fset:\n            setattr(  # noqa: B010\n                prop.fset, \"_torchscript_modifier\", FunctionModifiers.UNUSED\n            )\n\n        return prop\n\n    fn._torchscript_modifier = FunctionModifiers.UNUSED\n    return fn\n\n\n# No op context manager from python side\nclass _IgnoreContextManager(contextlib.AbstractContextManager):\n    def __init__(self, **kwargs):\n        pass\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        pass\n\n\ndef ignore(drop=False, **kwargs):\n    \"\"\"\n    This decorator indicates to the compiler that a function or method should\n    be ignored and left as a Python function. This allows you to leave code in\n    your model that is not yet TorchScript compatible. If called from TorchScript,\n    ignored functions will dispatch the call to the Python interpreter. Models with ignored\n    functions cannot be exported; use :func:`@torch.jit.unused <torch.jit.unused>` instead.\n\n    Example (using ``@torch.jit.ignore`` on a method)::\n\n        import torch\n        import torch.nn as nn\n\n        class MyModule(nn.Module):\n            @torch.jit.ignore\n            def debugger(self, x):\n                import pdb\n                pdb.set_trace()\n\n            def forward(self, x):\n                x += 10\n                # The compiler would normally try to compile `debugger`,\n                # but since it is `@ignore`d, it will be left as a call\n                # to Python\n                self.debugger(x)\n                return x\n\n        m = torch.jit.script(MyModule())\n\n        # Error! The call `debugger` cannot be saved since it calls into Python\n        m.save(\"m.pt\")\n\n    Example (using ``@torch.jit.ignore(drop=True)`` on a method):\n\n    .. testcode::\n\n        import torch\n        import torch.nn as nn\n\n        class MyModule(nn.Module):\n            @torch.jit.ignore(drop=True)\n            def training_method(self, x):\n                import pdb\n                pdb.set_trace()\n\n            def forward(self, x):\n                if self.training:\n                    self.training_method(x)\n                return x\n\n        m = torch.jit.script(MyModule())\n\n        # This is OK since `training_method` is not saved, the call is replaced\n        # with a `raise`.\n        m.save(\"m.pt\")\n\n    .. testcleanup::\n\n        import os\n        os.remove('m.pt')\n    \"\"\"\n\n    if callable(drop):\n        # used without any args, so drop is actually a function\n        #   @torch.jit.ignore\n        #   def fn(...):\n        fn = drop\n        fn._torchscript_modifier = FunctionModifiers.IGNORE\n        return fn\n\n    if not isinstance(drop, bool):\n        raise RuntimeError(\n            \"Argument to @torch.jit.ignore must be a bool or \"\n            f\"a function but got {drop}\"\n        )\n\n    # for backwards compat\n    drop_on_export = kwargs.pop(\"drop_on_export\", None)\n    if drop_on_export:\n        warnings.warn(\n            \"ignore(drop_on_export=True) has been deprecated. TorchScript will now drop the function \"\n            \"call on compilation. Use torch.jit.unused now. {}\",\n            category=FutureWarning,\n        )\n\n        drop = drop_on_export\n    elif drop:\n        warnings.warn(\n            \"ignore(True) has been deprecated. TorchScript will now drop the function \"\n            \"call on compilation. Use torch.jit.unused now. {}\",\n            category=FutureWarning,\n        )\n\n    def decorator(fn):\n        if drop:\n            fn._torchscript_modifier = FunctionModifiers.UNUSED\n        else:\n            fn._torchscript_modifier = FunctionModifiers.IGNORE\n        return fn\n\n    return decorator\n\n\ndef _drop(fn):\n    fn._torchscript_modifier = FunctionModifiers._DROP\n    return fn\n\n\ndef _copy_to_script_wrapper(fn):\n    fn._torchscript_modifier = FunctionModifiers.COPY_TO_SCRIPT_WRAPPER\n    return fn\n\n\ndef module_has_exports(mod):\n    for name in dir(mod):\n        if hasattr(mod, name):\n            item = getattr(mod, name)\n            if callable(item):\n                if get_torchscript_modifier(item) is FunctionModifiers.EXPORT:\n                    return True\n    return False\n\n\n# WARNING: should_drop is currently being used by our JIT code coverage plug-in to mark JIT'd code as covered. If you\n# rename this function, please update references in tools/coverage_plugins_package/src/coverage_plugins/jit_plugin.py to\n# allow JIT'd code to still be covered.\ndef should_drop(fn) -> bool:\n    attr = get_torchscript_modifier(fn)\n    if attr is None:\n        return False\n    return attr is FunctionModifiers.UNUSED or attr is FunctionModifiers._DROP\n\n\ndef is_ignored_fn(fn) -> bool:\n    mod = get_torchscript_modifier(fn)\n    return (\n        mod is FunctionModifiers.UNUSED\n        or mod is FunctionModifiers.IGNORE\n        or mod is FunctionModifiers._DROP\n    )\n\n\ndef _is_drop_fn(fn) -> bool:\n    mod = get_torchscript_modifier(fn)\n    return mod is FunctionModifiers._DROP\n\n\ndef is_static_fn(cls, fn) -> bool:\n    return isinstance(inspect.getattr_static(cls, fn, default=None), staticmethod)\n\n\ndef get_static_fn(cls, fn):\n    return inspect.getattr_static(cls, fn).__func__\n\n\ndef get_torchscript_modifier(fn):\n    if not callable(fn):\n        return None\n    if hasattr(fn, \"__func__\"):\n        fn = fn.__func__\n    return getattr(fn, \"_torchscript_modifier\", FunctionModifiers.DEFAULT)\n\n\ndef copy_torchscript_modifier(orig, new) -> None:\n    attr = get_torchscript_modifier(orig)\n    if attr is None:\n        return\n    new._torchscript_modifier = attr\n\n\n# overloading registration\n# overloads get registered in this file, and compiled in torch/jit/__init__.py\n# so that they can be imported in nn/functional.py without an import cycle\n\n# qualified_name => list[overload_functions]\n_overloaded_fns: Dict[str, List[Callable]] = {}  # noqa: T484\n\n\n_OVERLOAD_EXAMPLE = \"\"\"\nExample usage of overload function:\n@torch.jit._overload\ndef my_function(x: type0) -> type0: # decl 1\n    pass\n\n@torch.jit._overload\ndef my_function(x: type1) -> type1: # decl 2\n    pass\n\ndef my_function(x):                 # implementation\n    if isinstance(x, type0):\n        return x\n    elif isinstance(x, type1):\n        return x\n\"\"\"\n\n\ndef get_overload_no_implementation_error_message(kind, obj):\n    sourcelines, file_lineno, filename = get_source_lines_and_file(obj)\n    return (\n        f'Implementation for the {kind} \"{_qualified_name(obj)}\" is missing. Please make '\n        f\"sure a definition is provided and defined after all overload declarations.\\n\"\n        f'File \"{filename}\", line {file_lineno}:\\n'\n        + \"\".join(sourcelines)\n        + \"\\n\"\n        + _OVERLOAD_EXAMPLE\n    )\n\n\ndef _check_overload_body(func):\n    try:\n        parsed_def = parse_def(func)\n    except OSError as e:\n        # Parsing the function definition can raise an OSError if source is unavailable.\n        # Since this is just an initial check, just raise a warning if this is the case.\n        warnings.warn(\n            f\"Unable to retrieve source for @torch.jit._overload function: {func}.\"\n        )\n        return\n\n    body = parsed_def.ast.body[0].body\n\n    def is_pass(x):\n        return isinstance(x, ast.Pass)\n\n    def is_ellipsis(x):\n        return isinstance(x, ast.Expr) and isinstance(x.value, ast.Ellipsis)\n\n    if len(body) != 1 or not (is_pass(body[0]) or is_ellipsis(body[0])):\n        msg = (\n            \"Only `pass` statement or `...` can be the body of overload declaration:\\n\"\n        )\n        msg += \"\\n\".join(parsed_def.source.split(\"\\n\")[:3])\n        msg += \" <- Expecting `pass` or `...` here!\\n\" + _OVERLOAD_EXAMPLE\n        raise RuntimeError(msg)\n\n\ndef _overload(func):\n    _check_overload_body(func)\n    qual_name = _qualified_name(func)\n    global _overloaded_fns\n    fn_overload_list = _overloaded_fns.get(qual_name)\n    if fn_overload_list is None:\n        fn_overload_list = []\n        _overloaded_fns[qual_name] = fn_overload_list\n    fn_overload_list.append(func)\n    return func\n\n\ndef _get_fn_overloads(qual_name):\n    return _overloaded_fns.get(qual_name)\n\n\ndef _clear_fn_overloads(qual_name) -> None:\n    del _overloaded_fns[qual_name]\n\n\ndef get_class_name_lineno(method) -> Tuple[str, int]:\n    current_frame = inspect.currentframe()\n\n    # one for the get_class_name call, one for _overload_method call\n    for i in range(2):\n        assert (\n            current_frame is not None\n        )  # assert current frame is not an Optional[FrameType]\n        current_frame = current_frame.f_back\n\n    assert current_frame is not None  # same here\n    class_name = current_frame.f_code.co_name\n    line_no = current_frame.f_code.co_firstlineno\n    return class_name, line_no\n\n\n# At the point the decorator is applied to class methods the method\n# has no reference to its owning class. _qualified_name would not include\n# the class it is defined in, so any methods with the same name in the same file\n# would have the same _qualified_name, even if they were defined in different\n# classes. This problem only exists in python 2.\n# We get around this problem by looking at the stack frame and identifying\n# the class name, and throwing an error whenever overloads are used\n# when modules of the same name are in the same file\n\n# qualified_name => class name => list[overload_functions]\n_overloaded_methods: Dict[str, Dict[str, List[Callable]]] = {}  # noqa: T484\n\n\n# (qualified_name, class name) => class_fileno\n_overloaded_method_class_fileno = {}\n\n\ndef _overload_method(func):\n    _check_overload_body(func)\n    qual_name = _qualified_name(func)\n    global _overloaded_methods\n    class_name_map = _overloaded_methods.get(qual_name, None)\n    if class_name_map is None:\n        class_name_map = {}\n        _overloaded_methods[qual_name] = class_name_map\n\n    class_name, line_no = get_class_name_lineno(func)\n    method_overloads = class_name_map.get(class_name, None)\n    if method_overloads is None:\n        method_overloads = []\n        class_name_map[class_name] = method_overloads\n        _overloaded_method_class_fileno[(qual_name, class_name)] = line_no\n    else:\n        existing_lineno = _overloaded_method_class_fileno[(qual_name, class_name)]\n        if existing_lineno != line_no:\n            raise RuntimeError(\n                \"Cannot currently overload the same method name in two different\"\n                \" classes with the same name in the same module\"\n            )\n\n    method_overloads.append(func)\n    return func\n\n\ndef _get_overloaded_methods(method, mod_class):\n    # TODO: __name__ not set for submodules in recursive script\n    if not hasattr(method, \"__name__\"):\n        return None\n    qual_name = _qualified_name(method)\n    class_name_map = _overloaded_methods.get(qual_name, None)\n    if class_name_map is None:\n        return None\n    overloads = class_name_map.get(mod_class.__name__, None)\n    if overloads is None:\n        return None\n\n    method_line_no = get_source_lines_and_file(method)[1]\n    mod_class_fileno = get_source_lines_and_file(mod_class)[1]\n    mod_end_fileno = mod_class_fileno + len(get_source_lines_and_file(mod_class)[0])\n    if not (method_line_no >= mod_class_fileno and method_line_no <= mod_end_fileno):\n        raise Exception(\n            \"Overloads are not useable when a module is redeclared within the same file: \"\n            + str(method)\n        )\n    return overloads\n\n\ndef is_tuple(ann) -> bool:\n    if ann is Tuple:\n        raise_error_container_parameter_missing(\"Tuple\")\n\n    # For some reason Python 3.7 violates the Type[A, B].__origin__ == Type rule\n    if not hasattr(ann, \"__module__\"):\n        return False\n\n    ann_origin = get_origin(ann)\n    if IS_PY39_PLUS and ann.__module__ == \"builtins\" and ann_origin is tuple:\n        return True\n    return ann.__module__ == \"typing\" and (ann_origin is Tuple or ann_origin is tuple)\n\n\ndef is_list(ann) -> bool:\n    if ann is List:\n        raise_error_container_parameter_missing(\"List\")\n\n    if not hasattr(ann, \"__module__\"):\n        return False\n\n    ann_origin = get_origin(ann)\n    if IS_PY39_PLUS and ann.__module__ == \"builtins\" and ann_origin is list:\n        return True\n    return ann.__module__ == \"typing\" and (ann_origin is List or ann_origin is list)\n\n\ndef is_dict(ann) -> bool:\n    if ann is Dict:\n        raise_error_container_parameter_missing(\"Dict\")\n\n    if not hasattr(ann, \"__module__\"):\n        return False\n\n    ann_origin = get_origin(ann)\n    if IS_PY39_PLUS and ann.__module__ == \"builtins\" and ann_origin is dict:\n        return True\n    return ann.__module__ == \"typing\" and (ann_origin is Dict or ann_origin is dict)\n\n\ndef is_union(ann):\n    if ann is Union:\n        raise_error_container_parameter_missing(\"Union\")\n\n    return isinstance(ann, BuiltinUnionType) or (\n        hasattr(ann, \"__module__\")\n        and ann.__module__ == \"typing\"\n        and (get_origin(ann) is Union)\n    )\n\n\ndef is_optional(ann):\n    if ann is Optional:\n        raise_error_container_parameter_missing(\"Optional\")\n\n    def is_optional_as_optional(ann):\n        return (\n            hasattr(ann, \"__module__\")\n            and ann.__module__ == \"typing\"\n            and (get_origin(ann) is Optional)\n        )\n\n    def is_union_as_optional(ann):\n        ann_args = get_args(ann)\n        return len(ann_args) == 2 and (None in ann_args or type(None) in ann_args)\n\n    return is_optional_as_optional(ann) or (is_union(ann) and is_union_as_optional(ann))\n\n\ndef is_future(ann) -> bool:\n    if ann is Future:\n        raise RuntimeError(\n            \"Attempted to use Future without a \"\n            \"contained type. Please add a contained type, e.g. \"\n            \"Future[int]\"\n        )\n    return get_origin(ann) is Future\n\n\ndef is_await(ann) -> bool:\n    if ann is _Await:\n        return True\n    return get_origin(ann) is _Await\n\n\nif torch.distributed.rpc.is_available():\n    from torch._C._distributed_rpc import PyRRef\n    from torch.distributed.rpc import RRef\n\n    def is_rref(ann) -> bool:\n        if ann is RRef:\n            raise RuntimeError(\n                \"Attempted to use RRef without a \"\n                \"contained type. Please add a contained type, e.g. \"\n                \"RRef[int]\"\n            )\n        return get_origin(ann) is RRef\n\n    def is_rref_instance(obj) -> bool:\n        return isinstance(obj, PyRRef)\n\nelse:\n\n    def is_rref_instance(obj) -> bool:\n        # If the RPC module doesn't exist then RRefs don't exist either.\n        return False\n\n\ndef is_final(ann) -> bool:\n    return ann.__module__ in {\"typing\", \"typing_extensions\"} and (\n        get_origin(ann) is Final or isinstance(ann, type(Final))\n    )\n\n\n# allows BroadcastingList instance to be subscriptable\nclass BroadcastingListCls:\n    def __getitem__(self, types):\n        return\n\n\n# mypy doesn't support parameters on types, so we have to explicitly type each\n# list size\nBroadcastingList1 = BroadcastingListCls()\nfor i in range(2, 7):\n    globals()[f\"BroadcastingList{i}\"] = BroadcastingList1\n\n\ndef is_scripting() -> bool:\n    r\"\"\"\n    Function that returns True when in compilation and False otherwise. This\n    is useful especially with the @unused decorator to leave code in your\n    model that is not yet TorchScript compatible.\n    .. testcode::\n\n        import torch\n\n        @torch.jit.unused\n        def unsupported_linear_op(x):\n            return x\n\n        def linear(x):\n           if torch.jit.is_scripting():\n              return torch.linear(x)\n           else:\n              return unsupported_linear_op(x)\n    \"\"\"\n    return False\n\n\n# Retrieves a fully-qualified name (module hierarchy + classname) for a given obj.\ndef _qualified_name(obj, mangle_name=True) -> str:\n    # This special case allows us to override the qualified name on a type.\n    # It's currently used in conjunction with tracing, where we create a\n    # fake module to filter only supported attributes. However, since this\n    # new type is defined as a local class, we need a mechanism to override\n    # its qualname so it appears correctly in the TorchScript system. This,\n    # we set '_jit_override_qualname' with the original traced module's\n    # qualified name, which is picked up here\n    if hasattr(obj, \"_jit_override_qualname\"):\n        return obj._jit_override_qualname\n    # short-circuit in cases where the object already has a known qualified name\n    if isinstance(obj, torch._C.ScriptFunction):\n        return obj.qualified_name\n\n    if getattr(obj, \"__name__\", None):\n        name = obj.__name__\n    # Enum classes do not have `__name__` attr, instead they have `name`.\n    elif isinstance(obj, enum.Enum):\n        name = obj.name\n    else:\n        raise RuntimeError(\"Could not get name of python class object\")\n\n    if name == \"<lambda>\":\n        name = \"_lambda\"  # make name a valid identifier\n\n    module_name = obj.__module__\n\n    # If the module is actually a torchbind module, then we should short circuit\n    if module_name == \"torch._classes\":\n        return obj.qualified_name\n\n    # The Python docs are very clear that `__module__` can be None, but I can't\n    # figure out when it actually would be.\n    if module_name is None:\n        raise RuntimeError(\n            f\"Could not get qualified name for class '{name}': \"\n            \"__module__ can't be None.\"\n        )\n\n    # if getattr(sys.modules[module_name], name) is not obj:\n    #     raise RuntimeError(f\"Could not get qualified name for class '{name}': \"\n    #                        f\"the attr {name} on module {module_name} is not the class\")\n\n    # torch.package and TorchScript have separate mangling schemes to avoid\n    # name collisions from multiple packages. To avoid them interfering with\n    # each other, normalize the package manging here.\n    if package_mangling.is_mangled(module_name):\n        module_name = module_name.replace(\"<\", \"_\")\n        module_name = module_name.replace(\">\", \"_\")\n\n    # The PythonExceptionValue C++ class in torch/csrc/jit/python/python_sugared_value.h\n    # does not need mangle the python class name.\n    if mangle_name:\n        # __main__ is a builtin module, so rewrite it to \"__torch__\".\n        if module_name == \"__main__\":\n            module_name = \"__torch__\"\n        else:\n            # Everything else gets a \"__torch__\" prefix to avoid name collisions\n            # with the names of user values.\n            module_name = \"__torch__.\" + module_name\n\n    if \".\" in name:\n        raise RuntimeError(\n            f\"Could not get qualified name for class '{name}': \"\n            f\"'{name}' is not a valid identifier\"\n        )\n\n    return module_name + \".\" + name\n\n\ndef _try_get_dispatched_fn(fn):\n    if not callable(fn):\n        return None\n    return boolean_dispatched.get(fn)\n\n\ndef _get_named_tuple_properties(\n    obj, loc: Optional[torch._C._jit_tree_views.SourceRange] = None, rcb=None\n):\n    if loc is None:\n        loc = fake_range()\n\n    assert issubclass(obj, tuple) and hasattr(obj, \"_fields\")\n    if hasattr(obj, \"_field_defaults\"):\n        defaults = [\n            obj._field_defaults[field]\n            for field in obj._fields\n            if field in obj._field_defaults\n        ]\n    else:\n        defaults = []\n    # In 3.10 recommended way to get annotations is to call `inspect.get_annotations` function\n    # Also, annotations from base class are not inherited so they need to be queried explicitly\n    if sys.version_info[:2] < (3, 10):\n        obj_annotations = getattr(obj, \"__annotations__\", {})\n    else:\n        obj_annotations = inspect.get_annotations(obj)\n        if len(obj_annotations) == 0 and hasattr(obj, \"__base__\"):\n            obj_annotations = inspect.get_annotations(obj.__base__)\n\n    annotations = []\n    for field in obj._fields:\n        if field in obj_annotations:\n            field_type = obj_annotations[field]\n            # [Note: ForwardRef annotations in NamedTuple attributes]\n            # NamedTuple types are slightly different from normal types.\n            #\n            # Normally, annotations are evaluted like this (during jit.script):\n            # 1. Load strings of python code into c++ and parse.\n            # 2. Get annotations as strings\n            # 3. Use the PythonResolver's resolution callback (rcb) to convert\n            #    the string into a python object\n            # 4. We call into annotations.py:ann_to_type to convert python obj\n            #    from step 3 into a type that torchscript understands.\n            #\n            # NamedTuples are more complicated, because it has sub-types.\n            # Normally, once we have the NamedTuple type object from #3,\n            # we can just look at the annotation literal values and use\n            # ann_to_type directly on them.\n            #\n            # But sometimes, users will annotate with string literals, e.g.\n            #    x: 'int'\n            # This also happens with PEP563 (from __forward__ import annotations)\n            #\n            # These annotations appear in the annotation dict as ForwardRef('int').\n            #\n            # Then, we need to convert the string into a python object. This\n            # requires having local context for custom objects or imported types.\n            # rcb() is what gives us this. So, we plumb rcb through the stack so\n            # it can be used in this context for the if block below.\n            #\n            # FAQ:\n            # - Why do we need this special handling for NamedTuple but string\n            #   annotations work fine for normal types? Normally, we parse the\n            #   string directly and then call rcb() directly from C++.\n            # - Why not use ForwardRef._evaluate? For that, we need globals()\n            #   and locals() for the local context where the NamedTuple was defined.\n            #   rcb is what lets us look up into these. So, basically rcb does the\n            #   hard work for us.\n            if isinstance(field_type, ForwardRef) and rcb is not None:\n                rcb_type = rcb(field_type.__forward_arg__)\n                # rcb returns None if it can't find anything.\n                if rcb_type is None:\n                    raise ValueError(\n                        f\"Unknown type annotation: '{field_type}' in NamedTuple {obj.__name__}.\"\n                        f\" Likely due to partial support for ForwardRef parameters in NamedTuples, see #95858.\"\n                        f\" Issue occurred at {loc.highlight()}\"\n                    )\n                field_type = rcb_type\n            the_type = torch.jit.annotations.ann_to_type(field_type, loc, rcb)\n            annotations.append(the_type)\n        else:\n            annotations.append(torch._C.TensorType.getInferred())\n    return type(obj).__name__, obj._fields, annotations, defaults\n\n\ndef _create_named_tuple(\n    t, unqual_name: str, field_names: List[str], defaults: Tuple[Any, ...]\n):\n    TupleType = collections.namedtuple(unqual_name, field_names, defaults=defaults)  # type: ignore[call-arg, no-redef, misc]\n    return TupleType(*t)\n\n\n@contextlib.contextmanager\ndef _disable_emit_hooks():\n    hooks = torch._C._jit_get_emit_hooks()\n    torch._C._jit_set_emit_hooks(None, None)\n    try:\n        yield\n    finally:\n        torch._C._jit_set_emit_hooks(hooks[0], hooks[1])\n\n\ndef _disable_emit_hooks_decorator(_DecoratorContextManager) -> None:  # noqa: F811\n    def __enter__(self) -> None:\n        self.hooks = torch._C._jit_get_emit_hooks()\n        torch._C._jit_set_emit_hooks(None, None)\n\n    def __exit__(self, *args) -> None:\n        torch._C._jit_set_emit_hooks(self.hooks[0], self.hooks[1])\n\n\ndef _is_exception(obj) -> bool:\n    if not inspect.isclass(obj):\n        return False\n    return issubclass(obj, Exception)\n\n\ndef raise_error_container_parameter_missing(target_type) -> None:\n    if target_type == \"Dict\":\n        raise RuntimeError(\n            \"Attempted to use Dict without \"\n            \"contained types. Please add contained type, e.g. \"\n            \"Dict[int, int]\"\n        )\n    raise RuntimeError(\n        f\"Attempted to use {target_type} without a \"\n        \"contained type. Please add a contained type, e.g. \"\n        f\"{target_type}[int]\"\n    )\n\n\ndef check_args_exist(target_type) -> None:\n    if target_type is List or target_type is list:\n        raise_error_container_parameter_missing(\"List\")\n    elif target_type is Tuple or target_type is tuple:\n        raise_error_container_parameter_missing(\"Tuple\")\n    elif target_type is Dict or target_type is dict:\n        raise_error_container_parameter_missing(\"Dict\")\n    elif target_type is None or target_type is Optional:\n        raise_error_container_parameter_missing(\"Optional\")\n\n\ndef check_empty_containers(obj) -> None:\n    if obj == [] or obj == {} or obj == ():\n        warnings.warn(\n            \"The inner type of a container is lost when \"\n            \"calling torch.jit.isinstance in eager mode. For \"\n            \"example, List[int] would become list and \"\n            \"therefore falsely return True for List[float] or\"\n            \" List[str].\"\n        )\n\n\n# supports List/Dict/Tuple and Optional types\n# TODO support future\ndef container_checker(obj, target_type) -> bool:\n    origin_type = get_origin(target_type)\n    check_args_exist(target_type)\n    if origin_type is None:\n        return False\n    elif origin_type is list or origin_type is List:\n        check_empty_containers(obj)\n        if not isinstance(obj, list):\n            return False\n        arg_type = get_args(target_type)[0]\n        arg_origin = get_origin(arg_type)\n        for el in obj:\n            # check if nested container, ex: List[List[str]]\n            if arg_origin:  # processes nested container, ex: List[List[str]]\n                if not container_checker(el, arg_type):\n                    return False\n            elif not isinstance(el, arg_type):\n                return False\n        return True\n    elif origin_type is Dict or origin_type is dict:\n        check_empty_containers(obj)\n        if not isinstance(obj, dict):\n            return False\n        key_type = get_args(target_type)[0]\n        val_type = get_args(target_type)[1]\n        for key, val in obj.items():\n            # check if keys are of right type\n            if not isinstance(key, key_type):\n                return False\n            val_origin = get_origin(val_type)\n            if val_origin:\n                if not container_checker(val, val_type):\n                    return False\n            elif not isinstance(val, val_type):\n                return False\n        return True\n    elif origin_type is Tuple or origin_type is tuple:\n        check_empty_containers(obj)\n        if not isinstance(obj, tuple):\n            return False\n        arg_types = get_args(target_type)\n        if len(obj) != len(arg_types):\n            return False\n        for el, el_type in zip(obj, arg_types):\n            el_origin = get_origin(el_type)\n            if el_origin:\n                if not container_checker(el, el_type):\n                    return False\n            elif not isinstance(el, el_type):\n                return False\n        return True\n    elif origin_type is Union or issubclass(\n        origin_type, BuiltinUnionType\n    ):  # also handles Optional\n        if obj is None:  # check before recursion because None is always fine\n            return True\n        inner_types = get_args(target_type)\n        for t in inner_types:\n            t_origin = get_origin(t)\n            if t_origin:\n                return container_checker(obj, t)\n            elif isinstance(obj, t):\n                return True\n    return False\n\n\ndef _isinstance(obj, target_type) -> bool:\n    if isinstance(target_type, collections.abc.Container):\n        if not isinstance(target_type, tuple):\n            raise RuntimeError(\n                \"The second argument to \"\n                \"`torch.jit.isinstance` must be a type \"\n                \"or a tuple of types\"\n            )\n        for t_type in target_type:\n            if _isinstance(obj, t_type):\n                return True\n        return False\n\n    origin_type = get_origin(target_type)\n    if origin_type:\n        return container_checker(obj, target_type)\n\n    # Check to handle non-typed optional origin returns as none instead\n    #    of as optional in 3.7-3.8\n    check_args_exist(target_type)\n\n    # handle non-containers\n    return isinstance(obj, target_type)\n\n\nclass _TensorExtractor(pickle.Pickler):\n    def __init__(self, *args, tensors: List[torch.Tensor], **kwargs):\n        super().__init__(*args, **kwargs)\n        self.tensors = tensors\n\n    def persistent_id(self, obj):\n        if isinstance(obj, torch.Tensor):\n            self.tensors.append(obj)\n            return \"\"\n        # Since we just want to extract tensors, we don't mind if an object is\n        # unpicklable if it doesn't contain tensors, as we can just ignore/skip\n        # it. To play it safe, we only do so for common objects that we're sure\n        # don't contain tensors. Feel free to add new types here. Note also that\n        # even if a type isn't listed here this won't block users, since thet\n        # can just add a __getstate__ or __reduce__ method to their class.\n        if isinstance(obj, LockType):\n            return \"\"\n        # Futures and RRefs don't technically contain a value, they just offer\n        # the means to access a value.\n        if isinstance(obj, CFuture) or is_rref_instance(obj):\n            return \"\"\n        if isinstance(obj, CAwait):\n            return \"\"\n        if isinstance(obj, torch.cuda.Event):\n            return \"\"\n        if isinstance(obj, threading.Thread):\n            return \"\"\n        return None\n\n\ndef _extract_tensors(obj):\n    r\"\"\"\n    This function is exclusively called from C++.\n    See ``torch/csrc/jit/python/python_ivalue.h``.\n\n    It extracts the tensors contained in the given object, through pickling.\n    \"\"\"\n    tensors: List[torch.Tensor] = []\n    extractor = _TensorExtractor(io.BytesIO(), protocol=-1, tensors=tensors)\n    extractor.dump(obj)\n    return tensors\n\n\n# In Python-3.11+ typed enums (i.e. IntEnum for example) retain number of base class methods in subclass\n# that were previously dropped. To preserve the behavior, explicitly drop them there\n\nif sys.version_info > (3, 10):\n    _drop(enum.Enum.__new__)\n    _drop(enum.Enum.__format__)\n    _drop(enum.Enum.__repr__)\n    _drop(enum.Enum.__str__)\n",1510],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py":["from typing import Any, Optional\n\nimport torch\n\nfrom torch.utils._contextlib import (\n    _DecoratorContextManager,\n    _NoParamDecoratorContextManager,\n    F,\n)\n\n__all__ = [\n    \"no_grad\",\n    \"enable_grad\",\n    \"set_grad_enabled\",\n    \"inference_mode\",\n    \"set_multithreading_enabled\",\n]\n\n\nclass no_grad(_NoParamDecoratorContextManager):\n    r\"\"\"Context-manager that disables gradient calculation.\n\n    Disabling gradient calculation is useful for inference, when you are sure\n    that you will not call :meth:`Tensor.backward()`. It will reduce memory\n    consumption for computations that would otherwise have `requires_grad=True`.\n\n    In this mode, the result of every computation will have\n    `requires_grad=False`, even when the inputs have `requires_grad=True`.\n    There is an exception! All factory functions, or functions that create\n    a new Tensor and take a requires_grad kwarg, will NOT be affected by\n    this mode.\n\n    This context manager is thread local; it will not affect computation\n    in other threads.\n\n    Also functions as a decorator.\n\n    .. note::\n        No-grad is one of several mechanisms that can enable or\n        disable gradients locally see :ref:`locally-disable-grad-doc` for\n        more information on how they compare.\n\n    .. note::\n        This API does not apply to :ref:`forward-mode AD <forward-mode-ad>`.\n        If you want to disable forward AD for a computation, you can unpack\n        your dual tensors.\n\n    Example::\n        >>> # xdoctest: +SKIP\n        >>> x = torch.tensor([1.], requires_grad=True)\n        >>> with torch.no_grad():\n        ...     y = x * 2\n        >>> y.requires_grad\n        False\n        >>> @torch.no_grad()\n        ... def doubler(x):\n        ...     return x * 2\n        >>> z = doubler(x)\n        >>> z.requires_grad\n        False\n        >>> @torch.no_grad\n        ... def tripler(x):\n        ...     return x * 3\n        >>> z = tripler(x)\n        >>> z.requires_grad\n        False\n        >>> # factory function exception\n        >>> with torch.no_grad():\n        ...     a = torch.nn.Parameter(torch.rand(10))\n        >>> a.requires_grad\n        True\n    \"\"\"\n\n    def __init__(self) -> None:\n        if not torch._jit_internal.is_scripting():\n            super().__init__()\n        self.prev = False\n\n    def __enter__(self) -> None:\n        self.prev = torch.is_grad_enabled()\n        torch.set_grad_enabled(False)\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        torch.set_grad_enabled(self.prev)\n\n\nclass enable_grad(_NoParamDecoratorContextManager):\n    r\"\"\"Context-manager that enables gradient calculation.\n\n    Enables gradient calculation, if it has been disabled via :class:`~no_grad`\n    or :class:`~set_grad_enabled`.\n\n    This context manager is thread local; it will not affect computation\n    in other threads.\n\n    Also functions as a decorator.\n\n    .. note::\n        enable_grad is one of several mechanisms that can enable or\n        disable gradients locally see :ref:`locally-disable-grad-doc` for\n        more information on how they compare.\n\n    .. note::\n        This API does not apply to :ref:`forward-mode AD <forward-mode-ad>`.\n\n    Example::\n        >>> # xdoctest: +SKIP\n        >>> x = torch.tensor([1.], requires_grad=True)\n        >>> with torch.no_grad():\n        ...     with torch.enable_grad():\n        ...         y = x * 2\n        >>> y.requires_grad\n        True\n        >>> y.backward()\n        >>> x.grad\n        tensor([2.])\n        >>> @torch.enable_grad()\n        ... def doubler(x):\n        ...     return x * 2\n        >>> with torch.no_grad():\n        ...     z = doubler(x)\n        >>> z.requires_grad\n        True\n        >>> @torch.enable_grad\n        ... def tripler(x):\n        ...     return x * 3\n        >>> with torch.no_grad():\n        ...     z = tripler(x)\n        >>> z.requires_grad\n        True\n\n    \"\"\"\n\n    def __enter__(self) -> None:\n        self.prev = torch.is_grad_enabled()\n        torch._C._set_grad_enabled(True)\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        torch._C._set_grad_enabled(self.prev)\n\n\nclass set_grad_enabled(_DecoratorContextManager):\n    r\"\"\"Context-manager that sets gradient calculation on or off.\n\n    ``set_grad_enabled`` will enable or disable grads based on its argument :attr:`mode`.\n    It can be used as a context-manager or as a function.\n\n    This context manager is thread local; it will not affect computation\n    in other threads.\n\n    Args:\n        mode (bool): Flag whether to enable grad (``True``), or disable\n                     (``False``). This can be used to conditionally enable\n                     gradients.\n\n    .. note::\n        set_grad_enabled is one of several mechanisms that can enable or\n        disable gradients locally see :ref:`locally-disable-grad-doc` for\n        more information on how they compare.\n\n    .. note::\n        This API does not apply to :ref:`forward-mode AD <forward-mode-ad>`.\n\n    Example::\n        >>> # xdoctest: +SKIP\n        >>> x = torch.tensor([1.], requires_grad=True)\n        >>> is_train = False\n        >>> with torch.set_grad_enabled(is_train):\n        ...     y = x * 2\n        >>> y.requires_grad\n        False\n        >>> _ = torch.set_grad_enabled(True)\n        >>> y = x * 2\n        >>> y.requires_grad\n        True\n        >>> _ = torch.set_grad_enabled(False)\n        >>> y = x * 2\n        >>> y.requires_grad\n        False\n\n    \"\"\"\n\n    def __init__(self, mode: bool) -> None:\n        self.prev = torch.is_grad_enabled()\n        self.mode = mode\n        torch._C._set_grad_enabled(mode)\n\n    def __call__(self, orig_func: F) -> F:\n        torch._C._set_grad_enabled(self.prev)\n        return super().__call__(orig_func)\n\n    def __enter__(self) -> None:\n        torch._C._set_grad_enabled(self.mode)\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        torch._C._set_grad_enabled(self.prev)\n\n    def clone(self) -> \"set_grad_enabled\":\n        return self.__class__(self.mode)\n\n\nclass inference_mode(_DecoratorContextManager):\n    r\"\"\"Context-manager that enables or disables inference mode.\n\n    InferenceMode is a new context manager analogous to :class:`~no_grad`\n    to be used when you are certain your operations will have no interactions\n    with autograd (e.g., model training). Code run under this mode gets better\n    performance by disabling view tracking and version counter bumps. Note that\n    unlike some other mechanisms that locally enable or disable grad,\n    entering inference_mode also disables to :ref:`forward-mode AD <forward-mode-ad>`.\n\n    This context manager is thread local; it will not affect computation\n    in other threads.\n\n    Also functions as a decorator.\n\n    .. note::\n        Inference mode is one of several mechanisms that can enable or\n        disable gradients locally see :ref:`locally-disable-grad-doc` for\n        more information on how they compare.\n\n    Args:\n        mode (bool or function): Either a boolean flag whether to enable or\n            disable inference mode or a Python function to decorate with\n            inference mode enabled\n\n    Example::\n        >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_AUTOGRAD)\n        >>> import torch\n        >>> x = torch.ones(1, 2, 3, requires_grad=True)\n        >>> with torch.inference_mode():\n        ...     y = x * x\n        >>> y.requires_grad\n        False\n        >>> # xdoctest: +SKIP(\"want string isnt quite right\")\n        >>> y._version\n        Traceback (most recent call last):\n        File \"<stdin>\", line 1, in <module>\n        RuntimeError: Inference tensors do not track version counter.\n        >>> @torch.inference_mode()\n        ... def func(x):\n        ...     return x * x\n        >>> out = func(x)\n        >>> out.requires_grad\n        False\n        >>> @torch.inference_mode\n        ... def doubler(x):\n        ...     return x * 2\n        >>> out = doubler(x)\n        >>> out.requires_grad\n        False\n\n    \"\"\"\n\n    def __init__(self, mode: bool = True) -> None:\n        if not torch._jit_internal.is_scripting():\n            super().__init__()\n        # Holds a context manager that can enable or disable inference mode\n        self._inference_mode_raii_context: Optional[torch._C._InferenceMode] = None\n        self.mode = mode\n\n    def __new__(cls, mode=True):\n        if isinstance(mode, bool):\n            return super().__new__(cls)\n        return cls()(mode)\n\n    def __enter__(self) -> None:\n        self._inference_mode_context = torch._C._InferenceMode(self.mode)\n        self._inference_mode_context.__enter__()\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        self._inference_mode_context.__exit__(exc_type, exc_value, traceback)\n\n    def clone(self) -> \"inference_mode\":\n        return self.__class__(self.mode)\n\n\ndef _enter_inference_mode(mode):\n    mode_context = torch._C._InferenceMode(mode)\n    mode_context.__enter__()\n    return mode_context\n\n\ndef _exit_inference_mode(mode):\n    mode.__exit__(None, None, None)\n\n\nclass set_multithreading_enabled(_DecoratorContextManager):\n    r\"\"\"Context-manager that sets multithreaded backwards on or off.\n\n    ``set_multithreading_enabled`` will enable or disable multithreaded backwards based on its argument :attr:`mode`.\n    It can be used as a context-manager or as a function.\n\n    This context manager is thread local; it will not affect computation\n    in other threads.\n\n    Args:\n        mode (bool): Flag whether to enable multithreaded backwards (``True``), or disable\n                     (``False``).\n\n    .. note::\n        This API does not apply to :ref:`forward-mode AD <forward-mode-ad>`.\n\n    \"\"\"\n\n    def __init__(self, mode: bool) -> None:\n        self.prev = torch._C._is_multithreading_enabled()\n        torch._C._set_multithreading_enabled(mode)\n        self.mode = mode\n\n    def __enter__(self) -> None:\n        pass\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        torch._C._set_multithreading_enabled(self.prev)\n\n    def clone(self) -> \"set_multithreading_enabled\":\n        return self.__class__(self.mode)\n\n\nclass _force_original_view_tracking(_DecoratorContextManager):\n    r\"\"\"Context-manager that sets whether or not to always enable view-replay in autograd.\n\n    ``set_view_replay_enabled`` will enable or disable view-replay based on its argument :attr:`mode`.\n    It can be used as a context-manager or as a function.\n\n    This context manager is thread local; it will not affect computation\n    in other threads.\n\n    When a tensor view is mutated, the autograd engine needs to decide whether or not\n    to regenerate the \"updated view\" by either replaying the chain of views from the updated base,\n    or with a single call to as_strided.\n\n    If set_view_replay_enabled is set to True, then autograd will always use view replay.\n    Otherwise, it will fall back to its existing logic.\n\n    Args:\n        mode (bool): Flag whether to enable view-replay (``True``), or disable\n                     (``False``).\n\n    \"\"\"\n\n    def __init__(self, mode: bool) -> None:\n        self.prev = torch._C._is_view_replay_enabled()\n        torch._C._set_view_replay_enabled(mode)\n        self.mode = mode\n\n    def __enter__(self) -> None:\n        pass\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        torch._C._set_view_replay_enabled(self.prev)\n\n    def clone(self):\n        return self.__class__(self.mode)\n\n\nclass _unsafe_preserve_version_counter(_DecoratorContextManager):\n    r\"\"\"DO NOT USE THIS UNLESS YOU KNOW EXACTLY WHAT YOU'RE DOING.\n\n    This context manager can lead to arbitrary silent-correctness issues in any other part of your code\n    (even the ones not touched directly by the context manager)!\n\n    Ordinarily, autograd will track mutations to tensors by incrementing it's `._version` attribute.\n    This is generally important for correctness, as for example, mutating a tensor that autograd has saved\n    for the backwards pass can result in incorrect gradients, and autograd uses the version counter to detect\n    and error out in this situation.\n\n    However, there are rare instances where it might be useful to hide mutations from autograd. For example:\n    if a tensor is very large, and you'd like to free its memory by storing it elsewhere, and re-populate\n    the tensor right before it is needed by autograd.\n\n    Args:\n        tensor (torch.Tensor): the tensor in question, that you would like to preserve the version counter of.\n\n    .. note::\n        This API does not apply to :ref:`forward-mode AD <forward-mode-ad>`.\n\n    \"\"\"\n\n    def __init__(self, tensor: torch.Tensor) -> None:\n        self.tensor = tensor\n        self.prev_version = tensor._version\n\n    def __enter__(self) -> None:\n        pass\n\n    def __exit__(self, *args) -> None:\n        torch._C._autograd._unsafe_set_version_counter(self.tensor, self.prev_version)\n",389],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py":["import contextlib\nfrom typing import Optional, Union, List, Set, Dict, Any\n\nimport warnings\nfrom dataclasses import dataclass\nimport torch\nimport torchgen\nfrom torch._C import _len_torch_dispatch_stack, _get_dispatch_stack_at,\\\n    _pop_torch_dispatch_stack, _push_on_torch_dispatch_stack, DispatchKey\n\n\n# TODO: Limitations and things about enable_torch_dispatch_mode we should fix before exposing it:\n# - We need a better user-facing api for _DisableTorchDispatch that\n#   is able to selectively disable __torch_dispatch__ of a particular class.\n# - It doesn't work with the tensor constructors (torch.tensor, torch.Tensor)\n# - Better name (see https://github.com/pytorch/pytorch/pull/63496#discussion_r694091694)\n\nclass TorchDispatchMode:\n    \"\"\"\n    A ``TorchDispatchMode`` allows you to override the meaning of all\n    ``__torch_dispatch__`` overrideable functions within a dynamic scope,\n    without having to actually create a tensor subclass or manually\n    monkey-patch functions in the PyTorch API.  Some common situations\n    where you should use a mode:\n\n        * You want to override the meaning of factory functions, or other\n          functions that do not otherwise take a tensor as an argument\n          (these cannot be overridden with tensor subclasses).\n\n        * You want to override the behavior of all functions without needing\n          to wrap your inputs in tensor subclasses; e.g., if you are just\n          interested in logging intermediate computations.\n\n        * You want to control the order of execution of various tensor\n          subclasses explicitly, rather than implicitly via the return of\n          ``NotImplemented``.\n\n    Independent subclasses of :class:`TorchDispatchMode` are compositional:\n    modes can be pushed onto a stack using ``with MyMode():``.\n    When you call functions in the PyTorch API inside your\n    ``__torch_dispatch__`` implementation, by default, they will forward on to\n    the next mode on the mode stack.  If you want recursively call back into\n    your current ``__torch_dispatch__`` implementation, either explicitly\n    invoke ``self.__torch_dispatch__(...)``, or use the context manager\n    ``__torch_dispatch__(self)`` to make PyTorch\n    API self-referential (beware of infinite loops, in this case!)\n    \"\"\"\n\n    def __init__(self, _dispatch_key=None):\n        if _dispatch_key is not None:\n            assert isinstance(_dispatch_key, torch._C.DispatchKey)\n            self.__dict__['_dispatch_key'] = _dispatch_key\n\n    def __torch_dispatch__(self, func, types, args=(), kwargs=None):\n        raise NotImplementedError()\n\n    def __enter__(self):\n        _push_mode(self, self.__dict__.get(\"_dispatch_key\", None))\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        mb_dk_or_mode_key = self.__dict__.get(\"_dispatch_key\", None)\n        if mb_dk_or_mode_key is None:\n            # Today, mode keys are not used at all in the per-dispatch-key-mode logic (for pre-dispatch)\n            # We should probably revisit this.\n            mb_dk_or_mode_key = self.__dict__.get(\"_mode_key\", None)\n        _pop_mode(mb_dk_or_mode_key)\n\n    @classmethod\n    def push(cls, *args, **kwargs):\n        warnings.warn(\"`Mode.push()` is no longer necessary and can be replaced with just `with Mode()`\")\n        instance = cls(*args, **kwargs)\n        return instance\n\ndef _get_current_dispatch_mode():\n    stack_len = _len_torch_dispatch_stack()\n    # Return a user mode on the stack if there are any\n    if stack_len > 0:\n        return _get_dispatch_stack_at(stack_len - 1)\n    return None\n\n\ndef _get_current_dispatch_mode_stack():\n    stack_len = _len_torch_dispatch_stack()\n    return [_get_dispatch_stack_at(i) for i in range(stack_len)]\n\ndef _push_mode(mode, k: Optional[DispatchKey] = None):\n    if k is not None:\n        from torch._ops import push_mode_for_key, get_cached_ops\n        # See Note [Not Caching Per-Dispatch-Key Mode Handlers]\n        # Clear the cache of every op that has been used so far, for this particular key.\n        ks = torch._C._functionality_to_backend_keys(k)\n        for op in get_cached_ops():\n            for key in ks:\n                op._uncache_dispatch(key)\n        push_mode_for_key(k, mode)\n    else:\n        _push_on_torch_dispatch_stack(mode)\n\n\ndef _pop_mode(k: Optional[Union[DispatchKey, torch._C._TorchDispatchModeKey]] = None):\n    if k is None or isinstance(k, torch._C._TorchDispatchModeKey):\n        return _pop_torch_dispatch_stack(k)\n    from torch._ops import pop_mode_for_key\n    # per-dispatch-key-mode-stack do not currently handle \"always running infra modes last\".\n    # In practice this doesn't matter, since ProxyTorchDispatchMode is the only mode\n    # that we push onto these per-dispatch-key-mode-stacks.\n    return pop_mode_for_key(k)\n\n\n@contextlib.contextmanager\ndef _pop_mode_temporarily(k: Optional[DispatchKey] = None):\n    old = _pop_mode(k)\n    try:\n        yield old\n    finally:\n        _push_mode(old, k)\n\n\n@contextlib.contextmanager\ndef _disable_current_modes():\n    mode_len = _len_torch_dispatch_stack()\n    old_modes = [_pop_mode() for _ in range(mode_len)]\n\n    # Manually disable proxy and fake modes, if any are active\n    try:\n        yield old_modes\n    finally:\n        for mode in reversed(old_modes):\n            _push_mode(mode)\n\n\nclass BaseTorchDispatchMode(TorchDispatchMode):\n    def __torch_dispatch__(self, func, types, args=(), kwargs=None):\n        if kwargs is None:\n            kwargs = {}\n        return func(*args, **kwargs)\n\ndef is_traceable_wrapper_subclass(t):\n    \"\"\"\n    Returns whether or not a tensor subclass that implements __torch_dispatch__\n    is 'traceable' with torch.compile.\n    In order for a tensor subclass to support TorchDispatchMode-style tracing in PT2,\n    It must implement two magic methods: __tensor_flatten__ and __tensor_unflatten__.\n    It is also expected to obey some restrictions around traceability and aliasing\n    (TODO: add clear documentation around this.)\n    \"\"\"\n    is_subclass = isinstance(t, torch.Tensor) and type(t) != torch.Tensor\n    return is_subclass and hasattr(t, \"__tensor_flatten__\") and hasattr(t, \"__tensor_unflatten__\")\n\ndef transform_subclass(t, callback):\n    \"\"\"\n    Given a traceable, wrapper tensor subclass ``t`` that implements\n    ``__torch_dispatch__`` and holds some inner tensors,\n    and a callback of type ``Callable[[str, torch.Tensor], torch.Tensor]``,\n    `transform_subclass` will construct a fresh instance of the wrapper tensor subclass.\n    It will do so by grabbing each inner tensor attribute from the wrapper,\n    passing them into ``callback`` to get a transformed tensor,\n    and putting each transformed tensor into the fresh tensor subclass instance.\n\n    Note: this function will not handle ensuring that the fresh subclass\n    gets the same (autograd, and aliasing) metadata as the original tensor.\n    This is generally handled in other subsystems like AOTAutograd.\n    \"\"\"\n    attrs, ctx = t.__tensor_flatten__()\n    transformed_tensors_dict = {}\n    for attr in attrs:\n        transformed_tensors_dict[attr] = callback(attr, getattr(t, attr))\n    return type(t).__tensor_unflatten__(transformed_tensors_dict, ctx)\n\ndef _correct_storage_aliasing(func, schema_info, args, outs):\n    \"\"\"\n    Given: an OpOverload, a SchemaInfo (cached information from torchgen about schema),\n    and the inputs/outputs to the OpOverload,\n    this function checks to see if func is a view operator\n    (by checking if any of the outputs in the op's schema\n     are immutable aliases of inputs).\n    If so, this function manually aliases the storage of the output tensor\n    with its corresponding input tensor alias.\n    It does this by unsafely overwriting the storage field of the output tensor\n    to be the same storage as the input.\n    \"\"\"\n    assert isinstance(func, torch._ops.OpOverload)\n    assert isinstance(args, tuple)\n    assert isinstance(outs, (list, tuple))\n    flat_outs = torch.utils._pytree.tree_leaves(outs)\n\n    def alias_non_inplace_storage(arg, ret):\n        # This is hopefully a reasonable assert:\n        # subclasses that rely on this API for output aliasing\n        # should always return wrapper tensor subclasses for us to manually alias.\n        # in theory if a subclass that needs this API wants to sometimes return\n        # plain tensors, we could remove the assert and just not perform the aliasing,\n        # but it seems safer to learn more about this case first.\n        if is_traceable_wrapper_subclass(arg) or is_traceable_wrapper_subclass(ret):\n            ret_list = ret if isinstance(ret, list) else [ret]\n            for r in ret_list:\n                assert type(arg) == type(r), f\"\"\"Called {str(func)} with input of type {type(arg)}\nand output of type {type(ret)}. But expected types to match.\"\"\"\n        # Need to run under no_dispatch, because we explicitly do **not**\n        # want our subclass to intercept the set_() call.\n        # instead, our subclass should directly have its storage swapped out.\n        with torch.utils._mode_utils.no_dispatch():\n            # See Note: [Fake Tensor Dispatch Keys]\n            # we're borrowing the way it modifies dispatch key TLS.\n            meta_in_tls = torch._C._meta_in_tls_dispatch_include()\n            torch._C._set_meta_in_tls_dispatch_include(True)\n            try:\n                # directly calling this overload, and passing ret.shape, because we **explicitly**\n                # don't want to reset the sizes on ret, if the storage implies a size change.\n                # Why?\n                # The purpose of this API is *not* to change the size/strides of our output- we assume it's already correct.\n                # We just want to \"fix up\" the storage aliasing, without modifying or output's metadata.\n                # Example: out = inp.expand(inp.shape[0], inp.shape[0])\n                #     This requires swapping the storage of out to be the same as inp,\n                #     but we do *not* want it to change the sizes/strides that were compute for out.\n                if isinstance(ret, list):\n                    for r in ret:\n                        torch.ops.aten.set_.source_Storage_storage_offset(r, arg.untyped_storage(), r.storage_offset(), r.shape)\n                else:\n                    assert isinstance(ret, torch.Tensor), f\"type: {type(ret)}\"\n                    torch.ops.aten.set_.source_Storage_storage_offset(ret, arg.untyped_storage(), ret.storage_offset(), ret.shape)\n            finally:\n                torch._C._set_meta_in_tls_dispatch_include(meta_in_tls)\n\n    def is_read_only_alias_match(arg, ret):\n        shared_aliases = arg.alias_set & ret.alias_set\n        return len(shared_aliases) > 0 and not arg.is_write\n\n    num_args = len(func._schema.arguments)\n    num_returns = len(func._schema.returns)\n    for arg_idx in range(num_args):\n        for return_idx in range(num_returns):\n            if is_read_only_alias_match(schema_info.args[arg_idx], schema_info.outs[return_idx]):\n                alias_non_inplace_storage(args[arg_idx], outs[return_idx])\n\n# This abstracts over the fact that in return_and_correct_aliasing,\n# we sometimes use torchgen schema parsing (for aten ops, since torchscript's schema parsing is sometimes buggy),\n# and sometimes use torchscript schema parsing (for custom ops, for which torchgen parsing is untested).\n@dataclass\nclass AliasInfo:\n    alias_set: Set[str]\n    is_write: bool\n    name: Optional[str]\n\n@dataclass\nclass SchemaInfo:\n    args: List[AliasInfo]\n    outs: List[AliasInfo]\n\n# Can't import torch._ops.OpOverload due to circular reference\nparsed_schema_map: Dict[Any, SchemaInfo] = {}\n\n# Given an OpOverload, returns schema information on it.\n# This is cached for efficiency, since it can involve running torchgen\ndef get_alias_info(func) -> SchemaInfo:\n    if func in parsed_schema_map:\n        return parsed_schema_map[func]\n    # For ATen ops: use torchgen (since torchscript parser doesn't handle alias annotations\n    # properly for some ops that output tensorlists)\n    if func.namespace == \"aten\":\n        torchgen_schema_str = str(func._schema)\n        assert torchgen_schema_str.startswith(\"aten::\")\n        # remove the aten:: namespace, which is added by the torchscript parser,\n        # and torchgen doesn't know how to handle\n        torchgen_schema_str = torchgen_schema_str[6:]\n        import re\n        # the torchscript parser ends up converting int[2]=1 into int[2]=[1, 1],\n        # which torchgen chokes on.\n        torchgen_schema_str = re.sub(r'=\\[[0, ]+\\]', '=0', torchgen_schema_str)\n        torchgen_schema_str = re.sub(r'=\\[[1, ]+\\]', '=1', torchgen_schema_str)\n        # for aten::rot90\n        torchgen_schema_str = torchgen_schema_str.replace(\"=[0, 1]\", \"=[0,1]\")\n        torchgen_schema = torchgen.model.FunctionSchema.parse(torchgen_schema_str)\n        arg_schemas = [AliasInfo(\n            alias_set=set() if a.annotation is None else set(a.annotation.alias_set),\n            is_write=a.annotation is not None and a.annotation.is_write,\n            name=a.name,\n        ) for a in torchgen_schema.arguments.flat_all]\n        out_schemas = [AliasInfo(\n            alias_set=set() if a.annotation is None else set(a.annotation.alias_set),\n            is_write=a.annotation is not None and a.annotation.is_write,\n            name=a.name,\n        ) for a in torchgen_schema.returns]\n    else:\n        # For non-aten ops, torchgen is untested so we rely on torchscript schema parsing\n        arg_schemas = [AliasInfo(\n            alias_set=set() if a.alias_info is None else set(a.alias_info.before_set),\n            is_write=a.alias_info is not None and a.alias_info.is_write,\n            name=a.name,\n        ) for a in func._schema.arguments]\n        out_schemas = [AliasInfo(\n            alias_set=set() if a.alias_info is None else set(a.alias_info.before_set),\n            is_write=a.alias_info is not None and a.alias_info.is_write,\n            name=a.name,\n        ) for a in func._schema.returns]\n    schema_info = SchemaInfo(args=arg_schemas, outs=out_schemas)\n    parsed_schema_map[func] = schema_info\n    return schema_info\n\ndef return_and_correct_aliasing(func, args, kwargs, out):\n    \"\"\"\n    This function should be used by wrapper tensor ``__torch_dispatch__`` subclasses\n    that would like to work with torch.compile. It ensures that the subclass\n    properly implements the aliasing behavior of every op,\n    which is needed for correctness in AOTAutograd.\n    This function will handle:\n\n        * When we see a view op, we will alias the storages of any\n          input and output tensor subclasses\n\n        * When we see an inplace or out= op, we will directly\n          return the corresponding input tensor, instead of returning\n          a (potentially) fresh output tensor.\n    \"\"\"\n\n    # Caching here because torchgen parsing is definitely not fast, and this function is called\n    # once for every op in the graph during functionalization.\n    schema_info = get_alias_info(func)\n\n    def get_write_alias(x):\n        if len(x.alias_set) == 0:\n            return None\n        alias_set = list(x.alias_set)\n        # torchscript allows for complicated alias sets, but our dispatcher ops only really involve simple aliasing\n        assert len(alias_set) == 1\n        if x.is_write:\n            return alias_set[0]\n        return None\n\n    def get_arg_from_alias(output_alias, schema_info, args, kwargs):\n        new_args, new_kwargs = torch.fx.operator_schemas.normalize_function(func, args=args, kwargs=kwargs)\n\n        arg_indices = [\n            i for i, a in enumerate(schema_info.args)\n            if output_alias in a.alias_set\n        ]\n        # For any dispatcher op with an output alias, we expect it to map to exactly one alias in the schema's input arguments.\n        assert len(arg_indices) == 1\n        idx = arg_indices[0]\n        arg_info = schema_info.args[idx]\n        if arg_info.name is not None and arg_info.name in new_kwargs:\n            return new_kwargs[arg_info.name]\n        return new_args[idx]\n\n    # Fix up the storages of any outs so that they point to the same storage as the input,\n    # if func is a view op.\n    _correct_storage_aliasing(func, schema_info, args, (out,) if not isinstance(out, tuple) else out)\n\n    # For inplace_view ops in particular, we'll try hard to make sure that the wrapper subclass's\n    # metadata is set correctly.\n    if torch.Tag.inplace_view in func.tags:\n        # no_dispatch() to make sure that we secretly change the metadata on the wrapper,\n        # but don't end up dispatching the op anywhere else.\n        mutated_args = [x for i, x in enumerate(args) if get_write_alias(schema_info.args[i]) is not None]\n        # Assumption: we have a very small number of inplace_view ops that follow a strict schema:\n        # there is only a single argument that gets its metadata mutated.\n        assert len(mutated_args) == 1\n        # This check exists because we generally *do* want to update the metadata of any wrapper subclasses,\n        # but FunctionalTensor is special: it overrides all size/stride calls to plumb to the inner tensor.\n        # so we don't actually need to update the metadata (and attempting to do so causes errors)\n        from torch._subclasses.functional_tensor import FunctionalTensor\n        if not isinstance(mutated_args[0], FunctionalTensor):\n            with torch.utils._mode_utils.no_dispatch():\n                # See Note: [Fake Tensor Dispatch Keys]\n                # we're borrowing the way it modifies dispatch key TLS.\n                meta_in_tls = torch._C._meta_in_tls_dispatch_include()\n                torch._C._set_meta_in_tls_dispatch_include(True)\n                try:\n                    func(*args, **kwargs)\n                finally:\n                    torch._C._set_meta_in_tls_dispatch_include(meta_in_tls)\n\n    # Next: we need to make sure to return inputs directly, if the output is a mutable alias (e.g. add_()).\n\n    # simple case: none of our outputs have mutable aliases, so we can return the output as-is\n    if not any(get_write_alias(r) is not None for r in schema_info.outs):\n        return out\n\n    # simplifying assumption: we don't have **any** ops with return types like \"-> (Tensor(a!), Tensor)\"\n    if not all(get_write_alias(r) is not None for r in schema_info.outs):\n        raise RuntimeError(\"Unsupported schema: \" + str(func._schema))\n\n    if len(func._schema.returns) == 1:\n        return get_arg_from_alias(get_write_alias(schema_info.outs[0]), schema_info, args, kwargs)\n\n    # In the multi-return case, all aten ops return a tuple / list, so cast accordingly.\n    outs_to_return = type(out)([\n        get_arg_from_alias(get_write_alias(schema_info.outs[i]), schema_info, args, kwargs)\n        if get_write_alias(r) is not None else o\n        for ((i, r), o) in zip(enumerate(schema_info.outs), out)\n    ])\n    return outs_to_return\n",393],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\forward_ad.py":["import os\nfrom collections import namedtuple\n\nfrom typing import Any\n\nimport torch\nfrom .grad_mode import _DecoratorContextManager\n\n__all__ = [\n    \"UnpackedDualTensor\",\n    \"enter_dual_level\",\n    \"exit_dual_level\",\n    \"make_dual\",\n    \"unpack_dual\",\n    \"dual_level\",\n]\n\n# Global variable used to make the python API simpler to use\n_current_level = -1\n\n\ndef enter_dual_level():\n    r\"\"\"Enter a new forward grad level.\n\n    This level can be used to make and unpack dual Tensors to compute\n    forward gradients.\n\n    This function also updates the current level that is used by default\n    by the other functions in this API.\n    \"\"\"\n    global _current_level\n    new_level = torch._C._enter_dual_level()\n    if new_level != _current_level + 1:\n        raise RuntimeError(\n            \"Entering a new forward AD level but the current level \"\n            \"is not valid. Make sure you did not modified it directly.\"\n        )\n    _current_level = new_level\n    return new_level\n\n\ndef exit_dual_level(*, level=None):\n    r\"\"\"Exit a forward grad level.\n\n    This function deletes all the gradients associated with this\n    level. Only deleting the latest entered level is allowed.\n\n    This function also updates the current level that is used by default\n    by the other functions in this API.\n    \"\"\"\n    global _current_level\n    if level is None:\n        level = _current_level\n    if level != _current_level:\n        raise RuntimeError(\n            \"Trying to exit a forward AD level that was not the last one \"\n            \"that was created. This is not supported.\"\n        )\n    torch._C._exit_dual_level(level=level)\n    _current_level = level - 1\n\n\ndef make_dual(tensor, tangent, *, level=None):\n    r\"\"\"Associate a tensor value with its tangent to create a \"dual tensor\" for forward AD gradient computation.\n\n    The result is a new tensor aliased to :attr:`tensor` with :attr:`tangent` embedded\n    as an attribute as-is if it has the same storage layout or copied otherwise.\n    The tangent attribute can be recovered with :func:`unpack_dual`.\n\n    This function is backward differentiable.\n\n    Given a function `f` whose jacobian is `J`, it allows one to compute the Jacobian-vector product (`jvp`)\n    between `J` and a given vector `v` as follows.\n\n    Example::\n\n        >>> # xdoctest: +SKIP(\"Undefined variables\")\n        >>> with dual_level():\n        ...     inp = make_dual(x, v)\n        ...     out = f(inp)\n        ...     y, jvp = unpack_dual(out)\n\n    Please see the `forward-mode AD tutorial <https://pytorch.org/tutorials/intermediate/forward_ad_usage.html>`__\n    for detailed steps on how to use this API.\n\n    \"\"\"\n    # See NOTE: [forward-mode AD decompositions mechanism]\n    #\n    # Import from torch._decomp import decompositions_for_jvp to register\n    # decompositions for jvp to the jit registry\n    #\n    # FIXME: We specify that __debug__ must be True because\n    # if python is run with -OO or -O flags (i.e., __debug__ is False), we encounter the\n    # following error:\n    #\n    # Return value was annotated as having type Tuple[NoneType, NoneType] but is actually of\n    # type Tuple[Tensor, Tensor]:\n    #   File \".../torch/_decomp/__init__.py\", line 1585\n    #     else:\n    #         buffer = z\n    #     return min - torch.log1p(z), buffer\n    #     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    if os.environ.get(\"PYTORCH_JIT\", \"1\") == \"1\" and __debug__:\n        from torch._decomp import decompositions_for_jvp  # noqa: F401\n\n    if level is None:\n        level = _current_level\n\n    if level < 0:\n        raise RuntimeError(\n            \"Trying to create a dual Tensor for forward AD but no level \"\n            \"exists, make sure to enter_dual_level() first.\"\n        )\n    if not (tensor.is_floating_point() or tensor.is_complex()):\n        raise ValueError(\n            f\"Expected primal to be floating point or complex, but got: {tensor.dtype}\"\n        )\n    if not (tangent.is_floating_point() or tangent.is_complex()):\n        raise ValueError(\n            f\"Expected tangent to be floating point or complex, but got: {tangent.dtype}\"\n        )\n\n    return torch._VF._make_dual(tensor, tangent, level=level)\n\n\n_UnpackedDualTensor = namedtuple(\"_UnpackedDualTensor\", [\"primal\", \"tangent\"])\n\n\nclass UnpackedDualTensor(_UnpackedDualTensor):\n    r\"\"\"Namedtuple returned by :func:`unpack_dual` containing the primal and tangent components of the dual tensor.\n\n    See :func:`unpack_dual` for more details.\n\n    \"\"\"\n\n    pass\n\n\ndef unpack_dual(tensor, *, level=None):\n    r\"\"\"Unpack a \"dual tensor\" to get both its Tensor value and its forward AD gradient.\n\n    The result is a namedtuple ``(primal, tangent)`` where ``primal`` is a view of\n    :attr:`tensor`'s primal and ``tangent`` is :attr:`tensor`'s tangent as-is.\n    Neither of these tensors can be dual tensor of level :attr:`level`.\n\n    This function is backward differentiable.\n\n    Example::\n\n        >>> # xdoctest: +SKIP(\"Undefined variables\")\n        >>> with dual_level():\n        ...     inp = make_dual(x, x_t)\n        ...     out = f(inp)\n        ...     y, jvp = unpack_dual(out)\n        ...     jvp = unpack_dual(out).tangent\n\n    Please see the `forward-mode AD tutorial <https://pytorch.org/tutorials/intermediate/forward_ad_usage.html>`__\n    for detailed steps on how to use this API.\n    \"\"\"\n    if level is None:\n        level = _current_level\n\n    if level < 0:\n        return UnpackedDualTensor(tensor, None)\n\n    primal, dual = torch._VF._unpack_dual(tensor, level=level)\n\n    return UnpackedDualTensor(primal, dual)\n\n\nclass dual_level(_DecoratorContextManager):\n    r\"\"\"Context-manager for forward AD, where all forward AD computation must occur within the ``dual_level`` context.\n\n    .. Note::\n\n        The ``dual_level`` context appropriately enters and exit the dual level to\n        controls the current forward AD level, which is used by default by the other\n        functions in this API.\n\n        We currently don't plan to support nested ``dual_level`` contexts, however, so\n        only a single forward AD level is supported. To compute higher-order\n        forward grads, one can use :func:`torch.func.jvp`.\n\n    Example::\n\n        >>> # xdoctest: +SKIP(\"Undefined variables\")\n        >>> x = torch.tensor([1])\n        >>> x_t = torch.tensor([1])\n        >>> with dual_level():\n        ...     inp = make_dual(x, x_t)\n        ...     # Do computations with inp\n        ...     out = your_fn(inp)\n        ...     _, grad = unpack_dual(out)\n        >>> grad is None\n        False\n        >>> # After exiting the level, the grad is deleted\n        >>> _, grad_after = unpack_dual(out)\n        >>> grad is None\n        True\n\n    Please see the `forward-mode AD tutorial <https://pytorch.org/tutorials/intermediate/forward_ad_usage.html>`__\n    for detailed steps on how to use this API.\n    \"\"\"\n\n    def __enter__(self):\n        return enter_dual_level()\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        exit_dual_level()\n\n\n# Private helper functions\n_is_fwd_grad_enabled = torch._C._is_fwd_grad_enabled\n\n\n# Private helper function to enable or disable fwd grad.\n# If you're a user and want to use this, please file an issue to discuss the use case.\nclass _set_fwd_grad_enabled(_DecoratorContextManager):\n    def __init__(self, mode: bool) -> None:\n        self.prev = _is_fwd_grad_enabled()\n        torch._C._set_fwd_grad_enabled(mode)\n\n    def __enter__(self) -> None:\n        pass\n\n    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n        torch._C._set_fwd_grad_enabled(self.prev)\n",227],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py":["import copyreg\nimport enum\nimport functools\nimport warnings\nfrom collections import OrderedDict\nfrom copy import deepcopy\nfrom numbers import Number\nfrom typing import Any, Dict, Optional, Tuple, Union\n\nimport torch\nimport torch._C as _C\nimport torch.utils.hooks as hooks\nfrom torch._namedtensor_internals import (\n    check_serializing_named_tensor,\n    is_ellipsis,\n    resolve_ellipsis,\n    single_ellipsis_index,\n    unzip_namedshape,\n    update_names,\n)\nfrom torch.overrides import (\n    get_default_nowrap_functions,\n    handle_torch_function,\n    has_torch_function,\n    has_torch_function_unary,\n    has_torch_function_variadic,\n)\nfrom torch.utils.dlpack import DLDeviceType\n\n\ndef _handle_torch_function_and_wrap_type_error_to_not_implemented(f):\n    assigned = functools.WRAPPER_ASSIGNMENTS\n\n    @functools.wraps(f, assigned=assigned)\n    def wrapped(*args, **kwargs):\n        try:\n            # See https://github.com/pytorch/pytorch/issues/75462\n            if has_torch_function(args):\n                return handle_torch_function(wrapped, args, *args, **kwargs)\n            return f(*args, **kwargs)\n        except TypeError:\n            return NotImplemented\n\n    return wrapped\n\n\n# Should not be used, this is kept only for BC of loading old serialized Tensor subclasses\ndef _rebuild_from_type(func, type, args, dict):\n    if type is Tensor:\n        return func(*args)\n\n    ret = func(*args).as_subclass(type)\n    ret.__dict__ = dict\n    return ret\n\n\ndef _rebuild_from_type_v2(func, new_type, args, state):\n    ret = func(*args)\n    if type(ret) is not new_type:\n        ret = ret.as_subclass(new_type)\n    # Tensor does define __setstate__ even though it doesn't define\n    # __getstate__. So only use __setstate__ if it is NOT the one defined\n    # on Tensor\n    if (\n        getattr(ret.__class__, \"__setstate__\", Tensor.__setstate__)\n        is not Tensor.__setstate__\n    ):\n        ret.__setstate__(state)\n    else:\n        ret = torch._utils._set_obj_state(ret, state)\n    return ret\n\n\n# NB: If you subclass Tensor, and want to share the subclassed class\n# across processes, you must also update torch/multiprocessing/reductions.py\n# to define a ForkingPickler serialization mode for the class.\n#\n# NB: If you add a new method to Tensor, you must update\n# torch/_C/__init__.pyi.in to add a type annotation for your method;\n# otherwise, it will not show up in autocomplete.\nclass Tensor(torch._C.TensorBase):\n    def __deepcopy__(self, memo):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__deepcopy__, (self,), self, memo)\n        if not self.is_leaf:\n            raise RuntimeError(\n                \"Only Tensors created explicitly by the user \"\n                \"(graph leaves) support the deepcopy protocol at the moment.  \"\n                \"If you were attempting to deepcopy a module, this may be because \"\n                \"of a torch.nn.utils.weight_norm usage, \"\n                \"see https://github.com/pytorch/pytorch/pull/103001\"\n            )\n        if id(self) in memo:\n            return memo[id(self)]\n        with torch.no_grad():\n            # TODO: skipping storage copy is wrong for meta, as meta\n            # does accurate alias tracking; however, the code below\n            # doesn't work because of\n            # https://github.com/pytorch/pytorch/issues/47442\n            # Update the test in test_serialization if you remove 'meta' from here\n            if (\n                self.is_sparse\n                or self.device.type\n                in [\"lazy\", \"xla\", \"mtia\", \"mps\", \"ort\", \"meta\", \"ipu\"]\n                or (\n                    not torch._C._has_storage(self)\n                    and self.device.type == torch._C._get_privateuse1_backend_name()\n                )\n                or (type(self) is not Tensor and self.data_ptr() == 0)\n            ):\n                new_tensor = self.clone()\n                if type(new_tensor) is not type(self):\n                    raise RuntimeError(\n                        \"The default implementation of __deepcopy__() for wrapper subclasses \"\n                        \"only works for subclass types that implement clone() and for which \"\n                        \"cloning returns another instance of the same subclass. You should either \"\n                        \"properly implement clone() for your subclass or override __deepcopy__() \"\n                        \"if it is intended behavior for clone() to return an instance of a \"\n                        \"different type.\"\n                    )\n            else:\n                new_storage = self._typed_storage()._deepcopy(memo)\n                if self.is_quantized:\n                    # quantizer_params can be different type based on torch attribute\n                    quantizer_params: Union[\n                        Tuple[torch.qscheme, float, int],\n                        Tuple[torch.qscheme, Tensor, Tensor, int],\n                    ]\n                    if self.qscheme() == torch.per_tensor_affine:\n                        quantizer_params = (\n                            self.qscheme(),\n                            self.q_scale(),\n                            self.q_zero_point(),\n                        )\n                    elif self.qscheme() in (\n                        torch.per_channel_affine,\n                        torch.per_channel_affine_float_qparams,\n                    ):\n                        quantizer_params = (\n                            self.qscheme(),\n                            self.q_per_channel_scales(),\n                            self.q_per_channel_zero_points(),\n                            self.q_per_channel_axis(),\n                        )\n                    else:\n                        raise RuntimeError(\n                            f\"Unsupported qscheme {self.qscheme()} in deepcopy\"\n                        )\n                    # TODO: Once we decide to break serialization FC, no longer\n                    # need to wrap with TypedStorage\n                    new_tensor = torch._utils._rebuild_qtensor(\n                        torch.storage.TypedStorage(\n                            wrap_storage=new_storage._untyped_storage,\n                            dtype=self.dtype,\n                            _internal=True,\n                        ),\n                        self.storage_offset(),\n                        self.size(),\n                        self.stride(),\n                        quantizer_params,\n                        self.requires_grad,\n                        self._backward_hooks,\n                    )\n                    if type(new_tensor) is not type(self):\n                        raise RuntimeError(\n                            \"The default implementation of __deepcopy__() for quantized tensors \"\n                            \"expects the tensor returned by torch._utils._rebuild_qtensor() to \"\n                            \"match the type of the instance being copied. If you encounter this, \"\n                            \"please open an issue on PyTorch's GitHub.\"\n                        )\n                else:\n                    new_tensor = self.new_empty([])\n                    if type(new_tensor) is not type(self):\n                        raise RuntimeError(\n                            \"The default implementation of __deepcopy__() for non-wrapper subclasses \"\n                            \"only works for subclass types that implement new_empty() and for which \"\n                            \"that function returns another instance of the same subclass. You should \"\n                            \"either properly implement new_empty() for your subclass or override \"\n                            \"__deepcopy__() if it is intended behavior for new_empty() to return \"\n                            \"an instance of a different type.\"\n                        )\n                    new_tensor.set_(\n                        new_storage, self.storage_offset(), self.size(), self.stride()\n                    )\n                    if self.is_conj():\n                        new_tensor = new_tensor.conj_physical()\n                    if self.is_neg():\n                        new_tensor = new_tensor.neg()\n            if self.requires_grad:\n                new_tensor.requires_grad_()\n            if self.grad is not None:\n                new_tensor.grad = self.grad.__deepcopy__(memo)\n\n            if type(self) is not Tensor:\n                if type(new_tensor) is not type(self):\n                    raise RuntimeError(\n                        \"Type of deepcopy result does not match the type of the source tensor. \"\n                        \"If you encounter this, please open an issue on PyTorch's GitHub.\"\n                    )\n\n                # Plain Tensors don't have slots\n                slots_to_save = copyreg._slotnames(self.__class__)  # type: ignore[attr-defined]\n                for slot in slots_to_save:\n                    if hasattr(self, slot):\n                        setattr(new_tensor, slot, deepcopy(getattr(self, slot), memo))\n\n            new_tensor.__dict__ = deepcopy(self.__dict__, memo)\n\n            memo[id(self)] = new_tensor\n            return new_tensor\n\n    def __reduce_ex__(self, proto):\n        state = torch._utils._get_obj_state(self)\n        if type(self) is Tensor and not state:\n            # Fast path for regular tensor without Python state.\n            return self._reduce_ex_internal(proto)\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__reduce_ex__, (self,), self, proto)\n        func, args = self._reduce_ex_internal(proto)\n        return (_rebuild_from_type_v2, (func, type(self), args, state))\n\n    def storage(self):\n        r\"\"\"\n        storage() -> torch.TypedStorage\n\n        Returns the underlying :class:`TypedStorage`.\n\n        .. warning::\n\n            :class:`TypedStorage` is deprecated. It will be removed in the future, and\n            :class:`UntypedStorage` will be the only storage class. To access the\n            :class:`UntypedStorage` directly, use :attr:`Tensor.untyped_storage()`.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.storage, (self,), self)\n\n        torch.storage._warn_typed_storage_removal(stacklevel=2)\n        return self._typed_storage()\n\n    # For internal use only, to avoid raising deprecation warning\n    def _typed_storage(self):\n        untyped_storage = self.untyped_storage()\n        return torch.TypedStorage(\n            wrap_storage=untyped_storage, dtype=self.dtype, _internal=True\n        )\n\n    def _reduce_ex_internal(self, proto):\n        check_serializing_named_tensor(self)\n        # See Note [Don't serialize hooks]\n        torch.utils.hooks.warn_if_has_hooks(self)\n        backward_hooks: Dict[Any, Any] = OrderedDict()\n        # Note: Numpy array is chosen to be the rebuild component for XLA, MTIA, ORT Tensors.\n        # We considered a few options:\n        # 1. CPU tensor can't be used here.\n        #    Otherwise in torch.load CPU storage is reconstructed with randomly\n        #    initialized data, moved onto backend device, and then storage is updated\n        #    to the serialized content. This works perfectly for CPU/CUDA but not these backends;\n        #    their tensors are disconnected with storage so they don't get the update.\n        # 2. Python list is not a good fit due to performance reason.\n        #    `tolist()` converts every single element in the tensor into python objects\n        #    and serialize them one by one.\n        if self.device.type in [\"xla\", \"mtia\", \"ort\"] or (\n            not torch._C._has_storage(self)\n            and self.device.type == torch._C._get_privateuse1_backend_name()\n        ):\n            # Convert BFloat16 tesors to Float32 before conversion to numpy, as numpy doesn't\n            # support BFloat16. The rebuild tensor from numpy takes in the original self.dtype,\n            # this would reconstruct the BFloat16 tensor from numpy.\n            numpy_tensor = (\n                self.cpu().numpy()\n                if self.dtype != torch.bfloat16\n                else self.cpu().to(torch.float32).numpy()\n            )\n            return (\n                torch._utils._rebuild_device_tensor_from_numpy,\n                (numpy_tensor, self.dtype, str(self.device), self.requires_grad),\n            )\n        if self.device.type == \"meta\":\n            # NB: This implementation BREAKS storage sharing.  Current\n            # hypothesis is that no one cares for meta tensors.\n            arg_meta = (\n                self.dtype,\n                tuple(self.size()),\n                self.stride(),\n                self.requires_grad,\n            )\n            return (torch._utils._rebuild_meta_tensor_no_storage, arg_meta)\n        if self.is_quantized:\n            # quantizer_params can be different type based on torch attribute\n            quantizer_params: Union[\n                Tuple[torch.qscheme, float, int], Tuple[Any, Tensor, Tensor, int]\n            ]\n            if self.qscheme() == torch.per_tensor_affine:\n                quantizer_params = (\n                    torch.per_tensor_affine,\n                    self.q_scale(),\n                    self.q_zero_point(),\n                )\n            elif self.qscheme() in (\n                torch.per_channel_affine,\n                torch.per_channel_affine_float_qparams,\n            ):\n                # convert scales and zero points to tuple to avoid recursive calls\n                # when/if we get multi-axis quantized tensors in the future, the shape\n                # is recoverable from the main tensor shape\n                quantizer_params = (\n                    torch.per_channel_affine,\n                    self.q_per_channel_scales(),\n                    self.q_per_channel_zero_points(),\n                    self.q_per_channel_axis(),\n                )\n            else:\n                raise RuntimeError(\n                    f\"Serialization is not supported for tensors of type {self.qscheme()}\"\n                )\n            # TODO: Once we decide to break serialization FC, no longer\n            # need to wrap with TypedStorage\n            args_qtensor = (\n                torch.storage.TypedStorage(\n                    wrap_storage=self._typed_storage()._untyped_storage,\n                    dtype=self.dtype,\n                    _internal=True,\n                ),\n                self.storage_offset(),\n                tuple(self.size()),\n                self.stride(),\n                quantizer_params,\n                self.requires_grad,\n                backward_hooks,\n            )\n            return (torch._utils._rebuild_qtensor, args_qtensor)\n        elif self.is_sparse:\n            if self.layout == torch.sparse_coo:\n                args_sparse = (\n                    self.layout,\n                    (self._indices(), self._values(), self.size(), self.is_coalesced()),\n                )\n            else:\n                raise NotImplementedError(\n                    f\"sparse tensor __reduce_ex__ for layout `{self.layout}`\"\n                )\n            return (torch._utils._rebuild_sparse_tensor, args_sparse)\n        elif self.layout in {\n            torch.sparse_csr,\n            torch.sparse_csc,\n            torch.sparse_bsr,\n            torch.sparse_bsc,\n        }:\n            if self.layout in {torch.sparse_csr, torch.sparse_bsr}:\n                compressed_indices, plain_indices = (\n                    self.crow_indices(),\n                    self.col_indices(),\n                )\n            else:\n                compressed_indices, plain_indices = (\n                    self.ccol_indices(),\n                    self.row_indices(),\n                )\n            args_sparse_compressed = (\n                self.layout,\n                (\n                    compressed_indices,\n                    plain_indices,\n                    self.values(),\n                    self.size(),\n                ),\n            )\n            return (torch._utils._rebuild_sparse_tensor, args_sparse_compressed)\n        elif self.is_nested:\n            args_nested = (\n                # NB: values() currently returns the storage as a buffer in an unsafe way.\n                # Ideally, we'd use a private API for this instead. TODO: Switch to this if\n                # we ever get around to adding it.\n                self.values(),\n                self._nested_tensor_size(),\n                self._nested_tensor_strides(),\n                self._nested_tensor_storage_offsets(),\n            )\n            return (torch._utils._rebuild_nested_tensor, args_nested)\n        elif (\n            self.data_ptr() == 0\n            and type(self) is not torch.Tensor\n            and type(self).__torch_dispatch__ is not torch.Tensor.__torch_dispatch__\n        ):\n            arg_wrapper_subclass = (\n                type(self),\n                self.dtype,\n                tuple(self.size()),\n                self.stride(),\n                self.storage_offset(),\n                self.layout,\n                self.device,\n                self.requires_grad,\n            )\n            return (torch._utils._rebuild_wrapper_subclass, arg_wrapper_subclass)\n        else:\n            v3_dtypes = [\n                torch.float8_e5m2,\n                torch.float8_e4m3fn,\n                torch.bits8,\n                torch.bits16,\n                torch.bits1x8,\n                torch.bits2x4,\n                torch.bits4x2,\n            ]\n            if self.dtype in v3_dtypes:\n                rebuild_func = torch._utils._rebuild_tensor_v3\n                storage = self.untyped_storage()\n            else:\n                # TODO: Once we decide to break serialization FC, no longer\n                # need to wrap with TypedStorage\n                rebuild_func = torch._utils._rebuild_tensor_v2  # type: ignore[assignment]\n                storage = torch.storage.TypedStorage(\n                    wrap_storage=self._typed_storage()._untyped_storage,\n                    dtype=self.dtype,\n                    _internal=True,\n                )  # type: ignore[assignment]\n            args = (\n                storage,\n                self.storage_offset(),\n                tuple(self.size()),\n                self.stride(),\n                self.requires_grad,\n                backward_hooks,\n            )  # previously was self._backward_hooks\n\n            if isinstance(storage, torch.storage.UntypedStorage):\n                args = args + (self.dtype,)  # type: ignore[assignment]\n\n            metadata = torch._utils.get_tensor_metadata(self)\n            if metadata:\n                args = args + (metadata,)  # type: ignore[assignment]\n\n            return (rebuild_func, args)\n\n    def __setstate__(self, state):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__setstate__, (self,), self, state)\n        # Warning: this method is NOT called when you torch.load() a tensor;\n        # that is managed by _rebuild_tensor_v2\n        if not self.is_leaf:\n            raise RuntimeError(\"__setstate__ can be only called on leaf Tensors\")\n        if len(state) == 4:\n            # legacy serialization of Tensor\n            self.set_(*state)\n            return\n        elif len(state) == 5:\n            # legacy serialization of Variable\n            self.data = state[0]\n            state = (state[3], state[4], state[2])\n        # The setting of _backward_hooks is expected to be a no-op.\n        # See Note [Don't serialize hooks]\n        self.requires_grad, _, self._backward_hooks = state\n\n    def __repr__(self, *, tensor_contents=None):\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.__repr__, (self,), self, tensor_contents=tensor_contents\n            )\n        # All strings are unicode in Python 3.\n        return torch._tensor_str._str(self, tensor_contents=tensor_contents)\n\n    def backward(\n        self, gradient=None, retain_graph=None, create_graph=False, inputs=None\n    ):\n        r\"\"\"Computes the gradient of current tensor wrt graph leaves.\n\n        The graph is differentiated using the chain rule. If the tensor is\n        non-scalar (i.e. its data has more than one element) and requires\n        gradient, the function additionally requires specifying ``gradient``.\n        It should be a tensor of matching type and location, that contains\n        the gradient of the differentiated function w.r.t. ``self``.\n\n        This function accumulates gradients in the leaves - you might need to zero\n        ``.grad`` attributes or set them to ``None`` before calling it.\n        See :ref:`Default gradient layouts<default-grad-layouts>`\n        for details on the memory layout of accumulated gradients.\n\n        .. note::\n\n            If you run any forward ops, create ``gradient``, and/or call ``backward``\n            in a user-specified CUDA stream context, see\n            :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n\n        .. note::\n\n            When ``inputs`` are provided and a given input is not a leaf,\n            the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).\n            It is an implementation detail on which the user should not rely.\n            See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n\n        Args:\n            gradient (Tensor or None): Gradient w.r.t. the\n                tensor. If it is a tensor, it will be automatically converted\n                to a Tensor that does not require grad unless ``create_graph`` is True.\n                None values can be specified for scalar Tensors or ones that\n                don't require grad. If a None value would be acceptable then\n                this argument is optional.\n            retain_graph (bool, optional): If ``False``, the graph used to compute\n                the grads will be freed. Note that in nearly all cases setting\n                this option to True is not needed and often can be worked around\n                in a much more efficient way. Defaults to the value of\n                ``create_graph``.\n            create_graph (bool, optional): If ``True``, graph of the derivative will\n                be constructed, allowing to compute higher order derivative\n                products. Defaults to ``False``.\n            inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n                accumulated into ``.grad``. All other Tensors will be ignored. If not\n                provided, the gradient is accumulated into all the leaf Tensors that were\n                used to compute the attr::tensors.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.backward,\n                (self,),\n                self,\n                gradient=gradient,\n                retain_graph=retain_graph,\n                create_graph=create_graph,\n                inputs=inputs,\n            )\n        torch.autograd.backward(\n            self, gradient, retain_graph, create_graph, inputs=inputs\n        )\n\n    def register_hook(self, hook):\n        r\"\"\"Registers a backward hook.\n\n        The hook will be called every time a gradient with respect to the\n        Tensor is computed. The hook should have the following signature::\n\n            hook(grad) -> Tensor or None\n\n\n        The hook should not modify its argument, but it can optionally return\n        a new gradient which will be used in place of :attr:`grad`.\n\n        This function returns a handle with a method ``handle.remove()``\n        that removes the hook from the module.\n\n        .. note::\n            See :ref:`backward-hooks-execution` for more information on how when this hook\n            is executed, and how its execution is ordered relative to other hooks.\n\n        Example::\n\n            >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n            >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n            >>> v.backward(torch.tensor([1., 2., 3.]))\n            >>> v.grad\n\n             2\n             4\n             6\n            [torch.FloatTensor of size (3,)]\n\n            >>> h.remove()  # removes the hook\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.register_hook, (self,), self, hook)\n        if not self.requires_grad:\n            raise RuntimeError(\n                \"cannot register a hook on a tensor that doesn't require gradient\"\n            )\n        if self._backward_hooks is None:\n            self._backward_hooks = OrderedDict()\n            if self.grad_fn is not None:\n                self.grad_fn._register_hook_dict(self)\n        handle = hooks.RemovableHandle(self._backward_hooks)\n        self._backward_hooks[handle.id] = hook\n        return handle\n\n    def register_post_accumulate_grad_hook(self, hook):\n        r\"\"\"Registers a backward hook that runs after grad accumulation.\n\n        The hook will be called after all gradients for a tensor have been accumulated,\n        meaning that the .grad field has been updated on that tensor. The post\n        accumulate grad hook is ONLY applicable for leaf tensors (tensors without a\n        .grad_fn field). Registering this hook on a non-leaf tensor will error!\n\n        The hook should have the following signature::\n\n            hook(param: Tensor) -> None\n\n        Note that, unlike other autograd hooks, this hook operates on the tensor\n        that requires grad and not the grad itself. The hook can in-place modify\n        and access its Tensor argument, including its .grad field.\n\n        This function returns a handle with a method ``handle.remove()``\n        that removes the hook from the module.\n\n        .. note::\n            See :ref:`backward-hooks-execution` for more information on how when this hook\n            is executed, and how its execution is ordered relative to other hooks. Since\n            this hook runs during the backward pass, it will run in no_grad mode (unless\n            create_graph is True). You can use torch.enable_grad() to re-enable autograd\n            within the hook if you need it.\n\n        Example::\n\n            >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n            >>> lr = 0.01\n            >>> # simulate a simple SGD update\n            >>> h = v.register_post_accumulate_grad_hook(lambda p: p.add_(p.grad, alpha=-lr))\n            >>> v.backward(torch.tensor([1., 2., 3.]))\n            >>> v\n            tensor([-0.0100, -0.0200, -0.0300], requires_grad=True)\n\n            >>> h.remove()  # removes the hook\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.register_post_accumulate_grad_hook, (self,), self, hook\n            )\n        if not self.requires_grad:\n            raise RuntimeError(\n                \"cannot register a hook on a tensor that doesn't require gradient\"\n            )\n        if self.grad_fn is not None:\n            raise RuntimeError(\n                \"post accumulate grad hooks cannot be registered on non-leaf tensors\"\n            )\n        if self._post_accumulate_grad_hooks is None:\n            self._post_accumulate_grad_hooks: Dict[Any, Any] = OrderedDict()\n        handle = hooks.RemovableHandle(self._post_accumulate_grad_hooks)\n        self._post_accumulate_grad_hooks[handle.id] = hook\n        return handle\n\n    def reinforce(self, reward):\n        def trim(str):\n            return \"\\n\".join([line.strip() for line in str.split(\"\\n\")])\n\n        raise RuntimeError(\n            trim(\n                r\"\"\"reinforce() was removed.\n            Use torch.distributions instead.\n            See https://pytorch.org/docs/master/distributions.html\n\n            Instead of:\n\n            probs = policy_network(state)\n            action = probs.multinomial()\n            next_state, reward = env.step(action)\n            action.reinforce(reward)\n            action.backward()\n\n            Use:\n\n            probs = policy_network(state)\n            # NOTE: categorical is equivalent to what used to be called multinomial\n            m = torch.distributions.Categorical(probs)\n            action = m.sample()\n            next_state, reward = env.step(action)\n            loss = -m.log_prob(action) * reward\n            loss.backward()\n        \"\"\"\n            )\n        )\n\n    detach = _C._add_docstr(\n        _C.TensorBase.detach,\n        r\"\"\"\n    Returns a new Tensor, detached from the current graph.\n\n    The result will never require gradient.\n\n    This method also affects forward mode AD gradients and the result will never\n    have forward mode AD gradients.\n\n    .. note::\n\n      Returned Tensor shares the same storage with the original one.\n      In-place modifications on either of them will be seen, and may trigger\n      errors in correctness checks.\n      IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n      (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n      also update the original tensor. Now, these in-place changes will not update the\n      original tensor anymore, and will instead trigger an error.\n      For sparse tensors:\n      In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n      returned tensor will not update the original tensor anymore, and will instead\n      trigger an error.\n    \"\"\",\n    )\n\n    detach_ = _C._add_docstr(\n        _C.TensorBase.detach_,\n        r\"\"\"\n    Detaches the Tensor from the graph that created it, making it a leaf.\n    Views cannot be detached in-place.\n\n    This method also affects forward mode AD gradients and the result will never\n    have forward mode AD gradients.\n    \"\"\",\n    )\n\n    def is_shared(self):\n        r\"\"\"Checks if tensor is in shared memory.\n\n        This is always ``True`` for CUDA tensors.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.is_shared, (self,), self)\n        return self._typed_storage()._is_shared()\n\n    def share_memory_(self):\n        r\"\"\"Moves the underlying storage to shared memory.\n\n        This is a no-op if the underlying storage is already in shared memory\n        and for CUDA tensors. Tensors in shared memory cannot be resized.\n\n        See :meth:`torch.UntypedStorage.share_memory_` for more details.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.share_memory_, (self,), self)\n        self._typed_storage()._share_memory_()\n        return self\n\n    def __reversed__(self):\n        r\"\"\"Reverses the tensor along dimension 0.\"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__reversed__, (self,), self)\n        if self.dim() == 0:\n            return self\n        else:\n            return self.flip(0)\n\n    def norm(\n        self,\n        p: Optional[Union[float, str]] = \"fro\",\n        dim=None,\n        keepdim=False,\n        dtype=None,\n    ):\n        r\"\"\"See :func:`torch.norm`\"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.norm, (self,), self, p=p, dim=dim, keepdim=keepdim, dtype=dtype\n            )\n        return torch.norm(self, p, dim, keepdim, dtype=dtype)\n\n    def solve(self, other):\n        from ._linalg_utils import solve\n\n        return solve(self, other)\n\n    def lstsq(self, other):\n        from ._linalg_utils import lstsq\n\n        return lstsq(self, other)\n\n    def eig(self, eigenvectors=False):\n        from ._linalg_utils import eig\n\n        return eig(self, eigenvectors=eigenvectors)\n\n    def symeig(self, eigenvectors=False):\n        from ._linalg_utils import _symeig\n\n        return _symeig(self, eigenvectors=eigenvectors)\n\n    def lu(self, pivot=True, get_infos=False):\n        r\"\"\"See :func:`torch.lu`\"\"\"\n        # If get_infos is True, then we don't need to check for errors and vice versa\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.lu, (self,), self, pivot=pivot, get_infos=get_infos\n            )\n\n        LU, pivots, infos = torch._lu_with_info(\n            self, pivot=pivot, check_errors=(not get_infos)\n        )\n        if get_infos:\n            return LU, pivots, infos\n        else:\n            return LU, pivots\n\n    def stft(\n        self,\n        n_fft: int,\n        hop_length: Optional[int] = None,\n        win_length: Optional[int] = None,\n        window: \"Optional[Tensor]\" = None,\n        center: bool = True,\n        pad_mode: str = \"reflect\",\n        normalized: bool = False,\n        onesided: Optional[bool] = None,\n        return_complex: Optional[bool] = None,\n    ):\n        r\"\"\"See :func:`torch.stft`\n\n        .. warning::\n          This function changed signature at version 0.4.1. Calling with\n          the previous signature may cause error or return incorrect result.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.stft,\n                (self,),\n                self,\n                n_fft,\n                hop_length=hop_length,\n                win_length=win_length,\n                window=window,\n                center=center,\n                pad_mode=pad_mode,\n                normalized=normalized,\n                onesided=onesided,\n                return_complex=return_complex,\n            )\n        return torch.stft(\n            self,\n            n_fft,\n            hop_length,\n            win_length,\n            window,\n            center,\n            pad_mode,\n            normalized,\n            onesided,\n            return_complex=return_complex,\n        )\n\n    def istft(\n        self,\n        n_fft: int,\n        hop_length: Optional[int] = None,\n        win_length: Optional[int] = None,\n        window: \"Optional[Tensor]\" = None,\n        center: bool = True,\n        normalized: bool = False,\n        onesided: Optional[bool] = None,\n        length: Optional[int] = None,\n        return_complex: bool = False,\n    ):\n        r\"\"\"See :func:`torch.istft`\"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.istft,\n                (self,),\n                self,\n                n_fft,\n                hop_length=hop_length,\n                win_length=win_length,\n                window=window,\n                center=center,\n                normalized=normalized,\n                onesided=onesided,\n                length=length,\n                return_complex=return_complex,\n            )\n        return torch.istft(\n            self,\n            n_fft,\n            hop_length,\n            win_length,\n            window,\n            center,\n            normalized,\n            onesided,\n            length,\n            return_complex=return_complex,\n        )\n\n    def resize(self, *sizes):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.resize, (self,), self, *sizes)\n        warnings.warn(\"non-inplace resize is deprecated\")\n        from torch.autograd._functions import Resize\n\n        return Resize.apply(self, sizes)\n\n    def resize_as(self, tensor):\n        if has_torch_function_variadic(self, tensor):\n            return handle_torch_function(Tensor.resize_as, (self, tensor), self, tensor)\n        warnings.warn(\"non-inplace resize_as is deprecated\")\n        from torch.autograd._functions import Resize\n\n        return Resize.apply(self, tensor.size())\n\n    def split(self, split_size, dim=0):\n        r\"\"\"See :func:`torch.split`\"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.split, (self,), self, split_size, dim=dim\n            )\n        if isinstance(split_size, Tensor):\n            try:\n                split_size = int(split_size)\n            except ValueError:\n                pass\n\n        if isinstance(split_size, (int, torch.SymInt)):\n            return torch._VF.split(self, split_size, dim)  # type: ignore[attr-defined]\n        else:\n            return torch._VF.split_with_sizes(self, split_size, dim)\n\n    def unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None):\n        r\"\"\"Returns the unique elements of the input tensor.\n\n        See :func:`torch.unique`\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.unique,\n                (self,),\n                self,\n                sorted=sorted,\n                return_inverse=return_inverse,\n                return_counts=return_counts,\n                dim=dim,\n            )\n        return torch.unique(\n            self,\n            sorted=sorted,\n            return_inverse=return_inverse,\n            return_counts=return_counts,\n            dim=dim,\n        )\n\n    def unique_consecutive(self, return_inverse=False, return_counts=False, dim=None):\n        r\"\"\"Eliminates all but the first element from every consecutive group of equivalent elements.\n\n        See :func:`torch.unique_consecutive`\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.unique_consecutive,\n                (self,),\n                self,\n                return_inverse=return_inverse,\n                return_counts=return_counts,\n                dim=dim,\n            )\n        return torch.unique_consecutive(\n            self, return_inverse=return_inverse, return_counts=return_counts, dim=dim\n        )\n\n    @_handle_torch_function_and_wrap_type_error_to_not_implemented\n    def __rsub__(self, other):\n        return _C._VariableFunctions.rsub(self, other)\n\n    @_handle_torch_function_and_wrap_type_error_to_not_implemented\n    def __rdiv__(self, other):\n        return self.reciprocal() * other\n\n    __rtruediv__ = __rdiv__\n    __itruediv__ = _C.TensorBase.__idiv__\n\n    __pow__ = _handle_torch_function_and_wrap_type_error_to_not_implemented(\n        _C.TensorBase.pow\n    )\n    __ipow__ = _handle_torch_function_and_wrap_type_error_to_not_implemented(\n        _C.TensorBase.pow_\n    )\n\n    @_handle_torch_function_and_wrap_type_error_to_not_implemented\n    def __rmod__(self, other):\n        return torch.remainder(other, self)\n\n    def __format__(self, format_spec):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__format__, (self,), self, format_spec)\n        if self.dim() == 0 and not self.is_meta and type(self) is Tensor:\n            return self.item().__format__(format_spec)\n        return object.__format__(self, format_spec)\n\n    @_handle_torch_function_and_wrap_type_error_to_not_implemented\n    def __rpow__(self, other):\n        return torch.pow(other, self)\n\n    @_handle_torch_function_and_wrap_type_error_to_not_implemented\n    def __floordiv__(self, other):\n        return torch.floor_divide(self, other)\n\n    @_handle_torch_function_and_wrap_type_error_to_not_implemented\n    def __rfloordiv__(self, other):\n        return torch.floor_divide(other, self)\n\n    @_handle_torch_function_and_wrap_type_error_to_not_implemented\n    def __rlshift__(self, other):\n        return torch.bitwise_left_shift(other, self)\n\n    @_handle_torch_function_and_wrap_type_error_to_not_implemented\n    def __rrshift__(self, other):\n        return torch.bitwise_right_shift(other, self)\n\n    @_handle_torch_function_and_wrap_type_error_to_not_implemented\n    def __rmatmul__(self, other):\n        return torch.matmul(other, self)\n\n    __pos__ = _C.TensorBase.positive\n    __neg__ = _C.TensorBase.neg\n    __abs__ = _C.TensorBase.abs\n\n    def __len__(self):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__len__, (self,), self)\n        if self.dim() == 0:\n            raise TypeError(\"len() of a 0-d tensor\")\n        if torch._C._get_tracing_state():\n            warnings.warn(\n                \"Using len to get tensor shape might cause the trace to be incorrect. \"\n                \"Recommended usage would be tensor.shape[0]. \"\n                \"Passing a tensor of different shape might lead to errors or silently give \"\n                \"incorrect results.\",\n                category=torch.jit.TracerWarning,\n                stacklevel=2,\n            )\n        return self.shape[0]\n\n    def __iter__(self):\n        # NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\n        # generator and don't eagerly perform all the indexes.  This could\n        # save us work, and also helps keep trace ordering deterministic\n        # (e.g., if you zip(*hiddens), the eager map will force all the\n        # indexes of hiddens[0] before hiddens[1], while the generator\n        # map will interleave them.)\n        # NB: We have intentionally skipped __torch_function__ dispatch here.\n        # See gh-54457\n        if self.dim() == 0:\n            raise TypeError(\"iteration over a 0-d tensor\")\n        if torch._C._get_tracing_state():\n            warnings.warn(\n                \"Iterating over a tensor might cause the trace to be incorrect. \"\n                \"Passing a tensor of different shape won't change the number of \"\n                \"iterations executed (and might lead to errors or silently give \"\n                \"incorrect results).\",\n                category=torch.jit.TracerWarning,\n                stacklevel=2,\n            )\n        return iter(self.unbind(0))\n\n    def __hash__(self):\n        # Do NOT handle __torch_function__ here as user's default\n        # implementation that handle most functions will most likely do it wrong.\n        # It can be easily overridden by defining this method on the user\n        # subclass if needed.\n        return id(self)\n\n    def __dir__(self):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__dir__, (self,), self)\n        tensor_methods = dir(self.__class__)\n        tensor_methods.remove(\"volatile\")  # deprecated\n        attrs = list(self.__dict__.keys())\n        keys = tensor_methods + attrs\n\n        # property only available dense, cuda tensors\n        if (not self.is_cuda) or self.is_sparse:\n            keys.remove(\"__cuda_array_interface__\")\n\n        return sorted(keys)\n\n    # Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\n    __array_priority__ = 1000  # prefer Tensor ops over numpy ones\n\n    def __array__(self, dtype=None):\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__array__, (self,), self, dtype=dtype)\n        if dtype is None:\n            return self.numpy()\n        else:\n            return self.numpy().astype(dtype, copy=False)\n\n    # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n    # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n    def __array_wrap__(self, array):\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.__array_wrap__, (self,), self, array=array\n            )\n        if array.dtype == bool:\n            # Workaround, torch has no built-in bool tensor\n            array = array.astype(\"uint8\")\n        return torch.from_numpy(array)\n\n    def __contains__(self, element):\n        r\"\"\"Check if `element` is present in tensor\n\n        Args:\n            element (Tensor or scalar): element to be checked\n                for presence in current tensor\"\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__contains__, (self,), self, element)\n        if isinstance(\n            element, (torch.Tensor, Number, torch.SymInt, torch.SymFloat, torch.SymBool)\n        ):\n            # type hint doesn't understand the __contains__ result array\n            return (element == self).any().item()  # type: ignore[union-attr]\n\n        raise RuntimeError(\n            f\"Tensor.__contains__ only supports Tensor or scalar, but you passed in a {type(element)}.\"\n        )\n\n    @property\n    def __cuda_array_interface__(self):\n        \"\"\"Array view description for cuda tensors.\n\n        See:\n        https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n        \"\"\"\n        if has_torch_function_unary(self):\n            # TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\n            return handle_torch_function(Tensor.__cuda_array_interface__.__get__, (self,), self)  # type: ignore[attr-defined]\n\n        # raise AttributeError for unsupported tensors, so that\n        # hasattr(cpu_tensor, \"__cuda_array_interface__\") is False.\n        if not self.is_cuda:\n            raise AttributeError(\n                \"Can't get __cuda_array_interface__ on non-CUDA tensor type: %s \"\n                \"If CUDA data is required use tensor.cuda() to copy tensor to device memory.\"\n                % self.type()\n            )\n\n        if self.is_sparse:\n            raise AttributeError(\n                \"Can't get __cuda_array_interface__ on sparse type: %s \"\n                \"Use Tensor.to_dense() to convert to a dense tensor first.\"\n                % self.type()\n            )\n\n        # RuntimeError, matching tensor.__array__() behavior.\n        if self.requires_grad:\n            raise RuntimeError(\n                \"Can't get __cuda_array_interface__ on Variable that requires grad. \"\n                \"If gradients aren't required, use var.detach() to get Variable that doesn't require grad.\"\n            )\n\n        # CUDA devices are little-endian and tensors are stored in native byte\n        # order. 1-byte entries are endian-agnostic.\n        typestr = {\n            torch.complex64: \"<c8\",\n            torch.complex128: \"<c16\",\n            torch.float16: \"<f2\",\n            torch.float32: \"<f4\",\n            torch.float64: \"<f8\",\n            torch.uint8: \"|u1\",\n            torch.int8: \"|i1\",\n            torch.int16: \"<i2\",\n            torch.int32: \"<i4\",\n            torch.int64: \"<i8\",\n        }[self.dtype]\n\n        itemsize = self.element_size()\n\n        shape = tuple(self.shape)\n        if self.is_contiguous():\n            # __cuda_array_interface__ v2 requires the strides to be omitted\n            # (either not set or set to None) for C-contiguous arrays.\n            strides = None\n        else:\n            strides = tuple(s * itemsize for s in self.stride())\n        data_ptr = self.data_ptr() if self.numel() > 0 else 0\n        data = (data_ptr, False)  # read-only is false\n\n        return dict(typestr=typestr, shape=shape, strides=strides, data=data, version=2)\n\n    def storage_type(self):\n        r\"\"\"storage_type() -> type\n\n        Returns the type of the underlying storage.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.storage_type, (self,), self)\n\n        torch.storage._warn_typed_storage_removal()\n\n        return self._typed_storage()._get_legacy_storage_class()\n\n    def refine_names(self, *names):\n        r\"\"\"Refines the dimension names of :attr:`self` according to :attr:`names`.\n\n        Refining is a special case of renaming that \"lifts\" unnamed dimensions.\n        A ``None`` dim can be refined to have any name; a named dim can only be\n        refined to have the same name.\n\n        Because named tensors can coexist with unnamed tensors, refining names\n        gives a nice way to write named-tensor-aware code that works with both\n        named and unnamed tensors.\n\n        :attr:`names` may contain up to one Ellipsis (``...``).\n        The Ellipsis is expanded greedily; it is expanded in-place to fill\n        :attr:`names` to the same length as ``self.dim()`` using names from the\n        corresponding indices of ``self.names``.\n\n        Python 2 does not support Ellipsis but one may use a string literal\n        instead (``'...'``).\n\n        Args:\n            names (iterable of str): The desired names of the output tensor. May\n                contain up to one Ellipsis.\n\n        Examples::\n\n            >>> imgs = torch.randn(32, 3, 128, 128)\n            >>> named_imgs = imgs.refine_names('N', 'C', 'H', 'W')\n            >>> named_imgs.names\n            ('N', 'C', 'H', 'W')\n\n            >>> tensor = torch.randn(2, 3, 5, 7, 11)\n            >>> tensor = tensor.refine_names('A', ..., 'B', 'C')\n            >>> tensor.names\n            ('A', None, None, 'B', 'C')\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.refine_names, (self,), self, *names)\n        names = resolve_ellipsis(names, self.names, \"refine_names\")\n        return super().refine_names(names)\n\n    def align_to(self, *names):\n        r\"\"\"Permutes the dimensions of the :attr:`self` tensor to match the order\n        specified in :attr:`names`, adding size-one dims for any new names.\n\n        All of the dims of :attr:`self` must be named in order to use this method.\n        The resulting tensor is a view on the original tensor.\n\n        All dimension names of :attr:`self` must be present in :attr:`names`.\n        :attr:`names` may contain additional names that are not in ``self.names``;\n        the output tensor has a size-one dimension for each of those new names.\n\n        :attr:`names` may contain up to one Ellipsis (``...``).\n        The Ellipsis is expanded to be equal to all dimension names of :attr:`self`\n        that are not mentioned in :attr:`names`, in the order that they appear\n        in :attr:`self`.\n\n        Python 2 does not support Ellipsis but one may use a string literal\n        instead (``'...'``).\n\n        Args:\n            names (iterable of str): The desired dimension ordering of the\n                output tensor. May contain up to one Ellipsis that is expanded\n                to all unmentioned dim names of :attr:`self`.\n\n        Examples::\n\n            >>> tensor = torch.randn(2, 2, 2, 2, 2, 2)\n            >>> named_tensor = tensor.refine_names('A', 'B', 'C', 'D', 'E', 'F')\n\n            # Move the F and E dims to the front while keeping the rest in order\n            >>> named_tensor.align_to('F', 'E', ...)\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.align_to, (self,), self, *names)\n        ellipsis_idx = single_ellipsis_index(names, \"align_to\")\n        if ellipsis_idx is None:\n            return super().align_to(names)\n        return super().align_to(\n            [name for name in names if not is_ellipsis(name)], ellipsis_idx\n        )\n\n    def unflatten(self, dim, sizes):\n        r\"\"\"\n        unflatten(dim, sizes) -> Tensor\n\n        See :func:`torch.unflatten`.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.unflatten, (self,), self, dim, sizes)\n\n        if not sizes:\n            raise RuntimeError(\"unflatten: sizes must be non-empty\")\n\n        names = None\n        if isinstance(sizes, OrderedDict) or (\n            isinstance(sizes, (tuple, list)) and isinstance(sizes[0], (tuple, list))\n        ):\n            names, sizes = unzip_namedshape(sizes)\n            return super().unflatten(dim, sizes, names)\n        else:\n            return super().unflatten(dim, sizes)\n\n    def rename_(self, *names, **rename_map):\n        \"\"\"In-place version of :meth:`~Tensor.rename`.\"\"\"\n\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.rename_, (self,), self, *names, **rename_map\n            )\n\n        # Note [rename_ / rename API]\n        # The Python API for these is different from the C++ API. In Python:\n        # 1) tensor.rename(*names) takes a vararglist of names\n        # 2) tensor.rename(**rename_map) takes a map of names to rename.\n        # C++ is static, making it difficult to implement similar behavior.\n        return update_names(self, names, rename_map, inplace=True)\n\n    def rename(self, *names, **rename_map):\n        \"\"\"Renames dimension names of :attr:`self`.\n\n        There are two main usages:\n\n        ``self.rename(**rename_map)`` returns a view on tensor that has dims\n        renamed as specified in the mapping :attr:`rename_map`.\n\n        ``self.rename(*names)`` returns a view on tensor, renaming all\n        dimensions positionally using :attr:`names`.\n        Use ``self.rename(None)`` to drop names on a tensor.\n\n        One cannot specify both positional args :attr:`names` and keyword args\n        :attr:`rename_map`.\n\n        Examples::\n\n            >>> imgs = torch.rand(2, 3, 5, 7, names=('N', 'C', 'H', 'W'))\n            >>> renamed_imgs = imgs.rename(N='batch', C='channels')\n            >>> renamed_imgs.names\n            ('batch', 'channels', 'H', 'W')\n\n            >>> renamed_imgs = imgs.rename(None)\n            >>> renamed_imgs.names\n            (None, None, None, None)\n\n            >>> renamed_imgs = imgs.rename('batch', 'channel', 'height', 'width')\n            >>> renamed_imgs.names\n            ('batch', 'channel', 'height', 'width')\n\n        .. warning::\n            The named tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor.rename, (self,), self, *names, **rename_map\n            )\n\n        # See Note [rename_ / rename API]\n        return update_names(self, names, rename_map, inplace=False)\n\n    def to_sparse_coo(self):\n        \"\"\"Convert a tensor to :ref:`coordinate format <sparse-coo-docs>`.\n\n        Examples::\n\n             >>> dense = torch.randn(5, 5)\n             >>> sparse = dense.to_sparse_coo()\n             >>> sparse._nnz()\n             25\n\n        \"\"\"\n        return self.to_sparse()\n\n    def dim_order(self):\n        \"\"\"\n\n        dim_order() -> tuple\n\n        Returns a tuple of int describing the dim order or physical layout of :attr:`self`.\n\n        Args:\n            None\n\n        Dim order represents how dimensions are laid out in memory,\n        starting from the outermost to the innermost dimension.\n\n        Example::\n            >>> torch.empty((2, 3, 5, 7)).dim_order()\n            (0, 1, 2, 3)\n            >>> torch.empty((2, 3, 5, 7), memory_format=torch.channels_last).dim_order()\n            (0, 2, 3, 1)\n\n        .. warning::\n            The dim_order tensor API is experimental and subject to change.\n\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.dim_order, (self,), self)\n\n        import torch._prims_common as utils\n\n        return tuple(utils.compute_elementwise_output_logical_to_physical_perm(self))\n\n    def _update_names(self, names, inplace):\n        if has_torch_function_unary(self):\n            return handle_torch_function(\n                Tensor._update_names, (self,), self, names, inplace\n            )\n\n        # See Note [rename_ / rename API]\n        if inplace:\n            return super().rename_(names)\n        else:\n            return super().rename(names)\n\n    @classmethod\n    def __torch_function__(cls, func, types, args=(), kwargs=None):\n        \"\"\"\n        This __torch_function__ implementation wraps subclasses such that\n        methods called on subclasses return a subclass instance instead of\n        a ``torch.Tensor`` instance.\n\n        One corollary to this is that you need coverage for torch.Tensor\n        methods if implementing __torch_function__ for subclasses.\n\n        We recommend always calling ``super().__torch_function__`` as the base\n        case when doing the above.\n\n        While not mandatory, we recommend making `__torch_function__` a classmethod.\n        \"\"\"\n        if kwargs is None:\n            kwargs = {}\n\n        if not all(issubclass(cls, t) for t in types):\n            return NotImplemented\n\n        with _C.DisableTorchFunctionSubclass():\n            ret = func(*args, **kwargs)\n            if func in get_default_nowrap_functions():\n                return ret\n            else:\n                return _convert(ret, cls)\n\n    __torch_dispatch__ = _C._disabled_torch_dispatch_impl\n\n    def __dlpack__(self, stream=None):\n        \"\"\"\n        Creates a DLpack `capsule https://data-apis.org/array-api/latest/design_topics/data_interchange.html#data-interchange`_\n        of the current tensor to be exported to other libraries.\n\n        This function will be called from the `from_dlpack` method\n        of the library that will consume the capsule. `from_dlpack` passes the current\n        stream to this method as part of the specification.\n\n        Args:\n            stream (integer or None): An optional Python integer representing a\n            pointer to a CUDA stream. The current stream is synchronized with\n            this stream before the capsule is created, and since the capsule\n            shares its storage with the tensor this make it safe to access from\n            both streams.  If None or -1 is passed then no synchronization is performed.\n            If 1 (on CUDA) or 0 (on ROCM) then the default stream is used for\n            synchronization.\n        \"\"\"\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__dlpack__, (self,), self, stream)\n\n        # DLPack capsules can't capture all of PyTorch's semantics,\n        # so we prohibit exporting tensors that would lose their properties like\n        # requires_grad and having the conjugate bit set.\n        if self.requires_grad:\n            raise RuntimeError(\n                \"Can't export tensors that require gradient, use tensor.detach()\"\n            )\n        if self.is_conj():\n            raise RuntimeError(\"Can't export tensors with the conjugate bit set\")\n        if self.layout != torch.strided:\n            raise RuntimeError(\n                \"Can't export tensors with layout other than torch.strided\"\n            )\n\n        if stream is not None and type(stream) is not int:\n            # Stream pointers in CUDA/ROCm are uniquely numbered and can\n            # be retrieved from their integer value.\n            raise TypeError(\"stream must be ``int`` or ``none``\")\n        elif stream is not None and stream != -1:\n            if self.device.type == \"cuda\":\n                # NB: This logic handles the special case values for default\n                # streams and must be kept in sync with from_dlpack in\n                # torch/utils/dlpack.py\n                if stream == 1 and torch.version.hip is None:\n                    stream = torch.cuda.default_stream()\n                elif stream == 0 and torch.version.hip is not None:\n                    stream = torch.cuda.default_stream()\n                else:\n                    stream = torch.cuda.ExternalStream(stream)\n                # Only synchronize on different streams\n                sync_stream = torch.cuda.current_stream()\n                if stream != sync_stream:\n                    event = torch.cuda.Event()\n                    event.record(sync_stream)\n                    stream.wait_event(event)\n        return torch.to_dlpack(self)\n\n    def __dlpack_device__(self) -> Tuple[enum.IntEnum, int]:\n        if has_torch_function_unary(self):\n            return handle_torch_function(Tensor.__dlpack_device__, (self,), self)\n        device = self.device\n        idx = device.index if device.index is not None else 0\n        torch_device_type = device.type\n        if torch_device_type == \"cuda\" and torch.version.hip is not None:\n            device_type = DLDeviceType.kDLROCM\n        elif torch_device_type == \"cpu\" and self.is_pinned():\n            device_type = DLDeviceType.kDLCPUPinned\n        elif torch_device_type == \"cuda\":\n            device_type = DLDeviceType.kDLGPU\n        elif torch_device_type == \"cpu\":\n            device_type = DLDeviceType.kDLCPU\n        elif self.device.type == \"xpu\":\n            device_type = DLDeviceType.kDLOneAPI\n        else:\n            raise ValueError(f\"Unknown device type {torch_device_type} for Dlpack\")\n        return (device_type, idx)\n\n    __module__ = \"torch\"\n\n\ndef _convert(ret, cls):\n    if cls is Tensor:\n        return ret\n\n    if isinstance(ret, Tensor) and not isinstance(ret, cls):\n        ret = ret.as_subclass(cls)\n\n    if isinstance(ret, (tuple, list)):\n        # Also handles things like namedtuples\n        ret = type(ret)(_convert(r, cls) for r in ret)\n\n    return ret\n",1518],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py":["import contextlib\nimport dataclasses\nimport math\nimport textwrap\nfrom typing import Any, Dict, Optional\n\nimport torch\nfrom torch import inf\n\n\n@dataclasses.dataclass\nclass __PrinterOptions:\n    precision: int = 4\n    threshold: float = 1000\n    edgeitems: int = 3\n    linewidth: int = 80\n    sci_mode: Optional[bool] = None\n\n\nPRINT_OPTS = __PrinterOptions()\n\n\n# We could use **kwargs, but this will give better docs\ndef set_printoptions(\n    precision=None,\n    threshold=None,\n    edgeitems=None,\n    linewidth=None,\n    profile=None,\n    sci_mode=None,\n):\n    r\"\"\"Set options for printing. Items shamelessly taken from NumPy\n\n    Args:\n        precision: Number of digits of precision for floating point output\n            (default = 4).\n        threshold: Total number of array elements which trigger summarization\n            rather than full `repr` (default = 1000).\n        edgeitems: Number of array items in summary at beginning and end of\n            each dimension (default = 3).\n        linewidth: The number of characters per line for the purpose of\n            inserting line breaks (default = 80). Thresholded matrices will\n            ignore this parameter.\n        profile: Sane defaults for pretty printing. Can override with any of\n            the above options. (any one of `default`, `short`, `full`)\n        sci_mode: Enable (True) or disable (False) scientific notation. If\n            None (default) is specified, the value is defined by\n            `torch._tensor_str._Formatter`. This value is automatically chosen\n            by the framework.\n\n    Example::\n\n        >>> # Limit the precision of elements\n        >>> torch.set_printoptions(precision=2)\n        >>> torch.tensor([1.12345])\n        tensor([1.12])\n        >>> # Limit the number of elements shown\n        >>> torch.set_printoptions(threshold=5)\n        >>> torch.arange(10)\n        tensor([0, 1, 2, ..., 7, 8, 9])\n        >>> # Restore defaults\n        >>> torch.set_printoptions(profile='default')\n        >>> torch.tensor([1.12345])\n        tensor([1.1235])\n        >>> torch.arange(10)\n        tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n    \"\"\"\n    if profile is not None:\n        if profile == \"default\":\n            PRINT_OPTS.precision = 4\n            PRINT_OPTS.threshold = 1000\n            PRINT_OPTS.edgeitems = 3\n            PRINT_OPTS.linewidth = 80\n        elif profile == \"short\":\n            PRINT_OPTS.precision = 2\n            PRINT_OPTS.threshold = 1000\n            PRINT_OPTS.edgeitems = 2\n            PRINT_OPTS.linewidth = 80\n        elif profile == \"full\":\n            PRINT_OPTS.precision = 4\n            PRINT_OPTS.threshold = inf\n            PRINT_OPTS.edgeitems = 3\n            PRINT_OPTS.linewidth = 80\n\n    if precision is not None:\n        PRINT_OPTS.precision = precision\n    if threshold is not None:\n        PRINT_OPTS.threshold = threshold\n    if edgeitems is not None:\n        PRINT_OPTS.edgeitems = edgeitems\n    if linewidth is not None:\n        PRINT_OPTS.linewidth = linewidth\n    PRINT_OPTS.sci_mode = sci_mode\n\n\ndef get_printoptions() -> Dict[str, Any]:\n    r\"\"\"Gets the current options for printing, as a dictionary that\n    can be passed as ``**kwargs`` to set_printoptions().\n    \"\"\"\n    return dataclasses.asdict(PRINT_OPTS)\n\n\n@contextlib.contextmanager\ndef printoptions(**kwargs):\n    r\"\"\"Context manager that temporarily changes the print options.  Accepted\n    arguments are same as :func:`set_printoptions`.\"\"\"\n    old_kwargs = get_printoptions()\n    set_printoptions(**kwargs)\n    try:\n        yield\n    finally:\n        set_printoptions(**old_kwargs)\n\n\ndef tensor_totype(t):\n    dtype = torch.float if t.is_mps else torch.double\n    return t.to(dtype=dtype)\n\n\nclass _Formatter:\n    def __init__(self, tensor):\n        self.floating_dtype = tensor.dtype.is_floating_point\n        self.int_mode = True\n        self.sci_mode = False\n        self.max_width = 1\n\n        with torch.no_grad():\n            tensor_view = tensor.reshape(-1)\n\n        if not self.floating_dtype:\n            for value in tensor_view:\n                value_str = f\"{value}\"\n                self.max_width = max(self.max_width, len(value_str))\n\n        else:\n            nonzero_finite_vals = torch.masked_select(\n                tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0)\n            )\n\n            if nonzero_finite_vals.numel() == 0:\n                # no valid number, do nothing\n                return\n\n            # Convert to double for easy calculation. HalfTensor overflows with 1e8, and there's no div() on CPU.\n            nonzero_finite_abs = tensor_totype(nonzero_finite_vals.abs())\n            nonzero_finite_min = tensor_totype(nonzero_finite_abs.min())\n            nonzero_finite_max = tensor_totype(nonzero_finite_abs.max())\n\n            for value in nonzero_finite_vals:\n                if value != torch.ceil(value):\n                    self.int_mode = False\n                    break\n\n            if self.int_mode:\n                # in int_mode for floats, all numbers are integers, and we append a decimal to nonfinites\n                # to indicate that the tensor is of floating type. add 1 to the len to account for this.\n                if (\n                    nonzero_finite_max / nonzero_finite_min > 1000.0\n                    or nonzero_finite_max > 1.0e8\n                ):\n                    self.sci_mode = True\n                    for value in nonzero_finite_vals:\n                        value_str = f\"{{:.{PRINT_OPTS.precision}e}}\".format(value)\n                        self.max_width = max(self.max_width, len(value_str))\n                else:\n                    for value in nonzero_finite_vals:\n                        value_str = f\"{value:.0f}\"\n                        self.max_width = max(self.max_width, len(value_str) + 1)\n            else:\n                # Check if scientific representation should be used.\n                if (\n                    nonzero_finite_max / nonzero_finite_min > 1000.0\n                    or nonzero_finite_max > 1.0e8\n                    or nonzero_finite_min < 1.0e-4\n                ):\n                    self.sci_mode = True\n                    for value in nonzero_finite_vals:\n                        value_str = f\"{{:.{PRINT_OPTS.precision}e}}\".format(value)\n                        self.max_width = max(self.max_width, len(value_str))\n                else:\n                    for value in nonzero_finite_vals:\n                        value_str = f\"{{:.{PRINT_OPTS.precision}f}}\".format(value)\n                        self.max_width = max(self.max_width, len(value_str))\n\n        if PRINT_OPTS.sci_mode is not None:\n            self.sci_mode = PRINT_OPTS.sci_mode\n\n    def width(self):\n        return self.max_width\n\n    def format(self, value):\n        if self.floating_dtype:\n            if self.sci_mode:\n                ret = f\"{{:{self.max_width}.{PRINT_OPTS.precision}e}}\".format(value)\n            elif self.int_mode:\n                ret = f\"{value:.0f}\"\n                if not (math.isinf(value) or math.isnan(value)):\n                    ret += \".\"\n            else:\n                ret = f\"{{:.{PRINT_OPTS.precision}f}}\".format(value)\n        else:\n            ret = f\"{value}\"\n        return (self.max_width - len(ret)) * \" \" + ret\n\n\ndef _scalar_str(self, formatter1, formatter2=None):\n    if formatter2 is not None:\n        real_str = _scalar_str(self.real, formatter1)\n        imag_str = (_scalar_str(self.imag, formatter2) + \"j\").lstrip()\n        # handles negative numbers, +0.0, -0.0\n        if imag_str[0] == \"+\" or imag_str[0] == \"-\":\n            return real_str + imag_str\n        else:\n            return real_str + \"+\" + imag_str\n    else:\n        return formatter1.format(self.item())\n\n\ndef _vector_str(self, indent, summarize, formatter1, formatter2=None):\n    # length includes spaces and comma between elements\n    element_length = formatter1.width() + 2\n    if formatter2 is not None:\n        # width for imag_formatter + an extra j for complex\n        element_length += formatter2.width() + 1\n\n    elements_per_line = max(\n        1, int(math.floor((PRINT_OPTS.linewidth - indent) / (element_length)))\n    )\n\n    def _val_formatter(val, formatter1=formatter1, formatter2=formatter2):\n        if formatter2 is not None:\n            real_str = formatter1.format(val.real)\n            imag_str = (formatter2.format(val.imag) + \"j\").lstrip()\n            # handles negative numbers, +0.0, -0.0\n            if imag_str[0] == \"+\" or imag_str[0] == \"-\":\n                return real_str + imag_str\n            else:\n                return real_str + \"+\" + imag_str\n        else:\n            return formatter1.format(val)\n\n    if summarize and not PRINT_OPTS.edgeitems:\n        # Deal with edge case that negative zero is zero\n        data = [\"...\"]\n    elif summarize and self.size(0) > 2 * PRINT_OPTS.edgeitems:\n        data = (\n            [_val_formatter(val) for val in self[: PRINT_OPTS.edgeitems].tolist()]\n            + [\" ...\"]\n            + [_val_formatter(val) for val in self[-PRINT_OPTS.edgeitems :].tolist()]\n        )\n    else:\n        data = [_val_formatter(val) for val in self.tolist()]\n\n    data_lines = [\n        data[i : i + elements_per_line] for i in range(0, len(data), elements_per_line)\n    ]\n    lines = [\", \".join(line) for line in data_lines]\n    return \"[\" + (\",\" + \"\\n\" + \" \" * (indent + 1)).join(lines) + \"]\"\n\n\n# formatter2 is only used for printing complex tensors.\n# For complex tensors, formatter1 and formatter2 are the formatters for tensor.real\n# and tensor.imag respesectively\ndef _tensor_str_with_formatter(self, indent, summarize, formatter1, formatter2=None):\n    dim = self.dim()\n\n    if dim == 0:\n        return _scalar_str(self, formatter1, formatter2)\n\n    if dim == 1:\n        return _vector_str(self, indent, summarize, formatter1, formatter2)\n\n    if summarize and self.size(0) > 2 * PRINT_OPTS.edgeitems:\n        slices = (\n            [\n                _tensor_str_with_formatter(\n                    self[i], indent + 1, summarize, formatter1, formatter2\n                )\n                for i in range(0, PRINT_OPTS.edgeitems)\n            ]\n            + [\"...\"]\n            + [\n                _tensor_str_with_formatter(\n                    self[i], indent + 1, summarize, formatter1, formatter2\n                )\n                for i in range(len(self) - PRINT_OPTS.edgeitems, len(self))\n            ]\n        )\n    else:\n        slices = [\n            _tensor_str_with_formatter(\n                self[i], indent + 1, summarize, formatter1, formatter2\n            )\n            for i in range(0, self.size(0))\n        ]\n\n    tensor_str = (\",\" + \"\\n\" * (dim - 1) + \" \" * (indent + 1)).join(slices)\n    return \"[\" + tensor_str + \"]\"\n\n\ndef _tensor_str(self, indent):\n    if self.numel() == 0:\n        return \"[]\"\n\n    if self.has_names():\n        # There are two main codepaths (possibly more) that tensor printing goes through:\n        # - tensor data can fit comfortably on screen\n        # - tensor data needs to be summarized\n        # Some of the codepaths don't fully support named tensors, so we send in\n        # an unnamed tensor to the formatting code as a workaround.\n        self = self.rename(None)\n\n    summarize = self.numel() > PRINT_OPTS.threshold\n\n    if self._is_zerotensor():\n        self = self.clone()\n\n    # handle the negative bit\n    if self.is_neg():\n        self = self.resolve_neg()\n\n    if self.dtype in [\n        torch.float16,\n        torch.bfloat16,\n        torch.float8_e5m2,\n        torch.float8_e5m2fnuz,\n        torch.float8_e4m3fn,\n        torch.float8_e4m3fnuz,\n    ]:\n        self = self.float()\n\n    if self.dtype is torch.complex32:\n        self = self.cfloat()\n\n    if self.dtype.is_complex:\n        # handle the conjugate bit\n        self = self.resolve_conj()\n        real_formatter = _Formatter(\n            get_summarized_data(self.real) if summarize else self.real\n        )\n        imag_formatter = _Formatter(\n            get_summarized_data(self.imag) if summarize else self.imag\n        )\n        return _tensor_str_with_formatter(\n            self, indent, summarize, real_formatter, imag_formatter\n        )\n    else:\n        formatter = _Formatter(get_summarized_data(self) if summarize else self)\n        return _tensor_str_with_formatter(self, indent, summarize, formatter)\n\n\ndef _add_suffixes(tensor_str, suffixes, indent, force_newline):\n    tensor_strs = [tensor_str]\n    last_line_len = len(tensor_str) - tensor_str.rfind(\"\\n\") + 1\n    for suffix in suffixes:\n        suffix_len = len(suffix)\n        if force_newline or last_line_len + suffix_len + 2 > PRINT_OPTS.linewidth:\n            tensor_strs.append(\",\\n\" + \" \" * indent + suffix)\n            last_line_len = indent + suffix_len\n            force_newline = False\n        else:\n            tensor_strs.append(\", \" + suffix)\n            last_line_len += suffix_len + 2\n    tensor_strs.append(\")\")\n    return \"\".join(tensor_strs)\n\n\ndef get_summarized_data(self):\n    dim = self.dim()\n    if dim == 0:\n        return self\n    if dim == 1:\n        if self.size(0) > 2 * PRINT_OPTS.edgeitems:\n            return torch.cat(\n                (self[: PRINT_OPTS.edgeitems], self[-PRINT_OPTS.edgeitems :])\n            )\n        else:\n            return self\n    if not PRINT_OPTS.edgeitems:\n        return self.new_empty([0] * self.dim())\n    elif self.size(0) > 2 * PRINT_OPTS.edgeitems:\n        start = [self[i] for i in range(0, PRINT_OPTS.edgeitems)]\n        end = [self[i] for i in range(len(self) - PRINT_OPTS.edgeitems, len(self))]\n        return torch.stack([get_summarized_data(x) for x in (start + end)])\n    else:\n        return torch.stack([get_summarized_data(x) for x in self])\n\n\ndef _str_intern(inp, *, tensor_contents=None):\n    if torch._C._functorch.is_functorch_wrapped_tensor(inp):\n        return _functorch_wrapper_str_intern(inp, tensor_contents=tensor_contents)\n    is_plain_tensor = type(inp) is torch.Tensor or type(inp) is torch.nn.Parameter\n    if inp.is_nested:\n        prefix = \"nested_tensor(\"\n    elif is_plain_tensor:\n        prefix = \"tensor(\"\n    else:\n        prefix = f\"{type(inp).__name__}(\"\n    indent = len(prefix)\n    suffixes = []\n    custom_contents_provided = tensor_contents is not None\n    if custom_contents_provided:\n        tensor_str = tensor_contents\n\n    # This is used to extract the primal value and thus disable the forward AD\n    # within this function.\n    # TODO(albanD) This needs to be updated when more than one level is supported\n    self, tangent = torch.autograd.forward_ad.unpack_dual(inp)\n\n    # Note [Print tensor device]:\n    # A general logic here is we only print device when it doesn't match\n    # the device specified in default tensor type.\n    # Currently torch.set_default_tensor_type() only supports CPU/CUDA, thus\n    # torch._C._get_default_device() only returns either cpu or cuda.\n    # In other cases, we don't have a way to set them as default yet,\n    # and we should always print out device for them.\n    if (\n        self.device.type != torch._C._get_default_device()\n        or (\n            self.device.type == \"cuda\"\n            and torch.cuda.current_device() != self.device.index\n        )\n        or (self.device.type == \"mps\")\n    ):\n        suffixes.append(\"device='\" + str(self.device) + \"'\")\n\n    # Tensor printing performs tensor operations like slice, indexing, etc to make it in a\n    # representable format. These operations on ipu/xla/lazy/mtia tensor results in compilations. Hence,\n    # to avoid compilations, copying the tensor to cpu before printing.\n    if self.device.type in [\"xla\", \"lazy\", \"ipu\", \"mtia\"]:\n        self = self.to(\"cpu\")\n\n    # TODO: add an API to map real -> complex dtypes\n    _default_complex_dtype = (\n        torch.cdouble if torch.get_default_dtype() == torch.double else torch.cfloat\n    )\n    has_default_dtype = self.dtype in (\n        torch.get_default_dtype(),\n        _default_complex_dtype,\n        torch.int64,\n        torch.bool,\n    )\n    if self.is_sparse:\n        suffixes.append(\"size=\" + str(tuple(self.shape)))\n        from torch._subclasses.fake_tensor import FakeTensor\n\n        if not self.is_meta and not isinstance(self, FakeTensor):\n            suffixes.append(\"nnz=\" + str(self._nnz()))\n        if not has_default_dtype:\n            suffixes.append(\"dtype=\" + str(self.dtype))\n        if not custom_contents_provided:\n            indices_prefix = \"indices=tensor(\"\n            indices = self._indices().detach()\n            indices_str = _tensor_str(indices, indent + len(indices_prefix))\n            if indices.numel() == 0:\n                indices_str += \", size=\" + str(tuple(indices.shape))\n            values_prefix = \"values=tensor(\"\n            values = self._values().detach()\n            values_str = _tensor_str(values, indent + len(values_prefix))\n            if values.numel() == 0:\n                values_str += \", size=\" + str(tuple(values.shape))\n            tensor_str = (\n                indices_prefix\n                + indices_str\n                + \"),\\n\"\n                + \" \" * indent\n                + values_prefix\n                + values_str\n                + \")\"\n            )\n    elif self.layout in {\n        torch.sparse_csr,\n        torch.sparse_csc,\n        torch.sparse_bsr,\n        torch.sparse_bsc,\n    }:\n        suffixes.append(\"size=\" + str(tuple(self.shape)))\n        suffixes.append(\"nnz=\" + str(self._nnz()))\n        if not has_default_dtype:\n            suffixes.append(\"dtype=\" + str(self.dtype))\n        if not custom_contents_provided:\n            compressed_indices_method, plain_indices_method = {\n                torch.sparse_csr: (torch.Tensor.crow_indices, torch.Tensor.col_indices),\n                torch.sparse_csc: (torch.Tensor.ccol_indices, torch.Tensor.row_indices),\n                torch.sparse_bsr: (torch.Tensor.crow_indices, torch.Tensor.col_indices),\n                torch.sparse_bsc: (torch.Tensor.ccol_indices, torch.Tensor.row_indices),\n            }[self.layout]\n            if self.layout in {torch.sparse_csr, torch.sparse_bsr}:\n                cdimname, pdimname = \"row\", \"column\"\n            else:\n                cdimname, pdimname = \"column\", \"row\"\n            compressed_indices_prefix = f\"c{cdimname[:3]}_indices=tensor(\"\n            compressed_indices = compressed_indices_method(self).detach()\n            compressed_indices_str = _tensor_str(\n                compressed_indices, indent + len(compressed_indices_prefix)\n            )\n            if compressed_indices.numel() == 0:\n                compressed_indices_str += \", size=\" + str(\n                    tuple(compressed_indices.shape)\n                )\n            plain_indices_prefix = f\"{pdimname[:3]}_indices=tensor(\"\n            plain_indices = plain_indices_method(self).detach()\n            plain_indices_str = _tensor_str(\n                plain_indices, indent + len(plain_indices_prefix)\n            )\n            if plain_indices.numel() == 0:\n                plain_indices_str += \", size=\" + str(tuple(plain_indices.shape))\n            values_prefix = \"values=tensor(\"\n            values = self.values().detach()\n            values_str = _tensor_str(values, indent + len(values_prefix))\n            if values.numel() == 0:\n                values_str += \", size=\" + str(tuple(values.shape))\n            tensor_str = (\n                compressed_indices_prefix\n                + compressed_indices_str\n                + \"),\\n\"\n                + \" \" * indent\n                + plain_indices_prefix\n                + plain_indices_str\n                + \"),\\n\"\n                + \" \" * indent\n                + values_prefix\n                + values_str\n                + \")\"\n            )\n    elif self.is_quantized:\n        suffixes.append(\"size=\" + str(tuple(self.shape)))\n        if not has_default_dtype:\n            suffixes.append(\"dtype=\" + str(self.dtype))\n        suffixes.append(\"quantization_scheme=\" + str(self.qscheme()))\n        if (\n            self.qscheme() == torch.per_tensor_affine\n            or self.qscheme() == torch.per_tensor_symmetric\n        ):\n            suffixes.append(\"scale=\" + str(self.q_scale()))\n            suffixes.append(\"zero_point=\" + str(self.q_zero_point()))\n        elif (\n            self.qscheme() == torch.per_channel_affine\n            or self.qscheme() == torch.per_channel_symmetric\n            or self.qscheme() == torch.per_channel_affine_float_qparams\n        ):\n            suffixes.append(\"scale=\" + str(self.q_per_channel_scales()))\n            suffixes.append(\"zero_point=\" + str(self.q_per_channel_zero_points()))\n            suffixes.append(\"axis=\" + str(self.q_per_channel_axis()))\n        if not custom_contents_provided:\n            tensor_str = _tensor_str(self.dequantize(), indent)\n    elif self.is_nested:\n        if not custom_contents_provided:\n\n            def indented_str(s, indent):\n                return \"\\n\".join(f\"  {line}\" for line in s.split(\"\\n\"))\n\n            strs = \",\\n\".join(\n                indented_str(str(t), indent + 1)\n                for t in torch.ops.aten.unbind.int(self, 0)\n            )\n            tensor_str = f\"[\\n{strs}\\n]\"\n    elif torch._is_functional_tensor(self):\n        prefix = \"_to_functional_tensor(\"\n        tensor_str = repr(torch._from_functional_tensor(self))\n    else:\n        # Circular import problem, so we import it here\n        from torch._subclasses.fake_tensor import FakeTensor\n\n        if self.is_meta or isinstance(self, FakeTensor):\n            suffixes.append(\"size=\" + str(tuple(self.shape)))\n            if self.dtype != torch.get_default_dtype():\n                suffixes.append(\"dtype=\" + str(self.dtype))\n            # TODO: This implies that ellipses is valid syntax for allocating\n            # a meta tensor or FakeTensor, which it could be, but it isn't right now\n            if not custom_contents_provided:\n                tensor_str = \"...\"\n        else:\n            if self.numel() == 0 and not self.is_sparse:\n                # Explicitly print the shape if it is not (0,), to match NumPy behavior\n                if self.dim() != 1:\n                    suffixes.append(\"size=\" + str(tuple(self.shape)))\n\n                # In an empty tensor, there are no elements to infer if the dtype\n                # should be int64, so it must be shown explicitly.\n                if self.dtype != torch.get_default_dtype():\n                    suffixes.append(\"dtype=\" + str(self.dtype))\n                if not custom_contents_provided:\n                    tensor_str = \"[]\"\n            else:\n                if not PRINT_OPTS.edgeitems:\n                    suffixes.append(\"size=\" + str(tuple(self.shape)))\n\n                if not has_default_dtype:\n                    suffixes.append(\"dtype=\" + str(self.dtype))\n\n                if not custom_contents_provided:\n                    if self.layout != torch.strided:\n                        tensor_str = _tensor_str(self.to_dense(), indent)\n                    else:\n                        tensor_str = _tensor_str(self, indent)\n\n    if self.layout != torch.strided:\n        suffixes.append(\"layout=\" + str(self.layout))\n\n    # Use inp here to get the original grad_fn and not the one generated by the forward grad\n    # unpacking.\n    grad_fn_name = None\n    try:\n        grad_fn = inp.grad_fn\n    except RuntimeError:\n        # Accessing the grad_fn calls rebasing logic which would cause an error\n        # if that tensor is a view created in no-grad mode modified in-place in\n        # no-grad mode. See: https://github.com/pytorch/pytorch/issues/99968\n        grad_fn_name = \"Invalid\"\n\n    if grad_fn_name is None and grad_fn is not None:\n        grad_fn_name = type(grad_fn).__name__\n        if grad_fn_name == \"CppFunction\":\n            grad_fn_name = grad_fn.name().rsplit(\"::\", 1)[-1]\n\n    if grad_fn_name is not None:\n        suffixes.append(f\"grad_fn=<{grad_fn_name}>\")\n    elif inp.requires_grad:\n        suffixes.append(\"requires_grad=True\")\n\n    if self.has_names():\n        suffixes.append(f\"names={self.names}\")\n\n    if tangent is not None:\n        suffixes.append(f\"tangent={tangent}\")\n\n    string_repr = _add_suffixes(\n        prefix + tensor_str, suffixes, indent, force_newline=self.is_sparse\n    )\n\n    # Check if this instance is flagged as a parameter and change the repr accordingly.\n    # Unfortunately, this function has to be aware of this detail.\n    # NB: This is currently skipped for plain tensor parameters to maintain BC. In the future,\n    # this should be done for those as well to produce a valid repr.\n    if isinstance(self, torch.nn.Parameter) and not is_plain_tensor:\n        string_repr = f\"Parameter({string_repr})\"\n\n    return string_repr\n\n\ndef _functorch_wrapper_str_intern(tensor, *, tensor_contents=None):\n    level = torch._C._functorch.maybe_get_level(tensor)\n    assert level != -1\n\n    if torch._C._functorch.is_functionaltensor(tensor):\n        # Since we're unwrapping the FunctionalTensorWrapper, we need to make sure\n        # that it's up to date first\n        torch._sync(tensor)\n\n    value = torch._C._functorch.get_unwrapped(tensor)\n    value_repr = repr(value)\n\n    indented_value_repr = textwrap.indent(value_repr, \" \" * 4)\n    if torch._C._functorch.is_batchedtensor(tensor):\n        bdim = torch._C._functorch.maybe_get_bdim(tensor)\n        assert bdim != -1\n        return (\n            f\"BatchedTensor(lvl={level}, bdim={bdim}, value=\\n\"\n            f\"{indented_value_repr}\\n\"\n            f\")\"\n        )\n    if torch._C._functorch.is_gradtrackingtensor(tensor):\n        return (\n            f\"GradTrackingTensor(lvl={level}, value=\\n\" f\"{indented_value_repr}\\n\" f\")\"\n        )\n    if torch._C._functorch.is_functionaltensor(tensor):\n        return f\"FunctionalTensor(lvl={level}, value=\\\\\\n{value_repr})\"\n\n    raise ValueError(\"We don't know how to print this, please file us an issue\")\n\n\ndef _str(self, *, tensor_contents=None):\n    with torch.no_grad(), torch.utils._python_dispatch._disable_current_modes():\n        guard = torch._C._DisableFuncTorch()\n        return _str_intern(self, tensor_contents=tensor_contents)\n",677],"C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\nn\\parameter.py":["import torch\nfrom torch._C import _disabled_torch_function_impl\nfrom collections import OrderedDict\n\n# Metaclass to combine _TensorMeta and the instance check override for Parameter.\nclass _ParameterMeta(torch._C._TensorMeta):\n    # Make `isinstance(t, Parameter)` return True for custom tensor instances that have the _is_param flag.\n    def __instancecheck__(self, instance):\n        return super().__instancecheck__(instance) or (\n            isinstance(instance, torch.Tensor) and getattr(instance, '_is_param', False))\n\n\nclass Parameter(torch.Tensor, metaclass=_ParameterMeta):\n    r\"\"\"A kind of Tensor that is to be considered a module parameter.\n\n    Parameters are :class:`~torch.Tensor` subclasses, that have a\n    very special property when used with :class:`Module` s - when they're\n    assigned as Module attributes they are automatically added to the list of\n    its parameters, and will appear e.g. in :meth:`~Module.parameters` iterator.\n    Assigning a Tensor doesn't have such effect. This is because one might\n    want to cache some temporary state, like last hidden state of the RNN, in\n    the model. If there was no such class as :class:`Parameter`, these\n    temporaries would get registered too.\n\n    Args:\n        data (Tensor): parameter tensor.\n        requires_grad (bool, optional): if the parameter requires gradient. Note that\n            the torch.no_grad() context does NOT affect the default behavior of\n            Parameter creation--the Parameter will still have `requires_grad=True` in\n            :class:`~no_grad` mode. See :ref:`locally-disable-grad-doc` for more\n            details. Default: `True`\n    \"\"\"\n\n    def __new__(cls, data=None, requires_grad=True):\n        if data is None:\n            data = torch.empty(0)\n        if type(data) is torch.Tensor or type(data) is Parameter:\n            # For ease of BC maintenance, keep this path for standard Tensor.\n            # Eventually (tm), we should change the behavior for standard Tensor to match.\n            return torch.Tensor._make_subclass(cls, data, requires_grad)\n\n        # Path for custom tensors: set a flag on the instance to indicate parameter-ness.\n        t = data.detach().requires_grad_(requires_grad)\n        if type(t) is not type(data):\n            raise RuntimeError(f\"Creating a Parameter from an instance of type {type(data).__name__} \"\n                               \"requires that detach() returns an instance of the same type, but return \"\n                               f\"type {type(t).__name__} was found instead. To use the type as a \"\n                               \"Parameter, please correct the detach() semantics defined by \"\n                               \"its __torch_dispatch__() implementation.\")\n        t._is_param = True\n        return t\n\n    # Note: the 3 methods below only apply to standard Tensor. Parameters of custom tensor types\n    # are still considered that custom tensor type and these methods will not be called for them.\n    def __deepcopy__(self, memo):\n        if id(self) in memo:\n            return memo[id(self)]\n        else:\n            result = type(self)(self.data.clone(memory_format=torch.preserve_format), self.requires_grad)\n            memo[id(self)] = result\n            return result\n\n    def __repr__(self):\n        return 'Parameter containing:\\n' + super().__repr__()\n\n    def __reduce_ex__(self, proto):\n        state = torch._utils._get_obj_state(self)\n\n        # See Note [Don't serialize hooks]\n        hooks = OrderedDict()\n        if not state:\n            return (\n                torch._utils._rebuild_parameter,\n                (self.data, self.requires_grad, hooks)\n            )\n\n        return (\n            torch._utils._rebuild_parameter_with_state,\n            (self.data, self.requires_grad, hooks, state)\n        )\n\n    __torch_function__ = _disabled_torch_function_impl\n\n\nclass UninitializedTensorMixin:\n    _allowed_methods = [\n        torch.Tensor.__hash__,\n        torch.Tensor.size,\n        torch.Tensor.copy_,\n        torch.Tensor.is_floating_point,\n        torch.Tensor.half,\n        torch.Tensor.float,\n        torch.Tensor.double,\n        torch.Tensor.char,\n        torch.Tensor.short,\n        torch.Tensor.int,\n        torch.Tensor.long,\n        torch.Tensor.cuda,\n        torch.Tensor.cpu,\n        torch.Tensor.to,\n        torch.Tensor.get_device,\n        torch._has_compatible_shallow_copy_type,\n    ]\n\n    def materialize(self, shape, device=None, dtype=None):\n        r\"\"\"Create a Parameter or Tensor with the same properties of the uninitialized one.\n\n        Given a shape, it materializes a parameter in the same device\n        and with the same `dtype` as the current one or the specified ones in the\n        arguments.\n\n        Args:\n            shape : (tuple): the shape for the materialized tensor.\n            device (:class:`torch.device`): the desired device of the parameters\n                and buffers in this module. Optional.\n            dtype (:class:`torch.dtype`): the desired floating point type of\n                the floating point parameters and buffers in this module. Optional.\n        \"\"\"\n        if device is None:\n            device = self.data.device\n        if dtype is None:\n            dtype = self.data.dtype\n        self.data = torch.empty(shape, device=device, dtype=dtype)\n        self.__class__ = self.cls_to_become\n\n    @property\n    def shape(self):\n        raise RuntimeError(\n            'Can\\'t access the shape of an uninitialized parameter or buffer. '\n            'This error usually happens in `load_state_dict` when trying to load '\n            'an uninitialized parameter into an initialized one. '\n            'Call `forward` to initialize the parameters before accessing their attributes.')\n\n    def share_memory_(self):\n        raise RuntimeError(\n            'Can\\'t share memory on an uninitialized parameter or buffer. '\n            'Call `forward` to initialize the parameters before calling '\n            '`module.share_memory()`.')\n\n    def __repr__(self):\n        return f'<{self.__class__.__name__}>'\n\n    def __reduce_ex__(self, proto):\n        # See Note [Don't serialize hooks]\n        return (\n            self.__class__,\n            (self.requires_grad,)\n        )\n\n    @classmethod\n    def __torch_function__(cls, func, types, args=(), kwargs=None):\n        # method-wrapper is to detect access to Tensor properties that are\n        # wrapped in descriptors\n        if func in cls._allowed_methods or func.__class__.__name__ == 'method-wrapper':\n            if kwargs is None:\n                kwargs = {}\n            return super().__torch_function__(func, types, args, kwargs)\n        raise ValueError(\n            f'Attempted to use an uninitialized parameter in {func}. '\n            'This error happens when you are using a `LazyModule` or '\n            f'explicitly manipulating `torch.nn.parameter.{cls.__name__}` '\n            'objects. When using LazyModules Call `forward` with a dummy batch '\n            'to initialize the parameters before calling torch functions')\n\n\ndef is_lazy(param):\n    return isinstance(param, UninitializedTensorMixin)\n\n\nclass UninitializedParameter(UninitializedTensorMixin, Parameter):\n    r\"\"\"A parameter that is not initialized.\n\n    Uninitialized Parameters are a a special case of :class:`torch.nn.Parameter`\n    where the shape of the data is still unknown.\n\n    Unlike a :class:`torch.nn.Parameter`, uninitialized parameters\n    hold no data and attempting to access some properties, like their shape,\n    will throw a runtime error. The only operations that can be performed on a uninitialized\n    parameter are changing its datatype, moving it to a different device and\n    converting it to a regular :class:`torch.nn.Parameter`.\n\n    The default device or dtype to use when the parameter is materialized can be set\n    during construction using e.g. ``device='cuda'``.\n    \"\"\"\n\n    cls_to_become = Parameter\n\n    def __new__(cls, requires_grad=True, device=None, dtype=None) -> None:\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        data = torch.empty(0, **factory_kwargs)\n        return torch.Tensor._make_subclass(cls, data, requires_grad)\n\n    def __deepcopy__(self, memo):\n        if id(self) in memo:\n            return memo[id(self)]\n        else:\n            result = type(self)(self.requires_grad, self.data.device, self.data.dtype)\n            memo[id(self)] = result\n            return result\n\nclass UninitializedBuffer(UninitializedTensorMixin, torch.Tensor):\n    r\"\"\"A buffer that is not initialized.\n\n    Uninitialized Buffer is a a special case of :class:`torch.Tensor`\n    where the shape of the data is still unknown.\n\n    Unlike a :class:`torch.Tensor`, uninitialized parameters\n    hold no data and attempting to access some properties, like their shape,\n    will throw a runtime error. The only operations that can be performed on a uninitialized\n    parameter are changing its datatype, moving it to a different device and\n    converting it to a regular :class:`torch.Tensor`.\n\n    The default device or dtype to use when the buffer is materialized can be set\n    during construction using e.g. ``device='cuda'``.\n    \"\"\"\n\n    cls_to_become = torch.Tensor\n\n    def __new__(cls, requires_grad=False, device=None, dtype=None) -> None:\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        data = torch.empty(0, **factory_kwargs)\n        return torch.Tensor._make_subclass(cls, data, requires_grad)\n",222]},"functions":{"__hash_new (C:\\Users\\adam\\miniconda3\\Lib\\hashlib.py:152)":["C:\\Users\\adam\\miniconda3\\Lib\\hashlib.py",152],"file_hash (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py:27)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py",27],"_has_hash (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py:65)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py",65],"_fetch (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py:166)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py",166],"__init__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:104)":["C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py",104],"helper (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:287)":["C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py",287],"is_url (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\util.py:14)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\util.py",14],"file_or_url_context (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\util.py:20)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\util.py",20],"__enter__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:132)":["C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py",132],"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1091)":["C:\\Users\\adam\\miniconda3\\Lib\\enum.py",1091],"__call__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:686)":["C:\\Users\\adam\\miniconda3\\Lib\\enum.py",686],"_missing_ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:118)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",118],"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:444)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",444],"value (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:1249)":["C:\\Users\\adam\\miniconda3\\Lib\\enum.py",1249],"__get__ (C:\\Users\\adam\\miniconda3\\Lib\\enum.py:193)":["C:\\Users\\adam\\miniconda3\\Lib\\enum.py",193],"io_mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:138)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",138],"_parse_uri (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:280)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",280],"splitroot (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:147)":["C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py",147],"parse_parts (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:56)":["C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py",56],"_parse_args (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:484)":["C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py",484],"_from_parts (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:504)":["C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py",504],"__new__ (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:868)":["C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py",868],"name (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:622)":["C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py",622],"suffix (C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py:630)":["C:\\Users\\adam\\miniconda3\\Lib\\pathlib.py",630],"format_hint (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:438)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",438],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:216)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",216],"format_hint (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:434)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",434],"extension (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:426)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",426],"import_module (C:\\Users\\adam\\miniconda3\\Lib\\importlib\\__init__.py:108)":["C:\\Users\\adam\\miniconda3\\Lib\\importlib\\__init__.py",108],"plugin_class (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\config\\plugins.py:89)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\config\\plugins.py",89],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py:96)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py",96],"<lambda> (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:96)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py",96],"find_spec (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:89)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\_distutils_hack\\__init__.py",89],"find_spec (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\six.py:194)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\six.py",194],"filename (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:414)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",414],"get_file (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:461)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",461],"is_path (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:10)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py",10],"preinit (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:302)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",302],"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\GifImagePlugin.py:63)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\GifImagePlugin.py",63],"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\BmpImagePlugin.py:51)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\BmpImagePlugin.py",51],"i32le (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:60)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py",60],"_dib_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\BmpImagePlugin.py:55)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\BmpImagePlugin.py",55],"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\JpegImagePlugin.py:347)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\JpegImagePlugin.py",347],"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PpmImagePlugin.py:45)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PpmImagePlugin.py",45],"_accept (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:692)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",692],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:486)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",486],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:152)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",152],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:347)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",347],"i32be (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py:84)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_binary.py",84],"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:156)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",156],"isEnabledFor (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1734)":["C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py",1734],"debug (C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py:1467)":["C:\\Users\\adam\\miniconda3\\Lib\\logging\\__init__.py",1467],"_safe_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:572)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py",572],"chunk_IHDR (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:412)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",412],"call (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:188)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",188],"_crc32 (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:143)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",143],"crc (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:194)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",194],"_safe_zlib_decompress (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:134)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",134],"chunk_iCCP (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:385)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",385],"chunk_pHYs (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:507)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",507],"check_text_memory (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:364)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",364],"chunk_tEXt (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:524)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",524],"chunk_IDAT (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:432)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",432],"_open (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:704)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",704],"mode (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:510)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",510],"size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:506)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",506],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:108)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py",108],"_decompression_bomb_check (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3172)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",3172],"_open_core (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3262)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",3262],"open (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3193)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",3193],"__enter__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:530)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",530],"__exit__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:541)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",541],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:71)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py",71],"imopen (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\imopen.py:15)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\imopen.py",15],"__enter__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py:363)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py",363],"tell (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:912)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",912],"_seek_check (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:334)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py",334],"seek (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:803)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",803],"load (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:820)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",820],"load_prepare (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:314)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py",314],"load_prepare (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:915)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",915],"_tilesort (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:88)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py",88],"<lambda> (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:254)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py",254],"<listcomp> (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:251)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py",251],"_getdecoder (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:377)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",377],"load_read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:924)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",924],"close (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:182)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",182],"load_end (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:957)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",957],"load (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py:175)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\ImageFile.py",175],"width (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:498)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",498],"height (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:502)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",502],"_getencoder (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:400)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",400],"tobytes (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:711)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",711],"_conv_type_shape (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:229)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",229],"__array_interface__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:671)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",671],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3665)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",3665],"__contains__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3926)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",3926],"getexif (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:1419)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",1419],"getexif (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:1015)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py",1015],"__len__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3914)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",3914],"metadata (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:492)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py",492],"_apply_transforms (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:301)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py",301],"read (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:151)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py",151],"_flush_writer (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:475)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py",475],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:20)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py",20],"_close_fp (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:533)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",533],"close (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:547)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",547],"finish (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py:540)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\request.py",540],"close (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py:143)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\plugins\\pillow.py",143],"__exit__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py:366)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py",366],"imread (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\v3.py:6)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\v3.py",6],"__getattr__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py:23)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\_util.py",23],"__del__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py:369)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\imageio\\core\\v3_plugin_api.py",369],"imread (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:9)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py",9],"call_plugin (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\manage_plugins.py:170)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\manage_plugins.py",170],"__exit__ (C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py:141)":["C:\\Users\\adam\\miniconda3\\Lib\\contextlib.py",141],"imread (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\_io.py:16)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\io\\_io.py",16],"_load (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py:316)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py",316],"astronaut (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py:380)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\skimage\\data\\_fetchers.py",380],"_average_dispatcher (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:393)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py",393],"_count_reduce_items (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py:67)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py",67],"_no_nep50_warning (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_ufunc_config.py:452)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_ufunc_config.py",452],"_mean (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py:101)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\core\\_methods.py",101],"average (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:398)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py",398],"parent_header (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:505)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py",505],"_is_master_process (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:550)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py",550],"utcoffset (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\dateutil\\tz\\tz.py:74)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\dateutil\\tz\\tz.py",74],"is_set (C:\\Users\\adam\\miniconda3\\Lib\\threading.py:568)":["C:\\Users\\adam\\miniconda3\\Lib\\threading.py",568],"_wait_for_tstate_lock (C:\\Users\\adam\\miniconda3\\Lib\\threading.py:1118)":["C:\\Users\\adam\\miniconda3\\Lib\\threading.py",1118],"is_alive (C:\\Users\\adam\\miniconda3\\Lib\\threading.py:1185)":["C:\\Users\\adam\\miniconda3\\Lib\\threading.py",1185],"_event_pipe (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:138)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py",138],"send (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\zmq\\sugar\\socket.py:621)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\zmq\\sugar\\socket.py",621],"schedule (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:259)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py",259],"_schedule_flush (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:577)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py",577],"write (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py:655)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\ipykernel\\iostream.py",655],"__new__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:149)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py",149],"is_scripting (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_jit_internal.py:1120)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_jit_internal.py",1120],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:74)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py",74],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:183)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py",183],"__enter__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:79)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py",79],"<listcomp> (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:123)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py",123],"_disable_current_modes (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:120)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py",120],"unpack_dual (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\forward_ad.py:139)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\forward_ad.py",139],"__exit__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py:83)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\autograd\\grad_mode.py",83],"__iter__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py:1012)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py",1012],"__format__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py:961)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py",961],"__init__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:122)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py",122],"format (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:192)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py",192],"_scalar_str (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:207)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py",207],"_tensor_str_with_formatter (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:265)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py",265],"_tensor_str (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:302)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py",302],"_add_suffixes (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:353)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py",353],"__instancecheck__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\nn\\parameter.py:8)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\nn\\parameter.py",8],"_str_intern (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:390)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py",390],"_str (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py:674)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor_str.py",674],"__repr__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py:455)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py",455],"__array__ (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py:1058)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\torch\\_tensor.py",1058],"_check_size (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:2884)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",2884],"_new (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:514)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",514],"new (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:2905)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",2905],"frombuffer (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:2983)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",2983],"fromarray (C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py:3040)":["C:\\workspace\\projects\\talk\\venv\\Lib\\site-packages\\PIL\\Image.py",3040]}}}